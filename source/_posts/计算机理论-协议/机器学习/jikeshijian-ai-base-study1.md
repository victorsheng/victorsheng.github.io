---
title: 极客时间-学习笔记-人工智能基础课1
author: Victor
tags:
  - 极客时间
categories:
  - 人工智能
abbrlink: 1318937602
date: 2017-12-19 19:03:00
---
# 最优化方法

# 百度
https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95
# 知乎
## 抽象概念
```
	在一定的约束条件下，求一个函数的最大（小）值。
	要理解的其实只有两个概念，函数和约束条件。甚至函数这个概念已经包含了对约束条件的考虑。所谓函数，简单理解的话，可以当做一个机器，你给它一个输入，它就给你一个输出，它是一个对应。你通过调节输入，达到最好的输出。它是现实状况的数学语言表达。例如我们要最小化总费用，我们知道单价，我们可以决定数量，于是我们得到的数学表达：总费用=单价乘以数量。我们通过调整数量来最小的总费用。至于约束条件，它有很多种，例如等式的约束，不等式的约束，微分方程的约束，概率的约束，等等等等。他们也是对我们现实状况中的约束的数学表达。不同的约束配上不同的目标函数就会得到一个不同的问题。例如目标函数和约束都是线性的，这个最优化问题就叫线性规划，如果约束是个常微分方程，就叫最优控制。等等等等。

作者：滴水
链接：https://www.zhihu.com/question/26341871/answer/41242951
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```

## 蛮形象的解释
https://www.zhihu.com/question/26341871
```
	之所以要使用计算机，是因为数据量太大，远远超过人脑的处理能力。比如我们需要从一堆人脸图片里给每个人标上正确的名字，一幅32像素见方的人脸图像有1024颗像素点，你能想象出一百万张这样的照片和1万个人名字之间的关系是什么样吗。再比如给你1万个患者的DNA序列，每个患者的序列由百万级的碱基对构成，你能找到这些天文数字量级的序列和是否患某种疾病之间的联系吗？
	答案是不能！所以研究者退而求其次，建立很多学习模型，这些模型输入是一个样本的数据（头像图片、一个人的DNA序列），输出是样本的标签（人名、是否患病）。模型里有大量可以调整的参数，这些参数通过训练，能够学习到数据和标签之间人类无法直接理解的、复杂的关系。科学家期望当模型训练完成后，再拿来一个样本，喂给这个训练好的机器，它能够吐出一个标签，这个标签恰好就是样本对应的那个正确的标签。
	目前人们已经研究出一大堆学习模型：神经网络、支持向量机、AdaBoost、随机森林、隐马尔科夫链、卷积神经网络等等。它们的结构差异很大，但是共同点都是拥有一大堆参数，就等着你喂给它数据供它学习。这些模型的学习也需要一个目标函数：让模型的分类错误率尽量小。为了达到目的，模型的训练往往首先给参数赋上随机初值，然后用各种下降法来寻找能让分类错误率更小的参数设置，梯度下降、牛顿法、共轭梯度法和Levenberg—Marquard法都是常见的方法。
    随着研究的深入，问题也越来越多，比如下降法往往只能保证找到目标函数的局部最小值，找不到全局最小值，怎么办呢？答案是不一味下降、也适当爬爬山，说不定能跳出小水沟（局部极小值）找到真正的深井（全局极小值），这种算法叫模拟退火。也可以增大搜索范围，让一群蚂蚁（蚁群算法）或者鸟儿（粒子群算法）一齐搜索，或者让参数巧妙地随机改变（遗传算法）。
    那么多模型，到底该选哪个？研究者又发现了一个定理“天下没有免费的午餐”定理，意思是没有一个模型能一直比其他模型好，对于不同类型的数据，必须要通过实验才能发现哪种学习模型更适合。机器学习领域也就成了学界灌水严重的领域之一——换模型、调参数就能发文章哎。
    下面说到了调参数，问题又来了，到底是参数多了好还是少了好？参数少了模型太笨学不到数据内的复杂关系，参数多了模型太精明又可能会把数据中的随机噪声当作某种关系进行认真学习（过拟合）。最后大家一致认为，确定模型的复杂度时，要保证模型能力足够强，能够学会数据之间的关系，能力又不能太强，以至于耍小聪明乱学习。这种选择模型的思想被称为奥卡姆剃刀：选择有能力的模型中最简单的那个。此外，训练模型的目标并不是为了使训练样本能够被尽量正确分类，更需要对未知新样本有好的分类效果，这样模型才有实用价值，这种能力被称为泛化能力。除了奥卡姆剃刀原理外，训练时引入随机性的模型比确定的模型（比如BP神经网络）具有更好的泛化能力。
    模型的更新也是问题。如果引入了新数据，全部模型都需要重新训练是一笔很大的开销，在线学习模型采用来一个样本学一点的模式，能够不断自我更新；半监督学习利用少量带标签的样本训练一个原始模型，然后利用大量无标签数据再学习。
```

## 举例
```
比如想从广州去杭州，怎样最快又最经济（目标函数）？你有很多种方法，可以坐火车，飞机，汽车(很多种解，而且可以对这些解进行组合)，但总是有个组合最让你满意（最优解），最符合你的期望。怎么去求解这个最优解，由此产生的一系列方法。
```
# 博客
http://www.cnblogs.com/maybe2030/p/4751804.html