title: study-cap
author: Victor
date: 2018-03-23 23:09:04
tags:
categories:
---
CAP（Consistency一致性、Availability可用性、Partition-tolerance分区可容忍性）理论普遍被看成是大数据技术的理论基础。同时，凭据该理论，业界有一种极度流行、极度“专业”的认识，那就是：关系型数据库设计选择了C（一致性）与A（可用性），NoSQL数据库设计则差别。其中，HBase选择了C（一致性）与P（分区可容忍性），Cassandra选择了A（可用性）与P（分区可容忍性）。

- Consistency一致性：你的客户再次来电时总能查到他们刚来电更新的信息，不论相隔多短
- Availability可用性：不论你和你妻子谁来工作，记忆公司总能接听来电，处理客户请求
- Partition-tolerance分区可容忍性：即便你和你妻子失联，记忆公司依然能正常运转


|Feature | Consul | zookeeper | etcd | euerka |
| :--- | :--- | :--- | :--- | :--- |
| 服务健康检查 | 服务状态，内存，硬盘等 | \(弱\)长连接，keepalive | 连接心跳 | 可配支持 |
| 多数据中心 | 支持 | — | — | — |
| kv存储服务 | 支持 | 支持 | 支持 | — |
| 一致性 | raft | paxos | raft | — |
| cap | ca | cp | cp | ap |
| 使用接口\(多语言能力\) | 支持http和dns | 客户端 | http/grpc | http（sidecar） |
| watch支持 | 全量/支持long polling | 支持 | 支持 long polling | 支持 long polling/大部分增量 |
| 自身监控 | metrics | — | metrics | metrics |
| 安全 | acl /https | acl | https支持（弱） | — |
| spring cloud集成 | 已支持 | 已支持 | 已支持 | 已支持 |


|特性| HBase | Cassandra |
| :--- | :--- | :--- |
| 语言 | Java | Java |
| 出发点 | BigTable | BigTable and Dynamo |
| License | Apache | Apache |
| Protocol | HTTP/REST \(also Thrift\) | Custom, binary \(Thrift\) |
| 数据分布 | 表划分为多个region存在不同region server上 | 改进的一致性哈希（虚拟节点） |
| 存储目标 | 大文件 | 小文件 |
| 一致性 | 强一致性 | 最终一致性，Quorum NRW策略 |
| 架构 | master/slave | p2p |
| 高可用性 | NameNode是HDFS的单点故障点 | P2P和去中心化设计，不会出现单点故障 |
| 伸缩性 | Region Server扩容，通过将自身发布到Master，Master均匀分布Region | 扩容需在Hash Ring上多个节点间调整数据分布 |
| 读写性能 | 数据读写定位可能要通过最多6次的网络RPC，性能较低。 | 数据读写定位非常快 |
| 数据冲突处理 | 乐观并发控制（optimistic concurrency control） | 向量时钟 |
| 临时故障处理 | Region Server宕机，重做HLog | 数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。 |
| 永久故障恢复 | Region Server恢复，master重新给其分配region | Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性 |
| 成员通信及错误检测 | Zookeeper | 基于Gossip |
| CAP | 1，强一致性，0数据丢失。2，可用性低。3，扩容方便。 | 1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。 |


- cap

有这样两种情况：一种情况是要求节点A、B、C的三份数据完全一致后返回。也就是说，这时从任何一个网络节点读取的数据都是一样的，这就是所谓的强一致性读。很明显，这时数据读取的Latency要高一些（由于要等数据在网络中的复制），同时A、B、C三个节点中任何一个宕机，都会导致数据不行用。也就是说，要保证强一致性，网络中的副本越多，数据的可用性就越差；

另一种情况是，允许读操作立刻返回，容忍B节点的读取与A节点的读取不一致的情况发生。这样一来，可用性显然获得了提高，网络中的副本也可以多一些，唯一得不到保证的是数据一致性。当然，对写操作同样也有多个节点一致性的情况，在此不再赘述。

- cap

分布式系统分区容忍肯定是要保证的，因为总会有网络延迟，网络波动导致每个节点互相有短暂或长时间的通讯不通。所以我们在这个基础上，如果我们解决了一致性问题，也就是我们在网络波动和延迟的时候也让每个节点的数据是一样的，保证同时从任意节点取到的数据是一样的。

那么我们就得舍弃可用性，也就是说我们在网络波动或者延迟的时候让整个分布式系统不可用，等到数据都同步完了，每个节点的数据都一样了，这时候我们在让分布式系统可用。这就是舍弃了可用性。

那什么是舍弃一致性呢？就是在有网络延迟的时候，我整个的分布式系统还对外提供服务，这时就有可能短暂的出现获取的数据不是一致的。这就是舍弃了一致性。所以一般来说我们都是保证可用性，虽然有短暂的数据不一致，但我们只要最终保证了一致性在有些时候也是可以满足需要的。

# 解读
http://kongchen.github.io/how-cap-defines-avaiability/
C容易理解，所有节点上的数据都一样。
P是说一旦集群因为内部通信故障发生分裂，集群还能正常运转。

关键是这个A。

说白了就是，CAP里的A指的是，只要是活着的节点能返回响应，那么就认为它是availability的。

用汽车来做个比喻：
汽车一切良好，故障灯一个都不亮，能开能刹，这是我们理解的传统的Available。只要是出了任何问题，例如车胎爆了，发动机坏了，或者是没油开不动了，这都已经是不可用了。

CAP理论里，车不能开不要紧，只要是这车车门还能打开，那就是Available的：车胎破了能从胎压监测里看到，发动机坏了打火打不着，没油了油表灯会亮……这都是车返回的response，只要是有response，那么就是”可用的“。

理解了A的真正含义以后再来看CAP。

## 只满足CA的系统
根据P的定义： 一旦集群因为内部通信故障发生分裂，集群还能正常运转。 舍弃P意味着一旦集群发生分裂，整个集群都将无法运转。这是符合A的，因为这是的节点是fail的，不需要给任何响应。
单机服务器显然是CA的，只要结点活着，那自然是C+A。而结点一旦挂了，整个集群也就没了，符合舍弃P的选择。

## 只满足CP的系统
一旦集群内部因为内部通信故障发生分裂（假设分裂成两部分），为了满足P，集群需要提供服务。而为了满足C，只能保留其中一部分提供服务，让另一部分整体退役。

## 只满足AP的系统
整个最容易理解，一旦集群内部因为内部通信故障发生分裂（假设分裂成两部分），为了满足P，而又不需要满足C，那么可以让分裂出来的两部分都提供服务，因为暂时数据不一致没关系。



