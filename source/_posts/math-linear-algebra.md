title: 线性代数学习
tags:
  - 数学
  - 线性代数
  - 机器学习
categories:
  - 机器学习
date: 2017-11-24 21:59:00
---
# 推荐一(博客)
http://www.hahack.com/wiki/math-linear-algebra.html

- 矩阵
    + 基本运算
        * 加
        * 减
        * 乘
        * 求逆
    + 矩阵的转职
    + 应用举例
        * 求解方程组
        * 求向量组合
- 向量
    + 基本运算
        * 加
        * 减
        * 乘
            - 标量乘向量
            - 向量点积
            - 向量外积
            - 矩阵向量积
    + 向量的转置
    + 线性无关
        * 张成空间
        * 线性相关和线性无关
        * 判断是否线性相关
- 张量
- 线性代数进阶
    + 阶梯形矩阵
        * 阶梯形矩阵
        * 行简化阶梯形矩阵
        * 行最简形矩阵
        * 将矩阵化简成行最简阶梯形
    + 线性子空间
        * 零空间
        * 列空间
        * 行空间
        * 左零空间
        * 子空间的正交补
    + 最小二乘逼近
        * 实例1：求解方程
        * 实例2：线性回归
    + 特征向量
        * 求解特征值
        * 求解特征向量
        * 

----------------------------

# 推荐二
- http://space.bilibili.com/88461692#!/
- 线性代数的本质 http://space.bilibili.com/88461692#!/channel/detail?cid=9450
- ![image.png](http://pic.victor123.cn/17-11-24/78104007.jpg)
- 一天就看了好几集,让我对数学又重新产生了兴趣, 对此,本篇的目的旨在记录这两天所学到的内容:

## 线性代数的本质
## 01向量究竟是什么
- 向量是函数
- 向量是一条记录(多个观察值)
- 向量是物理运动

## 02线性组合、张成的空间
## 03矩阵与线性变换
- 矩阵向量乘法是一种线性变化,第一列是i帽移动的,第二列是j帽移动的位置
- 其中,2X2矩阵就是二维线性变换

## 04矩阵乘法与线性变换复合
- 矩阵的乘法就是两个线性变化的相继结果
- 从右往左读
- 先是e,g向量,线性变化,chengwei ae+bg,ce+dg,如图
- 矩阵的乘法没有交换律,有结合律

## 04三维空间中的线性
## 05行列式(线性变化的行列式)
- 行列式= 二位线性变化所对应的面积缩放比例,三维实体积
- 行列式结果=1,代表面积没有变化
- 行列式结果=6,代表面积乘以6
- 行列式结果=0,代表在降维了
- 行列式结果为负数,代表空间反面了
- 结算公式:ad-bc
- det(矩阵)=行列式


## 06逆矩阵、列空间与零空
- 求解线性方程组
- 行列式不为0时:线性变化*逆向线性变化=什么都不做(1)
- 行列式为0时:无法求逆
- 秩:变化后的空间维数
- 3*3矩阵的最大秩:为3,否则就意味着被压缩了
- 矩阵的列空间:所有可能的输出向量构成的集合(列张成的空间=列空间)
- 整个线被压缩:降1维(零空间)
- 整个平面被压缩:降2维(零空间)

## 06补充说明:非方阵
## 07点积与对偶性
- 向量的点成:一个向量*另一个向量在该向量上的投影
- 矩阵和向量之间的联系
- 转换*向量
- 矩阵向量乘积 类似 向量的点积

## 08第一部分:叉积的标准介绍
## 08第二部分:以线性变化的眼光看叉积
## 09基变换
## 10特征向量与特征值
## 11抽象向量空间

