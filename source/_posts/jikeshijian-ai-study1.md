title: 极客时间-学习笔记-AI技术内参1-经典搜索核心算法
tags: []
categories: []
date: 2017-12-18 21:43:00
---
# TF-IDF及其变种
- 信息检索,文本挖掘,自然语言处理领域
- 把查询关键字(Query)和文档(Document)都转为向量
- '向量空间模型'Vector Spcece Model就是希望吧查询关键字和文档都表达成变量,然后利用向量之间的运算来进行进一步表达向量之间的关系
- 相似性:余弦相似性,或者是点积
- V个词汇,V维度,查询关键字和每个文档的向量都有V个维度
- TF和IDF的乘机
- TF单词频率Term Frequency,计算一个查询关键字中某一个单子在目标文档中出现的次数
    + 如查询'car insurance',那么计算car出现了多少次,insurance出现了多少次
    + 表示相关度
- IDF,逆文档频率Inerse Document Frequency,需要去惩罚哪些出现在太多文档中的单词
    + 多少文档包含了这个单词,越大越不重要
- 其他学习资料
http://www.ruanyifeng.com/blog/2013/03/tf-idf.html
```
    让我们从一个实例开始讲起。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。所以，排在最前面的几个词，就是这篇文章的关键词。
    除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如，信息检索时，对于每个文档，都可以分别计算一组搜索词（"中国"、"蜜蜂"、"养殖"）的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。
    TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以"词频"衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。）

```

# BM25及其变种
- BM是'最佳匹配'Best Match的简称
- 用来计算某一目标文档(Document)相对于一个查询关键字(Query)的"相关性"(Relevance)的流程, 非监督学习排序算法中的一个典型代表
- 定义:
    + 单词和目标文档的相关性
    	* 词频 TF-IDF里面的TF部分,but词频需要"标准化",某一个单词对最后的分数的贡献不会随着词频的增加而无限增加
        * 两个超参数:当前文档的长度,整个数据集所有文档的平均长度
    + 单词和查询关键词的相关性
    	* 同样需要标准化过程
    + 单词的权重部分
        * 某种变形的来对单词加权,例如某种变形的IDF来对单词甲醛
        * 罗伯逊-斯巴克-琼斯权重,需要一个监督信息
        * 在很多情况下,利用IDF来直接对单词权重的版本更加普遍,如果再有监督信息的情况下,RSJ值也不失为一个很好的选择
    + 这个三个部分的乘积组成某一个单词的分数,然后,整个文档相对于某个查询关键字的分数,就是所有查询关键字里所有单词分数的总和 
- bm25是对某一概率相关模型的逼近
- bm25算法变种:bm25f,
	+ 域的概念(文档包括标题,摘要和正文)
    + 把BM25和其他文档信息(非文字)结合起来
    + BM25和PageRank的线性结果来确定网页的相关性
    
# 语言模型及其变种
- 详解:用概率模型(Probabilistic Model)来描述查询关键字和目标文档之间的关系
- 最简单的:查询关键字似然检索模型
	+ 一个语言模型就是一个针对词汇表的概率分布
    + 词汇表1w个单词,1w个单词上的离散概率分布
    + 查询关键字是从一个语言模型中"抽样"得到一个样本
    + 对一个查询关键字打分=这组词出现的联合概率,因为联合概率可能会很小,因此很多时候都通过一个对数变化,来把概率的乘积变成概率对数加和
    + 语言模型的参数:"类别分布"(Categorical Distiribution),也就是多项式分布,去除排列组合信息
    + 参数股计算法:最大似然估计
    + 每个单词出现的可能性,正好等于这个单词在目标文档中出现的次数,除以所有单词在文档中出现的次数.
    + 每个文档都对应一个类别分布,有多少文档,就有多少个类别分布
    + 如果没有在训练数据中出现过,最优解就是0
    + 平滑(Smoohting)
http://52opencourse.com/111/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88language-modeling%EF%BC%89

