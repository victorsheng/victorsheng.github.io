<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[source_dubbo_cluster]]></title>
    <url>%2F2018%2F01%2F31%2Fsource-dubbo-cluster%2F</url>
    <content type="text"><![CDATA[cluster层在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance 各节点关系： 这里的 Invoker 是 Provider 的一个可调用 Service 的抽象，Invoker 封装了 Provider 地址及 Service 接口信息 Directory 代表多个 Invoker，可以把它看成 List&lt;Invoker&gt; ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个 Router 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选 dubbo提供的实现Failover Cluster失败自动切换，当出现失败，重试其它服务器 [^1]。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。 重试次数配置如下： 1&lt;dubbo:service retries="2" /&gt; 或 1&lt;dubbo:reference retries="2" /&gt; 或 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; Failfast Cluster快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。 Broadcast Cluster广播调用所有提供者，逐个调用，任意一台报错则报错 [^2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。 源码解析AbstractClusterInvoker的invoke方法12345678910111213141516public Result invoke(final Invocation invocation) throws RpcException &#123; checkWheatherDestoried(); LoadBalance loadbalance; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);&#125; FailoverClusterInvoker失败自动切换，当出现失败，重试其它服务器 ^1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation); int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Although retry the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot; was successful by the provider &quot; + invoker.getUrl().getAddress() + &quot;, but there have been failed providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + le.getMessage(), le); &#125; return result; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(le != null ? le.getCode() : 0, &quot;Failed to invoke the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot;. Tried &quot; + len + &quot; times of the providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + (le != null ? le.getMessage() : &quot;&quot;), le != null &amp;&amp; le.getCause() != null ? le.getCause() : le); &#125; FailbackClusterInvoker失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; checkInvokers(invokers, invocation); Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failback to invoke method &quot; + invocation.getMethodName() + &quot;, wait for retry in background. Ignored exception: &quot; + e.getMessage() + &quot;, &quot;, e); addFailed(invocation, this); return new RpcResult(); // ignore &#125;&#125; //失败重试 private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) &#123; //单例初始化一个定时任务 if (retryFuture == null) &#123; synchronized (this) &#123; if (retryFuture == null) &#123; retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // 收集统计信息 try &#123; retryFailed(); &#125; catch (Throwable t) &#123; // 防御性容错 logger.error(&quot;Unexpected error occur at collect statistic&quot;, t); &#125; &#125; &#125;, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); &#125; &#125; &#125; //将失败的调用加入到Map中 failed.put(invocation, router);&#125;//重试的Futureprivate volatile ScheduledFuture&lt;?&gt; retryFuture;private final ConcurrentMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; failed = new ConcurrentHashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;(); //真实的进行重新调用 void retryFailed() &#123; //说明没有失败任务 if (failed.size() == 0) &#123; return; &#125; //遍历失败任务 for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;( failed).entrySet()) &#123; Invocation invocation = entry.getKey(); Invoker&lt;?&gt; invoker = entry.getValue(); try &#123; invoker.invoke(invocation); failed.remove(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failed retry to invoke method &quot; + invocation.getMethodName() + &quot;, waiting again.&quot;, e); &#125; &#125;&#125; ScheduledExecutorService核心方法 schedule 接收Runnable 接收Callable scheduleAtFixedRate 基于固定时间间隔进行任务调度 固定的频率来执行某项计划，它不受计划执行时间的影响。到时间，它就执行。 每次执行时间为 :initialDelay, initialDelay+period, initialDelay+2*period, … ScheduleWithFixedDelay 基于不固定时间间隔进行任务调度 是相对任务的。即无论某个任务执行多长时间，等执行完了，我再延迟指定的时间。也就是第二个方法，它受计划执行时间的影响。 每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：initialDelay, initialDelay+executeTime+delay ScheduledExecutorService的构造方法12345public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125; ForkingClusterInvoker并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。并行调用，只要一个成功即返回，通常用于实时性要求较高的操作，但需要浪费更多服务资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private final ExecutorService executor = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;forking-cluster-timer&quot;, true));public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; checkInvokers(invokers, invocation); final List&lt;Invoker&lt;T&gt;&gt; selected; final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (forks &lt;= 0 || forks &gt;= invokers.size()) &#123; selected = invokers; &#125; else &#123; selected = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (int i = 0; i &lt; forks; i++) &#123; //在invoker列表(排除selected)后,如果没有选够,则存在重复循环问题.见select实现. Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); if(!selected.contains(invoker))&#123;//防止重复添加invoker selected.add(invoker); &#125; &#125; &#125; RpcContext.getContext().setInvokers((List)selected); final AtomicInteger count = new AtomicInteger(); //核心代码:通过阻塞队列,来收集结果 final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;Object&gt;(); for (final Invoker&lt;T&gt; invoker : selected) &#123; executor.execute(new Runnable() &#123; public void run() &#123; try &#123; Result result = invoker.invoke(invocation); ref.offer(result); &#125; catch(Throwable e) &#123; int value = count.incrementAndGet(); if (value &gt;= selected.size()) &#123; ref.offer(e); &#125; &#125; &#125; &#125;); &#125; try &#123; //只要得到一个结果,就返回 Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); if (ret instanceof Throwable) &#123; Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException)e).getCode() : 0, &quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; return (Result) ret; &#125; catch (InterruptedException e) &#123; throw new RpcException(&quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e); &#125; &#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[review-java-thread-pool]]></title>
    <url>%2F2018%2F01%2F31%2Freview-java-thread-pool%2F</url>
    <content type="text"><![CDATA[线程池背景 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了， 频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 请求频繁，但是连接上以后读/写很少量的数据就断开连接。考虑到服务的并发问题，如果每个请求来到以后服务都为它启动一个线程，那么这对服务的资源可能会造成很大的浪费。 优点 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 核心接口ExecutorService,Executor 类 ExecutorService：真正的线程池接口。 ScheduledExecutorService:能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。 ThreadPoolExecutor:ExecutorService的默认实现。 ScheduledThreadPoolExecutor:继承ThreadPoolExecutor的- - ScheduledExecutorService接口实现，周期性任务调度的类实现。 Executors类里面提供了一些静态工厂，生成一些常用的线程池。 Executors 提供四种线程池 1）newCachedThreadPool 是一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute() 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。注意，可以使用 ThreadPoolExecutor 构造方法创建具有类似属性但细节不同（例如超时参数）的线程池。 2）newSingleThreadExecutor 创建是一个单线程池，也就是该线程池只有一个线程在工作，所有的任务是串行执行的，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 3）newFixedThreadPool 创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小，线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 4）newScheduledThreadPool 创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。 程池相关参数corePoolSize（线程池的基本大小）：当提交一个任务时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，直到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreTreads()方法，线程池就会提前创建并启动所有基本线程。 maximumPoolSize（线程最大数量）：线程池允许创建的最大线程数。如果队列已满，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。但如果使用了无解的任务队列，该参数没有效果。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。如果任务很多，且每个任务执行时间较短，可调大该值。 TimeUnit（线程活动保持时间的单位）：keepAliveTime的时间度量单位。可选天、小时、分钟、毫秒、微妙、纳秒。 BlockingQueue（任务队列）：用于保存等待执行的任务的阻塞嘟列，可以选择以下几个阻塞队列 ArrayBlockingQueue：基于数组结构的有界阻塞队列 LinkedBlockingQueue：基于链表机构的阻塞队列，吞吐量通常高于ArrayBlockingQueue，静态工厂方法Executors.newFixedThreadPool()使用该队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除，否则插入操作一直处于阻塞状态，吞吐量通常高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool()使用该队列。 PriorityBlockingQueue：具有优先级的无限阻塞队列。 ThreadFactory：创建线程的工厂。 RejectedExecutionHandler：饱和策略，即队列和线程池都满了，对于新提交的任务无法执行，这时采取的处理新来的任务的方法，有4种策略可选（也可以自定义策略—实现RejectedExecutionHandler接口，如记录日志或持久化不能处理的任务）： CallerRunsPolicy：使用调用者所在的线程来运行任务。 AbortPolicy：直接抛出RejectedExecutionException异常。（默认策略） DiscardPolicy：对新任务直接丢弃，不做任何事情 DiscardOldestPolicy：丢掉队列里最近（the oldest unhandled）的一个任务，并执行当前新任务。 线程池的关闭 ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是 shutdown() 和 shutdownNow()。 shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 核心流程 线程池规则线程池的线程执行规则跟任务队列有很大的关系。 下面都假设任务队列没有大小限制： 如果线程数量&lt;=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。 任务队列大小有限时 当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。 SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。 使用方法123456789101112131415 void execute(Runnable task) Future&lt;?&gt; submit(Runnable task) &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; 全部执行,其中一个执行结束,或异常,则取消其他Callable的运行 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合 future.isDone() //return true,false 无阻塞 future.get() // return 返回值，阻塞直到该线程运行结束 实际案例1(优化分页查询)1234567891011121314ExecutorService slaver = Executors.newSingleThreadExecutor();FutureTask&lt;List&lt;Map&lt;String, Object&gt;&gt;&gt; lastFuture = new FutureTask&lt;&gt;(countCallable);slaver.execute(lastFuture);slaver.shutdown();List&lt;Map&lt;String, Object&gt;&gt; stockFirst = jdbcTemplate.queryForList(contentSql);List&lt;Map&lt;String, Object&gt;&gt; stockLast = null;try &#123; stockLast = lastFuture.get();&#125; catch (Exception e) &#123; logger.error(&quot;错误&quot;, e);&#125; finally &#123; lastFuture.cancel(true);&#125; 实际案例2(dts抓单)12345678910111213141516171819202122232425262728executor = new ThreadPoolExecutor(config.getMaxActive()/2+1, config.getMaxActive(), config.getTimeout4Borrow(), TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(config.getMaxActive()), this); //通用abstract处理 @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; logger.error(&quot;wait too long to borrow worker: &quot; + taskOwner); try &#123; getMQService().push(getConfig().getAlertMq(), taskOwner); &#125; catch (Exception e) &#123; logger.error(&quot;mq service error: &quot;, e); &#125; logger.warn(&quot;worker &#123;&#125; need sleep &#123;&#125; millis to back to working &quot;, taskOwner, getConfig().getTimeout4Borrow()); try &#123; Thread.sleep(getConfig().getTimeout4Borrow() * 5); &#125; catch (Exception e) &#123; logger.error(&quot;thread error :&quot;, e); &#125; &#125; //业务级别处理 @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; logger.error(&quot;线程池不够用: &#123;&#125; &quot;, taskOwner); ThreadPoolExecutor.CallerRunsPolicy callerRunsPolicy = new ThreadPoolExecutor.CallerRunsPolicy(); callerRunsPolicy.rejectedExecution(r, executor); &#125; CompletionService接口 根据上面的介绍我们知道，现在在Java中使用多线程通常不会再使用Thread对象了。而是会用到java.util.concurrent包下的ExecutorService来初始化一个线程池供我们使用。使用ExecutorService类的时候，我们常维护一个list保存submit的callable task所返回的Future对象。然后在主线程中遍历这个list并调用Future的get()方法取到Task的返回值。 其实除了使用ExecutorService外，还可通过CompletionService包装ExecutorService，然后调用其take()方法去取Future对象。 CompletionService和ExecutorService的主要的区别在于submit的task不一定是按照加入自己维护的list顺序完成的。 ExecutorService中从list中遍历的每个Future对象并不一定处于完成状态，这时调用get()方法就会被阻塞住，如果系统是设计成每个线程完成后就能根据其结果继续做后面的事，这样对于处于list后面的但是先完成的线程就会增加了额外的等待时间。 而CompletionService的实现是维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。所以，先完成的必定先被取出。这样就减少了不必要的等待时间。 SingleThreadExecutorCachedThreadPool①使用无容量队列SynchronousQueue，但maxmumPoolSize无界。如果提交任务的速度大于线程处理任务的速度，将会不断创建新线程，极端情况会因为创建过多线程而耗尽CPU资源。②keepAliveTime为60s，空闲线程超过该时间将会终止。③执行完任务的某线程会执行SynchronousQueue.poll()从队列中取任务，这个取的动作会持续60s，如果在60s内有新的任务，则执行新的任务，没有任务则终止线程。因此长时间保持空闲的CachedThreadPool不会占用任何资源。④当有任务提交时，a.如果当前线程池为空或者已创建的线程都正在处理任务，则CachedThreadPool会创建新线程来执行该任务。b.如果当前线程池有空闲的线程（正在执行阻塞方法SynchronousQueue.poll()），则将任务交给该等待任务的空闲线程来执行。 CachedThreadPool适用于执行很多的短期异步任务的小程序或者是负载较轻的服务器。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[data-Archiving-research]]></title>
    <url>%2F2018%2F01%2F25%2Fdata-Archiving-research%2F</url>
    <content type="text"><![CDATA[归档需求 主要处于性能考虑,减少查找的范围 同时要求系统中可以查询到之前的数据,不能归档到非结构化系统中 要求可以添加自定义条件,保证业务 目前:订单(平行表,主子表),售后单(主子表),发货单(主子表),日志表… 已经归档过一次 &lt; !–more–&gt; 归档流程梳理 复制指定条件的旧数据 删除旧数据(是否需要人工介入?)后续自动 读取归档数据 归档方案思路:1.建立归档表_archive这种方式是通过建立一个以_archive结尾的归档表来实施的。如果使用这种方式，那么一般需要在业务层进行查询的分离改造，比如基于我们的特定归档规则 ，对业务端核心代码改造或者使用proxy方案等来决定是使用主表还是归档表。同时我们还需要一个数据归档过程，当数据过时或者变成冷数据时，将该数据从主表迁移到归档表中。 在业务层查询时，我们可以通过时间字段来进行查询判断，例如将90天之前的数据在归档表中查询，否则就在主表查询。另一种方式可以通过增加status列去判断查询主表还是归档表，如果是inactive则查询归档表，否则就在主表查询。 mysql分区为了让优化器能将查询发送到正确的分区键，在创建分区表的时候，我们需要将分区键添加到主键里，并且理想情况下，该分区键能被包含在所有select/update/delete等语句的where条件里面，否则的话，你的查询将会按照顺序查找表对应的每个分区，这种情况下查询性能就没有那么好了。 根据日期进行分区这种方式是通过对表进行分区来实现，虽然这是一种不同的物理数据模型，但是确实有助于将表的数据进行拆分到不同的物理磁盘，并且不需要代码的任何改造。作为DBA，一般对表进行分区是比较常用的方式，我们可以通过日期字段很容易确定哪些是冷数据，并根据日期将不同日期的时间分配到不同的分区中，在查询的时候，我们可以通过日期来从分区中快速定位到对应的数据，同时建立分区表也比较利于DBA对大表进行管理操作。 我们根据数据行的创建时间，按年将数据放入到不同的分区，这里需要注意的是在2020年以后，我们还需要在表里添加新的年份，当然我们可以提前加更多的分区或者部署脚本来自动化创建新的分区。 通过状态进行分区我们也可以通过status状态列来进行分区，这种情况下，通常状态列会包含active/inactive两种状态，然后通过update进行状态列的更新（使用replace或者insert+delete也是可以的），将数据放入到正确的分区当中。请看下面的示例 通过ID进行分区具体方案复制表并且按照条件插入数据（此种方法除了主键索引不包括其他索引）–&gt;手动sqlhttp://blog.csdn.net/bluestarf/article/details/49641047 123CREATE TABLE lime_survey_549656_20151001 as select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; ALTER TABLE lime_survey_549656_20151001 change id id int primary key auto_increment; 创建一张空表，结构和索引和原表一样 –&gt;手动sql12create table lime_survey_549656_20151001 like lime_survey_549656; INSERT INTO lime_survey_549656_20151001 select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; 存储过程来归档程序来归档pt-archvierhttps://yq.aliyun.com/articles/277145 python实现https://github.com/dbarun/mysql_archiver MySQL_archiver基本上实现了数据归档的自动运转，统一的归档任务调度管理、自动监控和预警、自动生成报表。在一定程度上节约了生产力，提高了运维效率。 要知道每个归档任务成功与否、跑了多长时间、归档了多少数据java实现https://github.com/Sunshow/JavaDataArchiver 阿里云maxcompute有误删除的风险,只做数据加工 阿里云数据迁移(复制)相对稳定,成本低 利弊权衡 对现有业务sql的影响 对归档查询实现的难易 分区实现 表中有全文索引,无法分区 分区的话,需要修改业务sql,改动较大–&gt;待确定 mysql脚本实现 是否需要跨数据库备份 外部程序实现结论 使用: mysql_archiver !!!!!!后续开发读取归档数据,同时不能影响生产库的性能(最好先定下来,否则目标 会不是mysql) target 也需要分区 目标库 冗余信息,nogsql mysql my maxcompute 废弃分表策略,对于v_sale_order和v_sale_order_detail结论 采用阿里云数据集成,跑归档任务 在数据集成任务结束后的回调函数,可以配置删除归档数据的任务 暂时目标库,还是mysql,后续的查询采用ElasticSearch进行查询,(阿里云提供1个月的免费试用,待研究确认后执行) 后续 v_sale_order视图的修改 开发]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-debug]]></title>
    <url>%2F2018%2F01%2F24%2Fmysql-debug%2F</url>
    <content type="text"><![CDATA[问题sql1234567 SELECT *FROM v_sale_orderWHERE 1 = 1 AND v_sale_order.is_usable = 1 AND v_sale_order.tenant_id = 100046 AND 1 = 1 AND archive_state IN (0, 1) AND# v_sale_order.buyer_nick LIKE '肆无忌惮演江山%' v_sale_order.buyer_nick LIKE 't_150175568%'ORDER BY v_sale_order.last_update_time DESC; 如果查询内容带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsosrefidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_idIDX_original_order_id6const,const837216Using where; Using filesort1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sos.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsorrefidx_sale_order_id,idx_buyer_nickidx_sale_order_id9egenie_kn.sos.sale_order_id1Using where1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL 如果查询内容不带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsorrangeidx_sale_order_id,idx_buyer_nickidx_buyer_nick303NULL7Using index condition; Using where; Using temporary; Using filesort1SIMPLEsoseq_refidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_ididx_sale_order_id8egenie_kn.sor.sale_order_id1Using where1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sor.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL 原因 %代表任意多个字符 _代表一个字符 如果想搜索 _ 就要用到转义符 “\” 解决1value = value.replaceAll("\\_", "\\\\_");]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>like</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_quick_sort]]></title>
    <url>%2F2018%2F01%2F22%2Fstudy-quick-sort%2F</url>
    <content type="text"><![CDATA[视频地址:https://visualgo.net/en/sorting 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class QuickSort &#123; public static void main(String[] args) throws Exception &#123; int[] ints = &#123;5, 3, 9, 1, 6, 7, 2, 4, 0, 8&#125;; int[] result = new QuickSort().sort(ints); System.out.println(Arrays.toString(result)); &#125; public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); return quickSort(arr, 0, arr.length - 1); &#125; private int[] quickSort(int[] arr, int left, int right) &#123; if (left &lt; right) &#123; int partitionIndex = partition(arr, left, right); System.out.println(partitionIndex); quickSort(arr, left, partitionIndex - 1); quickSort(arr, partitionIndex + 1, right); &#125; return arr; &#125; private int partition(int[] arr, int left, int right) &#123; // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) &#123; if (arr[i] &lt; arr[pivot]) &#123; swap(arr, i, index); index++; &#125; &#125; swap(arr, pivot, index - 1); return index - 1; &#125; private void swap(int[] arr, int i, int j) &#123; if (i == j) &#123; return; &#125; System.out.println(&quot;swap&quot; + i + &quot;----&quot; + j); int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(原理篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fstudy-springboot-springmvc%2F</url>
    <content type="text"><![CDATA[springboot如何配置DispatcherServlet?org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration中完成的 在springboot项目中,进行springmvc配置的新的方式12345678910111213141516171819202122232425@Configurationpublic class SpringMvcConfigure extends WebMvcConfigurerAdapter &#123; @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(&quot;/WEB-INF/jsp/&quot;); viewResolver.setSuffix(&quot;.jsp&quot;); // viewResolver.setViewClass(JstlView.class); // 这个属性通常并不需要手动配置，高版本的Spring会自动检测 return viewResolver; &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new Interceptor1()).addPathPatterns(&quot;/**&quot;); registry.addInterceptor(new Interceptor2()).addPathPatterns(&quot;/users&quot;).addPathPatterns(&quot;/users/**&quot;); super.addInterceptors(registry); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; // addResourceHandler指的是访问路径，addResourceLocations指的是文件放置的目录 registry.addResourceHandler(&quot;/**&quot;).addResourceLocations(&quot;classpath:/res/&quot;); &#125;&#125; HTTP序列化/反序列化@RestController中有@ResponseBody，可以帮我们把User序列化到resp.body中。@RequestBody可以帮我们把req.body的内容转化为User对象。如果是开发Web应用，一般这两个注解对应的就是Json序列化和反序列化的操作。这里实际上已经体现了Http序列化/反序列化这个过程，只不过和普通的对象序列化有些不一样，Http序列化/反序列化的层次更高，属于一种Object2Object之间的转换。 有过Netty使用经验的对这个应该比较了解，Netty中的Decoder和Encoder就有两种基本层次，层次低的一种是Byte &lt;—&gt; Message，二进制与程序内部消息对象之间的转换，就是常见的序列化/反序列化；另外一种是 Message &lt;—&gt; Message，程序内部对象之间的转换，比较高层次的序列化/反序列化。 Http协议的处理过程，TCP字节流 &lt;—&gt; HttpRequest/HttpResponse &lt;—&gt; 内部对象，就涉及这两种序列化。在springmvc中第一步已经由Servlet容器（tomcat等等）帮我们处理了，第二步则主要由框架帮我们处理。上面所说的Http序列化/反序列化就是指的这第二个步骤，它是controller层框架的核心功能之一，有了这个功能，就能大大减少代码量，让controller的逻辑更简洁清晰，就像上面示意的代码那样，方法中只有一行代码。 spirngmvc进行第二步操作，也就是Http序列化和反序列化的核心是HttpMessageConverter。用过老版本springmvc的可能有些印象，那时候需要在xml配置文件中注入MappingJackson2HttpMessageConverter这个类型的bean，告诉springmvc我们需要进行Json格式的转换，它就是HttpMessageConverter的一种实现。 几种实现 json:gson,fastjson,jackson Protobuf java序列化 HttpMessageConverter优先级另外有很重要的一点需要说明一下，springmvc可以同时配置多个Converter，根据一定的规则（主要是Content-Type、Accept、controller方法的consumes/produces、Converter.mediaType以及Converter的排列顺序这四个属性）来选择到底是使用哪一个，这使得springmvc能够一个接口支持多种报文格式。 默认的converters12345678910ByteArrayHttpMessageConverter – converts byte arraysStringHttpMessageConverter – converts StringsResourceHttpMessageConverter – converts org.springframework.core.io.Resource for any type of octet streamSourceHttpMessageConverter – converts javax.xml.transform.SourceFormHttpMessageConverter – converts form data to/from a MultiValueMap&lt;String, String&gt;.Jaxb2RootElementHttpMessageConverter – converts Java objects to/from XML (added only if JAXB2 is present on the classpath)MappingJackson2HttpMessageConverter – converts JSON (added only if Jackson 2 is present on the classpath)MappingJacksonHttpMessageConverter – converts JSON (added only if Jackson is present on the classpath)AtomFeedHttpMessageConverter – converts Atom feeds (added only if Rome is present on the classpath)RssChannelHttpMessageConverter – converts RSS feeds (added only if Rome is present on the classpath) 源码中的调用栈1234567891011com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter.write(FastJsonHttpMessageConverter.java:185) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:231) at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:203) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:81) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:113) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at 常见的contentType 1.text/html 2.text/plain 3.text/css 4.text/javascript 5.application/x-www-form-urlencoded 6.multipart/form-data 7.application/json 8.application/xml]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(实战篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fstudy-fastjson-formatter%2F</url>
    <content type="text"><![CDATA[背景老的方式:controller的参数与返回值123456public JsonResult queryDrillDetail(@RequestBody String body) &#123;List&lt;Map&lt;String, Object&gt;&gt; detailMapList = new ArrayList&lt;&gt;();.......return new JsonResult(JsonResult.SUCCESSFUL, new PagedList&lt;&gt;(query.getPage() + 1, pageable.getPageSize(), query.getTotalCount(), detailMapList));&#125; 老的方式:问题 入参不明确 返回值类型不明确 Map的key只有在运行时,才会知道,且不知道类型 期望的方式:使用vo改造步骤:1.在使用converters的最后一个优先级,添加FastJsonHttpMessageConverter 1234567891011121314@Componentpublic class MyWebAppConfigurer extends WebMvcConfigurerAdapter &#123; // 添加converter的第三种方式 // 同一个WebMvcConfigurerAdapter中的configureMessageConverters方法先于extendMessageConverters方法执行 // 可以理解为是三种方式中最后执行的一种，不过这里可以通过add指定顺序来调整优先级，也可以使用remove/clear来删除converter，功能强大 // 使用converters.add(xxx)会放在最低优先级（List的尾部） // 使用converters.add(0,xxx)会放在最高优先级（List的头部） @Override public void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; converters.add(new FastJsonHttpMessageConverter()); &#125;&#125; 2.model遵循老的接口原则,转为下划线分割的 1234567891011@JSONType(naming = PropertyNamingStrategy.SnakeCase)public class PurchaseDetailDrillVo &#123; private Long pmsPurchaseOrderId; private Long pmsPurchaseOrderDetailId; private String pmsPurchaseOrderNo; private Integer productType; private String deliverAddress; private Long provinceId; ....&#125; 3.使用@RequestBody注解,类型改为vo 测试,接受参数和返回参数都是vo,而接口的字段映射依然为下划线, 以下为项目本身的问题4.pom文件中排除jackson的依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;com.ejlerp&lt;/groupId&gt; &lt;artifactId&gt;ejlerp-common&lt;/artifactId&gt; &lt;version&gt;3.2.0-SNAPSHOT&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 5.fastjason默认支持所有的contentType,及*, 与springmvc校验相冲突,so需要声明fastjason能支持的contentType,在初始化FastJsonHttpMessageConverter,注入参数1234567891011@Overridepublic void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); ArrayList&lt;MediaType&gt; supportedMediaTypes = Lists.newArrayList(); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_PLAIN); fastJsonHttpMessageConverter.setSupportedMediaTypes(supportedMediaTypes); converters.add(fastJsonHttpMessageConverter);&#125; fastjson官网https://github.com/alibaba/fastjson/issues/1555https://github.com/alibaba/fastjson/wiki/PropertyNamingStrategy_cn]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>fastjson</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_equals_and_hashCode]]></title>
    <url>%2F2018%2F01%2F22%2Fstudy-equals-and-hashCode%2F</url>
    <content type="text"><![CDATA[https://www.ibm.com/developerworks/cn/java/j-jtp05273/index.html 为什么 Override equals()和hashCode()? 如果 Integer 不 Override equals() 和 hashCode() 情况又将如何?如果我们从未在 HashMap 或其它基于散列的集合中使用 Integer 作为关键字的话，什么也不会发生。但是，如果我们在 HashMap中 使用这类 Integer 对象作为关键字，我们将不能够可靠地检索相关的值，除非我们在 get() 调用中使用与 put() 调用中极其类似的 Integer 实例。这要求确保在我们的整个程序中，只能使用对应于特定整数值的 Integer 对象的一个实例。不用说，这种方法极不方便而且错误频频。 Object 的interface contract要求如果根据 equals() 两个对象是相等的，那么它们必须有相同的 hashCode() 值。当其识别能力整个包含在 equals() 中时，为什么我们的根对象类需要 hashCode() ？ 如果重写了equals方法，则一定要重写hashCode方法。 hashCode() 方法纯粹用于提高效率。Java平台设计人员预计到了典型Java应用程序中基于散列的集合类（Collection Class)的重要性–如 Hashtable 、 HashMap 和 HashSet ，并且使用 equals() 与许多对象进行比较在计算方面非常昂贵。使所有Java对象都能够支持 hashCode() 并结合使用基于散列的集合，可以实现有效的存储和检索。 hashCode方法 如果重写了equals方法，则一定要重写hashCode方法。 重写hashCode方法的原则如下： 在程序执行期间，只要equals方法的比较操作用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法必须始终如一地返回同一个整数 如果两个对象通过equals方法比较得到的结果是相等的，那么对这两个对象进行hashCode得到的值应该相同 两个不同的对象，hashCode的结果可能是相同的，这就是哈希表中的冲突。为了保证哈希表的效率，哈希算法应尽可能的避免冲突 关于相应的哈希算法，一个简单的算法如下: 永远不要让哈希算法返回一个常值，这时哈希表将退化成链表，查找时间复杂度也从 O(1)O(1) 退化到 O(N)O(N) 如果参数是boolean型，计算(f ? 1 : 0) 如果参数是byte, char, short或者int型，计算(int) f 如果参数是long型，计算(int) (f ^ (f &gt;&gt;&gt; 32)) 如果参数是float型，计算Float.floatToIntBits(f) 如果参数是double型，计算Double.doubleToLongBits(f)得到long类型的值，再根据公式计算出相应的hash值 如果参数是Object型，那么应计算其有用的成员变量的hash值，并按照下面的公式计算最终的hash值 如果参数是个数组，那么把数组中的每个值都当做单独的值，分别按照上面的方法单独计算hash值，最后按照下面的公式计算最终的hash值 组合公式：result = 31 * result + c String类的hashCode方法如下（JDK 1.8）：1234567891011public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; 举个自定义类的hashCode例子：123456789101112131415161718192021222324252627282930class Duck &#123; private int id; private String name; private double weight; private float height; private String note; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Duck duck = (Duck) o; if (id != duck.id) return false; if (Double.compare(duck.weight, weight) != 0) return false; if (Float.compare(duck.height, height) != 0) return false; if (name != null ? !name.equals(duck.name) : duck.name != null) return false; return !(note != null ? !note.equals(duck.note) : duck.note != null); &#125; @Override public int hashCode() &#123; int result; long temp; result = id; result = 31 * result + (name != null ? name.hashCode() : 0); temp = Double.doubleToLongBits(weight); result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); result = 31 * result + (height != +0.0f ? Float.floatToIntBits(height) : 0); result = 31 * result + (note != null ? note.hashCode() : 0); return result; &#125;&#125; BTW 回顾一下 hashmap内部的实现e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[review_spring]]></title>
    <url>%2F2018%2F01%2F19%2Freview-spring%2F</url>
    <content type="text"><![CDATA[spring生命周期 1.Spring对Bean进行实例化（相当于程序中的new Xx()） 2.Spring将值和Bean的引用注入进Bean对应的属性中 3.如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的） 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等） 5.如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把y应用上下文作为参数传入.(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory ) 6.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization（预初始化）方法（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能） 7.如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。 8.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization（后初始化）方法（作用与6的一样，只不过6是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 ) 9.经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 10.如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。 Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类： 1、Bean自身的方法 ： 这个包括了Bean本身调用的方法和通过配置文件中的init-method和destroy-method指定的方法 2、Bean级生命周期接口方法 ： 这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法 3、容器级生命周期接口方法 ： 这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。 4、工厂后处理器接口方法 ： 这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器 接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 由AbstractBeanFactory控制Aware接口12345678910111213private void invokeAwareMethods(final String beanName, final Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader()); &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; BeanPostProcessor接口InitializingBean接口DisposableBean接口 https://www.cnblogs.com/zrtqsk/p/3735273.html springbean是否线程安全我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。 无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[desin_pattern]]></title>
    <url>%2F2018%2F01%2F19%2Fdesin-pattern%2F</url>
    <content type="text"><![CDATA[模板方法（Template Method ）定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。Template Method模式一般是需要继承的。这里想要探讨另一种对Template Method的理解。spring中的JdbcTemplate，在用这个类时并不想去继承这个类，因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。这可能是Template Method不需要继承的另一种实现方式吧。 策略（Strategy ）观察者（Observer ）定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。spring中Observer模式常用的地方是listener的实现。如ApplicationListener。 包装器（Decorator ）在我们的项目中遇到这样一个问题：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。我们以往在spring和hibernate框架中总是配置一个数据源，因而sessionFactory的dataSource属性总是指向这个数据源并且恒定不变，所有DAO在使用sessionFactory的时候都是通过这个数据源访问数据库。但是现在，由于项目的需要，我们的DAO在访问sessionFactory的时候都不得不在多个数据源中不断切换，问题就出现了：如何让sessionFactory在执行数据持久化的时候，根据客户的需求能够动态切换不同的数据源？我们能不能在spring的框架下通过少量修改得到解决？是否有什么设计模式可以利用呢？首先想到在spring的applicationContext中配置所有的dataSource。这些dataSource可能是各种不同类型的，比如不同的数据库：Oracle、SQL Server、MySQL等，也可能是不同的数据源：比如apache 提供的org.apache.commons.dbcp.BasicDataSource、spring提供的org.springframework.jndi.JndiObjectFactoryBean等。然后sessionFactory根据客户的每次请求，将dataSource属性设置成不同的数据源，以到达切换数据源的目的。spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。基本上都是动态地给一个对象添加一些额外的职责。 代理（Proxy ）为其他对象提供一种代理以控制对这个对象的访问。 从结构上来看和Decorator模式类似，但Proxy是控制，更像是一种对功能的限制，而Decorator是增加职责。spring的Proxy模式在aop中有体现，比如JdkDynamicAopProxy和Cglib2AopProxy。 单例模式（Singleton ）保证一个类仅有一个实例，并提供一个访问它的全局访问点。spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是是任意的java对象。核心提示点：Spring下默认的bean均为singleton，可以通过singleton=“true|false” 或者 scope=“？”来指定 适配器（Adapter ）在Spring的Aop中，使用的Advice（通知）来增强被代理类的功能。Spring实现这一AOP功能的原理就使用代理模式（1、JDK动态代理。2、CGLib字节码生成技术代理。）对类进行方法级别的切面增强，即，生成被代理类的代理类， 并在代理类的方法前，设置拦截器，通过执行拦截器重的内容增强了代理方法的功能，实现的面向切面编程。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reivew_spring_mvc]]></title>
    <url>%2F2018%2F01%2F18%2Freivew-spring-mvc%2F</url>
    <content type="text"><![CDATA[springmvc是什么 Spring Web MVC是一种基于Java的实现了Web MVC设计模式的请求驱动类型的轻量级Web框架 将web层进行职责解耦 工作者模式的实现???帮我们做什么 让我们能非常简单的设计出干净的Web层和薄薄的Web层； 进行更简洁的Web层的开发； 天生与Spring框架集成（如IoC容器、AOP等）； 提供强大的约定大于配置的契约式编程支持； 能简单的进行Web层的单元测试； 支持灵活的URL到页面控制器的映射； 非常容易与其他视图技术集成，如Velocity、FreeMarker等等，因为模型数据不放在特定的API里，而是放在一个Model里（Map数据结构实现，因此很容易被其他框架使用）； 非常灵活的数据验证、格式化和数据绑定机制，能使用任何对象进行数据绑定，不必实现特定框架的API； 提供一套强大的JSP标签库，简化JSP开发； 支持灵活的本地化、主题等解析； 更加简单的异常处理； 对静态资源的支持； 支持Restful风格。 架构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//前端控制器分派方法 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try &#123; ModelAndView mv; boolean errorView = false; try &#123; //检查是否是请求是否是multipart（如文件上传），如果是将通过MultipartResolver解析 processedRequest = checkMultipart(request); //步骤2、请求到处理器（页面控制器）的映射，通过HandlerMapping进行映射 mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; //步骤3、处理器适配，即将我们的处理器包装成相应的适配器（从而支持多种类型的处理器） HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 304 Not Modified缓存支持 //此处省略具体代码 // 执行处理器相关的拦截器的预处理（HandlerInterceptor.preHandle） //此处省略具体代码 // 步骤4、由适配器执行处理器（调用处理器相应功能处理方法） mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) &#123; mv.setViewName(getDefaultViewName(request)); &#125; // 执行处理器相关的拦截器的后处理（HandlerInterceptor.postHandle） //此处省略具体代码 &#125; catch (ModelAndViewDefiningException ex) &#123; logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, ex); mv = ex.getModelAndView(); &#125; catch (Exception ex) &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); &#125; //步骤5 步骤6、解析视图并进行视图的渲染 //步骤5 由ViewResolver解析View（viewResolver.resolveViewName(viewName, locale)） //步骤6 视图在渲染时会把Model传入（view.render(mv.getModelInternal(), request, response);） if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, processedRequest, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Null ModelAndView returned to DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;: assuming HandlerAdapter completed request handling&quot;); &#125; &#125; // 执行处理器相关的拦截器的完成后处理（HandlerInterceptor.afterCompletion） //此处省略具体代码 catch (Exception ex) &#123; // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; catch (Error err) &#123; ServletException ex = new NestedServletException(&quot;Handler processing failed&quot;, err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; finally &#123; // Clean up any resources used by a multipart request. if (processedRequest != request) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; 核心架构的具体流程步骤如下： 1、 首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制； 2、 DispatcherServlet——&gt;HandlerMapping， HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略； 3、 DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器； 4、 HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）； 5、 ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术； 6、 View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术； 7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 此处我们只是讲了核心流程，没有考虑拦截器、本地解析、文件上传解析等，后边再细述。 hello world DispatcherServlet与HttpMessageConverter的关系//TODO http://sishuok.com/forum/blogPost/list/5160.html]]></content>
      <categories>
        <category>springmvc</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[btrace-study]]></title>
    <url>%2F2018%2F01%2F18%2Fbtrace-study%2F</url>
    <content type="text"><![CDATA[btrace概念: Probe Point: “location” or “event” at which a set of tracing statements are executed. Probe point is “place” or “event” of interest where we want to execute some tracing statements.（探测点，就是我们想要执行一些追踪语句的地方或事件） Trace Actions or Actions: Trace statements that are executed whenever a probe “fires”.（当探测触发时执行追踪语句） Action Methods: BTrace trace statements that are executed when a probe fires are defined inside a static method a class. Such methods are called “action” methods.（当在类的静态方法中定义了探测触发时执行的BTrace跟踪语句。这种方法被称为“操作”方法。） 学习的博客:http://mgoann.iteye.com/blog/1409685http://calvin1978.blogcn.com/articles/btrace1.htmlhttp://codepub.cn/2017/09/22/btrace-uses-tutorials/ byteman局部变量http://codepub.cn/2017/09/22/byteman-uses-tutorials/ github地址:https://github.com/btraceio/btrace 可运行包 下载地址https://github.com/btraceio/btrace/releases/tag/v1.3.10]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful-API概念学习]]></title>
    <url>%2F2018%2F01%2F15%2Fadvantage-api%2F</url>
    <content type="text"><![CDATA[RESTful API 透明性，暴露资源存在。 充分利用 HTTP 协议本身语义。 无状态，这点非常重要。在调用一个接口（访问、操作资源）的时候，可以不用考虑上下文，不用考虑当前状态，极大的降低了复杂度 HTTP 本身提供了丰富的内容协商手段，无论是缓存，还是资源修改的乐观并发控制，都可以以业务无关的中间件来实现 理解RESTful架构 Representational State Transfer REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 最常见的一种设计错误，就是URI包含动词。因为”资源”表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。 因为不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。版本号可以在HTTP请求头信息的Accept字段中进行区分http://www.ruanyifeng.com/blog/2011/09/restful.html RESTful API 设计指南 协议 域名 版本（Versioning） 路径（Endpoint）在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 HTTP动词 过滤信息（Filtering） 状态码（Status Codes） 错误处理 返回结果 Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 其他 （1）API的身份认证应该使用OAuth 2.0框架。 （2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。 http://www.ruanyifeng.com/blog/2014/05/restful_api.html]]></content>
      <categories>
        <category>HTTP协议</category>
      </categories>
      <tags>
        <tag>HTTP协议</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-线程复习]]></title>
    <url>%2F2018%2F01%2F13%2Freview-java-thread%2F</url>
    <content type="text"><![CDATA[线程创建线程有两种方式：一、继承 Thread 类，扩展线程。二、实现 Runnable 接口。 Callable接口Future接口FutureTask实现了 Future 接口FutureTask 的好处是 FutureTask 是为了弥补 Thread 的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果。FutureTask 是一种可以取消的异步的计算任务，它的计算是通过 Callable 实现的，它等价于可以携带结果的 Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。 多线程多线程的概念很好理解就是多条线程同时存在，但要用好多线程确不容易，涉及到多线程间通信，多线程共用一个资源等诸多问题。 synchronized解决多个线程之间访问资源的同步性 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。volatile解决变量在多个线程之间的可见性wait()、notify()、notifyAll()wait():我的部分已经做完了,等别人让我做的时候再做,释放锁notify():等我做完了,释放锁后,让其他一个人做wait() 与 Thread.sleep(long time) 的区别:sleep傻等,sleep不释放锁 ThreadLocal 变量线程隔离InheritableTreadLocal让子线程获取父线程中取得值 join() 方法等待线程对象销毁等待子进程执行完,我再执行Thread.yield() 方法 ReentrantLocklock()unlock()condition等待/通知 awiate() 相当于Object类中的wait()方法 await(long time,TImeUnit unit) 相当于Object类中的wait()方法 signal() 相当于Object类中的notify()方法 sigalAll() 相当于Object类中的notifyAll()方法 通知部分线程Lock lock=new Reentrantock();Condition conditionA=lock.newCondition();Condition conditionB=lock.newCondition(); 公平锁,非公平锁 获取锁的顺序是按照线程加锁的顺序来分配的,及先来先得的FIFO先进先出顺序 getHoldCount(),getQueueLength(),getWaiteQueueLength() getHoldCount()查询当前线程保持此锁定的个数,调用lock()方法的次数 getQueueLength()返回正在等待次锁定的线程估计数 getWaiteQueueLength(Condition condition)返回等待与此锁定翔安的给定条件Condition的线程估计数 线程状态切换 监视器代表synchronized lock代表锁 AtomicInteger类ReentrantReadWriteLock]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk1.9-maven-fix]]></title>
    <url>%2F2018%2F01%2F08%2Fjdk1-9-maven-fix%2F</url>
    <content type="text"><![CDATA[背景在安装了多个jdk版本后,发现maven命令不好使了 现象 maven-compiler-plugin:3.1:compile (default-compile) @ report 出现异常12345678910111213141516171819202122[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ report ---[INFO] Changes detected - recompiling the module![INFO] Compiling 60 source files to /Users/victor/code/egenieProjects/report/target/classesWARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by lombok.javac.apt.Processor to field com.sun.tools.javac.processing.JavacProcessingEnvironment.processorClassLoaderWARNING: Please consider reporting this to the maintainers of lombok.javac.apt.ProcessorWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.198 s[INFO] Finished at: 2018-01-08T14:04:55+08:00[INFO] Final Memory: 35M/115M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project report: Fatal error compiling: java.lang.NoSuchFieldError: pid -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 解决 1.9 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 9.0.1, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/HomeDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 执行命令 1echo -n &quot;JAVA_HOME=`/usr/libexec/java_home -v 1.8`&quot; &gt; ~/.mavenrc 1.8 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 1.8.0_151, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 思考虽然此种方法解决了这个问题,但具体是什么原因导致的此问题,还需进一步研究 参考http://geeekr.com/fix-maven-java-version-mac-osx/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>JDK1.9</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-sql-update-lock]]></title>
    <url>%2F2018%2F01%2F06%2Ferror-sql-update-lock%2F</url>
    <content type="text"><![CDATA[com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction 事务没有提交导致 锁等待 https://www.jianshu.com/p/0b4aaa93e7f6]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenv安装(管理多个jdk版本)]]></title>
    <url>%2F2018%2F01%2F06%2Finstall-jenv%2F</url>
    <content type="text"><![CDATA[1.安装jenv1brew install jenv 2.oracle官网下载各版本jdk 3.安装本地123jenv add /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home 4.列表jdk1jenv versions system (set by /Users/victor/.jenv/version)1.71.7.0.801.81.8.0.1519.09.0.1oracle64-1.7.0.80oracle64-1.8.0.151oracle64-9.0.1 5.选择jdk12jenv global 1.7java -version java version “1.7.0_80”Java(TM) SE Runtime Environment (build 1.7.0_80-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BI-olap技术选型]]></title>
    <url>%2F2018%2F01%2F05%2FBI-olap-tool%2F</url>
    <content type="text"><![CDATA[备选列表: 阿里云-分析性数据库 GreePlum Presto Kylin 阿里云-分析性数据库 GreePlum Greenplum采用Postgresl作为底层引擎，良好的兼容了Postgresql的功能 Greenplum的艺术，一切皆并行（Parallel Everything） Greenplum建立在Share-nothing无共享架构上，让每一颗CPU和每一块磁盘IO都运转起来，无共享架构将这种并行处理发挥到极致。相比一些其它传统数据仓库的Sharedisk架构，后者最大瓶颈就是在IO吞吐上，在大规模数据处理时，IO无法及时feed数据给到CPU，CPU资源处于wait 空转状态，无法充分利用系统资源，导致SQL效率低下 得益于Postgresql的良好扩展性（这里是extension，不是scalability），Greenplum 可以采用各种开发语言来扩展用户自定义函数（UDF） Greenplum MPP 与 Hadoop相同点 分布式存储数据在多个节点服务器上 采用分布式并行计算框架 支持横向扩展来提高整体的计算能力和存储容量 都支持X86开放集群架构 差异点 MPP按照关系数据库行列表方式存储数据（有模式），Hadoop按照文件切片方式分布式存储（无模式） 两者采用的数据分布机制不同，MPP采用Hash分布，计算节点和存储紧密耦合，数据分布粒度在记录级的更小粒度（一般在1k以下）；Hadoop FS按照文件切块后随机分配，节点和数据无耦合，数据分布粒度在文件块级（缺省64MB）。 MPP采用SQL并行查询计划，Hadoop采用Mapreduce框架 Presto Facebook贡献的开源MPP OLAP引擎。 这是一个红酒的名字，因为开发组所有的人都喜欢喝这个牌子的红酒，所以把它命名为这个名字。作为MPP引擎，它的处理方式是把所有的数据Scan出来，通过Hash的方法把数据变成更小的块，让不同的节点并发，处理完结果后快速地返回给用户。我们看到它的逻辑架构也是这样，发起一个SQL，然后找这些数据在哪些HDFS节点上，然后分配后做具体的处理，最后再把数据返回。 Kylin Kylin是由eBay开源的一个引擎，Kylin把数据读出来做计算，结算的结果会被存在HBase里，通过HBase做Ad-hoc的功能。HBase的好处是有索引的，所以做Ad-hoc的性能非常好。]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>olap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java集合并发修改]]></title>
    <url>%2F2018%2F01%2F05%2Fstudy-ConcurrentModificationException%2F</url>
    <content type="text"><![CDATA[并发修改当一个或多个线程正在遍历一个集合Collection，此时另一个线程修改了这个集合的内容（添加，删除或者修改）.这就是并发修改 快速失败（fail—fast） “快速失败”，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出ConcurrentModificationException 异常，从而产生fail-fast机制。 何时触发快速失败 无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。所以我们这里可以初步判断由于expectedModCount得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。 安全失败（fail—safe） 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 p.s.迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的 快速失败和安全失败的比较 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModification Exception Yes No Clone object No Yes Memory Overhead No Yes Examples HashMap,Vector,ArrayList,HashSet CopyOnWriteArrayList,ConcurrentHashMap 产生fail-fast的是在java.util包中的collection实现类；产生fail-safe的是在java.util.concurrent包中的collection实现类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发修改</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-skip-list]]></title>
    <url>%2F2018%2F01%2F05%2Fstudy-skip-list%2F</url>
    <content type="text"><![CDATA[跳跃表 一种基于有序链表的扩展 利用类似索引的思想,找到关键点 删除 自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。O（logN） 删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）。O（logN） 区别 跳跃表 维持平衡的成本较低,完全靠随机 二叉树需要靠rebalance来重新调整结构 应用Redis当中的Sorted-set]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>跳跃表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-red–black-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fstudy-red%E2%80%93black-tree%2F</url>
    <content type="text"><![CDATA[二叉搜索树由于红黑树本质上就是一棵二叉查找树，所以在了解红黑树之前，咱们先来看下二叉查找树。 二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 因为，一棵由n个结点，随机构造的二叉查找树的高度为lgn，所以顺理成章，一般操作的执行时间为O（lgn）.（至于n个结点的二叉树高度为lgn的证明，可参考算法导论 第12章 二叉查找树 第12.4节）。 但二叉树若退化成了一棵具有n个结点的线性链后，则此些操作最坏情况运行时间为O（n）。后面我们会看到一种基于二叉查找树-红黑树，它通过一些性质使得树相对平衡，使得最终查找、插入、删除的时间复杂度最坏情况下依然为O（lgn）。 红黑树特性前面我们已经说过，红黑树，本质上来说就是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。 但它是如何保证一棵n个结点的红黑树的高度始终保持在h = logn的呢？这就引出了红黑树的5条性质： 1）每个结点要么是红的，要么是黑的。 2）根结点是黑的。 3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 4）如果一个结点是红的，那么它的俩个儿子都是黑的。 5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度，从而也就解释了上面我们所说的“红黑树的查找、插入、删除的时间复杂度最坏为O(log n)”这一结论的原因。 如下图所示，即是一颗红黑树(下图引自wikipedia：http://t.cn/hgvH1l)： 应用 treemap treeset 1.8中的hashset https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-b-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fstudy-b-tree%2F</url>
    <content type="text"><![CDATA[b-树 数据库索引使用b-树 二叉树查找的时间复杂度O(logN) 问题:磁盘IO 最坏的情况下,磁盘IO等于索引树的高度 把原来”瘦高”的树结构变得”矮胖”就是b-树的特征之一 B树是一种多路平衡查找树 B树与红黑树最大的不同在于，B树的结点可以有许多子女，从几个到几千个。 定义 树中每个结点最多含有m个孩子（m&gt;=2）； 除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子（其中ceil(x)是一个取上限的函数）； 根结点至少有2个孩子（除非B树只包含一个结点：根结点）； 所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询失败的结点，指向这些结点的指针都为null)；（注：叶子节点只是没有孩子和指向孩子的指针，这些节点也存在，也有元素。类似红黑树中，每一个NULL指针即当做叶子结点，只是没画出来而已）。 每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，……，Kn，Pn)。其中：a) Ki (i=1…n)为关键字，且关键字按顺序升序排序K(i-1)&lt; Ki。b) Pi为指向子树根的结点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。c) 关键字的个数n必须满足： [ceil(m / 2)-1]&lt;= n &lt;= m-1。比如有j个孩子的非叶结点恰好有j-1个关键码。 应用 文件系统 数据库索引 b+树 1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 b+树种,只有叶子节点带有卫星信息,其余中间节点仅仅是索引,没有任何数据关联 在数据库的聚集索引（Clustered Index）中，叶子节点直接包含卫星数据。在非聚集索引（NonClustered Index）中，叶子节点带有指向卫星数据的指针。 B+树的优势：1.单一节点存储更多的元素，使得查询的IO次数更少。2.所有查询都要查找到叶子节点，查询性能稳定。3.所有叶子节点形成有序链表，便于范围查询。 引用 mysql的b树索引的物理文件 B*树 B-tree是B+-tree的变体，在B+树的基础上(所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针)，B树中非根和非叶子结点再增加指向兄弟的指针；B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）。 B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针。 B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。 所以，B*树分配新结点的概率比B+树要低，空间使用率更高； 总结通过以上介绍，大致将B树，B+树，B*树总结如下： B树：有序数组+平衡多叉树； B+树：有序数组链表+平衡多叉树； B*树：一棵丰满的B+树。 顺便说一句，无论是B树，还是B+树、b树，由于根或者树的上面几层被反复查询，所以这几块可以存在内存中，换言之，B树、B+树、B树的根结点和部分顶层数据在内存中，大部分下层数据在磁盘上。 mysql中InnoDB索引和MyISAM索引的区别： 主索引的区别，InnoDB的数据文件本身就是索引文件。而MyISAM的索引和数据是分开的。 辅助索引的区别：InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。 聚簇索引 非聚簇索引 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.02.md]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>b-tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK- MashMap 学习]]></title>
    <url>%2F2018%2F01%2F05%2Fstudy-hashmap%2F</url>
    <content type="text"><![CDATA[hashmap数据结构12345678910//链表static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125;//数组transient Node&lt;K,V&gt;[] table; HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干。 HashMap 使用后台数组（backing array）作为桶，并使用链表（linked list）存储键／值对。 通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Factor则resize为原来的2倍)。 获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。 如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。HashMap存储着Entry(hash, key, value, next)对象。 当key==null时，存在table[0]即第一个桶中，hash值为0。HashMap对key==null的键值对会做单独处理 Capacity的默认值为16： static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; 负载因子的默认值为0.75： static final float DEFAULT_LOAD_FACTOR = 0.75f; 简单的说，Capacity就是bucket的大小，Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话不要把Capacity设置过大，也不要把load factor设置过小。当bucket中的entries的数目大于capacity*load factor时就需要调整bucket的大小为当前的2倍。 可以设置初始容量Capacity，但是在HashMap处理过程中，是会把Capacity扩充成2的倍数 HashMap中有一个成员变量modCount，这个用来实现“fast-fail”机制（也就是快速失败）。所谓快速失败就是在并发集合中，其进行迭代操作时，若有其他线程对其结构性的修改，这是迭代器会立马感知到，并且立刻抛出ConcurrentModificationException异常，而不是等待迭代完成之后才告诉你已经出错。 get方法 取key的hashCode值 高位运算 取模运算jdk1.7的hash方法12345678910final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; jdk1.8的hash方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 混合原始哈希码的高位和低位，以此来加大低位的随机性 而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来 图片出处:https://www.zhihu.com/question/20733617 indexFor方法(根据上一步hash结果,计算数组的下表)1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; getNode/getEntry–在链表中确定元素12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; hashmap的初始长度 16,长度必须是2的幂 之所以16是为了服务于哈希函数 index = HashCode（Key） &amp; （Length - 1） 与运算，101110001110101110 1001 &amp; 1111 = 1001，十进制是9，所以 index=9。 Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位 效果上等同于取模,而且大大提高了性能 put方法 先插找 如果已存在,则替换 如果不存在,插入 检查是否需要rehash rehash用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。 hashmap在扩容时候的步骤之一 衡量HashMap是否进行Resize的条件如下： HashMap.Size &gt;= Capacity * LoadFactor 具体两个步骤 1.扩容:创建一个新的Entry空数组，长度是原数组的2倍。 2.ReHash:遍历原Entry数组，把所有的Entry重新Hash到新数组 1.7源码123456789101112131415161718192021222324252627282930 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置 在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 其他博客中resize的错误表述:1对于原bullet中的链表中的数据在扩容之后肯定还在一个链表中，因为hash值是一样的 此描述是错误的,在一个链表中,不一定代表hash是一样的,只是代表hash&amp;(length-1)计算后的结果是一样的 并发问题 ReHash在并发的情况下可能会形成链表环。 让下一次循环出现死循环 ConcurrentHashMap 避免hashmap的方法有:hashtable,Collections.sysnchronizedMap 但是上面的都有性能问题,导致阻塞 Sement 可以说，ConcurrentHashMap是一个二级哈希表。在一个总的哈希表下面，有若干个子哈希表。这样的二级结构，和数据库的水平拆分有些相似。 不同Segment的写入是可以并发执行的。 同一Segment的一写一读 同一Segment的并发写入 12345678910111213141516171819202122Get方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.再次通过hash值，定位到Segment当中数组的具体位置。Put方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.获取可重入锁4.再次通过hash值，定位到Segment当中数组的具体位置。5.插入或覆盖HashEntry对象。6.释放锁。 如果在统计Segment元素数量的过程中，已统计过的Segment瞬间插入新的元素，这时候该怎么办呢？ 123456789101112131415ConcurrentHashMap的Size方法是一个嵌套循环，大体逻辑如下：1.遍历所有的Segment。2.把Segment的元素数量累加起来。3.把Segment的修改次数累加起来。4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。7.释放锁，统计结束。 为了尽量不锁住所有Segment，首先乐观地假设Size过程中不会有修改。当尝试一定次数，才无奈转为悲观锁，锁住所有Segment保证强一致性。 jdk 1.8hashmap HashMap采用的是数组+链表+红黑树的形式。 什么时候链表转化为红黑树？当数组大小已经超过64并且链表中的元素个数超过默认设定（8个）时，将链表转化为红黑树 jdk 1.8ConcurrentHashMap与hashTable的区别 继承的父类不同:Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类， 线程安全性不同:Hashtable 中的方法是Synchronize的 是否提供contains方法:HashMap把Hashtable的contains方法去掉了 key和value是否允许null值:Hashtable中，key和value都不允许出现null值。HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。 两个遍历方式的内部实现上不同:Hashtable还使用了Enumeration的方式 。 hash值不同:哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。 内部实现使用的数组初始化和扩容方式不同:Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 数据结构要知道hashmap是什么，首先要搞清楚它的数据结构，在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，hashmap也不例外。Hashmap实际上是一个数组和链表的结合体（在数据结构中，一般称之为“链表散列“） 哈希冲突概念 hashcode通过hash算法得到有限的地址区间 哈希冲突：由于哈希算法被计算的数据是无限的，而计算后的结果范围有限，因此总会存在不同的数据经过计算后得到的值相同，这就是哈希冲突。 解决哈希冲突的方法 开放定址法 开放定址法需要的表长度要大于等于所需要存放的元素。 线行探查法 它从发生冲突的单元起，依次判断下一个单元是否为空，当达到最后一个单元时，再从表首依次判断。直到碰到空闲的单元或者探查完全部单元为止。 平方探查法 双散列函数探查法 链地址法（拉链法） 注：在java中，链接地址法也是HashMap解决哈希冲突的方法之一，jdk1.7完全采用单链表来存储同义词，jdk1.8则采用了一种混合模式，对于链表长度大于8的，会转换为红黑树存储。 再哈希法 就是同时构造多个不同的哈希函数,发生冲突时，再用H2 = RH2(key) 进行计算，直到冲突不再产生，这种方法不易产生聚集，但是增加了计算时间。 建立公共溢出区 将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。 1.8源码hash算法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 混合高位和地位,以此来加大地位的随机性 数组的位置: (n - 1) &amp; hash 确定数组后,链表中确定相同的方法: e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))) always check first node 在一个数组中,不代表hash是一样的,so必须判断 数组的长度:因为16是2的整数次幂的原因,n-1 二进制中都是x个1,这样,更能减少key之间的碰撞 位运算符(知识补充)左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; )位与、位或、位异或、位非 123456789101112131415161718192021222324255&lt;&lt;20000 0000 0000 0000 0000 0000 0000 0101 然后左移2位后，低位补0：0000 0000 0000 0000 0000 0000 0001 0100 换算成10进制为205&gt;&gt;2还是先将5转为2进制表示形式：0000 0000 0000 0000 0000 0000 0000 0101 然后右移2位，高位补0：0000 0000 0000 0000 0000 0000 0000 0001-5&gt;&gt;&gt;3-5换算成二进制： 1111 1111 1111 1111 1111 1111 1111 1011-5无符号右移3位后的结果 536870911 换算成二进制： 0001 1111 1111 1111 1111 1111 1111 1111 // (用0进行补位)------------位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为05 &amp; 35转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 00111转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 0001位异或：第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为05 ^ 35转换为二进制：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制：0000 0000 0000 0000 0000 0000 0000 00116转换为二进制：0000 0000 0000 0000 0000 0000 0000 0110 参考http://blog.csdn.net/u013256816/article/details/50912762https://tech.meituan.com/java-hashmap.htmlhttps://bestswifter.com/hashtable/ 更新日志 2018.01.22:终于理解这段的代码:e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>java</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-线性回归]]></title>
    <url>%2F2018%2F01%2F03%2Fjikeshijian-ai-base-study-linear-regression%2F</url>
    <content type="text"><![CDATA[概念 线性回归假设输出变量是若干输入变量的线性组合,并根据这一关系求解线性组合中的最优系数. 误差 在线性回归中,误差误差是以军方误差来定义的 求解 当线性回归的模型为二维平面上的直线时,军方误差就是预测输出和真实输出之间的欧几里得距离 求解方法是:最小二乘法 防止过拟合 存在多个最优解,意味着存在拟合,要解决过拟合问题,常见的做法是正则化,即添加额外的惩罚项,可分为两种:灵回过和LASSO回归 岭回归又被称作”参数衰减” LASSO回归,全程是”最小绝对缩减和选择算子” 与岭回归相比,LASSO回归的特点在于稀疏性的引入,时间花复杂问题的常用方法,在数据压缩,信号处理等其他领域中已有广泛的应用]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-机器学习概率]]></title>
    <url>%2F2018%2F01%2F02%2Fjikeshijian-ai-base-study-outline%2F</url>
    <content type="text"><![CDATA[概念 经验学习:从大量现象中提取反复出现的规律和模式 计算机给予数据构建概率统计模型并与应用模型对数据进行预测与分析的学科 根据输入输出类型的不行,预测问题分为三类 分类问题:输出离散变量 回归问题:连续变量 标注问题:序列 实际中就会存在误差,机器学习也是一样(误差性能) 误差并定义为学习器的实际预测与样本真实输出之间的差异 误差分为训练误差和测试误差 典型的过拟合现象:训练误差较低,但是训练误差较低 欠拟合:学习能力太弱 整体来看,测试误差与模型复杂度之间呈现得是抛物线的关系 交叉验证法,重复利用有限的样本,不同模型中平均测试误差最小的模型就是最有模型 调参:性能和效率之间的这种 根据训练数据是否有标签信息,可以将机器学习的任务分为三类 监督学习 无监督学习 半监督学习 监督学习分为: 生成方法:更快的收敛速度和更广的应用范围 判别方法:更高的准确性和更简单的使用方式 生成/判别方法 https://www.zhihu.com/question/20446337 有监督机器学习方法可以分为生成方法和判别方法 常见的生成方法有混合高斯模型、朴素贝叶斯法和隐形马尔科夫模型等 常见的判别方法有SVM、LR等 生成模型的求解思路是：联合分布——-&gt;求解类别先验概率和类别条件概率 判别模型求解的思路是：条件分布——&gt;模型参数后验概率最大——-&gt;（似然函数\cdot 参数先验）最大——-&gt;最大似然 生成模型:要知道原始数据的概率密度（或者估计参数得到），然后习惯用bayes理论去做预测 判别模型是不需要知道原始数据概率密度，比较粗线条 wiki例子 假设有四个samples： 生成式模型的世界是这个样子： 而判定式模型的世界是这个样子：]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-saleorder]]></title>
    <url>%2F2017%2F12%2F28%2Ferror-saleorder%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## An error report file with more information is saved as:# /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#Process finished with exit code 134 (interrupted by signal 6: SIGABRT) /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log中的文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#--------------- T H R E A D ---------------Current thread (0x00007fae5502f800): VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251]siginfo: si_signo: 11 (SIGSEGV), si_code: 1 (SEGV_MAPERR), si_addr: 0x00007f2e56b22522Registers:RAX=0x000000010c14e578, RBX=0x000000010c5c9148, RCX=0x0000000000330006, RDX=0x000000000000060aRSP=0x000070000d787430, RBP=0x000070000d787430, RSI=0x0000000000000000, RDI=0x00007f2e56b22520R8 =0x0000000000000007, R9 =0x00007fae56abe9c0, R10=0x000007fae56abee1, R11=0x0000000000000008R12=0x00000000000007d0, R13=0x000000010c5c9148, R14=0x000000000000034d, R15=0x0000000000000001RIP=0x000000010146e882, EFLAGS=0x0000000000010246, ERR=0x0000000000000004 TRAPNO=0x000000000000000eTop of Stack: (sp=0x000070000d787430)0x000070000d787430: 000070000d787450 000000010111c8970x000070000d787440: 000000010c5c9148 000000010c5c91480x000070000d787450: 000070000d787470 000000010112057c0x000070000d787460: 00007fae54611360 000000010c5c91480x000070000d787470: 000070000d787490 00000001011205f90x000070000d787480: 000000010c5c9148 00007fae546113600x000070000d787490: 000070000d7874c0 00000001010c46560x000070000d7874a0: 0000000000000003 0000000101518ec80x000070000d7874b0: 00007fae54611360 00000000000000030x000070000d7874c0: 000070000d787500 00000001010c8e640x000070000d7874d0: 000000010137f91e 00007fae546113600x000070000d7874e0: 000000010182d590 00000000000000000x000070000d7874f0: 000000010182d501 00007fae54502d100x000070000d787500: 000070000d787520 00000001010c8ec60x000070000d787510: 0000000000000000 00000000000000000x000070000d787520: 000070000d787550 00000001010c8f500x000070000d787530: 000070000d787550 00000001010c831b0x000070000d787540: 000000010182d501 000000010182d5010x000070000d787550: 000070000d787590 00000001010c8ff20x000070000d787560: 0000000000000000 000000010182d5900x000070000d787570: 0000000000000000 00007fae553f3ce00x000070000d787580: 000000010182d590 000070000d7876e00x000070000d787590: 000070000d7875b0 0000000101474c300x000070000d7875a0: 000070000d787690 000000010182d5900x000070000d7875b0: 000070000d787760 00000001013ff48b0x000070000d7875c0: 000000010182d810 000000000000001c0x000070000d7875d0: 0000000000000000 00000000000003a50x000070000d7875e0: 0000000000000172 00000000000000110x000070000d7875f0: 000000010151e9b3 00000000000000800x000070000d787600: 000070000d787640 00007fff6764d5620x000070000d787610: 000070000d787728 00000000000000000x000070000d787620: 00000000000003a5 0000000000000172 Instructions: (pc=0x000000010146e882)0x000000010146e862: 4c 89 e6 e8 c8 d0 f5 ff 49 ff c7 0f b7 03 41 390x000000010146e872: c7 7c e2 48 8d 35 25 da 0a 00 eb a5 55 48 89 e50x000000010146e882: 66 83 7f 02 00 79 02 5d c3 48 83 c7 02 5d e9 f70x000000010146e892: 74 b9 ff 90 55 48 89 e5 66 83 7f 02 00 79 02 5d Register to memory mapping:RAX=0x000000010c14e578 is pointing into metadataRBX=0x000000010c5c9148 is pointing into metadataRCX=0x0000000000330006 is an unknown valueRDX=0x000000000000060a is an unknown valueRSP=0x000070000d787430 is an unknown valueRBP=0x000070000d787430 is an unknown valueRSI=0x0000000000000000 is an unknown valueRDI=0x00007f2e56b22520 is an unknown valueR8 =0x0000000000000007 is an unknown valueR9 =0x00007fae56abe9c0 is an unknown valueR10=0x000007fae56abee1 is an unknown valueR11=0x0000000000000008 is an unknown valueR12=0x00000000000007d0 is an unknown valueR13=0x000000010c5c9148 is pointing into metadataR14=0x000000000000034d is an unknown valueR15=0x0000000000000001 is an unknown valueStack: [0x000070000d688000,0x000070000d788000], sp=0x000070000d787430, free space=1021kNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4V [libjvm.dylib+0x1e2897] ConstantPool::unreference_symbols()+0x29V [libjvm.dylib+0x1e657c] ConstantPool::release_C_heap_structures()+0x12V [libjvm.dylib+0x1e65f9] ConstantPool::deallocate_contents(ClassLoaderData*)+0x51V [libjvm.dylib+0x18a656] void MetadataFactory::free_metadata&lt;ConstantPool*&gt;(ClassLoaderData*, ConstantPool*)+0x44V [libjvm.dylib+0x18ee64] ClassLoaderData::free_deallocate_list()+0x96V [libjvm.dylib+0x18eec6] ClassLoaderDataGraph::free_deallocate_lists()+0x1aV [libjvm.dylib+0x18ef50] ClassLoaderDataGraph::clean_metaspaces()+0x5cV [libjvm.dylib+0x18eff2] ClassLoaderDataGraph::do_unloading(BoolObjectClosure*, bool)+0x90V [libjvm.dylib+0x53ac30] SystemDictionary::do_unloading(BoolObjectClosure*, bool)+0x12V [libjvm.dylib+0x4c548b] PSParallelCompact::marking_phase(ParCompactionManager*, bool, ParallelOldTracer*)+0x52fV [libjvm.dylib+0x4c6977] PSParallelCompact::invoke_no_policy(bool)+0x41bV [libjvm.dylib+0x4c6f8b] PSParallelCompact::invoke(bool)+0x57V [libjvm.dylib+0x19eef6] CollectedHeap::collect_as_vm_thread(GCCause::Cause)+0x5eV [libjvm.dylib+0x5b2cb4] VM_CollectForMetadataAllocation::doit()+0xb0V [libjvm.dylib+0x5b9b29] VM_Operation::evaluate()+0x4fV [libjvm.dylib+0x5b8195] VMThread::evaluate_operation(VM_Operation*)+0xdfV [libjvm.dylib+0x5b85e2] VMThread::loop()+0x328V [libjvm.dylib+0x5b7f01] VMThread::run()+0x79V [libjvm.dylib+0x48bbb2] java_start(Thread*)+0xf6C [libsystem_pthread.dylib+0x36c1] _pthread_body+0x154C [libsystem_pthread.dylib+0x356d] _pthread_body+0x0C [libsystem_pthread.dylib+0x2c5d] thread_start+0xdVM_Operation (0x0000700016e3fbd8): CollectForMetadataAllocation, mode: safepoint, requested by thread 0x00007fae55a24000--------------- P R O C E S S ---------------Java Threads: ( =&gt; current thread ) 0x00007fae5638a000 JavaThread &quot;JMX server connection timeout 320&quot; daemon [_thread_blocked, id=128775, stack(0x0000700016838000,0x0000700016938000)] 0x00007fae55a24000 JavaThread &quot;RMI TCP Connection(10)-192.168.0.123&quot; daemon [_thread_blocked, id=88323, stack(0x0000700016d47000,0x0000700016e47000)] 0x00007fae55353000 JavaThread &quot;JMX server connection timeout 317&quot; daemon [_thread_blocked, id=129027, stack(0x0000700016c44000,0x0000700016d44000)] 0x00007fae55808800 JavaThread &quot;RMI TCP Connection(9)-192.168.0.123&quot; daemon [_thread_blocked, id=129283, stack(0x0000700016b41000,0x0000700016c41000)] 0x00007fae55352800 JavaThread &quot;RMI TCP Connection(8)-127.0.0.1&quot; daemon [_thread_in_native, id=129795, stack(0x0000700016a3e000,0x0000700016b3e000)] 0x00007fae5638f000 JavaThread &quot;RMI TCP Connection(7)-127.0.0.1&quot; daemon [_thread_in_native, id=130051, stack(0x000070001693b000,0x0000700016a3b000)] 0x00007fae54c28800 JavaThread &quot;DestroyJavaVM&quot; [_thread_blocked, id=4611, stack(0x000070000d073000,0x000070000d173000)] 0x00007fae5534f000 JavaThread &quot;Thread-149&quot; [_thread_blocked, id=87315, stack(0x0000700016735000,0x0000700016835000)] 0x00007fae54c23000 JavaThread &quot;RMI TCP Connection(6)-192.168.0.123&quot; daemon [_thread_in_native, id=65027, stack(0x0000700016632000,0x0000700016732000)] 0x00007fae5532b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-41&quot; daemon [_thread_blocked, id=65539, stack(0x000070001652f000,0x000070001662f000)] 0x00007fae56310800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-40&quot; daemon [_thread_blocked, id=66051, stack(0x000070001642c000,0x000070001652c000)] 0x00007fae5532a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-39&quot; daemon [_thread_blocked, id=64259, stack(0x0000700016329000,0x0000700016429000)] 0x00007fae55cc4000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-38&quot; daemon [_thread_blocked, id=63747, stack(0x0000700016226000,0x0000700016326000)] 0x00007fae55335800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-37&quot; daemon [_thread_blocked, id=66567, stack(0x0000700016123000,0x0000700016223000)] 0x00007fae54c22000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-36&quot; daemon [_thread_blocked, id=63235, stack(0x0000700016020000,0x0000700016120000)] 0x00007fae54c21800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-35&quot; daemon [_thread_blocked, id=66819, stack(0x0000700015f1d000,0x000070001601d000)] 0x00007fae56502800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-34&quot; daemon [_thread_blocked, id=67075, stack(0x0000700015e1a000,0x0000700015f1a000)] 0x00007fae55cc3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-33&quot; daemon [_thread_blocked, id=62467, stack(0x0000700015d17000,0x0000700015e17000)] 0x00007fae562fc000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-32&quot; daemon [_thread_blocked, id=67587, stack(0x0000700015c14000,0x0000700015d14000)] 0x00007fae55bd9000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-31&quot; daemon [_thread_blocked, id=67843, stack(0x0000700015b11000,0x0000700015c11000)] 0x00007fae55335000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-30&quot; daemon [_thread_blocked, id=68359, stack(0x0000700015a0e000,0x0000700015b0e000)] 0x00007fae562fa000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-29&quot; daemon [_thread_blocked, id=61443, stack(0x000070001590b000,0x0000700015a0b000)] 0x00007fae54f20800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-28&quot; daemon [_thread_blocked, id=68611, stack(0x0000700015808000,0x0000700015908000)] 0x00007fae55334000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-27&quot; daemon [_thread_blocked, id=60679, stack(0x0000700015705000,0x0000700015805000)] 0x00007fae54f1f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-26&quot; daemon [_thread_blocked, id=60467, stack(0x0000700015602000,0x0000700015702000)] 0x00007fae5631e000 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-4&quot; daemon [_thread_blocked, id=60163, stack(0x00007000154ff000,0x00007000155ff000)] 0x00007fae55cc1800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-3&quot; daemon [_thread_blocked, id=69635, stack(0x00007000153fc000,0x00007000154fc000)] 0x00007fae54d20000 JavaThread &quot;job-event-8&quot; daemon [_thread_blocked, id=70163, stack(0x00007000152f9000,0x00007000153f9000)] 0x00007fae5631f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-25&quot; daemon [_thread_blocked, id=59683, stack(0x00007000151f6000,0x00007000152f6000)] 0x00007fae55383800 JavaThread &quot;job-event-7&quot; daemon [_thread_blocked, id=59399, stack(0x00007000150f3000,0x00007000151f3000)] 0x00007fae56316800 JavaThread &quot;job-event-6&quot; daemon [_thread_blocked, id=58883, stack(0x0000700014ff0000,0x00007000150f0000)] 0x00007fae54d06800 JavaThread &quot;job-event-5&quot; daemon [_thread_blocked, id=58379, stack(0x0000700014eed000,0x0000700014fed000)] 0x00007fae56316000 JavaThread &quot;DubboResponseTimeoutScanTimer&quot; daemon [_thread_blocked, id=70915, stack(0x0000700014dea000,0x0000700014eea000)] 0x00007fae56409800 JavaThread &quot;job-event-3&quot; daemon [_thread_blocked, id=71171, stack(0x0000700014ce7000,0x0000700014de7000)] 0x00007fae5594e800 JavaThread &quot;job-event-4&quot; daemon [_thread_blocked, id=57859, stack(0x0000700014be4000,0x0000700014ce4000)] 0x00007fae5594d800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-2&quot; daemon [_thread_blocked, id=71683, stack(0x0000700014ae1000,0x0000700014be1000)] 0x00007fae56406800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-1&quot; daemon [_thread_blocked, id=71939, stack(0x00007000149de000,0x0000700014ade000)] 0x00007fae54cfa800 JavaThread &quot;job-event-2&quot; daemon [_thread_blocked, id=72195, stack(0x00007000148db000,0x00007000149db000)] 0x00007fae56405000 JavaThread &quot;job-event-1&quot; daemon [_thread_blocked, id=72723, stack(0x00007000147d8000,0x00007000148d8000)] 0x00007fae54d48800 JavaThread &quot;RMI TCP Connection(5)-192.168.0.123&quot; daemon [_thread_in_native, id=73223, stack(0x00007000146d5000,0x00007000147d5000)] 0x00007fae55341000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=73739, stack(0x00007000145d2000,0x00007000146d2000)] 0x00007fae55362800 JavaThread &quot;Curator-TreeCache-6&quot; daemon [_thread_blocked, id=56839, stack(0x00007000144cf000,0x00007000145cf000)] 0x00007fae55361800 JavaThread &quot;Timer-6&quot; daemon [_thread_blocked, id=56323, stack(0x00007000143cc000,0x00007000144cc000)] 0x00007fae5644d800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=56067, stack(0x00007000142c9000,0x00007000143c9000)] 0x00007fae5644d000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_Worker-1&quot; [_thread_blocked, id=55555, stack(0x00007000141c6000,0x00007000142c6000)] 0x00007fae55361000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=55311, stack(0x00007000140c3000,0x00007000141c3000)] 0x00007fae552de000 JavaThread &quot;Curator-TreeCache-5&quot; daemon [_thread_blocked, id=55047, stack(0x0000700013fc0000,0x00007000140c0000)] 0x00007fae54ca0800 JavaThread &quot;Timer-5&quot; daemon [_thread_blocked, id=54531, stack(0x0000700013ebd000,0x0000700013fbd000)] 0x00007fae54ca0000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_QuartzSchedulerThread&quot; [_thread_blocked, id=75011, stack(0x0000700013dba000,0x0000700013eba000)] 0x00007fae552dd000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_Worker-1&quot; [_thread_blocked, id=54019, stack(0x0000700013cb7000,0x0000700013db7000)] 0x00007fae5534b800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=75779, stack(0x0000700013bb4000,0x0000700013cb4000)] 0x00007fae55a1c000 JavaThread &quot;Curator-TreeCache-4&quot; daemon [_thread_blocked, id=76295, stack(0x0000700013ab1000,0x0000700013bb1000)] 0x00007fae5534b000 JavaThread &quot;Timer-4&quot; daemon [_thread_blocked, id=76547, stack(0x00007000139ae000,0x0000700013aae000)] 0x00007fae55a3b000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=53507, stack(0x00007000138ab000,0x00007000139ab000)] 0x00007fae54c96000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_Worker-1&quot; [_thread_blocked, id=52999, stack(0x00007000137a8000,0x00007000138a8000)] 0x00007fae5644a000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=52743, stack(0x00007000136a5000,0x00007000137a5000)] 0x00007fae56449000 JavaThread &quot;Curator-TreeCache-3&quot; daemon [_thread_blocked, id=77323, stack(0x00007000135a2000,0x00007000136a2000)] 0x00007fae54c95800 JavaThread &quot;Timer-3&quot; daemon [_thread_blocked, id=52227, stack(0x000070001349f000,0x000070001359f000)] 0x00007fae54c94800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=51971, stack(0x000070001339c000,0x000070001349c000)] 0x00007fae54c94000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_Worker-1&quot; [_thread_blocked, id=51459, stack(0x0000700013299000,0x0000700013399000)] 0x00007fae564e6800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=78351, stack(0x0000700013196000,0x0000700013296000)] 0x00007fae54c92800 JavaThread &quot;Curator-TreeCache-2&quot; daemon [_thread_blocked, id=51207, stack(0x0000700013093000,0x0000700013193000)] 0x00007fae562ef800 JavaThread &quot;Timer-2&quot; daemon [_thread_blocked, id=79107, stack(0x0000700012f90000,0x0000700013090000)] 0x00007fae562ef000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=79363, stack(0x0000700012e8d000,0x0000700012f8d000)] 0x00007fae54c91800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_Worker-1&quot; [_thread_blocked, id=79895, stack(0x0000700012d8a000,0x0000700012e8a000)] 0x00007fae5533d000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80131, stack(0x0000700012c87000,0x0000700012d87000)] 0x00007fae552a6800 JavaThread &quot;Curator-TreeCache-1&quot; daemon [_thread_blocked, id=50187, stack(0x0000700012b84000,0x0000700012c84000)] 0x00007fae55a3d800 JavaThread &quot;Timer-1&quot; daemon [_thread_blocked, id=49667, stack(0x0000700012a81000,0x0000700012b81000)] 0x00007fae55a3c800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_QuartzSchedulerThread&quot; [_thread_blocked, id=49411, stack(0x000070001297e000,0x0000700012a7e000)] 0x00007fae55be1000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_Worker-1&quot; [_thread_blocked, id=49155, stack(0x000070001287b000,0x000070001297b000)] 0x00007fae55be0800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80915, stack(0x0000700012778000,0x0000700012878000)] 0x00007fae56400000 JavaThread &quot;Curator-TreeCache-0&quot; daemon [_thread_blocked, id=81411, stack(0x0000700012675000,0x0000700012775000)] 0x00007fae563ff800 JavaThread &quot;Timer-0&quot; daemon [_thread_blocked, id=48643, stack(0x0000700012572000,0x0000700012672000)] 0x00007fae56112800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_QuartzSchedulerThread&quot; [_thread_blocked, id=48387, stack(0x000070001246f000,0x000070001256f000)] 0x00007fae562bf800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_Worker-1&quot; [_thread_blocked, id=82439, stack(0x000070001236c000,0x000070001246c000)] 0x00007fae54ae4800 JavaThread &quot;DubboClientHandler-192.168.0.157:20881-thread-1&quot; daemon [_thread_blocked, id=82703, stack(0x0000700012269000,0x0000700012369000)] 0x00007fae5533e800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-24&quot; daemon [_thread_blocked, id=82947, stack(0x0000700012166000,0x0000700012266000)] 0x00007fae54a64800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-23&quot; daemon [_thread_blocked, id=47363, stack(0x0000700012063000,0x0000700012163000)] 0x00007fae560f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-22&quot; daemon [_thread_blocked, id=83459, stack(0x0000700011f60000,0x0000700012060000)] 0x00007fae54b1b800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-21&quot; daemon [_thread_blocked, id=83971, stack(0x0000700011e5d000,0x0000700011f5d000)] 0x00007fae54b1a800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-20&quot; daemon [_thread_blocked, id=84227, stack(0x0000700011d5a000,0x0000700011e5a000)] 0x00007fae563f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-19&quot; daemon [_thread_blocked, id=46595, stack(0x0000700011c57000,0x0000700011d57000)] 0x00007fae54b1a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-18&quot; daemon [_thread_blocked, id=46083, stack(0x0000700011b54000,0x0000700011c54000)] 0x00007fae54b7f000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-17&quot; daemon [_thread_blocked, id=45831, stack(0x000070001194e000,0x0000700011a4e000)] 0x00007fae563f2000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-16&quot; daemon [_thread_blocked, id=84739, stack(0x0000700011a51000,0x0000700011b51000)] 0x00007fae54b7e000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-15&quot; daemon [_thread_blocked, id=45571, stack(0x000070001184b000,0x000070001194b000)] 0x00007fae54a3f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-14&quot; daemon [_thread_blocked, id=85507, stack(0x0000700011748000,0x0000700011848000)] 0x00007fae562a7000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-13&quot; daemon [_thread_blocked, id=45059, stack(0x0000700011645000,0x0000700011745000)] 0x00007fae54a54800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-12&quot; daemon [_thread_blocked, id=86275, stack(0x0000700011542000,0x0000700011642000)] 0x00007fae54a54000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-11&quot; daemon [_thread_blocked, id=44547, stack(0x000070001143f000,0x000070001153f000)] 0x00007fae54b76000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-10&quot; daemon [_thread_blocked, id=44035, stack(0x000070001133c000,0x000070001143c000)] 0x00007fae551ee800 JavaThread &quot;Druid-ConnectionPool-Destroy-2073021938&quot; daemon [_thread_blocked, id=86787, stack(0x0000700011239000,0x0000700011339000)] 0x00007fae55202800 JavaThread &quot;Druid-ConnectionPool-Create-2073021938&quot; daemon [_thread_blocked, id=87051, stack(0x0000700011136000,0x0000700011236000)] 0x00007fae564b8000 JavaThread &quot;Abandoned connection cleanup thread&quot; daemon [_thread_blocked, id=32003, stack(0x0000700011033000,0x0000700011133000)] 0x00007fae54976000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-9&quot; daemon [_thread_blocked, id=31763, stack(0x0000700010f30000,0x0000700011030000)] 0x00007fae552c4000 JavaThread &quot;DubboClientHandler-192.168.0.134:20880-thread-1&quot; daemon [_thread_blocked, id=31495, stack(0x0000700010e2d000,0x0000700010f2d000)] 0x00007fae54b36800 JavaThread &quot;DubboClientHandler-192.168.0.157:20887-thread-1&quot; daemon [_thread_blocked, id=31003, stack(0x0000700010d2a000,0x0000700010e2a000)] 0x00007fae5622d000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-8&quot; daemon [_thread_blocked, id=30723, stack(0x0000700010c27000,0x0000700010d27000)] 0x00007fae54b91000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-7&quot; daemon [_thread_blocked, id=33031, stack(0x0000700010b24000,0x0000700010c24000)] 0x00007fae54b8b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-6&quot; daemon [_thread_blocked, id=33283, stack(0x0000700010a21000,0x0000700010b21000)] 0x00007fae56231800 JavaThread &quot;DubboClientHandler-192.168.0.157:20883-thread-1&quot; daemon [_thread_blocked, id=29955, stack(0x000070001091e000,0x0000700010a1e000)] 0x00007fae559ae000 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-2&quot; daemon [_thread_blocked, id=29443, stack(0x000070001081b000,0x000070001091b000)] 0x00007fae552a3800 JavaThread &quot;DubboClientHandler-192.168.0.126:20882-thread-1&quot; daemon [_thread_blocked, id=34067, stack(0x0000700010718000,0x0000700010818000)] 0x00007fae56228000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-5&quot; daemon [_thread_blocked, id=28939, stack(0x0000700010615000,0x0000700010715000)] 0x00007fae56200000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-4&quot; daemon [_thread_blocked, id=34307, stack(0x0000700010512000,0x0000700010612000)] 0x00007fae54bbf800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-3&quot; daemon [_thread_blocked, id=28431, stack(0x000070001040f000,0x000070001050f000)] 0x00007fae56421800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-2&quot; daemon [_thread_blocked, id=28163, stack(0x000070001030c000,0x000070001040c000)] 0x00007fae54b66000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-1&quot; daemon [_thread_blocked, id=35339, stack(0x0000700010209000,0x0000700010309000)] 0x00007fae54bf4800 JavaThread &quot;dubbo-remoting-server-heartbeat-thread-1&quot; daemon [_thread_blocked, id=27651, stack(0x0000700010106000,0x0000700010206000)] 0x00007fae54bf3800 JavaThread &quot;New I/O server boss #12&quot; daemon [_thread_in_native, id=27139, stack(0x0000700010003000,0x0000700010103000)] 0x00007fae54b63000 JavaThread &quot;New I/O worker #11&quot; daemon [_thread_in_native, id=35843, stack(0x000070000ff00000,0x0000700010000000)] 0x00007fae54bf3000 JavaThread &quot;New I/O worker #10&quot; daemon [_thread_in_native, id=36099, stack(0x000070000fdfd000,0x000070000fefd000)] 0x00007fae54bf2000 JavaThread &quot;New I/O worker #9&quot; daemon [_thread_in_native, id=26371, stack(0x000070000fcfa000,0x000070000fdfa000)] 0x00007fae56421000 JavaThread &quot;New I/O worker #8&quot; daemon [_thread_in_native, id=36611, stack(0x000070000fbf7000,0x000070000fcf7000)] 0x00007fae54bf1800 JavaThread &quot;New I/O worker #7&quot; daemon [_thread_in_native, id=37139, stack(0x000070000faf4000,0x000070000fbf4000)] 0x00007fae54c5f800 JavaThread &quot;DubboClientReconnectTimer-thread-2&quot; daemon [_thread_blocked, id=26131, stack(0x000070000f9f1000,0x000070000faf1000)] 0x00007fae563e4800 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-1&quot; daemon [_thread_blocked, id=37891, stack(0x000070000f8ee000,0x000070000f9ee000)] 0x00007fae563e4000 JavaThread &quot;DubboClientHandler-192.168.0.157:20880-thread-1&quot; daemon [_thread_blocked, id=25859, stack(0x000070000f7eb000,0x000070000f8eb000)] 0x00007fae54c3c800 JavaThread &quot;Hashed wheel timer #1&quot; [_thread_blocked, id=25603, stack(0x000070000f6e8000,0x000070000f7e8000)] 0x00007fae56016800 JavaThread &quot;DubboClientReconnectTimer-thread-1&quot; daemon [_thread_blocked, id=25091, stack(0x000070000f5e5000,0x000070000f6e5000)] 0x00007fae54a33800 JavaThread &quot;New I/O boss #6&quot; daemon [_thread_in_native, id=38659, stack(0x000070000f4e2000,0x000070000f5e2000)] 0x00007fae54c3e000 JavaThread &quot;New I/O worker #5&quot; daemon [_thread_blocked, id=24579, stack(0x000070000f3df000,0x000070000f4df000)] 0x00007fae561d4800 JavaThread &quot;New I/O worker #4&quot; daemon [_thread_in_native, id=39427, stack(0x000070000f2dc000,0x000070000f3dc000)] 0x00007fae561c7800 JavaThread &quot;New I/O worker #3&quot; daemon [_thread_in_native, id=39683, stack(0x000070000f1d9000,0x000070000f2d9000)] 0x00007fae561c6800 JavaThread &quot;New I/O worker #2&quot; daemon [_thread_in_native, id=24067, stack(0x000070000f0d6000,0x000070000f1d6000)] 0x00007fae561cb800 JavaThread &quot;New I/O worker #1&quot; daemon [_thread_blocked, id=23811, stack(0x000070000efd3000,0x000070000f0d3000)] 0x00007fae55c61000 JavaThread &quot;DubboSaveRegistryCache-thread-1&quot; daemon [_thread_blocked, id=40459, stack(0x000070000eed0000,0x000070000efd0000)] 0x00007fae561c6000 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=40963, stack(0x000070000edcd000,0x000070000eecd000)] 0x00007fae56502000 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_in_native, id=41475, stack(0x000070000ecca000,0x000070000edca000)] 0x00007fae56501000 JavaThread &quot;ZkClient-EventThread-50-192.168.0.156:2181&quot; daemon [_thread_blocked, id=23307, stack(0x000070000ebc7000,0x000070000ecc7000)] 0x00007fae564fc000 JavaThread &quot;DubboRegistryFailedRetryTimer-thread-1&quot; daemon [_thread_blocked, id=5703, stack(0x000070000eac4000,0x000070000ebc4000)] 0x00007fae55283800 JavaThread &quot;Curator-Framework-0&quot; daemon [_thread_blocked, id=42243, stack(0x000070000e9c1000,0x000070000eac1000)] 0x00007fae55282800 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=42499, stack(0x000070000e8be000,0x000070000e9be000)] 0x00007fae564f2800 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_blocked, id=22787, stack(0x000070000e7bb000,0x000070000e8bb000)] 0x00007fae5526d800 JavaThread &quot;Curator-ConnectionStateManager-0&quot; daemon [_thread_blocked, id=43047, stack(0x000070000e6b8000,0x000070000e7b8000)] 0x00007fae55aad000 JavaThread &quot;RMI TCP Connection(3)-192.168.0.123&quot; daemon [_thread_in_native, id=43267, stack(0x000070000e5b5000,0x000070000e6b5000)] 0x00007fae551e2000 JavaThread &quot;RMI Scheduler(0)&quot; daemon [_thread_blocked, id=21763, stack(0x000070000e4b2000,0x000070000e5b2000)] 0x00007fae5497b000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=15875, stack(0x000070000e2ac000,0x000070000e3ac000)] 0x00007fae55a09000 JavaThread &quot;RMI TCP Connection(1)-127.0.0.1&quot; daemon [_thread_in_native, id=15363, stack(0x000070000e1a9000,0x000070000e2a9000)] 0x00007fae55a16000 JavaThread &quot;RMI TCP Accept-52007&quot; daemon [_thread_in_native, id=16899, stack(0x000070000e0a6000,0x000070000e1a6000)] 0x00007fae5617f000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=17155, stack(0x000070000dfa3000,0x000070000e0a3000)] 0x00007fae54956800 JavaThread &quot;Service Thread&quot; daemon [_thread_blocked, id=17411, stack(0x000070000dea0000,0x000070000dfa0000)] 0x00007fae560f0000 JavaThread &quot;C1 CompilerThread2&quot; daemon [_thread_blocked, id=14083, stack(0x000070000dd9d000,0x000070000de9d000)] 0x00007fae5593f000 JavaThread &quot;C2 CompilerThread1&quot; daemon [_thread_blocked, id=13571, stack(0x000070000dc9a000,0x000070000dd9a000)] 0x00007fae560ef800 JavaThread &quot;C2 CompilerThread0&quot; daemon [_thread_blocked, id=17923, stack(0x000070000db97000,0x000070000dc97000)] 0x00007fae55034000 JavaThread &quot;Monitor Ctrl-Break&quot; daemon [_thread_in_native, id=18435, stack(0x000070000da94000,0x000070000db94000)] 0x00007fae5600f000 JavaThread &quot;Signal Dispatcher&quot; daemon [_thread_blocked, id=12811, stack(0x000070000d991000,0x000070000da91000)] 0x00007fae5482b000 JavaThread &quot;Finalizer&quot; daemon [_thread_blocked, id=11779, stack(0x000070000d88e000,0x000070000d98e000)] 0x00007fae55032800 JavaThread &quot;Reference Handler&quot; daemon [_thread_blocked, id=20995, stack(0x000070000d78b000,0x000070000d88b000)]Other Threads:=&gt;0x00007fae5502f800 VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251] 0x00007fae5497b800 WatcherThread [stack: 0x000070000e3af000,0x000070000e4af000] [id=16131]VM state:at safepoint (normal execution)VM Mutex/Monitor currently owned by a thread: ([mutex/lock_event])[0x00007fae54601800] Threads_lock - owner thread: 0x00007fae5502f800[0x00007fae54601d00] Heap_lock - owner thread: 0x00007fae55a24000Heap: PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KCard table byte_map: [0x0000000102bc0000,0x0000000102fc1000] byte_map_base: 0x00000000ff1c0000Marking Bits: (ParMarkBitMap*) 0x000000010182d5d0 Begin Bits: [0x000000010326c000, 0x000000010526c000) End Bits: [0x000000010526c000, 0x000000010726c000)Polling page: 0x0000000101f24000CodeCache: size=245760Kb used=13228Kb max_used=13248Kb free=232531Kb bounds [0x000000010d78b000, 0x000000010e48b000, 0x000000011c78b000] total_blobs=6800 nmethods=6274 adapters=438 compilation: enabledCompilation events (10 events):Event: 72.788 Thread 0x00007fae560f0000 nmethod 6375 0x000000010dd32b10 code [0x000000010dd32c80, 0x000000010dd32da8]Event: 72.790 Thread 0x00007fae560f0000 6376 1 com.sun.jmx.mbeanserver.MBeanSupport::invoke (19 bytes)Event: 72.790 Thread 0x00007fae560f0000 nmethod 6376 0x000000010dd50590 code [0x000000010dd50700, 0x000000010dd50898]Event: 72.792 Thread 0x00007fae560f0000 6377 1 javax.management.remote.rmi.RMIConnectionImpl::nullIsEmpty (12 bytes)Event: 72.793 Thread 0x00007fae560f0000 nmethod 6377 0x000000010dd502d0 code [0x000000010dd50420, 0x000000010dd50530]Event: 72.793 Thread 0x00007fae560f0000 6378 1 com.sun.jmx.mbeanserver.PerInterface::invoke (269 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6378 0x000000010dd3e510 code [0x000000010dd3e820, 0x000000010dd3f4a8]Event: 72.797 Thread 0x00007fae560f0000 6379 1 javax.management.remote.rmi.RMIConnectionImpl$6::run (17 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6379 0x000000010dd3e190 code [0x000000010dd3e300, 0x000000010dd3e448]Event: 72.797 Thread 0x00007fae560f0000 6380 ! 1 javax.management.remote.rmi.RMIConnectionImpl::unwrap (301 bytes)GC Heap History (10 events):Event: 54.010 GC heap afterHeap after GC invocations=24 (full 3): PSYoungGen total 611840K, used 34359K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40321K, capacity 41992K, committed 42112K, reserved 1085440K class space used 4923K, capacity 5182K, committed 5248K, reserved 1048576K&#125;Event: 55.308 GC heap before&#123;Heap before GC invocations=25 (full 3): PSYoungGen total 611840K, used 568887K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 100% used [0x0000000795580000,0x00000007b5f80000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576KEvent: 55.332 GC heap afterHeap after GC invocations=25 (full 3): PSYoungGen total 617472K, used 47568K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576K&#125;Event: 56.843 GC heap before&#123;Heap before GC invocations=26 (full 3): PSYoungGen total 617472K, used 589776K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576KEvent: 56.881 GC heap afterHeap after GC invocations=26 (full 3): PSYoungGen total 586752K, used 44259K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576K&#125;Event: 71.208 GC heap before&#123;Heap before GC invocations=27 (full 3): PSYoungGen total 586752K, used 586467K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576KEvent: 71.246 GC heap afterHeap after GC invocations=27 (full 3): PSYoungGen total 623616K, used 33938K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576K&#125;Event: 72.798 GC heap before&#123;Heap before GC invocations=28 (full 3): PSYoungGen total 623616K, used 66204K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 5% used [0x0000000795580000,0x0000000797502a20,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KEvent: 72.833 GC heap afterHeap after GC invocations=28 (full 3): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576K&#125;Event: 72.833 GC heap before&#123;Heap before GC invocations=29 (full 4): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KDeoptimization events (0 events):No eventsInternal exceptions (10 events):Event: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeBeanInfo&gt; (0x0000000795895208) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictionaEvent: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeCustomizer&gt; (0x00000007958b3560) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictioEvent: 71.290 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795901e88) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanBeanInfo&gt; (0x00000007959c81d8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanCustomizer&gt; (0x00000007959ea158) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/syEvent: 71.309 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795a1a220) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.327 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b18538) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2dd00) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2ead8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b34770) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Events (10 events):Event: 72.768 Thread 0x00007fae560f0000 flushing nmethod 0x000000010df51bd0Event: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparatorEvent: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparator doneEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContextEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContext doneEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContextEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContext doneEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$SegmentEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$Segment doneEvent: 72.798 Executing VM operation: CollectForMetadataAllocationDynamic libraries:0x000000001832f000 /System/Library/Frameworks/Cocoa.framework/Versions/A/Cocoa0x000000001832f000 /System/Library/Frameworks/Security.framework/Versions/A/Security0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices0x000000001832f000 /usr/lib/libz.1.dylib0x000000001832f000 /usr/lib/libSystem.B.dylib0x000000001832f000 /usr/lib/libobjc.A.dylib0x000000001832f000 /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation0x000000001832f000 /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation0x000000001832f000 /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit0x000000001832f000 /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData0x000000001832f000 /System/Library/PrivateFrameworks/RemoteViewServices.framework/Versions/A/RemoteViewServices0x000000001832f000 /System/Library/PrivateFrameworks/UIFoundation.framework/Versions/A/UIFoundation0x000000001832f000 /System/Library/PrivateFrameworks/DFRFoundation.framework/Versions/A/DFRFoundation0x000000001832f000 /System/Library/Frameworks/Metal.framework/Versions/A/Metal0x000000001832f000 /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv0x000000001832f000 /usr/lib/libenergytrace.dylib0x000000001832f000 /System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight0x000000001832f000 /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics0x000000001832f000 /usr/lib/libScreenReader.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate0x000000001832f000 /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface0x000000001832f000 /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox0x000000001832f000 /System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit0x000000001832f000 /System/Library/PrivateFrameworks/DataDetectorsCore.framework/Versions/A/DataDetectorsCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox0x000000001832f000 /usr/lib/libicucore.A.dylib0x000000001832f000 /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition0x000000001832f000 /usr/lib/libauto.dylib0x000000001832f000 /usr/lib/libxml2.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI0x000000001832f000 /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio0x000000001832f000 /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration0x000000001832f000 /usr/lib/liblangid.dylib0x000000001832f000 /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport0x000000001832f000 /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit0x000000001832f000 /usr/lib/libDiagnosticMessagesClient.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices0x000000001832f000 /System/Library/PrivateFrameworks/PerformanceAnalysis.framework/Versions/A/PerformanceAnalysis0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL0x000000001832f000 /System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync0x000000001832f000 /System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage0x000000001832f000 /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO0x000000001832f000 /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup0x000000001832f000 /usr/lib/libarchive.2.dylib0x000000001832f000 /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork0x000000001832f000 /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration0x000000001832f000 /usr/lib/libCRFSuite.dylib0x000000001832f000 /usr/lib/libc++.1.dylib0x000000001832f000 /usr/lib/libc++abi.dylib0x000000001832f000 /usr/lib/system/libcache.dylib0x000000001832f000 /usr/lib/system/libcommonCrypto.dylib0x000000001832f000 /usr/lib/system/libcompiler_rt.dylib0x000000001832f000 /usr/lib/system/libcopyfile.dylib0x000000001832f000 /usr/lib/system/libcorecrypto.dylib0x000000001832f000 /usr/lib/system/libdispatch.dylib0x000000001832f000 /usr/lib/system/libdyld.dylib0x000000001832f000 /usr/lib/system/libkeymgr.dylib0x000000001832f000 /usr/lib/system/liblaunch.dylib0x000000001832f000 /usr/lib/system/libmacho.dylib0x000000001832f000 /usr/lib/system/libquarantine.dylib0x000000001832f000 /usr/lib/system/libremovefile.dylib0x000000001832f000 /usr/lib/system/libsystem_asl.dylib0x000000001832f000 /usr/lib/system/libsystem_blocks.dylib0x000000001832f000 /usr/lib/system/libsystem_c.dylib0x000000001832f000 /usr/lib/system/libsystem_configuration.dylib0x000000001832f000 /usr/lib/system/libsystem_coreservices.dylib0x000000001832f000 /usr/lib/system/libsystem_darwin.dylib0x000000001832f000 /usr/lib/system/libsystem_dnssd.dylib0x000000001832f000 /usr/lib/system/libsystem_info.dylib0x000000001832f000 /usr/lib/system/libsystem_m.dylib0x000000001832f000 /usr/lib/system/libsystem_malloc.dylib0x000000001832f000 /usr/lib/system/libsystem_network.dylib0x000000001832f000 /usr/lib/system/libsystem_networkextension.dylib0x000000001832f000 /usr/lib/system/libsystem_notify.dylib0x000000001832f000 /usr/lib/system/libsystem_sandbox.dylib0x000000001832f000 /usr/lib/system/libsystem_secinit.dylib0x000000001832f000 /usr/lib/system/libsystem_kernel.dylib0x000000001832f000 /usr/lib/system/libsystem_platform.dylib0x000000001832f000 /usr/lib/system/libsystem_pthread.dylib0x000000001832f000 /usr/lib/system/libsystem_symptoms.dylib0x000000001832f000 /usr/lib/system/libsystem_trace.dylib0x000000001832f000 /usr/lib/system/libunwind.dylib0x000000001832f000 /usr/lib/system/libxpc.dylib0x000000001832f000 /usr/lib/closure/libclosured.dylib0x000000001832f000 /usr/lib/libbsm.0.dylib0x000000001832f000 /usr/lib/system/libkxld.dylib0x000000001832f000 /usr/lib/libOpenScriptingUtil.dylib0x000000001832f000 /usr/lib/libcoretls.dylib0x000000001832f000 /usr/lib/libcoretls_cfhelpers.dylib0x000000001832f000 /usr/lib/libpam.2.dylib0x000000001832f000 /usr/lib/libsqlite3.dylib0x000000001832f000 /usr/lib/libxar.1.dylib0x000000001832f000 /usr/lib/libbz2.1.0.dylib0x000000001832f000 /usr/lib/liblzma.5.dylib0x000000001832f000 /usr/lib/libnetwork.dylib0x000000001832f000 /usr/lib/libapple_nghttp2.dylib0x000000001832f000 /usr/lib/libpcap.A.dylib0x000000001832f000 /usr/lib/libboringssl.dylib0x000000001832f000 /usr/lib/libusrtcp.dylib0x000000001832f000 /usr/lib/libapple_crypto.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList0x000000001832f000 /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS0x000000001832f000 /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth0x000000001832f000 /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport0x000000001832f000 /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC0x000000001832f000 /usr/lib/libmecabra.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis0x000000001832f000 /System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib0x000000001832f000 /System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator0x000000001832f000 /System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment0x000000001832f000 /System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib0x000000001832f000 /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo0x000000001832f000 /System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders0x000000001832f000 /usr/lib/libFosl_dynamic.dylib0x000000001832f000 /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore0x000000001832f000 /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL0x000000001832f000 /usr/lib/libcompression.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG0x000000001832f000 /System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib0x000000001832f000 /usr/lib/libcups.2.dylib0x000000001832f000 /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos0x000000001832f000 /System/Library/Frameworks/GSS.framework/Versions/A/GSS0x000000001832f000 /usr/lib/libresolv.9.dylib0x000000001832f000 /usr/lib/libiconv.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal0x000000001832f000 /usr/lib/libheimdal-asn1.dylib0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory0x000000001832f000 /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory0x000000001832f000 /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation0x000000001832f000 /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS0x000000001832f000 /usr/lib/libutil.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce0x000000001832f000 /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData0x000000001832f000 /usr/lib/libmarisa.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon0x000000001832f000 /usr/lib/libChineseTokenizer.dylib0x000000001832f000 /usr/lib/libcmph.dylib0x000000001832f000 /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling0x000000001832f000 /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji0x000000001832f000 /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement0x000000001832f000 /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement0x000000001832f000 /usr/lib/libxslt.1.dylib0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink0x000000001832f000 /System/Library/PrivateFrameworks/TextureIO.framework/Versions/A/TextureIO0x000000001832f000 /usr/lib/libate.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport0x000000001832f000 /System/Library/PrivateFrameworks/Sharing.framework/Versions/A/Sharing0x000000001832f000 /System/Library/PrivateFrameworks/IconServices.framework/Versions/A/IconServices0x000000001832f000 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/Versions/A/ProtocolBuffer0x000000001832f000 /System/Library/PrivateFrameworks/Apple80211.framework/Versions/A/Apple802110x000000001832f000 /System/Library/Frameworks/CoreWLAN.framework/Versions/A/CoreWLAN0x000000001832f000 /System/Library/PrivateFrameworks/CoreUtils.framework/Versions/A/CoreUtils0x000000001832f000 /System/Library/Frameworks/IOBluetooth.framework/Versions/A/IOBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/CoreWiFi.framework/Versions/A/CoreWiFi0x000000001832f000 /System/Library/Frameworks/CoreBluetooth.framework/Versions/A/CoreBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/SignpostNotification.framework/Versions/A/SignpostNotification0x000000001832f000 /System/Library/PrivateFrameworks/DebugSymbols.framework/Versions/A/DebugSymbols0x000000001832f000 /System/Library/PrivateFrameworks/CoreSymbolication.framework/Versions/A/CoreSymbolication0x000000001832f000 /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication0x000000001832f000 /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression0x000000001832f000 /System/Library/PrivateFrameworks/SpeechRecognitionCore.framework/Versions/A/SpeechRecognitionCore0x000000001832f000 /System/Library/CoreServices/Encodings/libSimplifiedChineseConverter.dylib0x0000000100f3a000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib0x000000001832f000 /usr/lib/libstdc++.6.0.9.dylib0x0000000101ee1000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libverify.dylib0x0000000101eef000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libjava.dylib0x0000000101f25000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libinstrument.dylib0x0000000101fc3000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libzip.dylib0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaRuntimeSupport.framework/Versions/A/JavaRuntimeSupport0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaNativeFoundation.framework/Versions/A/JavaNativeFoundation0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/JavaVM0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon0x000000001832f000 /System/Library/PrivateFrameworks/JavaLaunching.framework/Versions/A/JavaLaunching0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI0x000000010ae78000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnet.dylib0x000000010aed7000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libmanagement.dylib0x000000010aee5000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnio.dylibVM Arguments:jvm_args: -XX:TieredStopAtLevel=1 -Xverify:none -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=52007 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=52008:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8 java_command: com.ejlerp.saleorder.SaleOrderProviderApplicationjava_class_path (initial): /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomeLauncher Type: SUN_STANDARDEnvironment Variables:JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomePATH=/Users/victor/jar/byteman-download-3.0.10/bin:/Users/victor/jar/btrace-bin-1.3.10/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbinSHELL=/bin/bashSignal Handlers:SIGSEGV: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_ONSTACK|SA_RESTART|SA_SIGINFOSIGBUS: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGFPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGPIPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGXFSZ: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGILL: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGUSR1: SIG_DFL, sa_mask[0]=00000000000000000000000000000000, sa_flags=noneSIGUSR2: [libjvm.dylib+0x488ce2], sa_mask[0]=00100000000000000000000000000000, sa_flags=SA_RESTART|SA_SIGINFOSIGHUP: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGINT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGTERM: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGQUIT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFO--------------- S Y S T E M ---------------OS:Bsduname:Darwin 17.3.0 Darwin Kernel Version 17.3.0: Thu Nov 9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64rlimit: STACK 8192k, CORE 0k, NPROC 709, NOFILE 10240, AS infinityload average:5.50 4.41 3.51CPU:total 4 (initial active 4) (2 cores per cpu, 2 threads per core) family 6 model 61 stepping 4, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, avx, avx2, aes, clmul, erms, 3dnowpref, lzcnt, ht, tsc, tscinvbit, bmi1, bmi2, adxMemory: 4k page, physical 8388608k(184936k free)/proc/meminfo:vm_info: Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for bsd-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:37:08 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)time: Thu Dec 28 15:17:01 2017elapsed time: 72 seconds (0d 0h 1m 12s)]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-web-zookeeper]]></title>
    <url>%2F2017%2F12%2F28%2Ferror-web-zookeeper%2F</url>
    <content type="text"><![CDATA[123452017-12-26 19:42:40.907 WARN [localhost-startStop-1-SendThread(10.26.235.193:2181)][ClientCnxn.java:1162] - Session 0x15e05c1c95a0370 for server 10.26.235.193/10.26.235.193:2181, unexpected error, closing socket connection and attempting reconnectjava.lang.NoClassDefFoundError: org/apache/zookeeper/proto/SetWatches at org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:926) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.8.jar:3.4.8--1] 问题 问题1:一直包上面的错误 问题2:26号把25号的日志给覆盖了,同时15号的错误日志也写到了9号的文件中]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2Fstudy-snowboard%2F</url>
    <content type="text"><![CDATA[goski视频教学走刃练习 前刃,后刃(不间断的跳,掌握重心重心和支撑的感觉) 向刃上加压力 直线加速,然后骤停 用刃向上跳。(前后刃) 换刃转身练习 双手抓裤子 防止搓雪太多 回山动作 如果能上去 代表 中心 不止是在前脚 两种转弯技巧 刻滑和扫雪 央视视频教学连续小回转 如羚羊一般自如 换刃平稳性检测双手背上放学块,不掉下来,说明稳定性高 滑雪助手视频教学换刃 重心前脚。身体站起。 直滑降 重心中心。下蹲。 走刃 换刃的开始 是靠膝盖的下降 YouTuBe Snowboard Addiction 前后刃刹车,一定要蹲下去,不能直腿,否则会chachacha 板头平衡/板尾平衡/后刃横向两侧平衡/后刃横向两侧平衡 Eurocarve 可以贴在地上 练习反脚 重心靠前,巧记后脚板子3下 连续转4个360度(慢慢的做) 其他视频 搓雪转弯:后刃减速,因为能看到前面,前刃比较自然 换刃: 用后面的板子的刃,向两边搓雪减速, 更快的转弯,(利用膝盖),陡坡管用 后刃,后手往前伸 前刃,后手往后伸,可以保持身体直立 走刃: 前刃时,弯曲膝盖;身体要直,不能太前倾,否则卡不住雪;重心在中间 后刃时,坐的越深;身体越要向前倾斜,否则卡不住雪;重心在中间 滑雪笔记历史视频 https://v.qq.com/x/page/y0374rcpz1y.html https://v.qq.com/x/page/p0374j04u5p.html https://v.qq.com/x/page/e0374vazd55.html 2017年11月30日-怀北-2017年冬天第一次滑单板 正脚：身体跟随刃一起动,可以保持不搓雪，压刃，重心中心;总体感觉较好,有时候后任会chachacha,应该是立刃不足,或者身体太直 反脚: 总体不是很流畅, https://v.qq.com/x/page/p0527pxet7b.html]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[双板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2Fstudy-ski%2F</url>
    <content type="text"><![CDATA[犁式直降动作成v字 犁式转弯练习方案 平举双手,转弯时,双手放到山下腿,其中山下退要承受重量,让身体靠近山下腿 重心的转移很重要 山上腿,打开(解锁)膝盖,很自然的并板子 动作要流畅,s形,而不是z形 平行式 之前是入弯后们转为平行 打开膝盖,提早并腿 转换重心时,同时换刃 转弯一个弯,再下一个(控制好速度,再转下一个) 转弯时拧板,会出现型 两个阶段: 准备入弯 控制速度 避免过早结束转弯 立刃,类似于单板的推坡(垂直方向) 练习:立刃,放平,来回切换 练习”直线,立刃,转弯,停]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mac安装kubernetes]]></title>
    <url>%2F2017%2F12%2F21%2Fstudy-ubernetes-install%2F</url>
    <content type="text"><![CDATA[https://github.com/jolestar/kubernetes-complete-course 容器的特性 让不标准的物品标准化（杂物，水，应用） 给上层工具提供标准化的操作方式，屏蔽细节 包装，运输 add/remove/iterator（复用算法） 应用管理和调度 Docker (Moby) 如何实现应用标准化 问题 现状 Docker 的方案 安装包 war/jar，rpm/deb, src, bin Image/Image Layer 运行环境 jvm，php, ruby, python Image/Image Layer 进程启动方式 web container, cmd, script Image ENTRYPOINT/CMD 进程资源隔离限制 Namespace/CGroup 进程文件路径冲突 Chroot 端口冲突 修改配置 Network（IP per Container） 日志输出 文件 stderr/stdout 安装包的仓库 nexus, rpm rep，ftp Docker Registry Kubernetes 为何而生 - 云发展到一个新阶段IaaS 云解决了哪些问题按需购买接管硬件资源的运维提供可编程接口来管理资源提供 SDN，SDS 模拟硬件网络以及存储 特点对应用无侵入面向资源 用户从关注资源的运维转向关注应用的开发运维成本 Kubernetes 为何而生 - 容器的成熟奠定了基础容器（Docker/Moby） 解决了哪些问题应用安装包的标准化（Image）应用进程的标准化（Container） 特点单进程标准化 容器编排系统应运而生我们需要一种 面向应用（Application Oriented） 的系统来降低服务端应用的开发部署和运维成本 We wanted people to be able to program for the data center just like they program for their laptop –Ben Hindman 我们再引申一下，从开发延伸到部署运维 We wanted people to be able to manager app for the data center just like they manager app on their laptop 官网地址http://kubernetes.kansea.com/docs/whatisk8s/ mac本地安装kubernetes(minikube)http://kubernetes.kansea.com/docs/getting-started-guides/minikube/ virtualBox安装 minikube安装 kubectl安装 需要ss的的代理,否则google的镜像无法下载123456789minikube deleteminikube start --docker-env HTTP_PROXY=http://192.168.99.1:1087 --docker-env HTTPS_PROXY=http://192.168.99.1:1087 --docker-env NO_PROXY=192.168.99.0/24kubectl get pods --all-namespaces等待readykubectl get nodes 12345678910111213141516171819202122232425victordeMacBook-Pro:~ victor$ kubectl run nginx --image=nginx --port=80deployment &quot;nginx&quot; createdvictordeMacBook-Pro:~ victor$ kubectl expose deployment nginx --port=80 --type=NodePort --name=nginx-httpservice &quot;nginx-http&quot; exposedvictordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 0/1 ContainerCreating 0 17svictordeMacBook-Pro:~ victor$ kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20mnginx-http NodePort 10.99.7.195 &lt;none&gt; 80:32562/TCP 12svictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlWaiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...^CvictordeMacBook-Pro:~ victor$ kubectl get nodesNAME STATUS ROLES AGE VERSIONminikube Ready &lt;none&gt; 22m v1.8.0victordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 1/1 Running 0 2mvictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlhttp://192.168.99.100:32562 tips: 本地的ss需要设置http代理,其中监听的地址从127.0.0.1改为0.0.0.0,这样虚拟机就可以访问到了,在这步卡了很久 docker安装https://yeasy.gitbooks.io/docker_practice/content/kubernetes/quickstart.html 这些服务大概分为三类：主节点服务、工作节点服务和其它服务。 主节点服务apiserver 是整个系统的对外接口，提供 RESTful 方式供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 工作节点服务kubelet 是工作节点执行操作的 agent，负责具体的容器生命周期管理，根据从数据库中获取的信息来管理容器，并上报 pod 运行状态等； proxy 为 pod 上的服务提供访问的代理。 其它服务Etcd 是所有状态的存储数据库； gcr.io/google_containers/pause:0.8.0 是 Kubernetes 启动后自动 pull 下来的测试镜像。 https://yeasy.gitbooks.io/docker_practice/content/kubernetes/concepts.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-service-mesh(服务网格)]]></title>
    <url>%2F2017%2F12%2F20%2Fstudy-service-mesh%2F</url>
    <content type="text"><![CDATA[service-mesh概念首先服务网格是一个基础设施层，功能在于处理服务间通信，职责是负责实现请求的可靠传递。在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明。 设计图 概念学习https://zhuanlan.zhihu.com/p/28794062https://zhuanlan.zhihu.com/p/30292372 Kubernetes和Spring Cloud哪个部署微服务更好？https://www.kubernetes.org.cn/1057.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>service-mesh</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opitimize_git_clone]]></title>
    <url>%2F2017%2F12%2F20%2Fopitimize-git-clone%2F</url>
    <content type="text"><![CDATA[找到自己代理的端口 命令:git config –global http.https://github.com.proxy https://127.0.0.1:1087git config –global https.https://github.com.proxy https://127.0.0.1:1087 作者：汪小九链接：https://www.zhihu.com/question/27159393/answer/141047266来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 查看git设置git config –list #BTW此种加速对http和https协议有效 对ssh协议无效,如:git clone git@github.com:xxxxxx/xxxxxx.git]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课1]]></title>
    <url>%2F2017%2F12%2F19%2Fjikeshijian-ai-base-study1%2F</url>
    <content type="text"><![CDATA[最优化方法百度https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95 知乎抽象概念1234567 在一定的约束条件下，求一个函数的最大（小）值。 要理解的其实只有两个概念，函数和约束条件。甚至函数这个概念已经包含了对约束条件的考虑。所谓函数，简单理解的话，可以当做一个机器，你给它一个输入，它就给你一个输出，它是一个对应。你通过调节输入，达到最好的输出。它是现实状况的数学语言表达。例如我们要最小化总费用，我们知道单价，我们可以决定数量，于是我们得到的数学表达：总费用=单价乘以数量。我们通过调整数量来最小的总费用。至于约束条件，它有很多种，例如等式的约束，不等式的约束，微分方程的约束，概率的约束，等等等等。他们也是对我们现实状况中的约束的数学表达。不同的约束配上不同的目标函数就会得到一个不同的问题。例如目标函数和约束都是线性的，这个最优化问题就叫线性规划，如果约束是个常微分方程，就叫最优控制。等等等等。作者：滴水链接：https://www.zhihu.com/question/26341871/answer/41242951来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 蛮形象的解释https://www.zhihu.com/question/263418711234567之所以要使用计算机，是因为数据量太大，远远超过人脑的处理能力。比如我们需要从一堆人脸图片里给每个人标上正确的名字，一幅32像素见方的人脸图像有1024颗像素点，你能想象出一百万张这样的照片和1万个人名字之间的关系是什么样吗。再比如给你1万个患者的DNA序列，每个患者的序列由百万级的碱基对构成，你能找到这些天文数字量级的序列和是否患某种疾病之间的联系吗？答案是不能！所以研究者退而求其次，建立很多学习模型，这些模型输入是一个样本的数据（头像图片、一个人的DNA序列），输出是样本的标签（人名、是否患病）。模型里有大量可以调整的参数，这些参数通过训练，能够学习到数据和标签之间人类无法直接理解的、复杂的关系。科学家期望当模型训练完成后，再拿来一个样本，喂给这个训练好的机器，它能够吐出一个标签，这个标签恰好就是样本对应的那个正确的标签。目前人们已经研究出一大堆学习模型：神经网络、支持向量机、AdaBoost、随机森林、隐马尔科夫链、卷积神经网络等等。它们的结构差异很大，但是共同点都是拥有一大堆参数，就等着你喂给它数据供它学习。这些模型的学习也需要一个目标函数：让模型的分类错误率尽量小。为了达到目的，模型的训练往往首先给参数赋上随机初值，然后用各种下降法来寻找能让分类错误率更小的参数设置，梯度下降、牛顿法、共轭梯度法和Levenberg—Marquard法都是常见的方法。 随着研究的深入，问题也越来越多，比如下降法往往只能保证找到目标函数的局部最小值，找不到全局最小值，怎么办呢？答案是不一味下降、也适当爬爬山，说不定能跳出小水沟（局部极小值）找到真正的深井（全局极小值），这种算法叫模拟退火。也可以增大搜索范围，让一群蚂蚁（蚁群算法）或者鸟儿（粒子群算法）一齐搜索，或者让参数巧妙地随机改变（遗传算法）。 那么多模型，到底该选哪个？研究者又发现了一个定理“天下没有免费的午餐”定理，意思是没有一个模型能一直比其他模型好，对于不同类型的数据，必须要通过实验才能发现哪种学习模型更适合。机器学习领域也就成了学界灌水严重的领域之一——换模型、调参数就能发文章哎。 下面说到了调参数，问题又来了，到底是参数多了好还是少了好？参数少了模型太笨学不到数据内的复杂关系，参数多了模型太精明又可能会把数据中的随机噪声当作某种关系进行认真学习（过拟合）。最后大家一致认为，确定模型的复杂度时，要保证模型能力足够强，能够学会数据之间的关系，能力又不能太强，以至于耍小聪明乱学习。这种选择模型的思想被称为奥卡姆剃刀：选择有能力的模型中最简单的那个。此外，训练模型的目标并不是为了使训练样本能够被尽量正确分类，更需要对未知新样本有好的分类效果，这样模型才有实用价值，这种能力被称为泛化能力。除了奥卡姆剃刀原理外，训练时引入随机性的模型比确定的模型（比如BP神经网络）具有更好的泛化能力。 模型的更新也是问题。如果引入了新数据，全部模型都需要重新训练是一笔很大的开销，在线学习模型采用来一个样本学一点的模式，能够不断自我更新；半监督学习利用少量带标签的样本训练一个原始模型，然后利用大量无标签数据再学习。 举例1比如想从广州去杭州，怎样最快又最经济（目标函数）？你有很多种方法，可以坐火车，飞机，汽车(很多种解，而且可以对这些解进行组合)，但总是有个组合最让你满意（最优解），最符合你的期望。怎么去求解这个最优解，由此产生的一系列方法。 博客http://www.cnblogs.com/maybe2030/p/4751804.html]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-AI技术内参1-经典搜索核心算法]]></title>
    <url>%2F2017%2F12%2F18%2Fjikeshijian-ai-study1%2F</url>
    <content type="text"><![CDATA[TF-IDF及其变种 信息检索,文本挖掘,自然语言处理领域 把查询关键字(Query)和文档(Document)都转为向量 ‘向量空间模型’Vector Spcece Model就是希望吧查询关键字和文档都表达成变量,然后利用向量之间的运算来进行进一步表达向量之间的关系 相似性:余弦相似性,或者是点积 V个词汇,V维度,查询关键字和每个文档的向量都有V个维度 TF和IDF的乘机 TF单词频率Term Frequency,计算一个查询关键字中某一个单子在目标文档中出现的次数 如查询’car insurance’,那么计算car出现了多少次,insurance出现了多少次 表示相关度 IDF,逆文档频率Inerse Document Frequency,需要去惩罚哪些出现在太多文档中的单词 多少文档包含了这个单词,越大越不重要 其他学习资料http://www.ruanyifeng.com/blog/2013/03/tf-idf.html123让我们从一个实例开始讲起。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。所以，排在最前面的几个词，就是这篇文章的关键词。除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如，信息检索时，对于每个文档，都可以分别计算一组搜索词（&quot;中国&quot;、&quot;蜜蜂&quot;、&quot;养殖&quot;）的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以&quot;词频&quot;衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。） BM25及其变种 BM是’最佳匹配’Best Match的简称 用来计算某一目标文档(Document)相对于一个查询关键字(Query)的”相关性”(Relevance)的流程, 非监督学习排序算法中的一个典型代表 定义: 单词和目标文档的相关性 词频 TF-IDF里面的TF部分,but词频需要”标准化”,某一个单词对最后的分数的贡献不会随着词频的增加而无限增加 两个超参数:当前文档的长度,整个数据集所有文档的平均长度 单词和查询关键词的相关性 同样需要标准化过程 单词的权重部分 某种变形的来对单词加权,例如某种变形的IDF来对单词甲醛 罗伯逊-斯巴克-琼斯权重,需要一个监督信息 在很多情况下,利用IDF来直接对单词权重的版本更加普遍,如果再有监督信息的情况下,RSJ值也不失为一个很好的选择 这个三个部分的乘积组成某一个单词的分数,然后,整个文档相对于某个查询关键字的分数,就是所有查询关键字里所有单词分数的总和 bm25是对某一概率相关模型的逼近 bm25算法变种:bm25f, 域的概念(文档包括标题,摘要和正文) 把BM25和其他文档信息(非文字)结合起来 BM25和PageRank的线性结果来确定网页的相关性 语言模型及其变种 详解:用概率模型(Probabilistic Model)来描述查询关键字和目标文档之间的关系 最简单的:查询关键字似然检索模型 一个语言模型就是一个针对词汇表的概率分布 词汇表1w个单词,1w个单词上的离散概率分布 查询关键字是从一个语言模型中”抽样”得到一个样本 对一个查询关键字打分=这组词出现的联合概率,因为联合概率可能会很小,因此很多时候都通过一个对数变化,来把概率的乘积变成概率对数加和 语言模型的参数:”类别分布”(Categorical Distiribution),也就是多项式分布,去除排列组合信息 参数股计算法:最大似然估计 每个单词出现的可能性,正好等于这个单词在目标文档中出现的次数,除以所有单词在文档中出现的次数. 每个文档都对应一个类别分布,有多少文档,就有多少个类别分布 如果没有在训练数据中出现过,最优解就是0 平滑(Smoohting)http://52opencourse.com/111/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88language-modeling%EF%BC%89]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[api网关学习]]></title>
    <url>%2F2017%2F12%2F18%2Fstudy-api-gateway%2F</url>
    <content type="text"><![CDATA[什么是api网关123王延炯：API Gateway（API GW / API 网关），顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界。在微服务概念的流行之前，API GW的实体就已经诞生了，这时的主要应用场景是OpenAPI，也就是开放平台，面向的是企业外部合作伙伴，对于这个应用场景，相信接触的人会比较多。当在微服务概念流行起来之后，API网关似乎成了在上层应用层集成的标配组件。 为什么需要api网关 负载均衡 减少客户端与服务端的直接调用 容错 服务发现与注册 统一认证 选型spring cloud zuulhttps://github.com/Netflix/zuul nginx konghttps://github.com/Kong/kong 阿里云apigatewayhttps://www.aliyun.com/product/apigateway API 生命周期管理 支持包括 API 发布、API 测试、API 下线等生命周期管理功能。 支持 API 日常管理、API 版本管理、API 快速回滚等维护功能。 全面的安全防护 支持多种认证方式，支持 HMAC (SHA-1，SHA-256) 算法签名。 支持 HTTPS 协议，支持 SSL 加密。 防攻击、防注入、请求防重放、请求防篡改。 灵活的权限控制 用户以 APP 作为请求 API 的身份，网关支持针对 APP 的权限控制。 只有已经获得授权的 APP 才能请求相应的 API。 API 提供者可以主动授权某个 APP 调用某个 API 的权限。 API 若上架到 API 市场，则购买者可以将已购买的 API 授权给自己的 APP。 精准的流量控制 流量控制可以用于管控 API的被访问频率、APP的请求频率、用户的请求频率。 流量控制的时间单位可以是分钟、小时、天。 同时支持流控例外，允许设置特殊的 APP 或者用户。 请求校验 支持参数类型、参数值（范围、枚举、正则、Json Schema）校验，无效校验直接会被 API 网关拒绝，减少无效请求对后端造成的资源浪费，大大降低后端服务的处理成本。 数据转换 通过配置映射规则，实现前、后端数据翻译。 支持前端请求的数据转换。 支持返回结果的数据转换。 监控报警 提供可视化的API实时监控，包括：调用量、流量大小、响应时间、错误率，在陆续增加维度。 支持历史情况查询，以便统筹分析。 可配置预警方式（短信、Email），订阅预警信息，以便实时掌握API运行情况。 自动工具 自动生成 API 文档，可供在线查看。 API 网关提供多种语言 SDK 的示例。降低 API 的运维成本。 提供可视化的界面调试工具，快速测试，快速上线。 API 市场 可将 API 上架到 API 市场，供更多开发者采购和使用。 参考资料http://www.infoq.com/cn/news/2016/07/API-background-architecture-floohttp://www.infoq.com/cn/articles/construct-micro-service-using-api-gateway]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[禁止使用@Reference的注解]]></title>
    <url>%2F2017%2F12%2F14%2Foptimize-dubbuo-reference%2F</url>
    <content type="text"><![CDATA[dubbo服务引用默认情况下可以通过@Reference和xml注解来引入例如1234567891011@Reference(version = "0.1", timeout = 8000) private TenantService tenantService; @Reference(version = "0.1", timeout = 8000) private ProductService productService; @Reference(version = "0.1", timeout = 8000) private DictService dictService; @Reference(version = "0.1", timeout = 8000) private CategoryService categoryService; 或者123456&lt;dubbo:reference id="remoteBaseCustomPropsService" interface="com.ejlerp.baseinfo.api.BaseCustomPropsService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuStepPriceService" interface="com.ejlerp.baseinfo.api.SkuStepPriceService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuUnitService" interface="com.ejlerp.baseinfo.api.SkuUnitService" version="0.1" timeout="60000"/&gt; 出现的问题生产环境上调用微服务超时,结果发现即使通过123service: @Reference(version = "0.1", timeout = 8000) private ProductService productService; 的方式设置了超时时间,但生产环境的错误,还是设置的1000ms的超时时间, 问题原因在其他的service中同样是引用了这个注解123其他service: @Reference(version = "0.1") private ProductService productService; Reference注解 包含了初始化和注入dubbo的bean,两种功能其实是声明了一个bean,但是到底是用哪个timeout,是有spring初始化bean的顺序所决定的,很可能出现设置了timeout但是仍然没有效果的情况 解决办法 在2017-12-12后的,所有微服务,禁止使用Reference注解,通过autowirdj进行钟乳 统一使用xml的方式,进行声明dubbo的bean 优点 统一Reference方式对其他微服务的引用,放置不一致的配置出现 xml的方式,方便设置方法级别的参数 1234&lt;dubbo:reference id="remoteArrivalStockOutReportService" interface="com.ejlerp.pms.api.StockOutReportService" version="0.1" timeout="60000"&gt; &lt;dubbo:method name="refreshAction" timeout="9000000" retry="0"/&gt;&lt;/dubbo:reference&gt; 修改步骤如下 去除掉DubboConf.java中大部分代码 添加spring-dubbo,xml 删除旧的@Reference,同时添加@Autowird 替换默认的@Reference无超时时间的,基本为dao中id 和 sn generater 将web中最全的dubbo.conf复制到为服务中 本项目为pms,删除掉所有pms相关的xml注入 逐行全文搜索,删掉没用的service 再次遍历dubb.conf的所有service,修改成项目中原来的超时时间,并去掉个性化设置的@Reference 编译,解决编译问题,补充一些@Autowird的包 尝试启动,补充一些egenie-web中没有声明,但是微服务中用到的service 例如:com.ejlerp.messages.api.QueueService,com.ejlerp.cache.api.SortedSetCacher,com.ejlerp.cache.api.IDGenerator,com.ejlerp.cache.api.IDGenerator等 启动成功 具体改动,见git: http://git.ejlerp.com/egenie/ejlerp-pms/commit/4d431233af740e0f1c85c8733afcaadfb0638a18 BTW http://dubbo.io/books/dubbo-user-book/demos/fault-tolerent-strategy.html 在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。 Failover Cluster 失败自动切换，当出现失败，重试其它服务器 1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 2。通常用于通知所有提供者更新缓存或日志等本地资源信息。 开发人员可以根据自己的实际业务,设置失败时的处理方式]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>reference</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm崩溃]]></title>
    <url>%2F2017%2F12%2F14%2Foperation-jvm%2F</url>
    <content type="text"><![CDATA[日常日志及错误1232017-12-13 18:26:00.001 [pool-27-thread-1] INFO com.ejlerp.pms.provider.mqCrond.MqPmsTradeOrderCrond.sendMsgToInter - == 处理采购推送交易库定时任务 start ==2017-12-13 18:26:05.711 [pool-27-thread-1] ERROR org.springframework.scheduling.support.TaskUtils$LoggingErrorHandler.handleError - Unexpected error occurred in scheduled task.java.lang.OutOfMemoryError: Java heap space 同时jvm由于重启过,gc日志也刷新了 每个jvm不仅用自己个性化的参数调优,还应该有共同参数,例如:打印gc日志,dump内存等参数TODO 待总结]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上redis崩溃记录]]></title>
    <url>%2F2017%2F12%2F14%2Foperation-redis%2F</url>
    <content type="text"><![CDATA[错误日志grep com.alibaba.dubbo.rpc.filter.ExceptionFilter.error123456789101112131415161718199:02org.springframework.data.redis.RedisConnectionFailureException: Unexpected end of stream.; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream.好多条org.springframework.dao.InvalidDataAccessApiUsageException: LOADING Redis is loading the dataset in memory; nested exception is redis.clients.jedis.exceptions.JedisDataException: LOADING Redis is loading the dataset in memory 好多条org.springframework.data.redis.RedisConnectionFailureException: java.net.SocketTimeoutException: Read timed out; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed outorg.springframework.data.redis.RedisConnectionFailureException: java.net.SocketException: Connection reset; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketException: Connection resetorg.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool很多9:21开始org.springframework.dao.InvalidDataAccessApiUsageException: ERR READONLY You can&apos;t write against a read only instance; nested exception is redis.clients.jedis.exceptions.JedisDataException: ERR READONLY You can&apos;t write against a read only instance很多 期间代码回滚到了上一版本,过了一段时间系统正常最后发现是 业务层面循环调用了redis操作,一次请求会有1k次的redis,导致redis崩掉,而且我们使用的阿里云的主从版云redis 几次循环调用,inFlow的变化 具体得失hset方法的调用 反思 对于监控系统,应该有各个节点的平时统计数据,包括,调用次数+相应时长 通过环比和同比数据的对比,可以快速的发现问题,解决问题,而不是当系统垮掉时,才有所反应 BTWnest exception学习http://www.iteye.com/problems/87876 即调用顺序是 action—&gt;service—&gt;dao—-&gt;hibernate—&gt;jdbc 抛出异常顺序是 jdbc—-&gt;hibernate—-&gt;dao–抛出–&gt;service–继续抛出–&gt;action 异常其实是栈调用的快照 1、最下层的异常是出错的原因，上边的异常是对下边的封装，目的是一致性 和 更可读；（即下边异常是引起上边异常的原因，每一个Exception都有一个cause，如hibernate异常的cause就是jdbc的异常） 2、对于每一段异常，方法调用顺序是从下往上 3、想知道是由于前面创建的错误导致后边的异常，还是后边的异常导致前面的创建错误，后边导致前面，，，前面对后面的进行了封装，，目的是提供一致的异常（并且把原始错误显示出来 就是 nested exception 后边部分） NestedRuntimeException 例子我们最熟悉的就是 DataAccessException12345678910111213package org.springframework.dao;import org.springframework.core.NestedRuntimeException;public abstract class DataAccessException extends NestedRuntimeException &#123; public DataAccessException(String msg) &#123; super(msg); &#125; public DataAccessException(String msg, Throwable cause) &#123; super(msg, cause); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>breakdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix总结-12.13]]></title>
    <url>%2F2017%2F12%2F14%2Fbugfix-2-1213%2F</url>
    <content type="text"><![CDATA[bugfix1-redis相关 快速定位问题 12345678910111213141516171819202017-12-13 18:33:39.688 DEBUG [http-bio-6000-exec-17][JdbcTemplate.java:875] - SQL update affected 1 rows2017-12-13 18:33:40.590 ERROR [http-bio-6000-exec-17][UniExceptionHandler.java:57] - 捕捉到技术异常: URI: /shop/insert 最大内存: 1012m 已分配内存: 1012m 已分配内存中的剩余空间: 532m 最大可用内存: 532mjava.lang.RuntimeException: org.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerExceptionorg.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerException at org.springframework.data.redis.FallbackExceptionTranslationStrategy.getFallback(FallbackExceptionTranslationStrategy.java:48) at org.springframework.data.redis.FallbackExceptionTranslationStrategy.translate(FallbackExceptionTranslationStrategy.java:38) at org.springframework.data.redis.connection.jedis.JedisConnection.convertJedisAccessException(JedisConnection.java:242) at org.springframework.data.redis.connection.jedis.JedisConnection.set(JedisConnection.java:1236) at org.springframework.data.redis.connection.DefaultStringRedisConnection.set(DefaultStringRedisConnection.java:744) at org.springframework.data.redis.core.DefaultValueOperations$10.inRedis(DefaultValueOperations.java:172) at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:57) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:207) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:91) at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169) at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34) at com.alibaba.dubbo.common.bytecode.Wrapper7.invokeMethod(Wrapper7.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) 首先这个是一个没有见过的异常 解决途径: 搜索自己公司包开头的代码,找到调用地方 下载源码,底层依赖可能有真的有 在本次bugfix中,由于是微服务调用,真正看出问题是在,controller层才看出的问题12345678910@ApiOperation(value = &quot;新增&quot;)@RequestMapping(value = &quot;/insert&quot;, method = RequestMethod.POST)public JsonResult insert(@RequestBody String body) &#123; Long id = IdGenerator.generate(getEntityName(), fetchTenantId()).getIdValue(); CommonVo vo = CommonVo.of(getEntityName(), WebHelper.parseJsonBody(body, false, false)); vo.put(&quot;shop_id&quot;, id); getService().insert(fetchTenantId(), fetchUserId(), vo); kvCacher.set(&quot;logistic_node_&quot; + id.toString(), vo.get(&quot;logistic_node&quot;)); return new JsonResult(JsonResult.SUCCESSFUL, null);&#125; vo可能别没有获取到 反思:at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34),这个一句其实只有两个参数,一个是传入的key,一个是value,一定是其中一个入参发生了问题,才会导致底层出现问题的 当然,也不排除是redis服务可能出现了问题,但是当时已经重启了reids,错误依旧存在 最后,bug定位到了是前端一个select标签,由于数据库中的dict没有初始化,导致这个select标签的初始值没有初始化完成,当然表单提交时,便不会提交这个字段, 小结 controller层的vo依然不要使用map,否则排查起来很费劲 bugfix2 分组问题 这个bugfix,其实是这样的,条件写反导致的 1234 Map&lt;Long, VSaleOrder&gt; orderMap = omsAgentService.findByIds(callerInfo, arriveMap.keySet());- Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::isNull).filter(v -&gt; &#123;+ Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::nonNull).filter(v -&gt; &#123; Integer courierPrintMarkState = v.getCourierPrintMarkState(); 问题是,历史数据的修复,其实应该在线上发现问题时,作为一套完整的方案,进行提交的,而不是部署到生产环境后,又发现历史数据有问题,在半夜升级后改数据,风险真是很大 对于一些合并操作,虽然业务上提出了操作,其实从逻辑上讲,应该出现拆分的反响逻辑预支对应 问题3 jvm参数设置]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix对接baidu语音合成]]></title>
    <url>%2F2017%2F12%2F13%2Fbugfix-voice-generate%2F</url>
    <content type="text"><![CDATA[背景项目中使用了baidu的语音合成,原本的设计是,批量获取设置到redis中,用户每次使用时从redis中获取 空指针异常12345678910112017-12-13 16:34:30.076 ERROR [http-bio-6000-exec-45][DownloadVoiceFromBaiduYY.java:36] - DownloadVoiceFromBaiduYY error &#123;&#125;java.lang.NullPointerException at com.baidu.aip.speech.AipSpeech.synthesis(AipSpeech.java:133) ~[java-sdk-3.2.0.jar:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoice(DownloadVoiceFromBaiduYY.java:33) [classes/:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoiceB64(DownloadVoiceFromBaiduYY.java:45) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getB64(VoiceController.java:233) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getVoiceData(VoiceController.java:149) [classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92] 下载源码后debug返现返回的response Content-Type是大写,与sdk中get的string不一致,于是查找github的源文件 发现了,这个bug已经fix了,https://github.com/Baidu-AIP/java-sdk/commit/c338bc71690f84351def0d64b311986c586763d2 其他遇到的问题 判断字符串写反 1234- if (StringUtils.isEmpty(value)) &#123;+ if (!StringUtils.isEmpty(value)) &#123; redisMap.put(key, value); &#125; APPkey修改错了配置文件 反思 在与外部api进行接口对接时,一定要判断各种异常情况的发生,不能只考虑正常情况 1234567try &#123; TtsResponse res = client.synthesis(voice, &quot;zh&quot;, 1, options); JSONObject result = res.getResult(); if (result != null) &#123; LOGGER.warn(&quot;downloadVoice:&#123;&#125;&quot;, result); &#125; download = res.getData(); 删除掉无用的代码,放置误导自己和别人 本地充分测试后,再提交测试部署,否则害人害己,耽误时间 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 不能依靠测试发现程序问题,即使是别人的代码,也要认真研读,滤清思路,不能头疼医头,脚痛医脚 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署 待提高 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 测试用例编写 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署]]></content>
      <categories>
        <category>bugfix</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化2:定位io高的原因mysql]]></title>
    <url>%2F2017%2F12%2F13%2Foptime-156%2F</url>
    <content type="text"><![CDATA[#重新定位问题-%wa指CPU等待磁盘写入完成的时间 首先看下%wa的解释：Percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. #iostat #pidstat 2 10 -d发现mysql的读写量非常高]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>io高</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化1:清理zookeeper过多的历史文件]]></title>
    <url>%2F2017%2F12%2F12%2Foptimize-zookeeper%2F</url>
    <content type="text"><![CDATA[背景156机器是本地开发环境上的机器跑了如下服务:mysqlzookeeperdubbokeeper 现象从ssh登陆服务器就比较卡top命令后,负载一直很高 排查iotop命令看到zookeeper的io比较高http://pic.victor123.cn/17-12-12/59575921.jpg 操作步骤 https://www.cnblogs.com/jxwch/p/6526271.html 打开这两个参数 autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个； autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。 清空历史数据 效果 相关知识http://www.linuxidc.com/Linux/2016-03/129509.htmdataDir用于存储Log（事务日志）与Snapshot（快照）数据 1在后续的观察中发现,156的io高并不全是zookeeper的问题,so本次支持清楚了历史文件,对于156的io高问题目前定位是mysql问题,待续]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>io高</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习pandas api时发现了一个奇怪的现象]]></title>
    <url>%2F2017%2F12%2F10%2Ferror-pandas-date-range%2F</url>
    <content type="text"><![CDATA[学习pandas api时发现了一个奇怪的现象 通过代码 dates = pd.date_range(‘20130101’, periods=6) 定义了函数, 下一行无法打印出来, 可是下面仍然能够使用这个datas的变脸,很是神奇,百思不得其解 结论 怀疑是应该是jupyter notebook的问题, 直接打印出pd.date_range(‘20130101’, periods=6)的结果都是正确的]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>机器学习</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas中read_csv方法的学习]]></title>
    <url>%2F2017%2F12%2F05%2Fpython-pandas-read-csv%2F</url>
    <content type="text"><![CDATA[#read_csv内容过大的处理方式:123451.train = pd.read_csv(&quot;/Users/victor/code/kaggle/Expedia/input/train.csv&quot;,nrows=3000)2.chunksize=100 总apihttp://pandas.pydata.org/pandas-docs/version/0.15]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kaggle-expedia-hotel-recommendations学习笔记]]></title>
    <url>%2F2017%2F12%2F05%2Fkaggle-expedia-hotel-recommendations%2F</url>
    <content type="text"><![CDATA[题目地址https://www.kaggle.com/c/expedia-hotel-recommendations#description 学习地址https://www.dataquest.io/blog/kaggle-tutorial/ 目标 初步了解机器学习流程 通过实际代码,了解python代码的语法 学习心得 数据探索 1234567import pandas as pddestinations = pd.read_csv("destinations.csv")test = pd.read_csv("test.csv")train = pd.read_csv("train.csv")#train文件有4个g大,读了半天都不出来 数据量 数据分布 目标变量 目标变量是什么 探索目标变量 探索用户id 采样统计 添加时间和日期 挑选1000名用户 区分测试集和验证集 移除无关数据(click 事件) 一个简单的算法 生成预测 1234567891011predictions = [most_common_clusters for i in range(t2.shape[0])]# 不是很理解 [] 和 shape[0]的含义# shape()方法返回 行数 和 维度数 .其中:0:行数 1:维度数# pyhton中的遍历:for iterating_var in sequence: statements(s)# 但是 for前面的most_common_clusters 是什么意思?# 通过测试了解到是复制一个变量n遍的意思aa=[&quot;abc&quot; for i in range(10)]print(aa)输出了10个 abc 评估效果 123456789import ml_metrics as metricstarget = [[l] for l in t2[&quot;hotel_cluster&quot;]]metrics.mapk(target, predictions, k=5)# 不是很理解 [l]代表什么# 把t2[&quot;hotel_cluster&quot;]列表中的变量l,外面 前一层 列表 []xx=[1,2,3,4]target = [[l] for l in xx]print(target)[[1], [2], [3], [4]] 查找相关因素 更近一步 生成特征 从destinations生成特征 123456789from sklearn.decomposition import PCApca = PCA(n_components=3)dest_small = pca.fit_transform(destinations[[&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)]])dest_small = pd.DataFrame(dest_small)dest_small[&quot;srch_destination_id&quot;] = destinations[&quot;srch_destination_id&quot;]# 解释 取d1-d149字段print([&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)])[&apos;d1&apos;, &apos;d2&apos;, &apos;d3&apos;, &apos;d4&apos;, &apos;d5&apos;, &apos;d6&apos;, &apos;d7&apos;, &apos;d8&apos;, &apos;d9&apos;, &apos;d10&apos;, &apos;d11&apos;, &apos;d12&apos;, &apos;d13&apos;, &apos;d14&apos;, &apos;d15&apos;, &apos;d16&apos;, &apos;d17&apos;, &apos;d18&apos;, &apos;d19&apos;, &apos;d20&apos;, &apos;d21&apos;, &apos;d22&apos;, &apos;d23&apos;, &apos;d24&apos;, &apos;d25&apos;, &apos;d26&apos;, &apos;d27&apos;, &apos;d28&apos;, &apos;d29&apos;, &apos;d30&apos;, &apos;d31&apos;, &apos;d32&apos;, &apos;d33&apos;, &apos;d34&apos;, &apos;d35&apos;, &apos;d36&apos;, &apos;d37&apos;, &apos;d38&apos;, &apos;d39&apos;, &apos;d40&apos;, &apos;d41&apos;, &apos;d42&apos;, &apos;d43&apos;, &apos;d44&apos;, &apos;d45&apos;, &apos;d46&apos;, &apos;d47&apos;, &apos;d48&apos;, &apos;d49&apos;, &apos;d50&apos;, &apos;d51&apos;, &apos;d52&apos;, &apos;d53&apos;, &apos;d54&apos;, &apos;d55&apos;, &apos;d56&apos;, &apos;d57&apos;, &apos;d58&apos;, &apos;d59&apos;, &apos;d60&apos;, &apos;d61&apos;, &apos;d62&apos;, &apos;d63&apos;, &apos;d64&apos;, &apos;d65&apos;, &apos;d66&apos;, &apos;d67&apos;, &apos;d68&apos;, &apos;d69&apos;, &apos;d70&apos;, &apos;d71&apos;, &apos;d72&apos;, &apos;d73&apos;, &apos;d74&apos;, &apos;d75&apos;, &apos;d76&apos;, &apos;d77&apos;, &apos;d78&apos;, &apos;d79&apos;, &apos;d80&apos;, &apos;d81&apos;, &apos;d82&apos;, &apos;d83&apos;, &apos;d84&apos;, &apos;d85&apos;, &apos;d86&apos;, &apos;d87&apos;, &apos;d88&apos;, &apos;d89&apos;, &apos;d90&apos;, &apos;d91&apos;, &apos;d92&apos;, &apos;d93&apos;, &apos;d94&apos;, &apos;d95&apos;, &apos;d96&apos;, &apos;d97&apos;, &apos;d98&apos;, &apos;d99&apos;, &apos;d100&apos;, &apos;d101&apos;, &apos;d102&apos;, &apos;d103&apos;, &apos;d104&apos;, &apos;d105&apos;, &apos;d106&apos;, &apos;d107&apos;, &apos;d108&apos;, &apos;d109&apos;, &apos;d110&apos;, &apos;d111&apos;, &apos;d112&apos;, &apos;d113&apos;, &apos;d114&apos;, &apos;d115&apos;, &apos;d116&apos;, &apos;d117&apos;, &apos;d118&apos;, &apos;d119&apos;, &apos;d120&apos;, &apos;d121&apos;, &apos;d122&apos;, &apos;d123&apos;, &apos;d124&apos;, &apos;d125&apos;, &apos;d126&apos;, &apos;d127&apos;, &apos;d128&apos;, &apos;d129&apos;, &apos;d130&apos;, &apos;d131&apos;, &apos;d132&apos;, &apos;d133&apos;, &apos;d134&apos;, &apos;d135&apos;, &apos;d136&apos;, &apos;d137&apos;, &apos;d138&apos;, &apos;d139&apos;, &apos;d140&apos;, &apos;d141&apos;, &apos;d142&apos;, &apos;d143&apos;, &apos;d144&apos;, &apos;d145&apos;, &apos;d146&apos;, &apos;d147&apos;, &apos;d148&apos;, &apos;d149&apos;] 生成其他特征 12345678910111213141516171819202122232425262728def calc_fast_features(df): df[&quot;date_time&quot;] = pd.to_datetime(df[&quot;date_time&quot;]) df[&quot;srch_ci&quot;] = pd.to_datetime(df[&quot;srch_ci&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) # 参数errors=&quot;coerce&quot; 遇到错误可以赋值为空。 df[&quot;srch_co&quot;] = pd.to_datetime(df[&quot;srch_co&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) props = &#123;&#125; for prop in [&quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;minute&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;]: props[prop] = getattr(df[&quot;date_time&quot;].dt, prop) carryover = [p for p in df.columns if p not in [&quot;date_time&quot;, &quot;srch_ci&quot;, &quot;srch_co&quot;]] for prop in carryover: props[prop] = df[prop] date_props = [&quot;month&quot;, &quot;day&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;] for prop in date_props: props[&quot;ci_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_ci&quot;].dt, prop) props[&quot;co_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_co&quot;].dt, prop) props[&quot;stay_span&quot;] = (df[&quot;srch_co&quot;] - df[&quot;srch_ci&quot;]).astype(&apos;timedelta64[h]&apos;) ret = pd.DataFrame(props) ret = ret.join(dest_small, on=&quot;srch_destination_id&quot;, how=&apos;left&apos;, rsuffix=&quot;dest&quot;) ret = ret.drop(&quot;srch_destination_iddest&quot;, axis=1) return retdf = calc_fast_features(t1)df.fillna(-1, inplace=True) 123456789101112131415161718192021新的列:[ &apos;channel&apos;, &apos;ci_day&apos;, &apos;ci_dayofweek&apos;, &apos;ci_month&apos;, &apos;ci_quarter&apos;, &apos;cnt&apos;, &apos;co_day&apos;, &apos;co_dayofweek&apos;, &apos;co_month&apos;, &apos;co_quarter&apos;, &apos;day&apos;, &apos;dayofweek&apos;, &apos;hotel_cluster&apos;, &apos;hotel_continent&apos;, &apos;hotel_country&apos;, &apos;hotel_market&apos;, &apos;hour&apos;, &apos;is_booking&apos;, &apos;is_mobile&apos;, &apos;is_package&apos;, &apos;minute&apos;, &apos;month&apos;, &apos;orig_destination_distance&apos;, &apos;posa_continent&apos;, &apos;quarter&apos;, &apos;site_name&apos;, &apos;srch_adults_cnt&apos;, &apos;srch_children_cnt&apos;, &apos;srch_destination_id&apos;, &apos;srch_destination_type_id&apos;, &apos;srch_rm_cnt&apos;, &apos;stay_span&apos;, &apos;user_id&apos;, &apos;user_location_city&apos;, &apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;year&apos;, 0, 1, 2] + 机器学习 * 随机森林 1234567predictors = [c for c in df.columns if c not in [&quot;hotel_cluster&quot;]]from sklearn import cross_validationfrom sklearn.ensemble import RandomForestClassifierclf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)scores = cross_validation.cross_val_score(clf, df[predictors], df[&apos;hotel_cluster&apos;], cv=3)scores * 二分分类 123456789101112131415161718192021222324252627282930313233from sklearn.ensemble import RandomForestClassifierfrom sklearn.cross_validation import KFoldfrom itertools import chainall_probs = []unique_clusters = df[&quot;hotel_cluster&quot;].unique()for cluster in unique_clusters: df[&quot;target&quot;] = 1 df[&quot;target&quot;][df[&quot;hotel_cluster&quot;] != cluster] = 0 predictors = [col for col in df if col not in [&apos;hotel_cluster&apos;, &quot;target&quot;]] probs = [] cv = KFold(len(df[&quot;target&quot;]), n_folds=2) # 交叉验证(CrossValidation) # 方法思想是为了在不动用测试集之前，就评估一下模型是否过于复杂而引起过度拟合 clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1) for i, (tr, te) in enumerate(cv): # 不是很理解 上面一句 clf.fit(df[predictors].iloc[tr], df[&quot;target&quot;].iloc[tr]) preds = clf.predict_proba(df[predictors].iloc[te]) probs.append([p[1] for p in preds]) full_probs = chain.from_iterable(probs) all_probs.append(list(full_probs))prediction_frame = pd.DataFrame(all_probs).Tprediction_frame.columns = unique_clustersdef find_top_5(row): return list(row.nlargest(5).index)preds = []for index, row in prediction_frame.iterrows(): preds.append(find_top_5(row))metrics.mapk([[l] for l in t2.iloc[&quot;hotel_cluster&quot;]], preds, k=5) 在目的地下的最受欢迎的酒店选择 123456789101112131415161718192021222324252627def make_key(items): return &quot;_&quot;.join([str(i) for i in items])match_cols = [&quot;srch_destination_id&quot;]cluster_cols = match_cols + [&apos;hotel_cluster&apos;]groups = t1.groupby(cluster_cols)top_clusters = &#123;&#125;for name, group in groups: clicks = len(group.is_booking[group.is_booking == False]) bookings = len(group.is_booking[group.is_booking == True]) score = bookings + .15 * clicks clus_name = make_key(name[:len(match_cols)]) if clus_name not in top_clusters: top_clusters[clus_name] = &#123;&#125; top_clusters[clus_name][name[-1]] = scoreimport operatorcluster_dict = &#123;&#125;for n in top_clusters: tc = top_clusters[n] top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]] cluster_dict[n] = top 给予目的地,进行预测 1234567preds = []for index, row in t2.iterrows(): key = make_key([row[m] for m in match_cols]) if key in cluster_dict: preds.append(cluster_dict[key]) else: preds.append([]) 评估错误 1metrics.mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], preds, k=5) 更好的结果 根据用户 12345678910111213141516match_cols = [&apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;user_location_city&apos;, &apos;hotel_market&apos;, &apos;orig_destination_distance&apos;]groups = t1.groupby(match_cols) def generate_exact_matches(row, match_cols): index = tuple([row[t] for t in match_cols]) try: group = groups.get_group(index) except Exception: return [] clus = list(set(group.hotel_cluster)) return clusexact_matches = []for i in range(t2.shape[0]): exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols)) 合并预测 1234567891011121314def f5(seq, idfun=None): if idfun is None: def idfun(x): return x seen = &#123;&#125; result = [] for item in seq: marker = idfun(item) if marker in seen: continue seen[marker] = 1 result.append(item) return result full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], full_preds, k=5) 生成提交文件 12345write_p = [&quot; &quot;.join([str(l) for l in p]) for p in full_preds]write_frame = [&quot;&#123;0&#125;,&#123;1&#125;&quot;.format(t2[&quot;id&quot;][i], write_p[i]) for i in range(len(full_preds))]write_frame = [&quot;id,hotel_clusters&quot;] + write_framewith open(&quot;predictions.csv&quot;, &quot;w+&quot;) as f: f.write(&quot;\n&quot;.join(write_frame)) 总结 下一步]]></content>
      <categories>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>kaggle</tag>
        <tag>随机森林</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac_Chrome浏览器下载csv.gz后缀时遇到的问题]]></title>
    <url>%2F2017%2F12%2F04%2Ferror-download-gz%2F</url>
    <content type="text"><![CDATA[问题描述: 下载一个应该为csv.gz后缀名的问题,不知道为什么没有了后缀名,一开始以为是字符集问题 下载的是kaggle的data数据https://www.kaggle.com/c/expedia-hotel-recommendations/data 报错错误 问了小伙伴,解压后的文件应该有几个g,不应该几百兆,因此推断是后缀名问题 解决http://pic.victor123.cn/17-12-4/7396408.jpg 知识小结123456789101112131415.tar 解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）———————————————.gz解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName.tar.gz 和 .tgz解压：tar zxvf FileName.tar.gz压缩：tar zcvf FileName.tar.gz DirName———————————————]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化idea插件安装]]></title>
    <url>%2F2017%2F12%2F01%2Fidea-plugins-install%2F</url>
    <content type="text"><![CDATA[常常遇到从idea程序中搜索插件，下载超时的情况,解决方式如下1.直接在官网下载并进行安装,然后Install from diskhttps://plugins.jetbrains.com/search?correctionAllowed=true&amp;pr=idea&amp;orderBy=&amp;search= 2.使用ss作代理，直接下载]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>代理</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next主题保存]]></title>
    <url>%2F2017%2F11%2F30%2Ferror-next-submodule%2F</url>
    <content type="text"><![CDATA[通过git的submodule功能对博客内容和主题分别进行版本控制方案https://stackoverflow.com/questions/12898278/issue-with-adding-common-code-as-git-submodule-already-exists-in-the-index 12345678git ls-files --stagegit rm --cached themes/nextgit submodule add git@github.com:victorsheng/hexo-theme-next.git themes/nextgit add .gitmodules .gitmodulesn内容如下：[submodule “themes/next”] path = themes/next url = git@github.com:victorsheng/hexo-theme-next.git]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>git</tag>
        <tag>submodule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac安装seaborn遇到的问题]]></title>
    <url>%2F2017%2F11%2F30%2Ferror-pip-install-seaborn%2F</url>
    <content type="text"><![CDATA[异常信息12345678910111213141516171819202122232425262728293031323334353637pip install numpyMacBook-Pro:~ victor$ pip install seabornCollecting seaborn Downloading seaborn-0.8.1.tar.gz (178kB) 100% |████████████████████████████████| 184kB 666kB/sCollecting pandas (from seaborn) Using cached pandas-0.21.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Collecting numpy&gt;=1.9.0 (from pandas-&gt;seaborn) Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: pytz&gt;=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Installing collected packages: numpy, pandas, seaborn Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-gOIIvZ-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos; 发现卸载这个numpy都不行1234567891011121314151617181920212223242526sudo -H pip uninstall numpyDEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.Uninstalling numpy-1.8.0rc1: /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-infoProceed (y/n)? yException:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/uninstall.py&quot;, line 76, in run requirement_set.uninstall(auto_confirm=options.yes) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 346, in uninstall req.uninstall(auto_confirm=auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/tmp/pip-Ez2DTF-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info 解决方案https://blog.wizchen.com/2016/06/17/Mac%E4%B8%8B%E6%9B%B4%E6%96%B0python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93numpy/ 说是System Integrity Protection的问题，解决的办法是关闭SIP: 重启电脑，电脑启动的时候安住 command + R 等画面上出现 apple logo 的，你会看到 OS X 工具程式的窗口，选择终端，等待终端打开，直接输入csrutil disable，回车后重启即可 重启完毕后，再次在终端输入 最后成功1234567891011121314151617181920212223242526272829303132333435363738pip install -U numpyCollecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-rfPgIG-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos;shengsiyudeMacBook-Pro:~ victor$ sudo -H pip install -U numpyPassword:Collecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1: Successfully uninstalled numpy-1.8.0rc1Successfully installed numpy-1.13.3]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mac</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术搜索技巧]]></title>
    <url>%2F2017%2F11%2F28%2Fcode-blog-website%2F</url>
    <content type="text"><![CDATA[结合搜索引擎语法 site:功能,可以高效的搜索出常见的技术类问题的解决方案常见的网址如下: 国内 博客园 cnblogs.com CSDN csdn.net 开源中国 oschina.net 简书 jianshu.com SegmentFault segmentfault.com 掘金 juejin.im 国外 stackoverflow Github GithubPage 知识分享 知乎 quora 而对于相对专业的技能 api文档 和官方文档]]></content>
      <categories>
        <category>搜索技巧</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据展现技术选型]]></title>
    <url>%2F2017%2F11%2F28%2FBI-show-tool%2F</url>
    <content type="text"><![CDATA[数据展现技术选型 阿里云Quick Bi(试用过30天)Quick BI 是一个基于云计算的灵活的轻量级的自助 BI 工具服务平台。 Quick BI 支持众多种类的数据源，既可以连接 MaxCompute（ODPS）、RDS、Analytic DB、HybridDB（Greenplum）等云数据源，也支持连接 ECS 上您自有的 MySQL 数据库，还支持上传本地文件到 Quick BI 内置的探索空间进行分析。 Tableauhttps://www.tableau.com/ From GitHubSuperset Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名Panoramix、Caravel），该工具在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。 https://github.com/apache/incubator-superset Saiku https://github.com/OSBI/saiku 另外一些是没有实际调研过的一些工具 QlikviewFineBIBDP商业数据平台永洪]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>数据展示</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习分型]]></title>
    <url>%2F2017%2F11%2F27%2Fshare-docker%2F</url>
    <content type="text"><![CDATA[简介 Docker 是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大提高了应用的运行效率，降低了云计算资源供应的成本！使用 Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松！ 无论是应用开发者、运维人员、还是其他信息技术从业人员，都有必要认识和掌握 Docker，节约有限的时间。 docker的由来 Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎，由 Go 语言编写的，源代码托管在 github 而且居然只有 1W 行就完成了这些功能。 Docker自2013年以来非常火热，无论是从 github 上的代码活跃度，还是Redhat在RHEL6.5中集成对Docker的支持, 就连 Google 的 Compute Engine 也支持 docker 在其之上运行。 Docker设想是交付运行环境如同海运，OS如同一个货轮，每一个在OS基础上的软件都如同一个集装箱，用户可以通过标准化手段自由组装运行环境，同时集装箱的内容可以由用户自定义，也可以由专业人员制造。这样，交付一个软件，就是一系列标准化组件的集合的交付，如同乐高积木，用户只需要选择合适的积木组合，并且在最顶端署上自己的名字(最后个标准化组件是用户的app)。这也就是基于docker的PaaS产品的原型。 为什么要使用 Docker？ 更高效的利用系统资源 更快速的启动时间 一致的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 镜像（Image） Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container） 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 仓库（Repository） 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 基本命令 docker run busybox echo “hello world” docker ps 官方仓库https://store.docker.com/ mac版本图形化客户端:kitematicKitematic 完全自动化了 Docker 安装和设置过程，并提供了一个直观的图形用户接口（GUI）来在 Mac 上运行 Docker。Kitematic 集成了 Docker Machine 来在 Mac 上分发一个虚拟机并安装 Docker 引擎。 一旦安装成功，Kitematic GUI 便会启动，紧接着你可以立刻运行控制台中的镜像。你仅仅只需要在 Kitematic 搜索框键入镜像名就可以搜索任何在 Docker Hub 上存在的镜像。通过 GUI 你可以非常容易的创建、运行和管理你的容器，不需要使用命令行或者是在 Docker CLI 和 GUI之间来回切换。 Kitematic 也让Docker的一些高级特性使用更加方便，比如管理端口和配置 volumes。你可以方便的修改环境变量、查看日志，单机终端就可以进入容器，这些特性GUI都支持。dockerfileDockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。例如:https://hub.docker.com/r/haocen/docker-hexo-with-hexo-admin/ 进阶数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性: 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 网络管理Docker启动时，会自动在主机上创建一个docker0虚拟网桥，实际上是Linux的一个bridge,可以理解为一个软件交换机，它会而挂载到它的网口之间进行转发 当创建一个Docker容器的时候，同理会创建一对veth pair接口(当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包)，这对接口一端在容器内，即eth0;另一端在本地并被挂载到docker0网桥，名称以veth开头。 容器安全 内核命名空间 控制组控制组是 Linux 容器机制的另外一个关键组件，负责实现资源的审计和限制。它提供了很多有用的特性；以及确保各个容器可以公平地分享主机的内存、CPU、磁盘 IO 等资源；当然，更重要的是，控制组确保了当容器内的资源使用产生压力时不会连累主机系统。 内核能力机制12345678910大部分情况下，容器并不需要“真正的” root 权限，容器只需要少数的能力即可。为了加强安全，容器可以禁用一些没必要的权限。 完全禁止任何 mount 操作； 禁止直接访问本地主机的套接字； 禁止访问一些文件系统的操作，比如创建新的设备、修改文件属性等； 禁止模块加载。这样，就算攻击者在容器中取得了 root 权限，也不能获得本地主机的较高权限，能进行的破坏也有限。默认情况下，Docker采用白名单机制，禁用必需功能之外的其它权限。 当然，用户也可以根据自身需求来为 Docker 容器启用额外的权限。 容器编排编排是一个新的词汇，指的是容器的集群化和调度。另一类含义指的是容器管理，负责管理容器化应用和组件任务。 &lt;img src=&quot;http://pic.victor123.cn/17-11-29/58239834.jpg&quot;&gt; Docker Swarm、Kubernetes、Marathon和Nomad 快速安装docker12345678910useradd appusrpasswd appusrgroupadd dockerusermod -aG docker appusryum install epel-release –yyum install docker-io –ysystemctl start dockersystemctl enable docker 使用案例本地的nginx12345678910111213141516171819202122232425262728293031323334353637383940docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -v $PWD/logs:/etc/nginx/logs -d nginxnginx配置文件:server &#123; listen 80 default_server; location /api/iac &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.222:9060; &#125; location /api/bi &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.106:9991; &#125; location = / &#123; proxy_connect_timeout 1800; proxy_read_timeout 1800; proxy_send_timeout 1800; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location / &#123; proxy_pass http://192.168.0.106:8099; &#125; location /page &#123; proxy_pass http://192.168.0.106:8888; &#125; location /static &#123; proxy_pass http://192.168.0.106:8888; &#125; location /main &#123; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location /login&#123; proxy_pass http://192.168.0.106:8888/page/login/index.html; &#125;&#125; 用docker安装mysql数据库准备工作123456789101112yum install gitmkdir /dockerchown -R appusr /dockersudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://cz3my8je.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 启动12345678910要复制conf到制定目录下docker run -p 3306:3306 --name mymysql -v /docker/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /docker/mysql/logs:/logs -v /docker/mysql/data:/mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6docker ps -adocker run -it --link mymysql:mysql --rm mysql sh -c &apos;exec mysql -h 172.18.0.1 -P 3306 -u root -p123456&apos;CREATE USER &apos;pig&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;GRANT ALL ON *.* TO &apos;pig&apos;@&apos;%&apos;; 附录10张图带你深入理解Docker容器和镜像http://dockone.io/article/783 菜鸟网 http://www.runoob.com/docker/docker-hello-world.html Docker 安装 Nginx Docker 安装 PHP Docker 安装 MySQL Docker 安装 Tomcat Docker 安装 Python Docker 安装 Redis Docker 安装 MongoDB Docker 安装 Apache 学习资料 https://joshhu.gitbooks.io/docker_theory_install/content/ https://docs.docker.com/ https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能采购实现逻辑梳理]]></title>
    <url>%2F2017%2F11%2F27%2Fcode-samrtPurchase%2F</url>
    <content type="text"><![CDATA[智能采购实现逻辑梳理销量部分计算(一天执行一次) 刷新1天,7天,30天,自定义天销量方法 排除掉不采购仓库的销量 排除掉备货仓的销量 分批进行持久化 触发一次采购部分计算 采购部分计算(定时半个小时执行一次) 获取界面上手动覆盖的参数 如果有批量修改勾选的ids则至处理这部分智能采购记录,否则查询全部智能采购记录 如果修改了上限和下限库存,则县持久化 填充库存 本仓库库存+本仓库的备货仓的库粗查询 计算存货天数 取采购周期,供货商 1234567* 根据excel公式,计算备货的字段* 日均销量=7天销量/7* 最低库存=日均销量*备货天数* 上限库存=日均销量*(备货天数+采购周期)* 存货预警库存=在途库存-最低库存 P.S.小于0的需要采购* 建议采购数量=上限采购数量-在途库存*/ 查询参数 强制覆盖采购周期和存货天数 计算上限和下限库存 Double minStock = avgSaleVolume * inventoryDays; Double maxStock = avgSaleVolume * (inventoryDays + procurementCycle); 强制覆盖上限和下限库存 如果开启智能计算跳过此步骤 查询SaleStockSetting表中记录的上限和线下库存,别设置isManual=true 计算预警库存和建议采购量 Integer saleStock = v.getSaleStock(); Integer onWayStock = v.getOnWayStock(); int stock = saleStock + onWayStock; double warningStock = stock - minStock; 如果预警库存&lt;0,double originAdviceNum = maxStock - stock,并向上取整 如果预警库存&gt;=0,不进行建议 强制覆盖最总结果 对verifyNum进行赋值 强制覆盖verifyNum 持久化更新]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数学习]]></title>
    <url>%2F2017%2F11%2F24%2Fmath-linear-algebra%2F</url>
    <content type="text"><![CDATA[推荐一(博客)http://www.hahack.com/wiki/math-linear-algebra.html 矩阵 基本运算 加 减 乘 求逆 矩阵的转职 应用举例 求解方程组 求向量组合 向量 基本运算 加 减 乘 标量乘向量 向量点积 向量外积 矩阵向量积 向量的转置 线性无关 张成空间 线性相关和线性无关 判断是否线性相关 张量 线性代数进阶 阶梯形矩阵 阶梯形矩阵 行简化阶梯形矩阵 行最简形矩阵 将矩阵化简成行最简阶梯形 线性子空间 零空间 列空间 行空间 左零空间 子空间的正交补 最小二乘逼近 实例1：求解方程 实例2：线性回归 特征向量 求解特征值 求解特征向量 推荐二 http://space.bilibili.com/88461692#!/ 线性代数的本质 http://space.bilibili.com/88461692#!/channel/detail?cid=9450 一天就看了好几集,让我对数学又重新产生了兴趣, 对此,本篇的目的旨在记录这两天所学到的内容: 线性代数的本质01向量究竟是什么 向量是函数 向量是一条记录(多个观察值) 向量是物理运动 02线性组合、张成的空间03矩阵与线性变换 矩阵向量乘法是一种线性变化,第一列是i帽移动的,第二列是j帽移动的位置 其中,2X2矩阵就是二维线性变换 04矩阵乘法与线性变换复合 矩阵的乘法就是两个线性变化的相继结果 从右往左读 先是e,g向量,线性变化,chengwei ae+bg,ce+dg,如图 矩阵的乘法没有交换律,有结合律 04三维空间中的线性05行列式(线性变化的行列式) 行列式= 二位线性变化所对应的面积缩放比例,三维实体积 行列式结果=1,代表面积没有变化 行列式结果=6,代表面积乘以6 行列式结果=0,代表在降维了 行列式结果为负数,代表空间反面了 结算公式:ad-bc det(矩阵)=行列式 06逆矩阵、列空间与零空 求解线性方程组 行列式不为0时:线性变化*逆向线性变化=什么都不做(1) 行列式为0时:无法求逆 秩:变化后的空间维数 3*3矩阵的最大秩:为3,否则就意味着被压缩了 矩阵的列空间:所有可能的输出向量构成的集合(列张成的空间=列空间) 整个线被压缩:降1维(零空间) 整个平面被压缩:降2维(零空间) 06补充说明:非方阵07点积与对偶性 向量的点成:一个向量*另一个向量在该向量上的投影 矩阵和向量之间的联系 转换*向量 矩阵向量乘积 类似 向量的点积 08第一部分:叉积的标准介绍08第二部分:以线性变化的眼光看叉积09基变换10特征向量与特征值11抽象向量空间]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺货销售订单生成采购单逻辑梳理]]></title>
    <url>%2F2017%2F11%2F21%2Fcode-saleGeneratePurchaseOrder%2F</url>
    <content type="text"><![CDATA[缺货销售订单生成采购单逻辑梳理入口: 采购单界面,一键生成采购单 订单处理界面 勾选制定订单,生成采购单 按照查询条件,生成采购单 实现逻辑: 查询基档案warehouse 是否需要采购,以及换货仓 查询之前的组号映射关系 未关闭的采购单 到货状态的唯一码 更新之前组的到货数量 查询总的缺货销售订单数 分页生成采购单,默认5000单一组 分页查询缺货销售订单 根据系统参数 过滤掉申请退款的明细 复制订单和订单明细,到新的数据结构(VSaleOrder,VSaleOrderDetail)–&gt;(PmsDailyPurchase,PmsDailyPurchaseDetail) 过滤采购完成 过滤无需采购 绝对唯一码规则.一条明细生成多个唯一码 根据三级明细分配采购单号 将未分拣墙上的设置到制定A组中 单件不进分组 相同订单的,使用上次的组号,同一订单组号继续使用 大单量分组 普通分组,并且分组下的订单数没有超过计划的订单数量 使用已有的分组(按A-Z的优先顺序) 创建新的分组 合并最后一个分组信息 回写新增的组至totalGroupMap(内存级别) 批量填充唯一码 生成36进制的唯一码 唯一码规则:租户内唯一 唯一码规则:9位唯一码 sku的唯一码,以1开头 (前绑定)根据采购单数,绑定订单和唯一码 (后绑定)先尝试使用为分拣墙上的sku,此部分无需采购,更新updateNum为-1 持久化PmsPurchaseOrder 汇总三级明细,生成二级明细 次品仓业务(原采购单有相同sku的,用次品仓的货物换;没有的,增加采购数量) 根据skuIds,查询换货仓的库存 原采购数量&lt;换货仓库存,新采购数量=换货仓数量 原采购数量&gt;=换货仓数量,新采购数量=原采购数量 自动生成次品仓盘点单 填充供货信息VendorSupply 根据skuIds查询默认供应商 设置采购周期和到货时间 设置最小采购数量 设置采购供应商 设置采购价格 优先价格体系 设置采购人(PDA推送的依据) 查询不到的取sku得采购信息,取sku得采购信息 设置采购周期和到货时间 设置最小采购数量 设置采购价格 反写采购单明细的信息到拿货明细 二级明细业务处理: update 和 insert的 持久化二级明细 回写二级明细id到二点五级明细和三级明细 移除掉不需要采购的采购单明细,和拿货订单明细,二级和三级需要同时移除 规则一:供应商无需采购(之所以再次移除,是因为此处采购供应商) 规则二:几天后到货的(目前已废弃) 如果所有明细都移除了,则无需持久化采购单主表 持久化(update 和 insert)订单主表 持久化PmsDailyPurchase,PmsDailyPurchaseDetail 返回生成采购单报告]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的武器库]]></title>
    <url>%2F2017%2F11%2F21%2F%E6%88%91%E7%9A%84%E6%AD%A6%E5%99%A8%E5%BA%93%2F</url>
    <content type="text"><![CDATA[搜索引擎我掌握的语言 java sql python 技术框架持续使用的githubmac常用软件 Sublime DateGrip IntliJ IDEA WebStorm SourceTree Jprofiler MAT Beyound Compare PlantUML ShadowSocks_NG Postman 命令常用软件 brew docker 文本处理器 vim Pandoc markdown]]></content>
      <categories>
        <category>技术栈</category>
      </categories>
      <tags>
        <tag>我的</tag>
      </tags>
  </entry>
</search>
