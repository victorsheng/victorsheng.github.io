<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[bugfix-remote-ssh]]></title>
    <url>%2F2018%2F04%2F20%2Ftd_bugfix%2Fbugfix-remote-ssh%2F</url>
    <content type="text"><![CDATA[问题通过ssh root@地址 “命令” 无法加载.bash_profile里面的配置 对比1远程的ssh命令123456789[ip1:vic@ip1:/home/vic]$ ssh hadoop@ip2 &quot;java -version&quot;java version &quot;1.7.0_101&quot;OpenJDK Runtime Environment (rhel-2.6.6.1.el7_2-x86_64 u101-b00)OpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode)ssh登陆后的[ip2:hadoop@ip2:/home/hadoop]$ java -versionjava version &quot;1.8.0_66&quot;Java(TM) SE Runtime Environment (build 1.8.0_66-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode) 对比212345[ip1:vic@ip1:/home/vic]$ ssh hadoop@ip2 &apos;echo $PATH&apos;/usr/local/bin:/usr/bin[ip2:hadoop@ip2:/home/hadoop]$ echo $PATH/usr/java/jdk1.8.0_66/bin:/usr/java/default/bin:/usr/java/default/jre/bin:/usr/local/mysql3306/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin 解决方案 设置BASH_ENV(没有找到设置的地方,export只会在本次登陆生效) 在远端要执脚本中加载配置文件(最终采取的方案)12#!/bin/bash. ~/.bash_profile 参考文章http://feihu.me/blog/2014/env-problem-when-ssh-executing-command-on-remote bash的四种模式在man page的INVOCATION一节讲述了bash的四种模式，bash会依据这四种模式而选择加载不同的配置文件，而且加载的顺序也有所不同。本文ssh问题的答案就存在于这几种模式当中，所以在我们揭开谜底之前先来分析这些模式。 interactive + login shell第一种模式是交互式的登陆shell，这里面有两个概念需要解释：interactive和login： login故名思义，即登陆，login shell是指用户以非图形化界面或者以ssh登陆到机器上时获得的第一个shell，简单些说就是需要输入用户名和密码的shell。因此通常不管以何种方式登陆机器后用户获得的第一个shell就是login shell。 interactive意为交互式，这也很好理解，interactive shell会有一个输入提示符，并且它的标准输入、输出和错误输出都会显示在控制台上。所以一般来说只要是需要用户交互的，即一个命令一个命令的输入的shell都是interactive shell。而如果无需用户交互，它便是non-interactive shell。通常来说如bash script.sh此类执行脚本的命令就会启动一个non-interactive shell，它不需要与用户进行交互，执行完后它便会退出创建的shell。 那么此模式最简单的两个例子为： 用户直接登陆到机器获得的第一个shell用户使用ssh user@remote获得的shell 加载配置文件这种模式下，shell首先加载/etc/profile，然后再尝试依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找： 123~/.bash_profile~/.bash_login~/.profile non-interactive + login shell第二种模式的shell为non-interactive login shell，即非交互式的登陆shell，这种是不太常见的情况。一种创建此shell的方法为：bash -l script.sh，前面提到过-l参数是将shell作为一个login shell启动，而执行脚本又使它为non-interactive shell。 对于这种类型的shell，配置文件的加载与第一种完全一样，在此不再赘述。 interactive + non-login shellbash，此时会打开一个交互式的shell，而因为不再需要登陆，因此不是login shell。 加载配置文件对于此种情况，启动shell时会去查找并加载/etc/bash.bashrc和~/.bashrc文件。 bashrc VS profile从刚引入的两个配置文件的存放路径可以很容易的判断，第一个文件是全局性的，第二个文件属于当前用户。在前面的模式当中，已经出现了几种配置文件，多数是以profile命名的，那么为什么这里又增加两个文件呢？这样不会增加复杂度么？我们来看看此处的文件和前面模式中的文件的区别。 首先看第一种模式中的profile类型文件，它是某个用户唯一的用来设置全局环境变量的地方, 因为用户可以有多个shell比如bash, sh, zsh等, 但像环境变量这种其实只需要在统一的一个地方初始化就可以, 而这个地方就是profile，所以启动一个login shell会加载此文件，后面由此shell中启动的新shell进程如bash，sh，zsh等都可以由login shell中继承环境变量等配置。 接下来看bashrc，其后缀rc的意思为Run Commands，由名字可以推断出，此处存放bash需要运行的命令，但注意，这些命令一般只用于交互式的shell，通常在这里会设置交互所需要的所有信息，比如bash的补全、alias、颜色、提示符等等。 所以可以看出，引入多种配置文件完全是为了更好的管理配置，每个文件各司其职，只做好自己的事情。 non-interactive + non-login shell最后一种模式为非交互非登陆的shell，创建这种shell典型有两种方式： bash script.shssh user@remote command这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。 加载配置文件对于这种模式而言，它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。 配置文件的种类 /etc/profile ~/.bash_profile ~/.bash_login ~/.profile /etc/bash.bashrc ~/.bashrc $BASH_ENV $ENV 小结 ~/.bash_profile：应该尽可能的简单，通常会在最后加载.profile和.bashrc(注意顺序) ~/.bash_login：在前面讨论过，别用它 ~/.profile：此文件用于login shell，所有你想在整个用户会话期间都有效的内容都应该放置于此，比如启动进程，环境变量等 ~/.bashrc：只放置与bash有关的命令，所有与交互有关的命令都应该出现在此，比如bash的补全、alias、颜色、提示符等等。特别注意：别在这里输出任何内容（我们前面只是为了演示，别学我哈）]]></content>
  </entry>
  <entry>
    <title><![CDATA[jenkins-Credentials]]></title>
    <url>%2F2018%2F04%2F20%2Fjenkins-Credentials%2F</url>
    <content type="text"><![CDATA[背景之前一直是运维部署的Jenkins,今天自己部署也遇到了些问题 Credentials Jenkins的“Credentials”直译为“证书”，“文凭”在这里，尽管说Jenkins界面中有相当一部分的文字经过了官方汉化，但是对于这个“Credentials”却仍然没有被汉化，可见对于其汉化之后对应的中文翻译，官方也是一脸懵逼的状态，在这里，我们可以把它直译为“证书”，如果通过意译，那它的理解就是“钥匙”，这个翻译对于我们而言是最为容易理解的。 如果要是把它理解为“钥匙”，那就不需要我进行过多的解释了，我们以SVN（版本控制器）为例来进行说明，当我们在访问SVN时，其实SVN是需要我们提供相应的账号与密码进行登录的，假如说我们把要访问的URL地址理解为锁，那么所提供的账号与密码就对应于开这把锁的钥匙，所以说“Credentials”中所记录的就是各种各样的这种钥匙，而这里的钥匙对应的锁是有多种可能的，可能是SVN，也可能是Git等，而“Credentials”就是对于这些钥匙所进行的统一管理。 Credentials IDJenkins自动帮我们生成了一条“ID”信息,这个id就是用来在pipeline中对git项目进行登陆认证. 例如:12345stage &apos;Build&apos;dir(&apos;gim&apos;) &#123; git branch: BRANCH_NAME,credentialsId: &apos;fe65e7e9-2c93-48a9-81f8-db19ec174adc&apos;, url: &apos;http://xxx.git&apos; sh &quot;mvn clean package -Dmaven.test.skip=true -U&quot;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[sofa-overview]]></title>
    <url>%2F2018%2F04%2F19%2Fsofa-overview%2F</url>
    <content type="text"><![CDATA[参考 https://github.com/alipay/sofa-rpc https://github.com/alipay/sofa-rpc/wiki/DeveloperGuide https://github.com/alipay/sofa-rpc/wiki/Programming]]></content>
  </entry>
  <entry>
    <title><![CDATA[restfule-result-status]]></title>
    <url>%2F2018%2F04%2F19%2Frestful-result-status%2F</url>
    <content type="text"><![CDATA[参考文档http://xiaochutian.github.io/2017/08/01/design-of-server-status-code-1/http://xiaochutian.github.io/2017/08/03/design-of-server-status-code-2/ 作者的设计自定义错误代码，HTTP状态码统一为200。为什么我不复用HTTP状态码？ HTTP状态码可能不够用。跟项目业务相关的错误细节无法反应出来。 HTTP状态码应该属于HTTP协议的定义之中。项目中服务器与客户端的协议，应该是HTTP的上层协议。上层协议不应该知道和依赖底层协议的细节。 协议设计HTTP状态码统一为200。Result对象里面的code为0表示正常返回，非0表示异常返回。异常详情如下： 4XXXX，表示客户端错误（参数问题等）5XXXX，表示服务器错误（服务器的bug导致的异常）6XXXX，表示业务逻辑上的异常逻辑的状态码（用于客户端执行异常逻辑流） 注：五位的状态码分为三个部分。X-XX-XX表示：错误类别-项目或模块编号-具体错误编号 这可以理解为，需求分析的时候，会有一个『主要成功场景』和一些『备选事件流』。主要成功场景 的返回code为0，而 备选事件流 的返回code为6XXXX。 举个栗子：有一个叫做『练耳大师』的产品，音乐爱好者可以在里面做乐感训练。产品里面有一个功能叫做『练习分析』。产品规定某一种练习，需要练习超过30道题才能进行分析。所以，在用户没有做满30道题，并且点了『练习分析』按钮的时候。服务器逻辑是完全正确执行的，发现用户没有做满30道题，这个时候就返回6XXXX给客户端。客户端在获取到这个状态码就知道该执行『备选事件流』：提示用户『必须要做满30道题才能分析哦~』。 3.2.1 客户端错误 code 说明 40000 客户端错误，通用 40001 客户端参数非法 40002 客户端参数json不符合格式要求 3.2.2 服务器（api）错误 code 说明 50000 服务器（api）错误，通用 3.2.3 服务器（dubbo）错误 code 说明 60000 服务器（dubbo）错误，通用]]></content>
  </entry>
  <entry>
    <title><![CDATA[http-status-code]]></title>
    <url>%2F2018%2F04%2F19%2Fhttp-status-code%2F</url>
    <content type="text"><![CDATA[一些常见的状态码为： 状态码 含义 备注 200 请求已完成 2XX状态码均为正常状态码返回 3XX 3XX状态码为重定向状态码 300 多种选择 服务器根据请求可执行多种操作。服务器可根据请求者 (User agent) 来选择一项操作，或提供操作列表供请求者选择 301 永久移动 请求的网页已被永久移动到新位置。服务器返回此响应（作为对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码通知 Googlebot 某个网页或网站已被永久移动到新位置 302 临时移动 服务器目前正从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置 303 查看其他位置 当请求者应对不同的位置进行单独的 GET 请求以检索响应时，服务器会返回此代码。对于除 HEAD 请求之外的所有请求，服务器会自动转到其他位置 304 未修改 自从上次请求后，请求的网页未被修改过。服务器返回此响应时，不会返回网页内容 305 使用代理 请求者只能使用代理访问请求的网页。如果服务器返回此响应，那么，服务器还会指明请求者应当使用的代理 307 临时重定向 服务器目前正从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置 4XX 客户端类错误 400 错误请求 服务器不理解请求的语法 401 未授权 请求要求进行身份验证。登录后，服务器可能会返回对页面的此响应 403 已禁止 服务器拒绝请求 404 未找到 服务器找不到请求的网页。例如，如果请求是针对服务器上不存在的网页进行的，那么，服务器通常会返回此代码 405 方法禁用 禁用请求中所指定的方法 406 不接受 无法使用请求的内容特性来响应请求的网页 407 需要代理授权 此状态代码与401（未授权）类似，但却指定了请求者应当使用代理进行授权。如果服务器返回此响应，那么，服务器还会指明请求者应当使用的代理 408 请求超时 服务器等候请求时超时 409 冲突 服务器在完成请求时发生冲突。服务器必须包含有关响应中所发生的冲突的信息。服务器在响应与前一个请求相冲突的PUT请求时可能会返回此代码，同时会提供两个请求的差异列表 410 已删除 如果请求的资源已被永久删除，那么，服务器会返回此响应。该代码与404（未找到）代码类似，但在资源以前有但现在已经不复存在的情况下，有时会替代 411 需要有效长度 服务器不会接受包含无效内容长度标头字段的请求。 412 未满足前提条件 服务器未满足请求者在请求中设置的其中一个前提条件。 413 请求实体过大 服务器无法处理请求，因为请求实体过大，已超出服务器的处理能力。 414 请求的URI过长 请求的URI（通常为网址）过长，服务器无法进行处理。 415 不支持的媒体类型 请求的格式不受请求页面的支持。 416 请求范围不符合要求 如果请求是针对网页的无效范围进行的，那么，服务器会返回此状态代码。 417 未满足期望值 服务器未满足”期望”请求标头字段的要求。 499 客户端断开连接 服务端处理时间过长，导致客户端关闭了连接造成的 5XX 服务器端发生错误 500 服务器内部错误 服务器遇到错误，无法完成请求。 501 尚未实施 服务器不具备完成请求的功能。例如，当服务器无法识别请求方法时，服务器可能会返回此代码。 502 错误网关 服务器作为网关或代理，从上游服务器收到了无效的响应。 503 服务不可用 目前无法使用服务器（由于超载或进行停机维护）。通常，这只是一种暂时的状态。 504 网关超时 服务器作为网关或代理，未及时从上游服务器接收请求。 505 HTTP版本不受支持 服务器不支持请求中所使用的HTTP协议版本。 常见的400 （错误请求） 服务器不理解请求的语法。 由于语法格式有误，服务器无法理解此请求。不作修改，客户程序就无法重复此请求。 账号已经欠费。 指定的 DataDisk.n.Category 不合法。 指定的 InternetMaxBandwidthOut 不合法或超出范围。 404 （未找到） 服务器找不到请求的网页。 指定的 HostName 不合法。 指定的 DataDisk.n.SnapshotId 不存在。 指定的镜像不存在。 指定的 InstanceChargeType 不存在。 403 （禁止） 服务器拒绝请求。 该磁盘不支持挂载与卸载。 您暂时无法使用该资源。 没有订阅镜像市场的镜像。 指定的磁盘类型组合不支持。 500 内部错误。]]></content>
  </entry>
  <entry>
    <title><![CDATA[vocode-kemap]]></title>
    <url>%2F2018%2F04%2F19%2Ftools%2Fvocode-kemap%2F</url>
    <content type="text"><![CDATA[快捷键放大/缩小窗口ctrl + ‘=’ 和 ctrl + ‘-‘]]></content>
  </entry>
  <entry>
    <title><![CDATA[netty应用]]></title>
    <url>%2F2018%2F04%2F17%2Fjava_netty%2Fnetty-usage%2F</url>
    <content type="text"><![CDATA[navi-pbrpc教程：http://neoremind.com/2016/02/%E5%9F%BA%E4%BA%8Eprotobuf%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E6%80%A7%E8%83%BDrpc%E6%A1%86%E6%9E%B6-navi-pbrpc/github地址：https://github.com/neoremind/navi-pbrpc 客户端handler链条的顺序： 序列化 反序列化 客户端处理 1234567891011121314151617181920212223242526272829303132SimplePbrpcClient(PbrpcClientConfiguration pbrpcClientConfiguration, boolean isShortLiveConn, String ip, int port, int connTimeout, int readTimeout) &#123; if (pbrpcClientConfiguration != null) &#123; this.pbrpcClientConfiguration = pbrpcClientConfiguration; &#125; this.ip = ip; this.port = port; this.connTimeout = connTimeout; this.readTimeout = readTimeout; this.isShortAliveConn = isShortLiveConn; bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, this.connTimeout); bootstrap.option(ChannelOption.SO_KEEPALIVE, this.pbrpcClientConfiguration.isSoKeepalive()); bootstrap.option(ChannelOption.SO_REUSEADDR, this.pbrpcClientConfiguration.isSoReuseaddr()); bootstrap.option(ChannelOption.TCP_NODELAY, this.pbrpcClientConfiguration.isTcpNodelay()); bootstrap.option(ChannelOption.SO_RCVBUF, this.pbrpcClientConfiguration.getSoRcvbuf()); bootstrap.option(ChannelOption.SO_SNDBUF, this.pbrpcClientConfiguration.getSoSndbuf()); ChannelInitializer&lt;SocketChannel&gt; initializer = new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new PbrpcMessageSerializer()); ch.pipeline().addLast(new PbrpcMessageDeserializer()); ch.pipeline().addLast(new PbrpcClientHandler()); &#125; &#125;; eventLoopGroup = new NioEventLoopGroup(); bootstrap.group(eventLoopGroup).handler(initializer); startTimeoutEvictor(); &#125; 序列化handler拼装协议 123456789101112@Overrideprotected void encode(ChannelHandlerContext ctx, PbrpcMsg pbrpcMsg, List&lt;Object&gt; out) throws Exception &#123; byte[] bodyBytes = ByteUtil.getNonEmptyBytes(pbrpcMsg.getData()); NsHead nsHead = contructNsHead(pbrpcMsg.getServiceId(), pbrpcMsg.getErrorCode(), pbrpcMsg.getLogId(), pbrpcMsg.getData(), pbrpcMsg.getProvider()); byte[] nsHeadBytes = nsHead.toBytes(); ByteBuf encoded = Unpooled.copiedBuffer(nsHeadBytes, bodyBytes); out.add(encoded); // LOG.info(&quot;Send total byte size=&quot; + (nsHeadBytes.length + bodyBytes.length) + &quot;, body size=&quot; // + bodyBytes.length);&#125; 反序列化handler 处理半包问题 反序列化 123456789101112131415161718192021222324252627282930313233343536@Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; // 解决半包问题，此时Nshead还没有接收全，channel中留存的字节流不做处理 if (in.readableBytes() &lt; NsHead.NSHEAD_LEN) &#123; return; &#125; in.markReaderIndex(); byte[] bytes = new byte[NsHead.NSHEAD_LEN]; in.readBytes(bytes, 0, NsHead.NSHEAD_LEN); NsHead nsHead = new NsHead(); nsHead.wrap(bytes); // 解决半包问题，此时body还没有接收全，channel中留存的字节流不做处理，重置readerIndex if (in.readableBytes() &lt; (int) nsHead.getBodyLen()) &#123; in.resetReaderIndex(); return; &#125; // 此时接受到了足够的一个包，开始处理 in.markReaderIndex(); byte[] totalBytes = new byte[(int) nsHead.getBodyLen()]; in.readBytes(totalBytes, 0, (int) nsHead.getBodyLen()); PbrpcMsg decoded = PbrpcMsg.of(nsHead).setData(totalBytes); ContextHolder.putContext(&quot;_logid&quot;, nsHead.getLogId()); // TODO if (decoded != null) &#123; out.add(decoded); &#125; // LOG.info(&quot;Deser data &quot; + nsHead.getLogId() + &quot; is&quot; + decoded + &quot; and using &quot; // + (System.nanoTime() - start) / 1000 + &quot;us&quot;); &#125; 客户端handler12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class PbrpcClientHandler extends SimpleChannelInboundHandler&lt;PbrpcMsg&gt; &#123; private static final Logger LOG = LoggerFactory.getLogger(PbrpcMessageDeserializer.class); /** * 可配置，默认使用protobuf来做body的序列化 */ private Codec codec = new ProtobufCodec(); /** * @see io.netty.channel.SimpleChannelInboundHandler#channelRead0(io.netty.channel.ChannelHandlerContext, * java.lang.Object) */ @SuppressWarnings(&quot;unchecked&quot;) @Override public void channelRead0(ChannelHandlerContext ctx, PbrpcMsg pbrpcMsg) throws Exception &#123; Preconditions .checkArgument(pbrpcMsg != null, &quot;Pbrpc msg is null which should never happen&quot;); try &#123; // LOG.info(&quot;Got msg from server:&quot; + pbrpcMsg); int logId = (int) pbrpcMsg.getLogId(); CallbackContext context = CallbackPool.getContext(logId); if (context == null) &#123; LOG.warn(&quot;Receive msg from server but no context found, logId=&quot; + logId); return; &#125; Callback&lt;GeneratedMessage&gt; cb = (Callback&lt;GeneratedMessage&gt;) context.getCallback(); if (pbrpcMsg.getErrorCode() != null) &#123; cb.handleError(ExceptionUtil.buildFromErrorCode(pbrpcMsg.getErrorCode())); &#125; else &#123; GeneratedMessage res = (GeneratedMessage) codec.decode( CallbackPool.getResClass(logId), pbrpcMsg.getData()); cb.handleResult(res); &#125; // 短连接则关闭channel if (context.isShortAliveConn()) &#123; Channel channel = context.getChannel(); if (channel != null) &#123; LOG.info(&quot;Close &quot; + channel + &quot;, logId=&quot; + logId); channel.close(); &#125; &#125; // LOG.info(&quot;Decoding and invoking callback &quot; + pbrpcMsg.getLogId() + &quot; total &quot; // + (System.currentTimeMillis() - context.getStarttime()) // + &quot;ms, transport using &quot; + (start - context.getStarttime()) + &quot;ms&quot;); &#125; finally &#123; CallbackPool.remove((int) pbrpcMsg.getLogId()); ContextHolder.clean(); // ctx.fireChannelReadComplete(); &#125; &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#channelReadComplete(io.netty.channel.ChannelHandlerContext) */ @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; // LOG.debug(&quot;Client channelReadComplete&gt;&gt;&gt;&gt;&gt;&quot;); // ctx.flush(); &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#channelActive(io.netty.channel.ChannelHandlerContext) */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // LOG.debug(&quot;Client channelActive&gt;&gt;&gt;&gt;&gt;&quot;); &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#exceptionCaught(io.netty.channel.ChannelHandlerContext, * java.lang.Throwable) */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; LOG.error(cause.getMessage(), cause); ctx.close(); // FIXME // ctx.fireChannelRead(); &#125;&#125; 服务端顺序： 空闲处理 反序列化 客户端处理 序列化 123456789101112131415161718192021222324252627282930313233343536373839public PbrpcServer(PbrpcServerConfiguration pbrpcServerConfiguration, int port) &#123; // use default conf otherwise use specified one if (pbrpcServerConfiguration == null) &#123; pbrpcServerConfiguration = this.pbrpcServerConfiguration; &#125; this.port = port; bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(); workerGroup = new NioEventLoopGroup(); bootstrap.channel(NioServerSocketChannel.class); bootstrap.option(ChannelOption.SO_BACKLOG, pbrpcServerConfiguration.getSoBacklog()); bootstrap.childOption(ChannelOption.SO_KEEPALIVE, pbrpcServerConfiguration.isSoKeepalive()); bootstrap.childOption(ChannelOption.TCP_NODELAY, pbrpcServerConfiguration.isTcpNodelay()); bootstrap.childOption(ChannelOption.SO_REUSEADDR, true); bootstrap.childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT); bootstrap.childOption(ChannelOption.SO_LINGER, pbrpcServerConfiguration.getSoLinger()); bootstrap.childOption(ChannelOption.SO_RCVBUF, pbrpcServerConfiguration.getSoRcvbuf()); bootstrap.childOption(ChannelOption.SO_SNDBUF, pbrpcServerConfiguration.getSoSndbuf()); ChannelInitializer&lt;SocketChannel&gt; initializer = new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast( &quot;idlestate&quot;, new IdleStateHandler(IDLE_CHANNEL_TIMEOUT, IDLE_CHANNEL_TIMEOUT, IDLE_CHANNEL_TIMEOUT)); ch.pipeline().addLast(&quot;idle&quot;, new RpcServerChannelIdleHandler()); ch.pipeline().addLast(&quot;deser&quot;, new PbrpcMessageDeserializer()); ch.pipeline().addLast(&quot;coreHandler&quot;, new PbrpcServerHandler(serviceLocator)); ch.pipeline().addLast(&quot;ser&quot;, new PbrpcMessageSerializer()); &#125; &#125;; bootstrap.group(bossGroup, workerGroup).childHandler(initializer); LOG.info(&quot;Pbrpc server init done&quot;); &#125; ide handler处理一些空闲的连接闭关它们，防止占用服务端资源 1234567891011121314@Overridepublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent) &#123; IdleStateEvent e = (IdleStateEvent) evt; if (e.state() == IdleState.WRITER_IDLE) &#123; LOG.warn(&quot;Write idle on channel:&quot; + ctx.channel() + &quot; is timeout&quot;); &#125; else if (e.state() == IdleState.READER_IDLE) &#123; LOG.warn(&quot;Read idle on channel:&quot; + ctx.channel() + &quot; is timeout on &quot; + ctx.channel().remoteAddress() + &quot;, so close it&quot;); // ctx.fireExceptionCaught(ReadTimeoutException.INSTANCE); ctx.close(); &#125; &#125;&#125; 服务端handler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class PbrpcServerHandler extends SimpleChannelInboundHandler&lt;PbrpcMsg&gt; &#123; private static final Logger LOG = LoggerFactory.getLogger(PbrpcMessageDeserializer.class); /** * 可配置，默认使用protobuf来做body的序列化 */ private Codec codec = new ProtobufCodec(); /** * 可配置，服务定位器 */ private ServiceLocator&lt;Integer&gt; serviceLocator; /** * Creates a new instance of PbrpcServerHandler. * * @param serviceLocator */ @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) public PbrpcServerHandler(ServiceLocator serviceLocator) &#123; this.serviceLocator = (ServiceLocator&lt;Integer&gt;) serviceLocator; &#125; /** * @see io.netty.channel.SimpleChannelInboundHandler#channelRead0(io.netty.channel.ChannelHandlerContext, * java.lang.Object) */ @Override public void channelRead0(ChannelHandlerContext ctx, PbrpcMsg pbrpcMsg) throws Exception &#123; Preconditions .checkArgument(pbrpcMsg != null, &quot;Pbrpc msg is null which should never happen&quot;); try &#123; if (pbrpcMsg.getErrorCode() != null) &#123; ctx.channel().writeAndFlush(PbrpcMsg.copyLiteOf(pbrpcMsg)); // ONLY COMMUNICATIN ERROR HERE FIXME return; &#125; int key = pbrpcMsg.getServiceId(); ServiceDescriptor&lt;Integer&gt; servDesc = serviceLocator.getServiceDescriptor(key); if (servDesc == null) &#123; throw new ServiceNotFoundException(&quot; serviceId=&quot; + pbrpcMsg.getServiceId()); &#125; GeneratedMessage arg = (GeneratedMessage) codec.decode(servDesc.getArgumentClass(), pbrpcMsg.getData()); GeneratedMessage ret = (GeneratedMessage) servDesc.getMethod().invoke( servDesc.getTarget(), arg); PbrpcMsg retMsg = new PbrpcMsg(); retMsg.setLogId(pbrpcMsg.getLogId()); retMsg.setServiceId(key); if (ret != null &amp;&amp; ret instanceof GeneratedMessage) &#123; byte[] response = ((GeneratedMessage) ret).toByteArray(); retMsg.setData(response); &#125; // LOG.debug(&quot;Service biz logic will return:&quot; + ret); ctx.channel().writeAndFlush(retMsg); // LOG.info(servDesc + &quot; exec using &quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); &#125; catch (ServiceNotFoundException e) &#123; LOG.error(ErrorCode.SERVICE_NOT_FOUND.getMessage() + e.getMessage(), e); ctx.channel().writeAndFlush( PbrpcMsg.copyLiteOf(pbrpcMsg).setErrorCode(ErrorCode.SERVICE_NOT_FOUND)); &#125; catch (CodecException e) &#123; LOG.error(ErrorCode.PROTOBUF_CODEC_ERROR.getMessage() + e.getMessage(), e); ctx.channel().writeAndFlush( PbrpcMsg.copyLiteOf(pbrpcMsg).setErrorCode(ErrorCode.PROTOBUF_CODEC_ERROR)); &#125; catch (InvocationTargetException e) &#123; LOG.error(ErrorCode.INVOCATION_TARGET_EXCEPTION.getMessage() + e.getMessage(), e); ctx.channel().writeAndFlush( PbrpcMsg.copyLiteOf(pbrpcMsg).setErrorCode( ErrorCode.INVOCATION_TARGET_EXCEPTION)); &#125; catch (Exception e) &#123; LOG.error(ErrorCode.UNEXPECTED_ERROR.getMessage() + e.getMessage(), e); ctx.channel().writeAndFlush( PbrpcMsg.copyLiteOf(pbrpcMsg).setErrorCode(ErrorCode.UNEXPECTED_ERROR)); &#125; finally &#123; ContextHolder.clean(); &#125; &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#channelReadComplete(io.netty.channel.ChannelHandlerContext) */ @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#channelActive(io.netty.channel.ChannelHandlerContext) */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; &#125; /** * @see io.netty.channel.ChannelInboundHandlerAdapter#exceptionCaught(io.netty.channel.ChannelHandlerContext, * java.lang.Throwable) */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; LOG.error(cause.getCause().getMessage(), cause.getCause()); long logId = (Long) (ContextHolder.getContext(&quot;_logid&quot;)); PbrpcMsg retMsg = new PbrpcMsg(); retMsg.setLogId(logId); retMsg.setErrorCode(ErrorCode.COMMUNICATION_ERROR); // ctx.channel().writeAndFlush(retMsg); ctx.fireChannelRead(retMsg); // FIXME 对于通信异常的这样处理是否OK？ &#125;&#125; gateway项目12345678910111213141516171819@Overrideprotected void initChannel(SocketChannel ch) throws Exception &#123; CorsConfig corsConfig = CorsConfigBuilder.forOrigins(parseCorsAllowHostList()) .allowedRequestHeaders(&quot;X-Access-Token&quot;, &quot;content-type&quot;) .allowedRequestMethods(HttpMethod.GET, HttpMethod.POST, HttpMethod.PUT).build(); ch.pipeline().addLast(&quot;codec&quot;, new HttpServerCodec()); ch.pipeline().addLast(&quot;aggegator&quot;, new HttpObjectAggregator(maxContentLength)); ch.pipeline().addLast(&quot;cors&quot;, new CorsHandler(corsConfig)); ch.pipeline().addLast(&quot;idleStateHandler&quot;, new IdleStateHandler(0, 0, 300, TimeUnit.SECONDS)); //zipkin相关的 if (ZipkinHelper.httpTracing().isPresent()) ch.pipeline().addLast(&quot;tracing&quot;, new RequestTracingHandler()); //业务相关的handler for (ChannelHandler handler : handlers) &#123; ch.pipeline().addLast(handler.getClass().getSimpleName(), handler); // Use this if need &#125; 聊天室https://waylau.com/netty-chat/ 聊天室websocket版本]]></content>
  </entry>
  <entry>
    <title><![CDATA[netty-study]]></title>
    <url>%2F2018%2F04%2F17%2Fjava_netty%2Fnetty-study%2F</url>
    <content type="text"><![CDATA[why Netty 是一个提供 asynchronous event-driven （异步事件驱动）的网络应用框架，是一个用以快速开发高性能、可扩展协议的服务器和客户端。 换句话说，Netty 是一个 NIO 客户端服务器框架，使用它可以快速简单地开发网络应用程序，比如服务器和客户端的协议。Netty 大大简化了网络程序的开发过程比如 TCP 和 UDP 的 socket 服务的开发。 现在很多互联网上面的项目比如Dubbo、Hadoop系列，MQ等都在使用netty了 原生jdk nio（1）NIO的类库和API繁杂，使用麻烦，你需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等； （2）需要具备其他的额外技能做铺垫，例如熟悉Java多线程编程。这是因为NIO编程涉及到Reactor模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的NIO程序； （3）可靠性能力补齐，工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题，NIO编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大； （4）JDK NIO的BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询，最终导致CPU 100%。官方声称在JDK1.6版本的update18修复了该问题，但是直到JDK1.7版本该问题仍旧存在，只不过该BUG发生概率降低了一些而已，它并没有被根本解决。该BUG以及与该BUG相关的问题单可以参见以下链接内容： ◎ http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6403933 ◎ http://bugs.java.com/bugdatabase/view_bug.do?bug_id=2147719 整体架构预览 灵拷贝 统一的异步io api,方便更改 基于拦截链模式的事件模型 适用快速开发的高级组件 Codec 框架 SSL / TLS 支持 HTTP 实现 WebSockets 实现 Google Protocol Buffer 整合 缓冲（buffer），通道（channel），事件模型（event model） 内部组件: NioEventLoop 是 Netty 的 Reactor 线程，其角色： Boss Group：作为服务端 Acceptor 线程，用于 accept 客户端链接，并转发给 WorkerGroup 中的线程。 Worker Group：作为 IO 线程，负责 IO 的读写，从 SocketChannel 中读取报文或向 SocketChannel 写入报文。 Task Queue／Delay Task Queue：作为定时任务线程，执行定时任务，例如链路空闲检测和发送心跳消息等。 内部流程 其中步骤一至步骤九是 Netty 服务端的创建时序，步骤十至步骤十三是 TCP 网关容器创建的时序。 步骤一：创建 ServerBootstrap 实例，ServerBootstrap 是 Netty 服务端的启动辅助类。 步骤二：设置并绑定 Reactor 线程池，EventLoopGroup 是 Netty 的 Reactor 线程池，EventLoop 负责所有注册到本线程的 Channel。 步骤三：设置并绑定服务器 Channel，Netty Server 需要创建 NioServerSocketChannel 对象。 步骤四：TCP 链接建立时创建 ChannelPipeline，ChannelPipeline 本质上是一个负责和执行 ChannelHandler 的职责链。 步骤五：添加并设置 ChannelHandler，ChannelHandler 串行的加入 ChannelPipeline 中。 步骤六：绑定监听端口并启动服务端，将 NioServerSocketChannel 注册到 Selector 上。 步骤七：Selector 轮训，由 EventLoop 负责调度和执行 Selector 轮询操作。 步骤八：执行网络请求事件通知，轮询准备就绪的 Channel，由 EventLoop 执行 ChannelPipeline。 步骤九：执行 Netty 系统和业务 ChannelHandler，依次调度并执行 ChannelPipeline 的 ChannelHandler。 步骤十：通过 Proxy 代理调用后端服务，ChannelRead 事件后，通过发射调度后端 Service。 步骤十一：创建 Session，Session 与 Connection 是相互依赖关系。 步骤十二：创建 Connection，Connection 保存 ChannelHandlerContext。 步骤十三：添加 SessionListener，SessionListener 监听 SessionCreate 和 SessionDestory 等事件。 reactor如果你对 Java 网络 IO 这个话题感兴趣的话，肯定看过 Doug Lea 的《Scalable IO in Java》，在这个 PPT 里详细介绍了如何使用 Java NIO 的技术来实现 Douglas C. Schmidt 发表的 Reactor 论文里所描述的 IO 模型。针对这个高效的通信模型，Netty 做了非常友好的支持： Reactor模型 我们只需要在初始化 ServerBootstrap 时，提供两个不同的 EventLoopGroup 实例，就实现了 Reactor 的主从模型。我们通常把处理建连事件的线程，叫做 BossGroup，对应 ServerBootstrap 构造方法里的 parentGroup 参数，即我们常说的 Acceptor 线程；处理已创建好的 channel 相关连 IO 事件的线程，叫做 WorkerGroup，对应 ServerBootstrap 构造方法里的 childGroup 参数，即我们常说的 IO 线程。 最佳实践：通常 bossGroup 只需要设置为 1 即可，因为 ServerSocketChannel 在初始化阶段，只会注册到某一个 eventLoop 上，而这个 eventLoop 只会有一个线程在运行，所以没有必要设置为多线程（什么时候需要多线程呢，可以参考 Norman Maurer 在 StackOverflow 上的这个回答）；而 IO 线程，为了充分利用 CPU，同时考虑减少线上下文切换的开销，通常设置为 CPU 核数的两倍，这也是 Netty 提供的默认值。 串行化设计理念 Netty 从 4.x 的版本之后，所推崇的设计理念是串行化处理一个 Channel 所对应的所有 IO 事件和异步任务，单线程处理来规避并发问题。Netty 里的 Channel 在创建后，会通过 EventLoopGroup 注册到某一个 EventLoop 上，之后该 Channel 所有读写事件，以及经由 ChannelPipeline 里各个 Handler 的处理，都是在这一个线程里。一个 Channel 只会注册到一个 EventLoop 上，而一个 EventLoop 可以注册多个 Channel 。所以我们在使用时，也需要尽可能避免使用带锁的实现，能无锁化就无锁。 最佳实践：Channel 的实现是线程安全的，因此我们通常在运行时，会保存一个 Channel 的引用，同时为了保持 Netty 的无锁化理念，也应该尽可能避免使用带锁的实现，尤其是在 Handler 里的处理逻辑。举个例子：这里会有一个比较特殊的容易死锁的场景，比如在业务线程提交异步任务前需要先抢占某个锁，Handler 里某个异步任务的处理也需要获取同一把锁。如果某一个时刻业务线程先拿到锁 lock1，同时 Handler 里由于事件机制触发了一个异步任务 A，并在业务线程提交异步任务之前，提交到了 EventLoop 的队列里。之后，业务线程提交任务 B，等待 B 执行完成后才能释放锁 lock1；而任务 A 在队列里排在 B 之前，先被执行，执行过程需要获取锁 lock1 才能完成。这样死锁就发生了，与常见的资源竞争不同，而是任务执行权导致的死锁。要规避这类问题，最好的办法就是不要加锁；如果实在需要用锁，需要格外注意 Netty 的线程模型与任务处理机制。 业务处理 IO 密集型的轻计算业务：此时线程的上下文切换消耗，会比 IO 线程的占用消耗更为突出，所以我们通常会建议在 IO 线程来处理请求； CPU 密集型的计算业务：比如需要做远程调用，操作 DB 的业务，此时 IO 线程的占用远远超过线程上下文切换的消耗，所以我们就会建议在单独的业务线程池里来处理请求，以此来释放 IO 线程的占用。该模式，也是我们蚂蚁微服务，消息通信等最常使用的模型。该模式在后面的 RPC 协议实现举例部分会详细介绍。 如文章开头所描述的场景，我们需要合理设计，来将硬件的 IO 能力，CPU 计算能力与内存结合起来，发挥最佳的效果。针对不同的业务类型，我们会选择不同的处理方式 最佳实践：“Never block the event loop, reduce context-swtiching”，引自Netty committer Norman Maurer，另外阿里 HSF 的作者毕玄也有类似的总结。 其他实践建议 最小化线程池，能复用 EventLoopGroup 的地方尽量复用。比如蚂蚁因为历史原因，有过两版 RPC 协议，在两个协议升级过渡期间，我们会复用 Acceptor 线程与 IO 线程在同一个端口处理不同协议的请求；除此，针对多应用合并部署的场景，我们也会复用 IO 线程防止一个进程开过多的 IO 线程。 对于无状态的 ChannelHandler ，设置成共享模式。比如我们的事件处理器，RPC 处理器都可以设置为共享，减少不同的 Channel 对应的 ChannelPipeline 里生成的对象个数。 正确使用 ChannelHandlerContext 的 ctx.write() 与 ctx.channel().write() 方法。前者是从当前 Handler 的下一个 Handler 开始处理，而后者会从 tail 开始处理。大多情况下使用 ctx.write() 即可。 在使用 Channel 写数据之前，建议使用 isWritable() 方法来判断一下当前 ChannelOutboundBuffer 里的写缓存水位，防止 OOM 发生。不过实践下来，正常的通信过程不太会 OOM，但当网络环境不好，同时传输报文很大时，确实会出现限流的情况。 demo案例discard服务器123456789101112131415public class DiscardServerHandler extends ChannelInboundHandlerAdapter &#123; // (1) @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // (2) // 以静默方式丢弃接收的数据 ((ByteBuf) msg).release(); // (3) &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // (4) // 出现异常时关闭连接。 cause.printStackTrace(); ctx.close(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class DiscardServer &#123; private int port; public DiscardServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); // (1) EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); // (2) b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; // (4) @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new DiscardServerHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) // (5) .childOption(ChannelOption.SO_KEEPALIVE, true); // (6) // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // (7) // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new DiscardServer(port).run(); &#125;&#125; echo服务12345@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ctx.write(msg); // (1) ctx.flush(); // (2)&#125; time服务器https://waylau.gitbooks.io/netty-4-user-guide/Getting%20Started/Writing%20a%20Time%20Server.html 处理一个基于流的传输基于流的传输比如 TCP/IP, 接收到数据是存在 socket 接收的 buffer 中。不幸的是，基于流的传输并不是一个数据包队列，而是一个字节队列。意味着，即使你发送了2个独立的数据包，操作系统也不会作为2个消息处理而仅仅是作为一连串的字节而言。因此这是不能保证你远程写入的数据就会准确地读取。举个例子，让我们假设操作系统的 TCP/TP 协议栈已经接收了3个数据包： 由于基于流传输的协议的这种普通的性质，在你的应用程序里读取数据的时候会有很高的可能性被分成下面的片段因此，一个接收方不管他是客户端还是服务端，都应该把接收到的数据整理成一个或者多个更有意思并且能够让程序的业务逻辑更好理解的数据。在上面的例子中，接收到的数据应该被构造成下面的格式 参考http://www.infoq.com/cn/articles/practice-of-java-nio-communication-frameworkhttps://waylau.gitbooks.io/netty-4-user-guidehttps://github.com/netty/netty/tree/4.0/example/src/main/java/io/netty/example]]></content>
  </entry>
  <entry>
    <title><![CDATA[并发工具之CompletionService]]></title>
    <url>%2F2018%2F04%2F16%2Fjava_thread%2FCompletionService%2F</url>
    <content type="text"><![CDATA[介绍当向Executor提交多个任务并且希望获得它们在完成之后的结果，如果用FutureTask，可以循环获取task，并调用get方法去获取task执行结果，但是如果task还未完成，获取结果的线程将阻塞直到task完成，由于不知道哪个task优先执行完毕，使用这种方式效率不会很高。在jdk5时候提出接口CompletionService，它整合了Executor和BlockingQueue的功能，可以更加方便在多个任务执行时获取到任务执行结果。 案例1234567891011121314151617181920212223242526public class CompletionServiceTest &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ExecutorService executorService = Executors.newFixedThreadPool(100); ExecutorCompletionService&lt;Integer&gt; completionService = new ExecutorCompletionService&lt;Integer&gt;(executorService); for (int i = 0; i &lt; 10; i++) &#123; completionService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; TimeUnit.SECONDS.sleep(5); int i1 = new Random().nextInt(); System.out.println(i1); return i1; &#125; &#125;); &#125; int sum = 0; for (int i = 0; i &lt; 10; i++) &#123; Future&lt;Integer&gt; poll = completionService.take(); Integer integer = poll.get(); sum += integer; &#125; System.out.println(sum); &#125;&#125; 源码分析ExecutorCompletionService有三个成员变量： executor：执行task的线程池，创建CompletionService必须指定； aes：主要用于创建待执行task； completionQueue：存储已完成状态的task，默认是基于链表结构的阻塞队列LinkedBlockingQueue。 从submit方法的源码可以看出，在提交到线程池的时候需要将FutureTask封装成QueueingFuture]]></content>
  </entry>
  <entry>
    <title><![CDATA[java并发编程实战-第二章-线程安全性]]></title>
    <url>%2F2018%2F04%2F15%2Freading-notes%2Fjava-con-2%2F</url>
    <content type="text"><![CDATA[什么是线程安全型 首先使代码正确运行，然后再提高代码速度。【正确编写并发程序的方法】 定义:当多个线程访问某个类时，不管是 1）运行时环境采用何种调度方式，2）或者这些线程如何交替执行，3）并在在主调代码中不需要任何额外的同步或者协同，这个类能始终表现出正确的行为。 无状态对象一定是线程安全的 Java主要用synchronized做同步，这是一种独占的加锁方式，其他还包括volatile、显式锁（explicit lock）等。 如果出现线程安全问题，要怎么解决？1）不在线程间共享（比如改成局部变量）2）将状态改为不可变变量3）访问状态变量时使用同步 原子性竞争条件 由于不恰当的执行时序而出现不正确的结果是一种重要的情况,叫做竞争条件 当某个计算的正确性取决于多个线程的交替执行时序。最常见的竞态条件类型先检查后执行（Check-Then-Act）。 实例:延迟初始化中的竞争条件单例模式,如果不加锁,返回不同的实例 复合操作加锁机制需要同时更新两个值 内置锁 synchronized 重入可重入意味着获取锁的操作的粒度是“线程”，而不是“调用”。重入的一种实现方法是为每一个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁没有被任何线程持有，当线程请求一个未被获取这个锁，计数值将递增，当线程退出同步代码块时，计数器会递减。当计数器为0时，释放该锁。 用锁来保护状态锁可以使其保护的代码路径以串行的方式来访问。 如果用同步来协调对某个变量的访问时,那么在访问这个变量的所有位置上都需要使用同步 最好注释变量是由哪个锁锁保护 活跃性与性能可以将执行时间较长的操作从锁中移除]]></content>
  </entry>
  <entry>
    <title><![CDATA[java并发编程实战-第三章-对象的共享]]></title>
    <url>%2F2018%2F04%2F15%2Freading-notes%2Fjava-con-3%2F</url>
    <content type="text"><![CDATA[3.1可见性 首先我们需要知道的是，java的线程都有自己独立的缓存，线程之间进行共享变量的交互是通过自身和缓存和主存的交互实现的。 如果线程的每次更改缓存都刷入主存，主存每次被一个线程的缓存修改，都通知所有的线程刷新自身的缓存的话，那样就太不经济了。 由于1和2，就会产生一个现象：当线程1修改了一个共享变量之后，线程2获取的共享变量还是更改前的值。即线程1更改共享变量并没有刷入主存，或者线程2并没有去主存中获取到新的共享变量，或以上两者皆有 为了解决内存可见性我们可以使用volatile关键字和同步这两种方式 变量的读取,指令重排序 失效数据非原子的64位操作当读取一个非volatile类型的long变量时,如果对该变量的读操作和写操作在不同的线程中执行,那么很可能读取到某个值的高32位和另外一个值的低32位 加锁和可见性加锁的含义不仅互斥,还包括内存可见性 volatile变量 用来确保变量的更新操作通知到其他线程 编译器与运行时都会注意到这个变量时共享的,不会进行重排序 volatile不会被缓存在寄存器或者其他处理器不可见的地方,读取变量时,总能返回最新的写入值 满足所有条件,才应该使用volatile 对变量的写入不依赖变量的当前值,只有单个线程更新变脸的值 该变量不会与其他状态一起纳入不变形条件中 在访问时不需要加锁 3.2发布与溢出 一般自定义类需要考虑发布(构造方法), juc的类已经处理过了 发布:是对象能够在当前作用域之外的代码中使用 将对象的引用存储到公共静态域。 在非私有方法中返回引用。 在发布某对象的时候可能会间接发布本不想发布的对象，如一个private的数组，一旦被发布，其中储存的对象也会被发布 溢出:不应该发布的被发布了类对自己的内部状态进行了同步操作,如果发布出去可能会破坏封装性,并使程序难以维护不变性条件一个对象在尚未准备好就将它发布出去——溢出。 “内部类发布也会引发溢出”，因为只有当对象通过构造函数返回之后，才处于稳定状态。这种发布会导致this溢出。 “即使在构造函数的最后一行发布也会有该问题”，指令重排序可能会引发一些奇怪的问题。而且该引用已经不是null了，但是内容还没有初始化完毕也有可能。 “不要让this在构造期溢出！” 常见错误 1.在构造函数中创建并启动线程这个时候线程已经获得了this的引用（即使是隐式的，因为该Runnable或者Thread是所属对象的内部类），this引用几乎总是被新线程所共享。所以在构造函数中创建线程没有错误，但是不要在构造函数中启动它。 2.注册一个内部类,使用this方法可以使用静态工厂和私有构造函数来解决这个问题。 3.3线程封闭数据仅在单线程中被访问，即数据不共享。几种方式： 特定的方法例如在一个线程中进行 读取修改写入,其他线程中进行读取 栈封闭引用在局部变量中注意不要让当前线程中的对象从所在线程溢出！ java的ThreadLocal使用ThreadLocal可以做到线程隔离，每个线程都有自己单独的一个区域保存变量。 3.4不变性对象 不可变对象满足下列条件： 所有域是final的，域内部的域也是final的 所有域不可改变 this没有在构造的时候逸出 final域使用volatile类型来发布不可变对象3.5安全发布不正确的发布:正确的对象被破坏导致其他县城看到尚未创建完的对象 不可变对象与初始化安全安全发布的常用模式 在静态初始化对象引用，因为JVM的类加载过程中是同步的 对对象引用使用volatile或AtomicReference 将对象引用放入final域中 对对象引用加锁 案例: 将一个键值对放入HashTable,syhronizedMap或者ConcurrentMap中 静态构造的对象public static Holder holder= new Holder(42) 事实不可变对象程序不会去修改,例如Date虽然是可变的,但是放入了同步的HashMap中,且不会修改,那么就认为是不可变的对象 可变对象 不仅要保证发布时的状态可见性 每次访问时同样需要使用同步来确保后需修改操作的可见性 小结 不可变对象可以通过任意机制来发布() 事实不可变对象必须通过安全方式来发布 可变对象必须通过安全方式来发布,并且是线程安全的或者由某个所保护起来 安全的共享对象在发布一个对象的时候需要明确指出该对象的多线程共享规则： 是线程封闭？：只能由一个线程拥有 是只读共享？：只能并发读 是线程安全共享？：类内部实现了同步，可以随意使用 是保护对象？：类内部没有实现同步，需要使用者在外部同步]]></content>
  </entry>
  <entry>
    <title><![CDATA[http和ajax区别和练习]]></title>
    <url>%2F2018%2F04%2F13%2Fhttp%2Fhttp-ajax-compare%2F</url>
    <content type="text"><![CDATA[AJAX和HTTP请求的区别从本质上将：AJAX就是浏览器发出的HTTP请求，只不过是浏览器加上了一个同源策略限制而已。 AJAX请求的XMLHTTPRequest对象就是浏览器开放给JS调用HTTP请求用的。 那么AJAX和HTTP的区别呢？列出以下几点： AJAX请求受到浏览器的同源策略限制，存在跨域问题 AJAX在进行复杂请求时，浏览器会预先发出OPTIONS预检（HTTP自己是不会预检的） 从使用角度上说，AJAX使用简单一点，少了些底层细节，多了些浏览器特性（如自动带上同域cookie等） 所以说，和认证上的HTTP请求的区别就是-多了一次浏览器的封装而已（浏览器会有自己的预处理，加上特定限制） 但是，从最终发出的报文来看，内容都是一样的（HTTP协议规范的内容），AJAX是发送HTTP请求的一种方式 CORS与AJAX安全性之间的关联这是一个跨域共享方案，大致流程就是：（仅以复杂请求的预检举例-这一部分要求提前掌握CORS相关知识） 前端AJAX请求前发出一个OPTIONS预检，会带一堆相关头部发送给服务端 服务端在接受到预检时，检查头部，来源等信息是否合法，合法则接下来允许正常的请求，否则直接无情的拒绝掉 浏览器端如果收到服务端拒绝的信息（响应头部检查），就抛出对应错误。否则就是正常的响应，接下来发出真正的请求（如POST）请求和响应的头部信息大概如下： Request Headers 12345// 在CORS中专门作为Origin信息供后端比对，表示来源域。Origin: http://xxxAccess-Control-Request-Headers: X-Requested-With// 所有用setRequestHeader方法设置的头部都将会以逗号隔开的形式包含在这个头中，一般POST请求中就会带上Access-Control-Request-Method: OPTIONS Response Headers 123Access-Control-Allow-Headers: Origin, X-Requested-With, Content-Type, AcceptAccess-Control-Allow-Methods: GET, POST, OPTIONSAccess-Control-Allow-Origin: http://xxx 最终，客户端发出的请求，必须符合服务端的校验规则才能正确，服务端才会返回正确头部，否则只会请求失败。报跨域错误。 关键问题来了，在上面的CORS配置是这样的： Access-Control-Allow-Origin: http://xxx但是这个配置只允许特定域名访问，鉴于前端的复杂性，有时候调试起来不是很方便，因此有时候，会偷懒的设置为： Access-Control-Allow-Origin: * 会对cookie认证造成影响么？ 不会。虽然*代表了所有来源都能正常请求，但是同源策略下，是无法带上跨域cookie的。因此根本无法用身份验证。 而且，就算用withCredentials强行带上跨域cookie，因为后台没有支持，所以会报错。（这可以看成是CORSs模型的最后一道防线） 再者，后台就算配置Access-Control-Allow-Credentials允许跨域cookie，但是这时候的安全策略是Origin不允许为，必须是一个明确的地址。（否则你就可以看到浏览器的报错信息-跨域cookie时，Origin不允许为） 两种请求浏览器将CORS请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。 只要同时满足以下两大条件，就属于简单请求。123456789101112（1) 请求方法是以下三种方法之一：HEADGETPOST（2）HTTP的头信息不超出以下几种字段：AcceptAccept-LanguageContent-LanguageLast-Event-IDContent-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 浏览器对这两种请求的处理，是不一样的。 简单请求基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 123456GET /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 1234Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Credentials: trueAccess-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(‘FooBar’)可以返回FooBar字段的值。 3.2 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true另一方面，开发者必须在AJAX请求中打开withCredentials属性。 var xhr = new XMLHttpRequest();xhr.withCredentials = true;否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 xhr.withCredentials = false;需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true另一方面，开发者必须在AJAX请求中打开withCredentials属性。 12var xhr = new XMLHttpRequest();xhr.withCredentials = true; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 非简单请求预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 12345var url = &apos;http://api.alice.com/cors&apos;;var xhr = new XMLHttpRequest();xhr.open(&apos;PUT&apos;, url, true);xhr.setRequestHeader(&apos;X-Custom-Header&apos;, &apos;value&apos;);xhr.send(); 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... “预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，”预检”请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 123456789101112HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2.0.61 (Unix)Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderContent-Type: text/html; charset=utf-8Content-Encoding: gzipContent-Length: 0Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 Access-Control-Allow-Origin: *如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 XMLHttpRequest cannot load http://api.alice.com.Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin.服务器回应的其他CORS相关字段如下。 1234Access-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderAccess-Control-Allow-Credentials: trueAccess-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是”预检”请求之后，浏览器的正常CORS请求。 1234567PUT /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comX-Custom-Header: valueAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 12Access-Control-Allow-Origin: http://api.bob.comContent-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 参考http://www.ruanyifeng.com/blog/2016/04/cors.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[通过浏览器插件SwitchyOmega进行代理]]></title>
    <url>%2F2018%2F04%2F10%2Ftools%2Fmanual-proxy-setting%2F</url>
    <content type="text"><![CDATA[背景由于公司安全原因，需要在本地安装Pulse-Secure vpn工具，导致之前使用的ShadowsocksX-NG PAC自动模式无法使用 步骤 ShadowsocksX-NG设置为手动模式 查看ShadowsocksX的偏好设置，查找http端口1087 下载chrome的SwitchyOmega插件 配置 制定域名下走proxy情景模式]]></content>
  </entry>
  <entry>
    <title><![CDATA[管理多个ssl私钥]]></title>
    <url>%2F2018%2F04%2F10%2Ftools%2Fmulti-ssl-key%2F</url>
    <content type="text"><![CDATA[背景由于本地的sshkey已经绑定了gitlab,github等多个账号，如果换的话很麻烦但是公司要求需要有公司邮箱的一个ssl私钥，so有了多个ssl管理的需求 步骤大体参照https://www.cnblogs.com/popfisher/p/5731232.html 这篇文章即可 指定名称生成私钥123456789101112131415161718192021222324[appusr@iZ2zed4vtb8cdfk7pw69dzZ ~]$ ssh-keygen -t rsa -C &quot;邮箱&quot; -f newkeyGenerating public/private rsa key pair.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in newkey.Your public key has been saved in newkey.pub.The key fingerprint is:bb:7a:24:8c:a7:ae:c8:81:6c:7a:b5:1a:82:19:84:d6 邮箱The key&apos;s randomart image is:+--[ RSA 2048]----+| ||. . ||.o E ||o ||. o S ||+o o + .. ||=+.. + o. ||+oo.o .. ||ooo+. .o. |+-----------------+-rw------- 1 appusr appusr 1675 4月 10 19:36 newkey-rw-r--r-- 1 appusr appusr 388 4月 10 19:36 newkey.pub 配置.ssh/config文件12345678910111213# 配置github.comHost github.com HostName github.com IdentityFile C:\\Users\\popfisher\\.ssh\\id_rsa_github PreferredAuthentications publickey User username1# 配置git.oschina.net Host git.oschina.net HostName git.oschina.net IdentityFile C:\\Users\\popfisher\\.ssh\\id_rsa_oschina PreferredAuthentications publickey User username2 完成只有指定的域名通过指定的ssl进行访问其他域名，还是走默认的路径~/.ssh/id_rsa]]></content>
  </entry>
  <entry>
    <title><![CDATA[normal-online-problem-fix]]></title>
    <url>%2F2018%2F04%2F10%2F%E8%BF%90%E7%BB%B4%2Fnormal-online-problem-fix%2F</url>
    <content type="text"><![CDATA[处理步骤发现问题发现问题通常通过自动化的监控和报警系统来实现，线上游戏服搭建了一个完善、有效的日志中心、监控和报警系统，通常我们会从系统层面、应用层面和数据库层面进行监控。 系统层对系统层面的监控包括对系统的CPU利用率、系统负载、内存使用情况、网络I/O负载、磁盘负载、I/O等待、交换区的使用、线程数及打开的文件句柄数等进行的监控，一旦超出阈值，就需要报警。 应用层对应用层面的监控包括对服务接口的响应时间、吞吐量、调用频次、接口成功率及接口的波动率等进行的监控。 数据库,缓存,消息队列对资源层的监控包括对数据库、缓存和消息队列的监控。我们通常会对数据库的负载、慢SQL、连接数等进行监控；对缓存的连接数、占用内存、吞吐量、响应时间等进行监控；并对消息队列的响应时间、吞吐量、负载、积压情况等进行监控。 定位问题定位问题时，首先要根据经验来分析，如果应急团队中有人对相应的问题有经验，并确定能够通过某种手段进行恢复，则应该第一时间恢复，同时保留现场，然后定位问题。应急人员在定位过程中需要与业务负责人、技术负责人、核心技术开发人员、技术专家、架构师、运营人员和运维人员一起，对产生问题的原因进行快速分析。在分析的过程中要先考虑系统最近的变化，考虑如下问题。 问题系统最近是否进行了上线？(系统本身) 依赖的基础平台和资源是否进行了上线或者升级？（基础资源） 依赖的系统最近是否进行了上线？（以来系统） 运营人员是否在系统里做过运营变更？（运营） 网络是否有波动？（网络） 最近的业务是否上量？（访问量） 服务的使用方是否有促销活动？（促销） 解决问题解决问题的阶段有时处于应急处理中，有时处于应急处理后。在理想情况下，每个系统都会对各种严重情况设计止损和降级开关，因此在发生严重问题时先使用止损策略，在恢复问题后再定位和解决问题。解决问题要以定位问题为基础，必须清晰地定位问题产生的根本原因，再提出解决问题的有效方案，切记在没有明确原因之前，不要使用各种可能的方法来尝试修复问题，这样可能导致还没有解决这个问题又引出另一个问题。 消除影响在解决问题时，某个问题可能还没被解决就已恢复，在任何情况下都需要消除问题带来的影响。 技术人员在应急过程中对系统做的临时性改变，若在后面证明是无效的，则要尝试恢复到原来的状态。 技术人员在应急过程中对系统进行的降级开关操作，在事后需要恢复。 运营人员在应急过程中对系统做的特殊设置如某些流量路由的开关，在事后需要恢复。 对使用方或者用户造成的问题，尽量采取补偿的策略进行修复，在极端情况下需要一一核实。 对外由专门的客服团队整理话术，统一对外宣布发生故障的原因并安抚用户，话术要贴近客观事实，并从用户的角度出发。 实际应用 首先，找运维看日志。如果在日志监控系统中有报错，则能很好地定位问题，我们只需根据日志报错的堆栈信息来解决问题即可。如果在日志监控系统中没有任何异常信息，就得保存现场了。 其次，保存现场并恢复服务。在日志系统中找不到任何线索的情况下，我们需要赶紧保存现场快照，并尽快恢复服务，以达到最大程度止损的目的。 保存现场在JVM中保存现场快照通常包括保存当前运行线程的快照和保存JVM内存堆栈快照。如下所述。 （1）保存当前运行线程的快照，可以使用jstack [pid]命令实现，在通常情况下需要保存三份不同时刻的线程快照，时间间隔为1～2分钟。（2）保存JVM内存堆栈快照，可以使用jmap –heap、jmap –histo、jmap -dump:format=b、file=xxx.hprof等命令实现。 快速恢复（1）隔离出现问题的服务，使其退出线上服务，便于后续的分析处理。（2）尝试快速重启服务，第一时间恢复系统，而不是彻底解决问题。（3）对服务降级处理，只使用少量的请求来重现问题，以便我们全程跟踪观察，因为之前可能没太注意这个问题是如何发生的。通过上面的一系列操作后，要分析日志并定位问题。这一步很关键，也需要有很多实战经验，需要先查看服务器的“当前症状”，才能进一步对症下药。下面提供从服务器的CPU、内存和I/O三方面查看症状的基本方法。 查看CPU或内存情况的命令如下： top：查看服务器的负载状况。 top+1：在top视图中按键盘数字“1”查看每个逻辑CPU的使用情况。 jstat –gcutil pid：查看堆中各内存区域的变化及GC的工作状态。 top+H：查看线程的使用情况。 ps -mp pid -o THREAD,tid,time | sort -rn：查看指定进程中各个线程占用CPU的状态，选出耗时最多、最繁忙的线程id。 jstack pid：打印进程中的线程堆栈信息。判断内存溢出（OOM）方法如下。 堆外内存溢出：由JNI的调用或NIO中的DirectByteBuffer等使用不当造成。 堆内内存溢出：容易由程序中创建的大对象、全局集合、缓存、ClassLoader加载的类或大量的线程消耗等造成。 使用jmap –heap命令、jmap –histo命令或者jmap-dump:format=b,file=xxx.hprof等命令查看JVM内存的使用情况。 分析I/O读写问题的方法如下。 文件I/O：使用命令vmstat、lsof –c -ppid等。 网络I/O：使用命令netstat –anp、tcpdump -i eth0 ‘dst host 239.33.24.212’ -w raw.pcap和wireshark工具等。 MySQL数据库：查看慢查询日志、数据库的磁盘空间、排查索引是否缺失，或使用show processlist检查具体的SQL语句情况。最后，在Hotfix后继续观察情况。在测试环境或预生产环境修改测试后，如果问题不能再复现了，就可以根据公司的Hotfix流程进行线上的Bug更新，并继续观察。如果一切都正常，就需要消除之前可能造成的影响。]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql-where]]></title>
    <url>%2F2018%2F04%2F08%2Fmysql%2Fmysql-where%2F</url>
    <content type="text"><![CDATA[where条件所有SQL的where条件，均可归纳为3大类：Index Key (First Key &amp; Last Key)，Index Filter，Table Filter。 接下来，让我们来详细分析者3大类分别是如何定义，以及如何提取的。 Index Key用于确定SQL查询在索引中的连续范围(起始范围+结束范围)的查询条件，被称之为Index Key。由于一个范围，至少包含一个起始与一个终止，因此Index Key也被拆分为Index First Key和Index Last Key，分别用于定位索引查找的起始，以及索引查询的终止条件。 Index First Key用于确定索引查询的起始范围。提取规则：从索引的第一个键值开始，检查其在where条件中是否存在，若存在并且条件是=、&gt;=，则将对应的条件加入Index First Key之中，继续读取索引的下一个键值，使用同样的提取规则；若存在并且条件是&gt;，则将对应的条件加入Index First Key中，同时终止Index First Key的提取；若不存在，同样终止Index First Key的提取。 针对上面的SQL，应用这个提取规则，提取出来的Index First Key为(b &gt;= 2, c &gt; 1)。由于c的条件为 &gt;，提取结束，不包括d。 Index Last KeyIndex Last Key的功能与Index First Key正好相反，用于确定索引查询的终止范围。提取规则：从索引的第一个键值开始，检查其在where条件中是否存在，若存在并且条件是=、&lt;=，则将对应条件加入到Index Last Key中，继续提取索引的下一个键值，使用同样的提取规则；若存在并且条件是 &lt; ，则将条件加入到Index Last Key中，同时终止提取；若不存在，同样终止Index Last Key的提取。 针对上面的SQL，应用这个提取规则，提取出来的Index Last Key为(b &lt; 8)，由于是 &lt; 符号，因此提取b之后结束。 Index Filter在完成Index Key的提取之后，我们根据where条件固定了索引的查询范围，但是此范围中的项，并不都是满足查询条件的项。在上面的SQL用例中，(3,1,1)，(6,4,4)均属于范围中，但是又均不满足SQL的查询条件。 Index Filter的提取规则：同样从索引列的第一列开始，检查其在where条件中是否存在：若存在并且where条件仅为 =，则跳过第一列继续检查索引下一列，下一索引列采取与索引第一列同样的提取规则；若where条件为 &gt;=、&gt;、&lt;、&lt;= 其中的几种，则跳过索引第一列，将其余where条件中索引相关列全部加入到Index Filter之中；若索引第一列的where条件包含 =、&gt;=、&gt;、&lt;、&lt;= 之外的条件，则将此条件以及其余where条件中索引相关列全部加入到Index Filter之中；若第一列不包含查询条件，则将所有索引相关条件均加入到Index Filter之中。 针对上面的用例SQL，索引第一列只包含 &gt;=、&lt; 两个条件，因此第一列可跳过，将余下的c、d两列加入到Index Filter中。因此获得的Index Filter为 c &gt; 1 and d != 4 。 Table FilterTable Filter是最简单，最易懂，也是提取最为方便的。提取规则：所有不属于索引列的查询条件，均归为Table Filter之中。 同样，针对上面的用例SQL，Table Filter就为 e != ‘a’。 Index Key/Index Filter/Table Filter小结SQL语句中的where条件，使用以上的提取规则，最终都会被提取到Index Key (First Key &amp; Last Key)，Index Filter与Table Filter之中。 Index First Key，只是用来定位索引的起始范围，因此只在索引第一次Search Path(沿着索引B+树的根节点一直遍历，到索引正确的叶节点位置)时使用，一次判断即可； Index Last Key，用来定位索引的终止范围，因此对于起始范围之后读到的每一条索引记录，均需要判断是否已经超过了Index Last Key的范围，若超过，则当前查询结束； Index Filter，用于过滤索引查询范围中不满足查询条件的记录，因此对于索引范围中的每一条记录，均需要与Index Filter进行对比，若不满足Index Filter则直接丢弃，继续读取索引下一条记录； Table Filter，则是最后一道where条件的防线，用于过滤通过前面索引的层层考验的记录，此时的记录已经满足了Index First Key与Index Last Key构成的范围，并且满足Index Filter的条件，回表读取了完整的记录，判断完整记录是否满足Table Filter中的查询条件，同样的，若不满足，跳过当前记录，继续读取索引的下一条记录，若满足，则返回记录，此记录满足了where的所有条件，可以返回给前端用户。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-lock]]></title>
    <url>%2F2018%2F04%2F07%2Fmysql%2Fmysql-lock%2F</url>
    <content type="text"><![CDATA[MySQL中锁的种类MySQL中锁的种类很多，有常见的表锁和行锁，也有新加入的Metadata Lock等等,表锁是对一整张表加锁，虽然可分为读锁和写锁，但毕竟是锁住整张表，会导致并发能力下降，一般是做ddl处理时使用。 行锁则是锁住数据行，这种加锁方法比较复杂，但是由于只锁住有限的数据，对于其它数据不加限制，所以并发能力强，MySQL一般都是用行锁来处理并发事务。这里主要讨论的也就是行锁。 Read Committed（读取提交内容）在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。 为了防止并发过程中的修改冲突，事务A中MySQL给teacher_id=1的数据行加锁，并一直不commit（释放锁），那么事务B也就一直拿不到该行锁，wait直到超时。 这时我们要注意到，teacher_id是有索引的，如果是没有索引的class_name呢？update class_teacher set teacher_id=3 where class_name = ‘初三一班’;那么MySQL会给整张表的所有数据行的加行锁。这里听起来有点不可思议，但是当sql运行的过程中，MySQL并不知道哪些数据行是 class_name = ‘初三一班’的（没有索引嘛），如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL Server层进行过滤。 但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181） 这种情况同样适用于MySQL的默认隔离级别RR。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。 Repeatable Read（可重读）读取读就是可重读，可重读这个概念是一事务的多个实例在并发读取数据时，会看到同样的数据行，有点抽象，我们来看一下效果。 使用悲观锁机制来处理这两种问题，但是MySQL、ORACLE、PostgreSQL等成熟的数据库，出于性能考虑，都是使用了以乐观锁为理论基础的MVCC（多版本并发控制）来避免这两种问题（不可重复读和幻读）。 悲观锁和乐观锁 悲观锁 正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。 乐观锁 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。 而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 要说明的是，MVCC的实现没有固定的规范，每个数据库都会有不同的实现方式，这里讨论的是InnoDB的MVCC。 MVCC在MySQL的InnoDB中的实现在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下： SELECT时，读取创建版本号&lt;=当前事务版本号，删除版本号为空或&gt;当前事务版本号。INSERT时，保存当前事务版本号为行的创建版本号DELETE时，保存当前事务版本号为行的删除版本号UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行通过MVCC，虽然每行记录都需要额外的存储空间，更多的行检查工作以及一些额外的维护工作，但可以减少锁的使用，大多数读操作都不用加锁，读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，也只锁住必要行。 我们不管从数据库方面的教课书中学到，还是从网络上看到，大都是上文中事务的四种隔离级别这一模块列出的意思，RR级别是可重复读的，但无法解决幻读，而只有在Serializable级别才能解决幻读。于是我就加了一个事务C来展示效果。在事务C中添加了一条teacher_id=1的数据commit，RR级别中应该会有幻读现象，事务A在查询teacher_id=1的数据时会读到事务C新加的数据。但是测试后发现，在MySQL中是不存在这种情况的，在事务C提交后，事务A还是不会读到这条数据。可见在MySQL的RR级别中，是解决了幻读的读问题的。参见下图 读问题解决了，根据MVCC的定义，并发提交数据时会出现冲突，那么冲突时如何解决呢？我们再来看看InnoDB中RR级别对于写数据的处理。 快照读(一致性读)和当前读可能有读者会疑惑，事务的隔离级别其实都是对于读数据的定义，但到了这里，就被拆成了读和写两个模块来讲解。这主要是因为MySQL中的读，和事务隔离级别中的读，是不一样的。 我们且看，在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效特别敏感的业务中，就很可能出问题。 对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。很显然，在MVCC中： 快照读：读取记录的可见版本(有可能是历史版本), no-locking select * from table ….; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert; update ; delete; 事务的隔离级别实际上都是定义了当前读的级别，MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”，就需要另外的模块来解决了。 写（”当前读”）事务的隔离级别中虽然只定义了读数据的要求，实际上这也可以说是写数据的要求。上文的“读”，实际是讲的快照读；而这里说的“写”就是当前读了。为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁。 Next-Key锁Next-Key锁是行锁和GAP（间隙锁）的合并，行锁上文已经介绍了，接下来说下GAP间隙锁。 行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题。我们可以看看RR级别和RC级别的对比 在RC级别中，事务A修改了所有teacher_id=30的数据，但是当事务Binsert进新数据后，事务A发现莫名其妙多了一行teacher_id=30的数据，而且没有被之前的update语句所修改，这就是“当前读”的幻读。 RR级别中，事务A在update后加锁，事务B无法插入新数据，这样事务A在update前后读的数据保持一致，避免了幻读。这个锁，就是Gap锁。 MySQL是这么实现的： 在class_teacher这张表中，teacher_id是个索引，那么它就会维护一套B+树的数据关系，为了简化，我们用链表结构来表达（实际上是个树形结构，但原理相同） 如图所示，InnoDB使用的是聚集索引，teacher_id身为二级索引，就要维护一个索引字段和主键id的树状结构（这里用链表形式表现），并保持顺序排列。 Innodb将这段数据分成几个个区间 (negative infinity, 5], (5,30], (30,positive infinity)；update class_teacher set class_name=’初三四班’ where teacher_id=30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了gap锁。这样事务B就无法在这个两个区间insert进新数据。 受限于这种实现方式，Innodb很多时候会锁住不需要锁的区间。如下所示： update的teacher_id=20是在(5，30]区间，即使没有修改任何数据，Innodb也会在这个区间加gap锁，而其它区间不会影响，事务C正常插入。 如果使用的是没有索引的字段，比如update class_teacher set teacher_id=7 where class_name=’初三八班（即使没有匹配到任何数据）’,那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。 行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。 Serializable这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。如果你的业务并发的特别少或者没有并发，同时又要求数据及时可靠的话，可以使用这种模式。 这里要吐槽一句，不要看到select就说不会加锁了，在Serializable这个级别，还是会加锁的！ MySQL 加锁处理分析背景MVCC：Snapshot Read vs Current ReadMySQL InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) (注：与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。 在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read)。快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例： 快照读：就是select select * from table ….; 当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。 select * from table where ? lock in share mode; select * from table where ? for update; insert; update ; delete; 所有以上的语句，都属于当前读，读取记录的最新版本。并且，读取之后，还需要保证其他并发事务不能修改当前记录，对读取记录加锁。其中，除了第一条语句，对读取记录加S锁 (共享锁)外，其他的操作，都加的是X锁 (排它锁)。 为什么将 插入/更新/删除 操作，都归为当前读？可以看看下面这个 更新 操作，在数据库中的执行流程： 从图中，可以看到，一个Update操作的具体流程。当Update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个Update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，Update操作内部，就包含了一个当前读。同理，Delete操作也一样。Insert操作会稍微有些不同，简单来说，就是Insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。 Cluster Index：聚簇索引InnoDB存储引擎的数据组织方式，是聚簇索引表：完整的记录，存储在主键索引中，通过主键索引，就可以获取记录所有的列。关于聚簇索引表的组织方式，可以参考MySQL的官方文档：Clustered and Secondary Indexes 。本文假设读者对这个，已经有了一定的认识，就不再做具体的介绍。接下来的部分，主键索引/聚簇索引 两个名称，会有一些混用，望读者知晓。 2PL：Two-Phase Locking传统RDBMS加锁的一个原则，就是2PL (二阶段锁)：Two-Phase Locking。相对而言，2PL比较容易理解，说的是锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交。下面，仍旧以MySQL为例，来简单看看2PL在MySQL中的实现。 Isolation Level隔离级别：Isolation Level，也是RDBMS的一个关键特性。相信对数据库有所了解的朋友，对于4种隔离级别：Read Uncommited，Read Committed，Repeatable Read，Serializable，都有了深入的认识。本文不打算讨论数据库理论中，是如何定义这4种隔离级别的含义的，而是跟大家介绍一下MySQL/InnoDB是如何定义这4种隔离级别的。 MySQL/InnoDB定义的4种隔离级别： Read Uncommited可以读取未提交记录。此隔离级别，不会使用，忽略。 Read Committed (RC)快照读忽略，本文不考虑。 针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。 Repeatable Read (RR)快照读忽略，本文不考虑。 针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。 Serializable从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。 Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。 一条简单SQL的加锁实现分析在介绍完一些背景知识之后，本文接下来将选择几个有代表性的例子，来详细分析MySQL的加锁处理。当然，还是从最简单的例子说起。经常有朋友发给我一个SQL，然后问我，这个SQL加什么锁？就如同下面两条简单的SQL，他们加什么锁？ SQL1：select * from t1 where id = 10;SQL2：delete from t1 where id = 10; 针对这个问题，该怎么回答？我能想象到的一个答案是： SQL1：不加锁。因为MySQL是使用多版本并发控制的，读不加锁。SQL2：对id = 10的记录加写锁 (走主键索引)。 这个答案对吗？说不上来。即可能是正确的，也有可能是错误的，已知条件不足，这个问题没有答案。如果让我来回答这个问题，我必须还要知道以下的一些前提，前提不同，我能给出的答案也就不同。要回答这个问题，还缺少哪些前提条件？ 前提一：id列是不是主键？ 前提二：当前系统的隔离级别是什么？ 前提三：id列如果不是主键，那么id列上有索引吗？ 前提四：id列上如果有二级索引，那么这个索引是唯一索引吗？ 前提五：两个SQL的执行计划是什么？索引扫描？全表扫描？ 没有这些前提，直接就给定一条SQL，然后问这个SQL会加什么锁，都是很业余的表现。而当这些问题有了明确的答案之后，给定的SQL会加什么锁，也就一目了然。下面，我将这些问题的答案进行组合，然后按照从易到难的顺序，逐个分析每种组合下，对应的SQL会加哪些锁？ 注：下面的这些组合，我做了一个前提假设，也就是有索引时，执行计划一定会选择使用索引进行过滤 (索引扫描)。但实际情况会复杂很多，真正的执行计划，还是需要根据MySQL输出的为准。 组合一：id列是主键，RC隔离级别 组合二：id列是二级唯一索引，RC隔离级别 组合三：id列是二级非唯一索引，RC隔离级别 组合四：id列上没有索引，RC隔离级别 组合五：id列是主键，RR隔离级别 组合六：id列是二级唯一索引，RR隔离级别 组合七：id列是二级非唯一索引，RR隔离级别 组合八：id列上没有索引，RR隔离级别 组合九：Serializable隔离级别 排列组合还没有列举完全，但是看起来，已经很多了。真的有必要这么复杂吗？事实上，要分析加锁，就是需要这么复杂。但是从另一个角度来说，只要你选定了一种组合，SQL需要加哪些锁，其实也就确定了。接下来，就让我们来逐个分析这9种组合下的SQL加锁策略。 注：在前面八种组合下，也就是RC，RR隔离级别下，SQL1：select操作均不加锁，采用的是快照读，因此在下面的讨论中就忽略了，主要讨论SQL2：delete操作的加锁。 组合一：id主键+RC这个组合，是最简单，最容易分析的组合。id是主键，Read Committed隔离级别，给定SQL：delete from t1 where id = 10; 只需要将主键上，id = 10的记录加上X锁即可。如下图所示： 结论：id是主键时，此SQL只需要在id=10这条记录上加X锁即可。 组合二：id唯一索引+RC这个组合，id不是主键，而是一个Unique的二级索引键值。那么在RC隔离级别下，delete from t1 where id = 10; 需要加什么锁呢？见下图： 此组合中，id是unique索引，而主键是name列。此时，加锁的情况由于组合一有所不同。由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤，在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。为什么聚簇索引上的记录也要加锁？试想一下，如果并发的一个SQL，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。 结论：若id列是unique列，其上有unique索引。那么SQL需要加两个X锁，一个对应于id unique索引上的id = 10的记录，另一把锁对应于聚簇索引上的[name=’d’,id=10]的记录。 组合三：id非唯一索引+RC相对于组合一、二，组合三又发生了变化，隔离级别仍旧是RC不变，但是id列上的约束又降低了，id列不再唯一，只有一个普通的索引。假设delete from t1 where id = 10; 语句，仍旧选择id列上的索引进行过滤where条件，那么此时会持有哪些锁？同样见下图： 根据此图，可以看到，首先，id列索引上，满足id = 10查询条件的记录，均已加锁。同时，这些记录对应的主键索引上的记录也都加上了锁。与组合二唯一的区别在于，组合二最多只有一个满足等值查询的记录，而组合三会将所有满足查询条件的记录都加锁。 结论：若id列上有非唯一索引，那么对应的所有满足SQL查询条件的记录，都会被加锁。同时，这些记录在主键索引上的记录，也会被加锁。 组合四：id无索引+RC相对于前面三个组合，这是一个比较特殊的情况。id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，那么只能走全表扫描做过滤。对应于这个组合，SQL会加什么锁？或者是换句话说，全表扫描时，会加什么锁？这个答案也有很多：有人说会在表上加X锁；有人说会将聚簇索引上，选择出来的id = 10;的记录加上X锁。那么实际情况呢？请看下图： 由于id列上没有索引，因此只能走聚簇索引，进行全部扫描。从图中可以看到，满足删除条件的记录有两条，但是，聚簇索引上所有的记录，都被加上了X锁。无论记录是否满足条件，全部被加上X锁。既不是加表锁，也不是在满足条件的记录上加行锁。 有人可能会问？为什么不是只在满足条件的记录上加锁呢？这是由于MySQL的实现决定的。如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。 注：在实际的实现中，MySQL有一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录放锁 (违背了2PL的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。 结论：若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁，最终持有的，是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。同时，优化也违背了2PL的约束。 组合五：id主键+RR上面的四个组合，都是在Read Committed隔离级别下的加锁行为，接下来的四个组合，是在Repeatable Read隔离级别下的加锁行为。 组合五，id列是主键列，Repeatable Read隔离级别，针对delete from t1 where id = 10; 这条SQL，加锁与组合一：{id主键，Read Committed}一致。 组合六：id唯一索引+RR与组合五类似，组合六的加锁，与组合二：{id唯一索引，Read Committed}一致。两个X锁，id唯一索引满足条件的记录上一个，对应的聚簇索引上的记录一个。 组合七：id非唯一索引+RR还记得前面提到的MySQL的四种隔离级别的区别吗？RC隔离级别允许幻读，而RR隔离级别，不允许存在幻读。但是在组合五、组合六中，加锁行为又是与RC下的加锁行为完全一致。那么RR隔离级别下，如何防止幻读呢？问题的答案，就在组合七中揭晓。 组合七，Repeatable Read隔离级别，id上有一个非唯一索引，执行delete from t1 where id = 10; 假设选择id列上的索引进行条件过滤，最后的加锁行为，是怎么样的呢？同样看下面这幅图： 此图，相对于组合三：{id列上非唯一锁，Read Committed}看似相同，其实却有很大的区别。最大的区别在于，这幅图中多了一个GAP锁，而且GAP锁看起来也不是加在记录上的，倒像是加载两条记录之间的位置，GAP锁有何用？ 其实这个多出来的GAP锁，就是RR隔离级别，相对于RC隔离级别，不会出现幻读的关键。确实，GAP锁锁住的位置，也不是记录本身，而是两条记录之间的GAP。所谓幻读，就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。 如何保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生。 如图中所示，有哪些位置可以插入新的满足条件的项 (id = 10)，考虑到B+树索引的有序性，满足条件的项一定是连续存放的。记录[6,c]之前，不会插入id=10的记录；[6,c]与[10,b]间可以插入[10, aa]；[10,b]与[10,d]间，可以插入新的[10,bb],[10,c]等；[10,d]与[11,f]间可以插入满足条件的[10,e],[10,z]等；而[11,f]之后也不会插入满足条件的记录。因此，为了保证[6,c]与[10,b]间，[10,b]与[10,d]间，[10,d]与[11,f]不会插入新的满足条件的记录，MySQL选择了用GAP锁，将这三个GAP给锁起来。 Insert操作，如insert [10,aa]，首先会定位到[6,c]与[10,b]间，然后在插入前，会检查这个GAP是否已经被锁上，如果被锁上，则Insert不能插入记录。因此，通过第一遍的当前读，不仅将满足条件的记录锁上 (X锁)，与组合三类似。同时还是增加3把GAP锁，将可能插入满足条件记录的3个GAP给锁上，保证后续的Insert不能插入新的id=10的记录，也就杜绝了同一事务的第二次当前读，出现幻象的情况。 有心的朋友看到这儿，可以会问：既然防止幻读，需要靠GAP锁的保护，为什么组合五、组合六，也是RR隔离级别，却不需要加GAP锁呢？ 首先，这是一个好问题。其次，回答这个问题，也很简单。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。而组合五，id是主键；组合六，id是unique键，都能够保证唯一性。一个等值查询，最多只能返回一条记录，而且新的相同取值的记录，一定不会在新插入进来，因此也就避免了GAP锁的使用。其实，针对此问题，还有一个更深入的问题：如果组合五、组合六下，针对SQL：select * from t1 where id = 10 for update; 第一次查询，没有找到满足查询条件的记录，那么GAP锁是否还能够省略？此问题留给大家思考。 结论：Repeatable Read隔离级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，加GAP上的GAP锁，然后加主键聚簇索引上的记录X锁，然后返回；然后读取下一条，重复进行。直至进行到第一条不满足条件的记录[11,f]，此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。 组合八：id无索引+RR组合八，Repeatable Read隔离级别下的最后一种情况，id列上没有索引。此时SQL：delete from t1 where id = 10; 没有其他的路径可以选择，只能进行全表扫描。最终的加锁情况，如下图所示： 如图，这是一个很恐怖的现象。首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。这个示例表，只有6条记录，一共需要6个记录锁，7个GAP锁。试想，如果表上有1000万条记录呢？ 在这种情况下，这个表上，除了不加锁的快照度，其他任何加锁的并发SQL，均不能执行，不能更新，不能删除，不能插入，全表被锁死。 当然，跟组合四：{id无索引, Read Committed}类似，这个情况下，MySQL也做了一些优化，就是所谓的semi-consistent read。semi-consistent read开启的情况下，对于不满足查询条件的记录，MySQL会提前放锁。针对上面的这个用例，就是除了记录[d,10]，[g,10]之外，所有的记录锁都会被释放，同时不加GAP锁。semi-consistent read如何触发：要么是read committed隔离级别；要么是Repeatable Read隔离级别，同时设置了 innodb_locks_unsafe_for_binlog 参数。更详细的关于semi-consistent read的介绍，可参考我之前的一篇博客：MySQL+InnoDB semi-consitent read原理及实现分析 。 结论：在Repeatable Read隔离级别下，如果进行全表扫描的当前读，那么会锁上表中的所有记录，同时会锁上聚簇索引内的所有GAP，杜绝所有的并发 更新/删除/插入 操作。当然，也可以通过触发semi-consistent read，来缓解加锁开销与并发影响，但是semi-consistent read本身也会带来其他问题，不建议使用。 组合九：Serializable针对前面提到的简单的SQL，最后一个情况：Serializable隔离级别。对于SQL2：delete from t1 where id = 10; 来说，Serializable隔离级别与Repeatable Read隔离级别完全一致，因此不做介绍。 Serializable隔离级别，影响的是SQL1：select * from t1 where id = 10; 这条SQL，在RC，RR隔离级别下，都是快照读，不加锁。但是在Serializable隔离级别，SQL1会加读锁，也就是说快照读不复存在，MVCC并发控制降级为Lock-Based CC。 结论：在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。 一条复杂的SQL写到这里，其实MySQL的加锁实现也已经介绍的八八九九。只要将本文上面的分析思路，大部分的SQL，都能分析出其会加哪些锁。而这里，再来看一个稍微复杂点的SQL，用于说明MySQL加锁的另外一个逻辑。SQL用例如下： 如图中的SQL，会加什么锁？假定在Repeatable Read隔离级别下 (Read Committed隔离级别下的加锁情况，留给读者分析。)，同时，假设SQL走的是idx_t1_pu索引。 在详细分析这条SQL的加锁情况前，还需要有一个知识储备，那就是一个SQL中的where条件如何拆分？具体的介绍，建议阅读我之前的一篇文章：SQL中的where条件，在数据库中提取与应用浅析 。在这里，我直接给出分析后的结果： Index key：pubtime &gt; 1 and puptime &lt; 20。此条件，用于确定SQL在idx_t1_pu索引上的查询范围。Index Filter：userid = ‘hdc’ 。此条件，可以在idx_t1_pu索引上进行过滤，但不属于Index Key。Table Filter：comment is not NULL。此条件，在idx_t1_pu索引上无法过滤，只能在聚簇索引上过滤。 在分析出SQL where条件的构成之后，再来看看这条SQL的加锁情况 (RR隔离级别)，如下图所示： 从图中可以看出，在Repeatable Read隔离级别下，由Index Key所确定的范围，被加上了GAP锁；Index Filter锁给定的条件 (userid = ‘hdc’)何时过滤，视MySQL的版本而定，在MySQL 5.6版本之前，不支持Index Condition Pushdown(ICP)，因此Index Filter在MySQL Server层过滤，在5.6后支持了Index Condition Pushdown，则在index上过滤。若不支持ICP，不满足Index Filter的记录，也需要加上记录X锁，若支持ICP，则不满足Index Filter的记录，无需加记录X锁 (图中，用红色箭头标出的X锁，是否要加，视是否支持ICP而定)；而Table Filter对应的过滤条件，则在聚簇索引中读取后，在MySQL Server层面过滤，因此聚簇索引上也需要X锁。最后，选取出了一条满足条件的记录[8,hdc,d,5,good]，但是加锁的数量，要远远大于满足条件的记录数量。 结论：在Repeatable Read隔离级别下，针对一个复杂的SQL，首先需要提取其where条件。Index Key确定的范围，需要加上GAP锁；Index Filter过滤条件，视MySQL版本是否支持ICP，若支持ICP，则不满足Index Filter的记录，不加X锁，否则需要X锁；Table Filter过滤条件，无论是否满足，都需要加X锁。 mysql死锁死锁成因&amp;&amp;检测方法我们mysql用的存储引擎是innodb，从日志来看，innodb主动探知到死锁，并回滚了某一苦苦等待的事务。问题来了，innodb是怎么探知死锁的？ 123直观方法是在两个事务相互等待时，当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。这种方法简单有效，在innodb中，参数innodb\_lock\_wait\_timeout用来设置超时时间。仅用上述方法来检测死锁太过被动，innodb还提供了wait-for graph算法来主动进行死锁检测，每当加锁请求无法立即满足需要并进入等待时，wait-for graph算法都会被触发。 innodb隔离级别、索引与锁(提交读(RC))假设我们有一张消息表（msg），里面有3个字段。假设id是主键，token是非唯一索引，message没有索引。 id: bigint token: varchar(30) message: varchar(4096) 1innodb对于主键使用了聚簇索引，这是一种数据存储方式，表数据是和主键一起存储，主键索引的叶结点存储行数据。对于普通索引，其叶子节点存储的是主键值。 12图4 聚簇索引和二级索引下面分析下索引和锁的关系。 1）delete from msg where id=2； 1由于id是主键，因此直接锁住整行记录即可。 图52）delete from msg where token=’ cvs’; 1由于token是二级索引，因此首先锁住二级索引（两行），接着会锁住相应主键所对应的记录； 图63）delete from msg where message=订单号是多少’； 1message没有索引，所以走的是全表扫描过滤。这时表上的各个记录都将添加上X锁。 图7 锁与隔离级别的关系123456789大学数据库原理都学过，为了保证并发操作数据的正确性，数据库都会有事务隔离级别的概念：1）未提交读（Read uncommitted）；2）已提交读（Read committed（RC））；3）可重复读（Repeatable read（RR））；4）可串行化（Serializable）。我们较常使用的是RC和RR。提交读\(RC\)：只能读取到已经提交的数据。可重复读\(RR\)：在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。我们在1.2.1节谈论的其实是RC隔离级别下的锁，它可以防止不同事务版本的数据修改提交时造成数据冲突的情况，但当别的事务插入数据时可能会出现问题。如下图所示，事务A在第一次查询时得到1条记录，在第二次执行相同查询时却得到两条记录。从事务A角度上看是见鬼了！这就是幻读，RC级别下尽管加了行锁，但还是避免不了幻读。 图8 innodb的RR隔离级别可以避免幻读发生，怎么实现？当然需要借助于锁了！ 为了解决幻读问题，innodb引入了gap锁。 在事务A执行：update msg set message=‘订单’ where token=‘asd’; innodb首先会和RC级别一样，给索引上的记录添加上X锁，此外，还在非唯一索引’asd’与相邻两个索引的区间加上锁。 这样，当事务B在执行insert into msg values (null,‘asd’,’hello’); commit;时，会首先检查这个区间是否被锁上，如果被锁上，则不能立即执行，需要等待该gap锁被释放。这样就能避免幻读问题。 图9 死锁成因1了解了innodb锁的基本原理后，下面分析下死锁的成因。如前面所说，死锁一般是事务相互等待对方资源，最后形成环路造成的。下面简单讲下造成相互等待最后形成环路的例子。 不同表相同记录行锁冲突1这种情况很好理解，事务A和事务B操作两张表，但出现循环等待锁情况。 图10 相同表记录行锁冲突1这种情况比较常见，之前遇到两个job在执行数据批量更新时，jobA处理的的id列表为\[1,2,3,4\]，而job处理的id列表为\[8,9,10,4,2\]，这样就造成了死锁。 图11 不同索引锁冲突1这种情况比较隐晦，事务A在执行时，除了在二级索引加锁外，还会在聚簇索引上加锁，在聚簇索引上加锁的顺序是\[1,4,2,3,5\]，而事务B执行时，只在聚簇索引上加锁，加锁顺序是\[1,2,3,4,5\]，这样就造成了死锁的可能性。 图12 3.4 锁冲突1innodb在RR级别下，如下的情况也会产生死锁，比较隐晦。不清楚的同学可以自行根据上节的gap锁原理分析下。 图13 如何尽可能避免死锁1）以固定的顺序访问表和行。比如对第2节两个job批量更新的情形，简单方法是对id列表先排序，后执行，这样就避免了交叉等待锁的情形；又比如对于3.1节的情形，将两个事务的sql顺序调整为一致，也能避免死锁。 2）大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。 3）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率。 4）降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。 5）为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 死锁案例： 案例一： 需求：将投资的钱拆成几份随机分配给借款人。 起初业务程序思路是这样的： 投资人投资后，将金额随机分为几份，然后随机从借款人表里面选几个，然后通过一条条select for update 去更新借款人表里面的余额等。 抽象出来就是一个session通过for循环会有几条如下的语句： Select * from xxx where id=’随机id’ for update 基本来说，程序开启后不一会就死锁。 这可以是说最经典的死锁情形了。 例如两个用户同时投资，A用户金额随机分为2份，分给借款人1，2 B用户金额随机分为2份，分给借款人2，1 由于加锁的顺序不一样，死锁当然很快就出现了。 对于这个问题的改进很简单，直接把所有分配到的借款人直接一次锁住就行了。 Select * from xxx where id in (xx,xx,xx) for update 在in里面的列表值mysql是会自动从小到大排序，加锁也是一条条从小到大加的锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263例如（以下会话id为主键）：Session1:mysql&gt; select * from t3 where id in (8,9) for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 8 | WA | f | 2016-03-02 11:36:30 || 9 | JX | f | 2016-03-01 11:36:30 |+----+--------+------+---------------------+2 rows in set (0.04 sec)Session2:select * from t3 where id in (10,8,5) for update;锁等待中……其实这个时候id=10这条记录没有被锁住的，但id=5的记录已经被锁住了，锁的等待在id=8的这里。不信请看Session3:mysql&gt; select * from t3 where id=5 for update;锁等待中Session4:mysql&gt; select * from t3 where id=10 for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 10 | JB | g | 2016-03-10 11:45:05 |+----+--------+------+---------------------+1 row in set (0.00 sec)在其它session中id=5是加不了锁的，但是id=10是可以加上锁的。 案例2： 在开发中，经常会做这类的判断需求：根据字段值查询（有索引），如果不存在，则插入；否则更新。 12345678910111213141516171819202122232425262728293031以id为主键为例，目前还没有id=22的行Session1:select * from t3 where id=22 for update;Empty set (0.00 sec)session2:select * from t3 where id=23 for update;Empty set (0.00 sec)Session1:insert into t3 values(22,&apos;ac&apos;,&apos;a&apos;,now());锁等待中……Session2:insert into t3 values(23,&apos;bc&apos;,&apos;b&apos;,now());ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 当对存在的行进行锁的时候(主键)，mysql就只有行锁。 当对未存在的行进行锁的时候(即使条件为主键)，mysql是会锁住一段范围（有gap锁） 锁住的范围为： (无穷小或小于表中锁住id的最大值，无穷大或大于表中锁住id的最小值) 如：如果表中目前有已有的id为（11 ， 12） 那么就锁住（12，无穷大） 如果表中目前已有的id为（11 ， 30） 那么就锁住（11，30） 对于这种死锁的解决办法是： insert into t3(xx,xx) on duplicate key updatexx=’XX’; 用mysql特有的语法来解决此问题。因为insert语句对于主键来说，插入的行不管有没有存在，都会只有行锁。 案例3： 直接上情景： 1234567891011121314151617181920212223242526272829mysql&gt; select * from t3 where id=9 for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 9 | JX | f | 2016-03-01 11:36:30 |+----+--------+------+---------------------+1 row in set (0.00 sec)Session2:mysql&gt; select * from t3 where id&lt;20 for update;锁等待中Session1:mysql&gt; insert into t3 values(7,&apos;ae&apos;,&apos;a&apos;,now());ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 这个跟案例一其它是差不多的情况，只是session1不按常理出牌了， Session2在等待Session1的id=9的锁，session2又持了1到8的锁（注意9到19的范围并没有被session2锁住），最后，session1在插入新行时又得等待session2,故死锁发生了。 这种一般是在业务需求中基本不会出现，因为你锁住了id=9，却又想插入id=7的行，这就有点跳了，当然肯定也有解决的方法，那就是重理业务需求，避免这样的写法。 参考https://tech.meituan.com/innodb-lock.html http://hedengcheng.com/?p=771\#\_Toc374698322]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2F2018%2F04%2F07%2Fjava_common%2Fjava-memory-model%2F</url>
    <content type="text"><![CDATA[java内存模型并发编程模型的分类在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java内存模型的抽象在java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java语言规范称之为formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下： 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。然后，线程B到主内存中去读取线程A之前已更新过的共享变量。下面通过示意图来说明这两个步骤： 如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。 从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。从java源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致 为了保证内存可见性，java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 happens-before从JDK5开始，java使用新的JSR -133内存模型（本文除非特别说明，针对的都是JSR- 133内存模型）。JSR-133提出了happens-before的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的happens-before规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读。 传递性：如果A happens- before B，且B happens- before C，那么A happens- before C。注意，两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before的定义很微妙，后文会具体说明happens-before为什么要这么定义。 happens-before与JMM的关系如下图所示： 重排序数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型： 名称 代码示例 说明 写后读 a = 1;b = a; 写一个变量之后，再读这个位置。 写后写 a = 1;a = 2; 写一个变量之后，再写这个变量。 读后写 a = b;b = 1; 读一个变量之后，再写这个变量。 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。 前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 as-if-serial语义as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守as-if-serial语义。 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例： 123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面三个操作的数据依赖关系如下图所示： 如上图所示，A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。下图是该程序的两种执行顺序： as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 程序顺序规则根据happens- before的程序顺序规则，上面计算圆的面积的示例代码存在三个happens- before关系： A happens- before B； B happens- before C； A happens- before C；这里的第3个happens- before关系，是根据happens- before的传递性推导出来的。 这里A happens- before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执行顺序）。在第一章提到过，如果A happens- before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B按happens- before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从happens- before的定义我们可以看出，JMM同样遵从这一目标。 重排序对多线程的影响现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码：12345678910111213141516class ReorderExample &#123;int a = 0;boolean flag = false;public void writer() &#123; a = 1; //1 flag = true; //2&#125;Public void reader() &#123; if (flag) &#123; //3 int i = a * a; //4 …… &#125;&#125;&#125; flag变量是个标记，用来标识变量a是否已被写入。这里假设有两个线程A和B，A首先执行writer()方法，随后B线程接着执行reader()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入？ 答案是：不一定能看到。 由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作1和操作2重排序时，可能会产生什么效果？请看下面的程序执行时序图： 如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！ ※注：本文统一用红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。 下面再让我们看看，当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作3和操作4重排序后，程序的执行时序图： 在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。 从图中我们可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！ 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。 顺序一致性数据竞争与顺序一致性保证当程序未正确同步时，就会存在数据竞争。java内存模型规范对数据竞争的定义如下： 在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果（前一章的示例正是如此）。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。 JMM对正确同步的多线程程序的内存一致性做了如下保证： 如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）–即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同（马上我们将会看到，这对于程序员来说是一个极强的保证）。这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile和final）的正确使用。 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。顺序一致性内存模型为程序员提供的视图如下： 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读/写操作。从上图我们可以看出，在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读/写操作串行化。 为了更好的理解，下面我们通过两个示意图来对顺序一致性模型的特性做进一步的说明。 假设有两个线程A和B并发执行。其中A线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。 假设这两个线程使用监视器来正确同步：A线程的三个操作执行后释放监视器，随后B线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示： 现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图： 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程A和B看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。 但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 同步程序的顺序一致性效果下面我们对前面的示例程序ReorderExample用监视器来同步，看看正确同步的程序如何具有顺序一致性。 请看下面的示例代码：12345678910111213141516class SynchronizedExample &#123;int a = 0;boolean flag = false;public synchronized void writer() &#123; a = 1; flag = true;&#125;public synchronized void reader() &#123; if (flag) &#123; int i = a; …… &#125;&#125;&#125; 上面示例代码中，假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。下面是该程序在两个内存模型中的执行时序对比图： 在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图（具体细节后文会说明）。虽然线程A在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 从这里我们可以看到JMM在具体实现上的基本方针：在不改变（正确同步的）程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false），JMM保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会清零内存空间，然后才会在上面分配对象（JVM内部会同步这两个操作）。因此，在以清零的内存空间（pre-zeroed memory）分配对象时，域的默认初始化已经完成了。 JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。保证未同步程序在两个模型中的执行结果一致毫无意义。 和顺序一致性模型一样，未同步程序在JMM中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异： 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。 JMM不保证对64位的long型和double型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和I/O设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制： 如上图所示，假设处理器A，B和C同时向总线发起总线事务，这时总线仲裁（bus arbitration）会对竞争作出裁决，这里我们假设总线在仲裁后判定处理器A在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。此时处理器A继续它的总线事务，而其它两个处理器则要等待处理器A的总线事务完成后才能开始再次执行内存访问。假设在处理器A执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器D向总线发起了总线事务，此时处理器D的这个请求会被总线禁止。 总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行；在任意时间点，最多只能有一个处理器能访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性。 在一些32位的处理器上，如果要求对64位数据的读/写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的读/写具有原子性。当JVM在这种处理器上运行时，会把一个64位long/ double型变量的读/写操作拆分为两个32位的读/写操作来执行。这两个32位的读/写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的读/写将不具有原子性。 当单个内存操作不具有原子性，将可能会产生意想不到后果。请看下面示意图： 如上图所示，假设处理器A写一个long型变量，同时处理器B要读这个long型变量。处理器A中64位的写操作被拆分为两个32位的写操作，且这两个32位的写操作被分配到不同的写事务中执行。同时处理器B中64位的读操作被拆分为两个32位的读操作，且这两个32位的读操作被分配到同一个的读事务中执行。当处理器A和B按上图的时序来执行时，处理器B将看到仅仅被处理器A“写了一半“的无效值。 volatile锁final总结如上图所示，JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为java程序员呈现了一个一致的内存模型。 JMM，处理器内存模型与顺序一致性内存模型之间的关系JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图： 从上图我们可以看出：常见的4种处理器内存模型比常用的3中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。 JMM对这两种不同性质的重排序，采取了不同的策略： JMM的设计JMM把happens- before要求禁止的重排序分为了下面两类： 会改变程序执行结果的重排序。 不会改变程序执行结果的重排序。 JMM对这两种不同性质的重排序，采取了不同的策略： 对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。 对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求（JMM允许这种重排序）。 下面是JMM的设计示意图： 从上图可以看出两点： JMM向程序员提供的happens- before规则能满足程序员的需求。JMM的happens- before规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的A happens- before B）。 JMM对编译器和处理器的束缚已经尽可能的少。从上面的分析我们可以看出，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个volatile变量仅仅只会被单个线程访问，那么编译器可以把这个volatile变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。 JMM的内存可见性保证Java程序的内存可见性保证按程序类型可以分为下列三类： 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。 未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。下图展示了这三类程序在JMM中与在顺序一致性内存模型中的执行结果的异同： 只要多线程程序是正确同步的，JMM保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。 参考http://www.infoq.com/cn/articles/java-memory-model-1 http://www.infoq.com/cn/articles/java-memory-model-7]]></content>
  </entry>
  <entry>
    <title><![CDATA[JUC-memory-barrier]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2FJUC-memory-barrier%2F</url>
    <content type="text"><![CDATA[背景大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待。通过乱序执行的技术，处理器可以大大提高执行效率。除了处理器，常见的Java运行时环境的JIT编译器也会做指令重排序操作，即生成的机器指令与字节码指令顺序不一致。 as-if-serial语义As-if-serial语义的意思是，所有的动作(Action)5都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。Java编译器、运行时和处理器都会保证单线程下的as-if-serial语义。比如，为了保证这一语义，重排序不会发生在有数据依赖的操作之中。 int a = 1;int b = 2;int c = a + b; 将上面的代码编译成Java字节码或生成机器指令，可视为展开成了以下几步动作（实际可能会省略或添加某些步骤）。 对a赋值1 对b赋值2 取a的值 取b的值 将取到两个值相加后存入c 在上面5个动作中，动作1可能会和动作2、4重排序，动作2可能会和动作1、3重排序，动作3可能会和动作2、4重排序，动作4可能会和1、3重排序。但动作1和动作3、5不能重排序。动作2和动作4、5不能重排序。因为它们之间存在数据依赖关系，一旦重排，as-if-serial语义便无法保证。 为保证as-if-serial语义，Java异常处理机制也会为重排序做一些特殊处理。例如在下面的代码中，y = 0 / 0可能会被重排序在x = 2之前执行，为了保证最终不致于输出x = 1的错误结果，JIT在重排序时会在catch语句中插入错误代偿代码，将x赋值为2，将程序恢复到发生异常时应有的状态。这种做法的确将异常捕捉的逻辑变得复杂了，但是JIT的优化的原则是，尽力优化正常运行下的代码逻辑，哪怕以catch块逻辑变得复杂为代价，毕竟，进入catch块内是一种“异常”情况的表现。12345678910111213public class Reordering &#123; public static void main(String[] args) &#123; int x, y; x = 1; try &#123; x = 2; y = 0 / 0; &#125; catch (Exception e) &#123; &#125; finally &#123; System.out.println(&quot;x = &quot; + x); &#125; &#125;&#125; 内存访问重排序与内存可见性计算机系统中，为了尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存(cache)以提高性能。其模型如下图所示。 处理器Cache模型 在这种模型下会存在一个现象，即缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据也不是实时同步的。这导致在同一个时间点，各CPU所看到同一内存地址的数据的值可能是不一致的。从程序的视角来看，就是在同一个时间点，各个线程所看到的共享变量的值可能是不一致的。有的观点会将这种现象也视为重排序的一种，命名为“内存系统重排序”。因为这种内存可见性问题造成的结果就好像是内存访问指令发生了重排序一样。这种内存可见性问题也会导致章节一中示例代码即便在没有发生指令重排序的情况下的执行结果也还是(0, 0)。 内存访问重排序与Java内存模型Java的目标是成为一门平台无关性的语言，即Write once, run anywhere. 但是不同硬件环境下指令重排序的规则不尽相同。例如，x86下运行正常的Java程序在IA64下就可能得到非预期的运行结果。为此，JSR-1337制定了Java内存模型(Java Memory Model, JMM)，旨在提供一个统一的可参考的规范，屏蔽平台差异性。从Java 5开始，Java内存模型成为Java语言规范的一部分。根据Java内存模型中的规定，可以总结出以下几条happens-before规则8。Happens-before的前后两个操作不会被重排序且后者对前者的内存可见。 程序次序法则：线程中的每个动作A都happens-before于该线程中的每一个动作B，其中，在程序中，所有的动作B都能出现在A之后。监视器锁法则：对一个监视器锁的解锁 happens-before于每一个后续对同一监视器锁的加锁。volatile变量法则：对volatile域的写入操作happens-before于每一个后续对同一个域的读写操作。线程启动法则：在一个线程里，对Thread.start的调用会happens-before于每个启动线程的动作。线程终结法则：线程中的任何动作都happens-before于其他线程检测到这个线程已经终结、或者从Thread.join调用中成功返回，或Thread.isAlive返回false。中断法则：一个线程调用另一个线程的interrupt happens-before于被中断的线程发现中断。终结法则：一个对象的构造函数的结束happens-before于这个对象finalizer的开始。传递性：如果A happens-before于B，且B happens-before于C，则A happens-before于CHappens-before关系只是对Java内存模型的一种近似性的描述，它并不够严谨，但便于日常程序开发参考使用，关于更严谨的Java内存模型的定义和描述，请阅读JSR-133原文或Java语言规范章节17.4。 除此之外，Java内存模型对volatile和final的语义做了扩展。对volatile语义的扩展保证了volatile变量在一些情况下不会重排序，volatile的64位变量double和long的读取和赋值操作都是原子的。对final语义的扩展保证一个对象的构建方法结束前，所有final成员变量都必须完成初始化（的前提是没有this引用溢出）。 Java内存模型关于重排序的规定，总结后如下表所示。 表中“第二项操作”的含义是指，第一项操作之后的所有指定操作。如，普通读不能与其之后的所有volatile写重排序。另外，JMM也规定了上述volatile和同步块的规则尽适用于存在多线程访问的情景。例如，若编译器（这里的编译器也包括JIT，下同）证明了一个volatile变量只能被单线程访问，那么就可能会把它做为普通变量来处理。留白的单元格代表允许在不违反Java基本语义的情况下重排序。例如，编译器不会对对同一内存地址的读和写操作重排序，但是允许对不同地址的读和写操作重排序。 除此之外，为了保证final的新增语义。JSR-133对于final变量的重排序也做了限制。 构建方法内部的final成员变量的存储，并且，假如final成员变量本身是一个引用的话，这个final成员变量可以引用到的一切存储操作，都不能与构建方法外的将当期构建对象赋值于多线程共享变量的存储操作重排序。例如对于如下语句x.finalField = v; … ;构建方法边界sharedRef = x;v.afield = 1; x.finalField = v; … ; 构建方法边界sharedRef = x;这两条语句中，构建方法边界前后的指令都不能重排序。初始读取共享对象与初始读取该共享对象的final成员变量之间不能重排序。例如对于如下语句x = sharedRef; … ; i = x.finalField;前后两句语句之间不会发生重排序。由于这两句语句有数据依赖关系，编译器本身就不会对它们重排序，但确实有一些处理器会对这种情况重排序，因此特别制定了这一规则。 内存屏障内存屏障或内存栅栏，也就是让一个CPU处理单元中的内存状态对其它处理单元可见的一项技术。 CPU使用了很多优化技术来实现一个目标：CPU执行单元的速度要远超主存访问速度。在上一篇文章 “Write Combing （合并写）”中我已经介绍了其中的一项技术。CPU避免内存访问延迟最常见的技术是将指令管道化，然后尽量重排这些管道的执行以最大化利用缓存，从而把因为缓存未命中引起的延迟降到最小。 当一个程序执行时，只要最终的结果是一样的，指令是否被重排并不重要。例如，在一个循环里，如果循环体内没用到这个计数器，循环的计数器什么时候更新（在循环开始，中间还是最后）并不重要。编译器和CPU可以自由的重排指令以最佳的利用CPU，只要下一次循环前更新该计数器即可。并且在循环执行中，这个变量可能一直存在寄存器上，并没有被推到缓存或主存，这样这个变量对其他CPU来说一直都是不可见的。 CPU核内部包含了多个执行单元。例如，现代Intel CPU包含了6个执行单元，可以组合进行算术运算，逻辑条件判断及内存操作。每个执行单元可以执行上述任务的某种组合。这些执行单元是并行执行的，这样指令也就是在并行执行。但如果站在另一个CPU角度看，这也就产生了程序顺序的另一种不确定性。 最后，当一个缓存失效发生时，现代CPU可以先假设一个内存载入的值并根据这个假设值继续执行，直到内存载入返回确切的值。 代码顺序并不是真正的执行顺序，只要有空间提高性能，CPU和编译器可以进行各种优化。缓存和主存的读取会利用load, store和write-combining缓冲区来缓冲和重排。这些缓冲区是查找速度很快的关联队列，当一个后来发生的load需要读取上一个store的值，而该值还没有到达缓存，查找是必需的，上图描绘的是一个简化的现代多核CPU，从上图可以看出执行单元可以利用本地寄存器和缓冲区来管理和缓存子系统的交互。 在多线程环境里需要使用某种技术来使程序结果尽快可见。这篇文章里我不会涉及到 Cache Conherence 的概念。请先假定一个事实：一旦内存数据被推送到缓存，就会有消息协议来确保所有的缓存会对所有的共享数据同步并保持一致。这个使内存数据对CPU核可见的技术被称为内存屏障或内存栅栏。 内存屏障提供了两个功能。首先，它们通过确保从另一个CPU来看屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性；其次它们可以实现内存数据可见性，确保内存数据会同步到CPU缓存子系统。 解决Java内存模型Java内存模型中volatile变量在写操作之后会插入一个store屏障，在读操作之前会插入一个load屏障。一个类的final字段会在初始化后插入一个store屏障，来确保final字段在构造函数初始化完成并可被使用时可见。 参考http://ifeve.com/memory-barriers-or-fences/https://tech.meituan.com/java-memory-reordering.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[JUC-Double-check]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2FJUC-Double-check%2F</url>
    <content type="text"><![CDATA[双重检查锁定在延迟初始化的单例模式中见得比较多（单例模式实现方式很多，这里为说明双重检查锁定问题，只选取这一种方式），先来看一个版本： 版本1123456789101112131415161718192021public class Singleton &#123; private static Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 上面是最原始的模式，一眼就可以看出，在多线程环境下，可能会产生多个Singleton实例，于是有了其同步的版本： 版本2123456789101112131415161718192021public class Singleton &#123; private static Singleton instance = null; private Singleton()&#123;&#125; public synchronized static Singleton getInstance() &#123; if(instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 在这个版本中，每次调用getInstance都需要取得Singleton.class上的锁，然而该锁只是在开始构建Singleton 对象的时候才是必要的，后续的多线程访问，效率会降低，于是有了接下来的版本： 版本31234567891011121314151617181920212223242526272829public class Singleton &#123; private static Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized(Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 很好的想法！不幸的是，该方案也未能解决问题之根本： 原因在于：初始化Singleton 和 将对象地址写到instance字段 的顺序是不确定的。在某个线程new Singleton()时，在构造方法被调用之前，就为该对象分配了内存空间并将对象的字段设置为默认值。此时就可以将分配的内存地址赋值给instance字段了，然而该对象可能还没有初始化；此时若另外一个线程来调用getInstance，取到的就是状态不正确的对象。 鉴于以上原因，有人可能提出下列解决方案： 版本4123456789101112131415161718192021222324252627282930313233343536373839public class Singleton &#123; private static Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; if(instance == null) &#123; Singleton temp; synchronized(Singleton.class) &#123; temp = instance; if(temp == null) &#123; synchronized(Singleton.class) &#123; temp = new Singleton(); &#125; instance = temp; &#125; &#125; &#125; return instance; &#125;&#125; 该方案将Singleton对象的构造置于最里面的同步块，这种思想是在退出该同步块时设置一个内存屏障，以阻止初始化Singleton 和 将对象地址写到instance字段 的重新排序。 不幸的是，这种想法也是错误的，同步的规则不是这样的。退出监视器（退出同步）的规则是：所以在退出监视器前面的动作都必须在释放监视器之前完成。然而，并没有规定说退出监视器之后的动作不能放到退出监视器之前完成。也就是说同步块里的代码必须在退出同步时完成，而同步块后面的代码则可以被编译器或运行时环境移到同步块中执行。 编译器可以合法的，也是合理的，将instance = temp移动到最里层的同步块内，这样就出现了上个版本同样的问题。 在JDK1.5及其后续版本中，扩充了volatile语义，系统将不允许对 写入一个volatile变量的操作与其之前的任何读写操作 重新排序，也不允许将 读取一个volatile变量的操作与其之后的任何读写操作 重新排序。 在jdk1.5及其后的版本中，可以将instance 设置成volatile以让双重检查锁定生效，如下： 版本5(volatile)1234567891011121314151617181920212223242526272829public class Singleton &#123; private static volatile Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized(Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[JUC-LongAccumulator]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2FJUC-LongAccumulator%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[JUC-LongAdder]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2FJUC-LongAdder%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ali-concurrent-rule]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2Fali-concurrent-rule%2F</url>
    <content type="text"><![CDATA[【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。说明:资源驱动类、工具类、单例工厂类都需要注意。 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。正例:public class TimerTaskThread extends Thread { public TimerTaskThread() {super.setName(“TimerTaskThread”); … } 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。说明:使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资 源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者 “过度切换”的问题。 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明:Executors 返回的线程池对象的弊端如下:1)FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2)CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。5.【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，必须加锁，或者使用 DateUtils 工具类。正例:注意线程安全，使用 DateUtils。亦推荐如下处理:private static final ThreadLocal df = new ThreadLocal() { @Overrideprotected DateFormat initialValue() {return new SimpleDateFormat(“yyyy-MM-dd”);} };说明:如果是 JDK8 的应用，可以使用 Instant 代替 Date，LocalDateTime 代替 Calendar， DateTimeFormatter 代替 Simpledateformatter，官方给出的解释:simple beautiful strong immutable thread-safe。 【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁;能 锁区块，就不要锁整个方法体;能用对象锁，就不要用类锁。 【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造 成死锁。说明:线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序 也必须是 A、B、C，否则可能出现死锁。 【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加 锁，要么在数据库层使用乐观锁，使用 version 作为更新依据。 说明:如果每次访问冲突概率小于 20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次 数不得小于 3 次。 【强制】多线程并行处理定时任务时，Timer 运行多个 TimeTask 时，只要其中之一没有捕获 抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。 【推荐】使用 CountDownLatch 进行异步转同步操作，每个线程退出前必须调用 countDown方法，线程执行代码注意 catch 异常，确保 countDown 方法可以执行，避免主线程无法执行 至 await 方法，直到超时才返回结果。说明:注意，子线程抛出异常堆栈，不能在主线程 try-catch 到。 【推荐】避免 Random 实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一 seed 导致的性能下降。说明:Random 实例包括 java.util.Random 的实例或者 Math.random()实例。正例:在 JDK7 之后，可以直接使用 API ThreadLocalRandom，在 JDK7 之前，可以做到每个 线程一个实例。 【推荐】在并发场景下，通过双重检查锁(double-checked locking)实现延迟初始化的优化问题隐患(可参考 The “Double-Checked Locking is Broken” Declaration)，推荐问题解决方案中较为简单一种(适用于 JDK5 及以上版本)，将目标属性声明为 volatile 型。 反例: 12345678class Foo &#123;private Helper helper = null; public Helper getHelper() &#123;if (helper == null) synchronized(this) &#123; if (helper == null)helper = new Helper();&#125;return helper; &#125;// other functions and members...&#125; 13.【参考】volatile 解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题， 但是如果多写，同样无法解决线程安全问题。如果是 count++操作，使用如下类实现: AtomicInteger count = new AtomicInteger(); count.addAndGet(1); 如果是 JDK8，推 荐使用 LongAdder 对象，比 AtomicLong 性能更好(减少乐观锁的重试次数)。 【参考】 HashMap 在容量不够进行 resize 时由于高并发可能出现死链，导致 CPU 飙升，在 开发过程中注意规避此风险。 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量是针对一个线程内所有操作共有的，所以设置为静态变量，所有此类实例共享 此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只 要是这个线程内定义的)都可以操控这个变量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[JUC-AtomicReference]]></title>
    <url>%2F2018%2F04%2F05%2Fjava_thread%2FJUC-AtomicReference%2F</url>
    <content type="text"><![CDATA[只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[future-task]]></title>
    <url>%2F2018%2F04%2F04%2Fjava_thread%2FJUC-5-future-task%2F</url>
    <content type="text"><![CDATA[123456public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; 从上面看到就是对Callable封装成一个新的任务，即FutureTask，调用Executor的原始接口execute方法来执行FutureTask，并且返回给用户FutureTask对象，用于追踪任务的状态和数据，下面就需要我们来详细看看FutureTask如何对任务进行封装的 FutureTaskFutureTask的属性和构造函数123456789101112131415161718192021222324private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;/** The underlying callable; nulled out after running */private Callable&lt;V&gt; callable;/** The result to return or exception to throw from get() */private Object outcome; // non-volatile, protected by state reads/writes/** The thread running the callable; CASed during run() */private volatile Thread runner;/** Treiber stack of waiting threads */private volatile WaitNode waiters;public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 有一个状态变量state, 一个Callable callable即原始任务， Object outcome存放原始任务的输出结果或者异常， Thread runner运行该任务的线程， WaitNode waiters等待获取任务结果的等待者 3.2 FutureTask的get方法实现使用FutureTask阻塞式等待任务执行结果，一种是永远阻塞另一种就是阻塞一定时间否则报超时异常，如下2个方法1234567891011121314151617public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 阻塞式等待的核心逻辑就在上述awaitDone方法中，来详细看看123456789101112131415161718192021222324252627282930313233343536private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; 可以看到有一个for循环不断处理着各种情况： 1 从最开始的WaitNode q = null，构建了一个WaitNode，即代表着当前线程作为一个等待者，WaitNode就是一个简单的链表，如下 12345static final class WaitNode &#123; volatile Thread thread; volatile WaitNode next; WaitNode() &#123; thread = Thread.currentThread(); &#125;&#125; 2 构建好WaitNode之后就要将该WaitNode放入链表中，这时候就会涉及多线程问题，使用UNSAFE的CAS来解决，这种方式也是AtomicLong等众多原子类的底层实现方式 3 成功放入WaitNode链表之后，采用LockSupport的park阻塞当前线程，要么只阻塞一定时间要么一直阻塞，直到被LockSupport的unpark唤醒。LockSupport在锁的底层实现AQS中也非常常见，使用了LockSupport就可以不用在for循环里不断判断当前任务状态而浪费CPU，只需要当前任务完成之后，使用LockSupport对等待线程进行unpark，就可以使等待的线程退出等待继续往下执行 4 如果LockSupport阻塞时间到了，还未收到unpark，则需要从等待者链表中删除当前线程代表的等待者 FutureTask的任务执行过程1234567891011121314151617181920212223242526272829303132public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; 1 一旦FutureTask任务开始执行了，就需要将当前执行线程设置到FutureTask的volatile Thread runner属性中 2 执行原始任务Callable的call方法，可能成功也可能失败也可能被中断被取消 文档中有如下状态的迁移过程： 12345Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED 成功和失败方法123456789101112131415protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125;protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; 都是首先将状态变成COMPLETING正在结束中，然后设置outcome，成功则设置正常的返回值，失败则设置成异常，然后根据划定最终的状态结果，成功就是NORMAL，失败就是EXCEPTIONAL，最后呢调用finishCompletion，去unpark之前说的WaitNode中对应的线程们 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 这里就是遍历WaitNode链表，对每一个WaitNode对应的线程依次进行LockSupport.unpark(t)，使其结束阻塞。WaitNode通知完毕后，调用一个done方法，目前该方法是空的实现，所以你如果想在任务完成后执行一些动作的时候就可以重写该方法 FutureTask任务的取消12345678910111213141516public boolean cancel(boolean mayInterruptIfRunning) &#123; if (state != NEW) return false; if (mayInterruptIfRunning) &#123; if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING)) return false; Thread t = runner; if (t != null) t.interrupt(); UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // final state &#125; else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED)) return false; finishCompletion(); return true;&#125; 取消任务，有2种情况，一种该任务正在运行，一种就是非运行状态，所以需要用户给出明示是否中断正在运行的任务，即需要一个参数mayInterruptIfRunning 中断任务就是通过中断运行该任务的线程，即直接调用该线程的interrupt()方法 结束语FutureTask大部分就简单分析完了，其他的自己去看下就行了。至此我们了解了一个任务被提交经过了封装，变成了一个新的任务FutureTask,同时FutureTask也明确了该任务的整个执行过程，只留出核心execute(futureTask)方法需要被子类来实现 参考https://my.oschina.net/pingpangkuangmo/blog/666762]]></content>
  </entry>
  <entry>
    <title><![CDATA[idea快捷键]]></title>
    <url>%2F2018%2F04%2F03%2Ftools%2Fidea-keymap%2F</url>
    <content type="text"><![CDATA[快捷键查看继承关系:1Ctrl + T 代码包围1alt+comand+t]]></content>
  </entry>
  <entry>
    <title><![CDATA[CyclicBarrier循环屏障]]></title>
    <url>%2F2018%2F04%2F03%2Fjava_thread%2FJUC-CyclicBarrier%2F</url>
    <content type="text"><![CDATA[简介一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。CyclicBarrier 支持一个可选的 Runnable 命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作 很有用。 CyclicBarrier 的字面意思是可循环使用(Cyclic)的屏障(Barrier)。它要做的事情是，让一组线程到达一个屏障(也可以叫同步点)时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。 CyclicBarrier类有两个常用的构造方法： CyclicBarrier(int parties) 这里的parties也是一个计数器，例如，初始化时parties里的计数是3，于是拥有该CyclicBarrier对象的线程当parties的计数为3时就唤醒，注：这里parties里的计数在运行时当调用CyclicBarrier:await()时,计数就加1，一直加到初始的值 CyclicBarrier(int parties, Runnable barrierAction) 这里的parties与上一个构造方法的解释是一样的，这里需要解释的是第二个入参(Runnable barrierAction),这个参数是一个实现Runnable接口的类的对象，也就是说当parties加到初始值时就出发barrierAction的内容。 代码示例12345678910111213141516171819202122232425262728293031323334353637383940class Player implements Runnable &#123; private CyclicBarrier cyclicBarrier; private int id; public Player(int id, CyclicBarrier cyclicBarrier) &#123; this.cyclicBarrier = cyclicBarrier; this.id = id; &#125; @Override public void run() &#123; try &#123; System.out.println(&quot;玩家&quot; + id + &quot;正在玩第一关...&quot;); cyclicBarrier.await(); System.out.println(&quot;玩家&quot; + id + &quot;进入第二关...&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class CyclicBarrierTest &#123; public static void main(String[] args) &#123; // CyclicBarrier cyclicBarrier = new CyclicBarrier(4); CyclicBarrier cyclicBarrier = new CyclicBarrier(4, new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;所有玩家进入第二关！&quot;); &#125; &#125;); for (int i = 0; i &lt; 4; i++) &#123; new Thread(new Player(i, cyclicBarrier)).start(); &#125; &#125;&#125; 输出结果123456789玩家0正在玩第一关...玩家3正在玩第一关...玩家2正在玩第一关...玩家1正在玩第一关...所有玩家进入第二关！玩家3进入第二关...玩家1进入第二关...玩家2进入第二关...玩家0进入第二关... CyclicBarrier和CountDownLatch的区别CountDownLatch: 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行。CyclicBarrier: N个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。CountDownLatch的计数器只能使用一次。而CyclicBarrier的计数器可以使用reset() 方法重置。所以CyclicBarrier能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。CountDownLatch：减计数方式，CyclicBarrier：加计数方式 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * 进行等待所有线程到达 barrier * 除非: 其中一个线程被 inetrrupt */public int await() throws InterruptedException, BrokenBarrierException&#123; try&#123; return dowait(false, 0L); &#125;catch (TimeoutException toe)&#123; throw new Error(toe); // cannot happen &#125;&#125;/** * 进行等待所有线程到达 barrier * 除非: 等待超时 */public int await(long timeout, TimeUnit unit) throws Exception&#123; return dowait(true, unit.toNanos(timeout));&#125;/** * Main barrier code, covering the various policies *//** * CyclicBarrier 的核心方法, 主要是所有线程都获取一个 ReeantrantLock 来控制 */private int dowait(boolean timed, long nanos)throws InterruptedException, BrokenBarrierException, TimeoutException&#123; final ReentrantLock lock = this.lock; lock.lock(); // 1. 获取 ReentrantLock try&#123; final Generation g = generation; if(g.broken)&#123; // 2. 判断 generation 是否已经 broken throw new BrokenBarrierException(); &#125; if(Thread.interrupted())&#123; // 3. 判断线程是否中断, 中断后就 breakBarrier breakBarrier(); throw new InterruptedException(); &#125; int index = --count; // 4. 更新已经到达 barrier 的线程数 if(index == 0)&#123; // triped // 5. index == 0 说明所有线程到达了 barrier boolean ranAction = false; try&#123; final Runnable command = barrierCommand; if(command != null)&#123; // 6. 最后一个线程到达 barrier, 执行 command command.run(); &#125; ranAction = true; nextGeneration(); // 7. 更新 generation return 0; &#125;finally &#123; if(!ranAction)&#123; breakBarrier(); &#125; &#125; &#125; // loop until tripped, broken, interrupted, or timed out for(;;)&#123; try&#123; if(!timed)&#123; trip.await(); // 8. 没有进行 timeout 的 await &#125;else if(nanos &gt; 0L)&#123; nanos = trip.awaitNanos(nanos); // 9. 进行 timeout 方式的等待 &#125; &#125;catch (InterruptedException e)&#123; if(g == generation &amp;&amp; !g.broken)&#123; // 10. 等待的过程中线程被中断, 则直接唤醒所有等待的 线程, 重置 broken 的值 breakBarrier(); throw e; &#125;else&#123; /** * We&apos;re about to finish waiting even if we had not * been interrupted, so this interrupt is deemed to * &quot;belong&quot; to subsequent execution */ /** * 情况 * 1. await 抛 InterruptedException &amp;&amp; g != generation * 所有线程都到达 barrier(这是会更新 generation), 并且进行唤醒所有的线程; 但这时 当前线程被中断了 * 没关系, 当前线程还是能获取 lock, 但是为了让外面的程序知道自己被中断过, 所以自己中断一下 * 2. await 抛 InterruptedException &amp;&amp; g == generation &amp;&amp; g.broken = true * 其他线程触发了 barrier broken, 导致 g.broken = true, 并且进行 signalALL(), 但就在这时 * 当前的线程也被 中断, 但是为了让外面的程序知道自己被中断过, 所以自己中断一下 * */ Thread.currentThread().interrupt(); &#125; &#125; if(g.broken)&#123; // 11. barrier broken 直接抛异常 throw new BrokenBarrierException(); &#125; if(g != generation)&#123; // 12. 所有线程到达 barrier 直接返回 return index; &#125; if(timed &amp;&amp; nanos &lt;= 0L)&#123; // 13. 等待超时直接抛异常, 重置 generation breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125;finally &#123; lock.unlock(); // 14. 调用 awaitXX 获取lock后进行释放lock &#125;&#125;]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[juc的Lock接口]]></title>
    <url>%2F2018%2F04%2F03%2Fjava_thread%2FJUC-2-Lock%2F</url>
    <content type="text"><![CDATA[Lock与synchronized比较Lock有着和synchronized一样的语意，但是比synchronized多了一些功能，单单就从Lock接口定义来看，比synchronized多出来的功能有： 可中断的获取锁，就是获取锁的线程可以响应中断。 可以尝试获取锁，也就是非阻塞获取锁，一个线程可以尝试去获取锁，获取成功就持有锁并返回true，否则返回false。 带超时的尝试获取锁，就是在尝试获取锁的时候，会有超时时间，当到达了指定的时间后，还未获取到锁，就返回false。 方法 1234567891011121314151617181920212223242526public interface Lock &#123; //获取锁，获取到锁后返回 //注意一定要记得释放锁 void lock(); //可中断的获取锁 //获取锁的时候，如果线程正在等待获取锁，则该线程能响应中断 void lockInterruptibly() throws InterruptedException; //尝试获取锁，当线程获取锁的时候，获取成功与否都会立即返回 //不会一直等着去获取锁 boolean tryLock(); //带有超时时间的尝试获取锁 //在一定的时间内获取到锁会返回true //在这段时间内被中断了，会返回 //在这段时间内，没有获取到锁，会返回false boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //释放锁 void unlock(); //获取一个Condition对象。 Condition newCondition();&#125; lockInterruptibly如果当前线程获得该锁，则将锁保持计数设置为 1。 如果当前线程：1）在进入此方法时已经设置了该线程的中断状态；或者2）在等待获取锁的同时被中断。 则抛出 InterruptedException，并且清除当前线程的已中断状态。 tryLock如果该锁没有被另一个线程保持，并且立即返回 true 值，则将锁的保持计数设置为 1。123即使已将此锁设置为使用公平排序策略，但是调用 tryLock() 仍将 立即获取锁（如果有可用的），而不管其他线程当前是否正在等待该锁。在某些情况下，此“闯入”行为可能很有用，即使它会打破公平性也如此。如果希望遵守此锁的公平设置，则使用 tryLock(0, TimeUnit.SECONDS) 总结lock ： 在锁上等待，直到获取锁； tryLock：立即返回，获得锁返回true,没获得锁返回false； tryInterruptibly：在锁上等待，直到获取锁，但是会响应中断，这个方法优先考虑响应中断，而不是响应锁的普通获取或重入获取。 Lock接口的实现Lock接口主要的实现是 ReentrantLock重入锁 ConcurrentHashMap中的Segment继承了ReentrantLock ReentrantReadWriteLock中的WriteLock和ReadLock也实现了Lock接口]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS-Semaphore]]></title>
    <url>%2F2018%2F04%2F02%2Fjava_thread%2FJUC-Semaphore%2F</url>
    <content type="text"><![CDATA[简介Semaphore 可以很轻松完成信号量控制，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 Semaphore 有两个构造函数，参数为许可的个数 permits 和是否公平竞争 fair。通过 acquire 方法能够获得的许可个数为 permits，如果超过了这个个数，就需要等待。当一个线程 release 释放了一个许可后，fair 决定了正在等待的线程该由谁获取许可，如果是公平竞争则等待时间最长的线程获取，如果是非公平竞争则随机选择一个线程获取许可。不传 fair 的构造函数默认采用非公开竞争。 12Semaphore(int permits)Semaphore(int permits, boolean fair) 使用案例123456789101112131415161718192021222324252627282930313233public class SemaphoreTest &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newCachedThreadPool();//使用并发库，创建缓存的线程池 final Semaphore sp = new Semaphore(3);//创建一个Semaphore信号量，并设置最大并发数为3 //availablePermits() //用来获取当前可用的访问次数 System.out.println(&quot;初始化：当前有&quot; + (3 - sp.availablePermits() + &quot;个并发&quot;)); //创建10个任务，上面的缓存线程池就会创建10个对应的线程去执行 for (int index = 0; index &lt; 10; index++) &#123; final int NO = index; //记录第几个任务 Runnable run = new Runnable() &#123; //具体任务 public void run() &#123; try &#123; sp.acquire(); // 获取许可 System.out.println(Thread.currentThread().getName() + &quot;获取许可&quot; + &quot;(&quot;+NO+&quot;)，&quot; + &quot;剩余：&quot; + sp.availablePermits()); Thread.sleep(1000); // 访问完后记得释放 ，否则在控制台只能打印3条记录，之后线程一直阻塞 sp.release(); //释放许可 System.out.println(Thread.currentThread().getName() + &quot;释放许可&quot; + &quot;(&quot;+NO+&quot;)，&quot; + &quot;剩余：&quot; + sp.availablePermits()); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125;; service.execute(run); //执行任务 &#125; service.shutdown(); //关闭线程池 &#125;&#125; 源码解析Semaphore 通过 AQS中的 state 来进行控制 permit 的获取控制, 其实它就是一个限制数量的 ReadLock]]></content>
  </entry>
  <entry>
    <title><![CDATA[AQS-ReentrantReadWriteLock]]></title>
    <url>%2F2018%2F04%2F02%2Fjava_thread%2FJUC-ReentrantReadWriteLock%2F</url>
    <content type="text"><![CDATA[读写所允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。 ReentrantReadWriteLock维护了一对相关的锁：共享锁readLock和独占锁writeLock。共享锁readLock用于读操作，能同时被多个线程获取；独占锁writeLock用于写入操作，只能被一个线程持有。独占锁的实现和我们上篇所讨论的ReentrantLock相似，共享锁我们接下来会详细分析。ReentrantReadWriteLock具有以下几种特性： 公平性： 非公平模式：默认模式。一个持续争用的非公平锁，可能会使其他读线程或写线程无限延期，但它比公平锁有更高的吞吐量。公平模式：当构造一个公平锁时，线程争用使用一个近似顺序到达的策略。当目前持有的锁被释放，要么是等待时间最长的单个写入线程被分配写入锁，或者如果有一组读线程比所有等待写线程等待更长的时间，该组将被分配读取锁。如果已经持有写锁，或者有一个正在等待写的线程，尝试获取公平读锁的线程（非重入）将会阻塞。在等待时间最长的写线程获取并释放写锁之前，当前线程将不能获取读锁。如果一个等待写入的线程放弃等待，并且在队列中等待时间最长的一个或多个读线程正在等待写锁空闲，那么这些读线程将被分配读取锁。 当读锁和写锁都是空闲时（这意味着已经没有等待线程）， 一个尝试获取公平写锁（非重入）的线程才会获取成功。注意非阻塞方法tryLock()会立即尝试获取锁，它并不会按照公平原则那样去等待前继节点。 重入性：ReentrantReadWriteLock允许读线程和写线程重复获取读锁或写锁。当所有写锁都被释放，不可重入读线程才允许获取锁。此外，一个写入线程可以获取读锁，但是一个读线程不能获取写锁。 锁降级：重入性允许从写锁降级到读锁：首先获取写锁，然后获取读锁，然后释放写锁。不过，从一个读锁升级到写锁是不允许的。读锁和写锁在获取过程中都支持中断。 Condition支持：Condition只有在写锁中用到，读锁是不支持Condition的。]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-locksupport]]></title>
    <url>%2F2018%2F04%2F02%2Fjava_thread%2Fstudy-locksupport%2F</url>
    <content type="text"><![CDATA[介绍这个类比较简单，是一个静态类，不需要实例化直接使用，底层是通过java未开源的Unsafe直接调用底层操作系统来完成对线程的阻塞。 方法park函数是将当前调用Thread阻塞，而unpark函数则是将指定线程Thread唤醒。 park()unpark(Thread thread)parkNanos(long nanos)阻塞当前线程，最长不超过nanos纳秒，返回条件在park()的基础上增加了超时返回。 parkUntil(long deadline)阻塞当前线程，知道deadline时间（deadline - 毫秒数）。 park(Object blocker)记录当前线程等待的对象（阻塞对象）； 阻塞当前线程； 当前线程等待对象置为null。 为什么在java6要在入参引入blocker呢？blocker的作用到底是什么？ 从线程dump结果可以看出：有blocker的可以传递给开发人员更多的现场信息，可以查看到当前线程的阻塞对象，方便定位问题。所以java6新增加带blocker入参的系列park方法，替代原有的park方法。 对比与Object类的wait/notify机制相比，park/unpark有两个优点： 以thread为操作对象更符合阻塞线程的直观定义 操作更精准，可以准确地唤醒某一个线程（notify随机唤醒一个线程，notifyAll唤醒所有等待的线程），增加了灵活性。 （2）关于“许可” 在上面的文字中，我使用了阻塞和唤醒，是为了和wait/notify做对比。 其实park/unpark的设计原理核心是“许可”：park是等待一个许可，unpark是为某线程提供一个许可。如果某线程A调用park，那么除非另外一个线程调用unpark(A)给A一个许可，否则线程A将阻塞在park操作上。 有一点比较难理解的，是unpark操作可以再park操作之前。也就是说，先提供许可。当某线程调用park时，已经有许可了，它就消费这个许可，然后可以继续运行。这其实是必须的。考虑最简单的生产者(Producer)消费者(Consumer)模型：Consumer需要消费一个资源，于是调用park操作等待；Producer则生产资源，然后调用unpark给予Consumer使用的许可。非常有可能的一种情况是，Producer先生产，这时候Consumer可能还没有构造好（比如线程还没启动，或者还没切换到该线程）。那么等Consumer准备好要消费时，显然这时候资源已经生产好了，可以直接用，那么park操作当然可以直接运行下去。如果没有这个语义，那将非常难以操作。 但是这个“许可”是不能叠加的，“许可”是一次性的。比如线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态。 测试123456789101112131415161718192021public static void main(String[] args) &#123; final Thread mainThread = Thread.currentThread(); Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;3秒后解锁主线程&quot;); try &#123; Thread.sleep(3000); LockSupport.unpark(mainThread); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread.start(); LockSupport.park(); System.out.println(&quot;Demo.main()&quot;); &#125; 底层实现原理在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AbstractQueuedSynchronizer学习]]></title>
    <url>%2F2018%2F04%2F02%2Fjava_thread%2FJUC-3-AQS%2F</url>
    <content type="text"><![CDATA[背景和简介AbstractQueuedSynchronizer简称AQS是一个抽象同步框架，可以用来实现一个依赖状态的同步器。JDK1.5中提供的java.util.concurrent包中的大多数的同步器(Synchronizer)如Lock, Semaphore, Latch, Barrier等，这些类之间大多可以互相实现，如使用Lock实现一个Semaphore或者反过来，但是它们都是基于java.util.concurrent.locks.AbstractQueuedSynchronizer这个类的框架实现的，理解了这个稍微复杂抽象的类再去理解其他的同步器就很轻松了。 等待条件发生的操作是开发中常见的需求，例如实现一个生产者消费者，当队列为空时，消费者获取消息可以立即返回并不断轮询，另外一种方式是阻塞直到有新的消息，后者对调用方更加友好一些。 设计与现实要完成这些，可以抽象出一些基本功能。首先，需要保存状态提供给子类去表示具体的含义，并且提供查询、设置、原子修改的操作。其次，要能够阻塞、唤醒线程。然后，还需要有一个容器来存放等待的线程 初步设计AQS内部通过一个int类型的state字段表示同步状态，状态的具体含义可以子类来定义，例如ReentrantLock中用state表示线程重入的次数，Semaphore表示可用的许可的数量等。使用int是由于int能够应对大部分的场景，而long在很多平台需要使用额外锁来保证一致性的读取。 类似模板模式，AQS暴露给子类一些方法实现(如tryAcquire，tryRelease), 获取操作通常是依赖state状态的，当状态允许时获取成功否则加入等待队列一直等待到允许的状态发生时重新获取，例如，Semaphore中当state(即许可数量)小于等于0时，获取不能成功。释放操作通过会修改状态并判断是否能让其他等待的线程能够重新获取，例如ReentrantLock中释放会减少重入次数并检查重入次数是否达到了0，达到0说明已经解锁，这时会通知其他等待线程重新获取。所以AQS的acquire和release会通过组合应用到不同的同步器实现中实现不同的语义，如 Reentrant.lock ReentrantReadWriteLock Semaphore.acquire, CountDownLatch.await SynchronousQueue FutureTask.get(1.5以后不再使用AQS) 另外AQS还提供其他功能，如非阻塞的获取tryAcquire, 带有超时时间的获取，可以中断的获取等。AQS可以根据具体的场景提供exclusive模式和shared模式，在exclusive模式下，同一时刻最多只能有一个线程能够处于成功获取的状态，排他锁是一个exclusive模式的例子，shared模式则可以多个线程一起获取成功，如多个许可的Semaphore。另外在java.util.concurrent包中还定义了Condition接口，用来提供监视器风格的等待通知操作，可以替换Object中基于synchronized、监视器锁的wait和notify机制。 实现具体的同步器时，需要将实现类作为具体同步器的内部类，然后调用实现类的acquire、acquireShared、release等方法。 更具体的设计同步状态synchronization管理(state字段)state字段可以通过volatile修饰，这样get和set方法具有了voaltile的相关语义，通过可以通过AtomicInteger或Unsafe类来实现原子CAS更新操作，基于减少indirection的考虑，JDK中一般都是使用Unsafe类。 阻塞、唤醒线程除了基于内置的监视器的synchronizer机制外，唯一可用的似乎是已经Deprecated的Thread.stop、Thread.suspend、Thread.resume, 而这几个个方法有严重的安全问题比如可能造成死锁。JDK1.5增加了一个LockSupport类来解决这个问题, LockSupport给每个线程绑定一个类似Semaphore的permit许可数量，不过permit最大为1，初始时permit为0。park()操作阻塞一直到permit为1并且将permit减1。unpark则进行加1，不过unpark并不会累加permit。而且如果先调用unpark()的话，之后调用park()会立即返回。park()返回的几个情况是 之前有其他线程调用剩余的unpark()或在park()之后其他调用了unpark()其他线程中断了目标线程调用虚假返回（类似Object.wait()的伪通知, 所以调用返回时需要检查是否等待条件已经达成hotspot的LockSupport最终还是使用了Unsafe的功能 线程等待队列AQS的核心是一个线程等待队列，采用的是一个先进先出FIFO队列。用来实现一个非阻塞的同步器队列有主要有两个选择Mellor-Crummey and Scott (MCS) locks和Craig, Landin, and Hagersten (CLH) locks的变种。CLH锁更适合处理取消和超时，所以AQS基于CLH进行修改作为线程等待队列。CLH队列使用pred引用前节点形成一个队列，入队enqueue和出队dequeue操作都可以通过原子操作完成。 CLH队列有很多优点，包括入队和出队非常快、无锁、非阻塞，并且是否有线程等待只需要判断head和tail是否相等。CLH中并没有只有向后的指针引用后继节点，每个节点只需要修改自己的状态就能通知后继节点。但是在AQS这样的阻塞同步器中，需要主动唤醒(unpark)后继节点。所以在AQS中增加了next引用引用后继节点，但是并没有合适的方法使用CAS进行无锁插入双向链表的方法，所以节点的插入并不是原子完成的，需要在CAS替换tail完成后调用pred.next=node。 ConditionObjectAQS还提供了一个ConditionObject类来表示监视器风格的等待通知操作，主要用在Lock中，和传统的监视器的区别在于一个Lock可以创建多个Condition。ConditionObject使用相同的内部队列节点，但是维护在一个单独的条件队列中，当收到signal操作的时候将条件队列的节点转移到等待队列。 代码实现节点1234567891011121314151617181920212223242526static final class Node &#123; // 省略部分代码... volatile Node prev; // 前节点 volatile Node next; // 后节点 volatile int waitStatus;// 等待状态 volatile Thread thread; // 节点线程 Node nextWaiter; // 节点模式 Node() &#123; &#125; Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 节点状态1234567891011121314// 表示当前节点的后续节点中的线程通过 park 被阻塞了，需要通过unpark解除它的阻塞static final int SIGNAL = -1;// 表示当前节点在 condition 队列中static final int CONDITION = -2;// 共享模式的头结点可能处于此状态，表示无条件往下传播// 引入此状态是为了优化锁竞争，使队列中线程有序地一个一个唤醒static final int PROPAGATE = -3;//表示当前节点的线程因为超时或中断被取消了static final int CANCELLED = 1;// 关键 -&gt; 0 表示初始化状态 Node 的等待状态，因为大于 0 的只有 CANCELLED 一种状态。因此在很多地方也用 waitStatus &gt; 0 表示该状态 CLH 队列(基本可以保持公平) 在 JUC 框架中，若有线程尝试获取锁时失败时，该线程会被包装成节点添加进此队列，也称入队。 在 JUC 框架中，若有线程释放锁时，等待队列的头节点会从队列中移除，表示不用再等待，也称出队。 入队在 AQS 中通过 addWaiter 方法将节点加入等待队列：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 头节点private transient volatile Node head;// 尾节点private transient volatile Node tail;private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 为空表示等待队列为空 if (pred != null) &#123; node.prev = pred; // 通过 CAS 操作设置 tail 为 node // 关键 -&gt;失败表示在这期间有其他线程的节点被设置为新的尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 关键 -&gt; 当[等待队列]为空，或者新节点入队失败时（说明存在并发），代码才会执行到这 enq(node); return node;&#125;// 往等待队列中（尾部）插入一个节点private Node enq(final Node node) &#123; // 关键 -&gt; 自旋直至成功 for (;;) &#123; Node t = tail; // t 为空表示等待队列为空 if (t == null) &#123; // 构建等待队列的头节点，实质是创建一个空的循环双链表 if (compareAndSetHead(new Node()))&#123; tail = head; &#125; &#125; else &#123; // 设置该节点为新的尾节点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 入队操作只与队列的尾节点有关，通过原子操作将新节点设置成新的尾节点。若操作失败则通过不断自旋直至成功。 出队出队操作跟头节点有关，将要执行出队的节点设置为新的头节点，并置空旧的头节点从等待队列移除即可。 设置新的 head 清除节点上的线程 将旧的头节点从等待队列移除（ 断开前指针和后指针） 123456789101112131415if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 设置新的头节点 setHead(node); // 将旧头节点后指针置空，表示从等待队列移除 p.next = null; failed = false; return interrupted;&#125;private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; 共享模式共享式的操作与独占式的主要区别在于，每次acquire竞争失败后，独占式将立即阻塞当前线程，而共享式需要在多次acquire失败后才会阻塞当前线程。简单来说，共享式是有一定限额的独占式。限额的满足方式，根据不同的子类不同的实现方式。 总结AbstractQueuedSynchronizer方法概述Lock的接口方法是针对用户的使用而定义的，我们在实现Lock的时候，就需要做如下事情，重点关注下这些事情的共性和异性 指明什么情况下才叫获取到锁：如独占锁，一旦有人占据了，就不能获取到锁。如共享锁，有人占据，但是没超过限制也能获取锁。这一部分应该是锁的实现的业务代码，每种锁都有自己的业务逻辑。这一部分其实就是AbstractQueuedSynchronizer对子类留出的tryAcquire方法 获取不到锁的时候该如何处理呢：我们当然希望它们能够继续等待，有一个队列就最好不过了，一旦获取锁失败就加入到等待队列中排队，队列中的等待者依次再去竞争获取锁。这一部分代码其实就和哪种锁没太大关系了，所以应该是锁的共性部分，这一部分其实就是AbstractQueuedSynchronizer实现的共性部分acquireQueued 12if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) 代表着先试着获取一下锁，如果获取不成功，就把之后的处理逻辑交给AbstractQueuedSynchronizer来处理。反正你只管告诉AbstractQueuedSynchronizer它怎样才叫获取到锁，其他的等待处理逻辑你就可以不用再关心了。 以上也仅仅是部分内容，下面来全面看下AbstractQueuedSynchronizer对外留出的接口和已实现的共性部分 对外留出的接口：tryAcquire：该方法向AQS解释了怎么才叫获取一把独占锁 tryRelease：该方法向AQS解释了怎么才叫释放一把独占锁 tryAcquireShared：该方法向AQS解释了怎么才叫获取一把共享锁 tryReleaseShared：该方法向AQS解释了怎么才叫释放一把共享锁 这些内容就是各种锁本身的业务逻辑，属于异性部分。123456789101112131415161718192021222324public class AbstractQueuedSynchronizerChild extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int arg) &#123; return super.tryAcquire(arg); &#125; @Override protected boolean tryRelease(int arg) &#123; return super.tryRelease(arg); &#125; @Override protected int tryAcquireShared(int arg) &#123; return super.tryAcquireShared(arg); &#125; @Override protected boolean tryReleaseShared(int arg) &#123; return super.tryReleaseShared(arg); &#125;&#125; 来看看锁的共性部分相关方法：来看看锁的共性部分相关方法： acquire：获取一把独占锁的过程 123456public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;就是先拿锁实现的tryAcquire方法去尝试获取独占锁，一旦获取锁失败就进入队列，交给AQS来处理，一旦成功就表示获取到了一把锁。 release：释放一把独占锁的过程 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 就是先拿锁实现的tryRelease方法尝试释放独占锁，一旦释放成功，就通知队列，有人释放锁了，队列前面的可以再次去竞争锁了（这一部分下面详细说明） acquireShared：获取一把共享锁的过程1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 就是先拿锁实现的tryAcquireShared方法尝试获取共享锁，一旦获取失败，就进入队列，交给AQS来处理 releaseShared：释放一把共享锁的过程1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 就是先拿锁实现的tryReleaseShared方法尝试释放共享锁，一旦释放成功，就通知队列，有人释放锁了 AbstractQueuedSynchronizer的状态属性state从上面我们就看到老是方法中会有各种的int参数，其实这是AbstractQueuedSynchronizer将获取锁的过程量化对数字的操作，而state变量就是用于记录当前数字值的。以独占锁为例: state=0 表示该锁未被其他线程获取 一旦有线程想获取锁，就可以对state进行CAS增量操作，这个增量可以是任意值，不过大多数都默认取1。也就是说一旦一个线程对state CAS操作成功就代表该线程获取到了锁，则state就变成1了。其他操作对state CAS操作失败的就代表没获取到锁，就自动进入AQS管理流程 其他线程发现当前state值不等于0表示锁已被其他线程获取，就自动进入AQS管理流程 一旦获取锁的线程想释放锁，就可以对state进行自减，即减到0，其他线程又可以去获取锁了 从上面的例子中可以看到对state的几种线程安全和非安全操作： compareAndSetState(int expect, int update)：线程安全的设置状态，因为可能多个线程并发调用该方法，所以需要CAS来保证线程安全 setState(int newState)：非线程安全的设置状态，这种一般是针对只有一个线程获取锁的时候来释放锁，此时没有并发的可能性，所以就不需要上述的compareAndSetState操作 getState()：获取状态值 AQS提供了上述线程安全和非安全的设置状态state的方法，供我们在实现锁的tryAcquire、tryRelease等方法的时候合理的时候它们。 AbstractQueuedSynchronizer的FIFO队列前面简单提到了，就是先拿锁实现的tryAcquire方法去尝试获取独占锁，一旦获取锁失败就进入队列，交给AQS来处理。AQS的处理简单描述下就是将当前线程包装成Node节点然后放到队列中进程排队，等待前面的Node节点都出队了，被唤醒轮到自己再次去竞争锁。 我们先来认识下Node节点,大致如下结构：123456789101112131415static final class Node &#123; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; volatile int waitStatus;&#125;private transient volatile Node head;private transient volatile Node tail; 首先就是prev、next节点可以构成一个双向队列。AQS中含有上述的head和tail两个属性一起来构成FIFO队列。 Thread thread则代表的是构成此节点的线程。 Node nextWaiter：是用于condition queue，用于构成一个单向的FIFO队列，详见下面。 volatile int waitStatus：则表示该节点当前的状态，目前有如下状态：1234567891011/** waitStatus value to indicate thread has cancelled */static final int CANCELLED = 1;/** waitStatus value to indicate successor&apos;s thread needs unparking */static final int SIGNAL = -1;/** waitStatus value to indicate thread is waiting on condition */static final int CONDITION = -2;/** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */static final int PROPAGATE = -3; CANCELLED：表示该节点所对应的线程因为获取锁的过程中超时或者被中断而被设置成此状态 SIGNAL：表示该节点所对应的线程被阻塞，不再被调度执行，需要等待其他线程释放锁之后来唤醒它，才能再次加入锁的竞争 CONDITION：表示该节点所对应的线程被阻塞，不再被调度执行，在等待某一个condition的signal、signalAll方法的唤醒 PROPAGATE：只用于共享状态的HEAD节点，目前还没弄清楚，欢迎一起来探讨 节点创建后默认状态值是0。 AbstractQueuedSynchronizer的condition queue参考https://my.oschina.net/pingpangkuangmo/blog/679636]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CountDownLatch学习]]></title>
    <url>%2F2018%2F04%2F02%2Fjava_thread%2FJUC-CountDownLatch%2F</url>
    <content type="text"><![CDATA[简介CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。 一个countdownlatch的使用案例题目n个赛车，让他们都在起跑线上就绪后，同时出发,并监控结束比赛的结束 答案12345678910111213141516171819202122232425262728293031323334353637383940414243public class CountDownTest &#123; private static class ProcessJob implements Runnable &#123; private CountDownLatch startLatch; private CountDownLatch stopLatch; public ProcessJob(CountDownLatch startLatch, CountDownLatch stopLatch) &#123; this.startLatch = startLatch; this.stopLatch = stopLatch; &#125; @Override public void run() &#123; try &#123; startLatch.await(); TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Some Job&quot;); stopLatch.countDown(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool(); int jobSize = 20; CountDownLatch startLatch = new CountDownLatch(1); CountDownLatch stopLatch = new CountDownLatch(jobSize); for (int i = 0; i &lt; jobSize; i++) &#123; executorService.submit(new ProcessJob(startLatch, stopLatch)); &#125; long start = System.currentTimeMillis(); startLatch.countDown(); // 等待所有线程执行完任务 stopLatch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;Total cost time: &quot; + (end - start)); executorService.shutdown(); executorService.awaitTermination(1, TimeUnit.MINUTES); &#125;&#125; 核心代码1234567891011121314151617181920212223242526272829private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; // 只有当当前state为0即count为0的时候能够返回 return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) // 成功CAS将count变为0的线程负责唤醒等待线程 return nextc == 0; &#125; &#125;&#125; 重写的aqs接口tryAcquireShared12345678910111213protected int tryAcquireShared(int arg)试图在共享模式下获取对象状态。此方法应该查询是否允许它在共享模式下获取对象状态，如果允许，则获取它。此方法总是由执行 acquire 线程来调用。如果此方法报告失败，则 acquire 方法可以将线程加入队列（如果还没有将它加入队列），直到获得其他某个线程释放了该线程的信号。默认实现将抛出 UnsupportedOperationException。参数：arg - acquire 参数。该值总是传递给 acquire 方法的那个值，或者是因某个条件等待而保存在条目上的值。该值是不间断的，并且可以表示任何内容。返回：在失败时返回负值；如果共享模式下的获取成功但其后续共享模式下的获取不能成功，则返回 0；如果共享模式下的获取成功并且其后续共享模式下的获取可能够成功，则返回正值，在这种情况下，后续等待线程必须检查可用性。（对三种返回值的支持使得此方法可以在只是有时候以独占方式获取对象的上下文中使用。）在成功的时候，此对象已被获取。抛出：IllegalMonitorStateException - 如果正在进行的获取操作将在非法状态下放置此同步器。必须以一致的方式抛出此异常，以便同步正确运行。UnsupportedOperationException - 如果不支持共享模式 tryReleaseShared1234567891011121314protected boolean tryReleaseShared(int arg)试图设置状态来反映共享模式下的一个释放。此方法总是由正在执行释放的线程调用。默认实现将抛出 UnsupportedOperationException。参数：arg - release 参数。该值总是传递给 release 方法的那个值，或者是因某个条件等待而保存在条目上的当前状态值。该值是不间断的，并且可以表示任何内容。返回：如果此对象现在处于完全释放状态，从而使正在等待的线程都可以试图获得此对象，则返回 true；否则返回 false抛出：IllegalMonitorStateException - 如果正在进行的释放操作将在非法状态下放置此同步器。必须以一致的方式抛出此异常，以便同步正确运行UnsupportedOperationException - 如果不支持共享模式 外部调用await()调用acquireShared的不可中断的方法acquireSharedInterruptibly，acquireSharedInterruptibly又会调用到上面Sync实现的tryAcquire方法判断是否能够返回还是继续等待。 countDown调用sync的releaseShared方法，releaseShared方法又会调用上面Sync实现的tryReleaseShared方法根据返回结果判定是否唤醒线程 参考文档https://liuzhengyang.github.io/2017/05/22/countdownlatch/]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[juc概览]]></title>
    <url>%2F2018%2F03%2F30%2Fjava_thread%2FJUC-1-overview%2F</url>
    <content type="text"><![CDATA[参考http://www.cnblogs.com/chenpi/p/5614290.htmlhttp://ifeve.com/doug-lea/ J.U.C：什么是JSR(Java Specification Requests)：JSR，全称 Java Specification Requests， 即Java规范提案， 主要是用于向JCP(Java Community Process)提出新增标准化技术规范的正式请求。每次JAVA版本更新都会有对应的JSR更新，比如在Java 8版本中，其新特性Lambda表达式对应的是JSR 335，新的日期和时间API对应的是JSR 310。 什么是JSR 166：当然，本文的关注点仅仅是JSR 166，它是一个关于Java并发编程的规范提案，在JDK中，该规范由java.util.concurrent包实现，是在JDK 5.0的时候被引入的； JDK6引入Deques、Navigable collections，对应的是JSR 166x， JDK7引入fork-join框架，用于并行执行任务，对应的是JSR 166y。 什么是J.U.C：即java.util.concurrent的缩写，该包参考自EDU.oswego.cs.dl.util.concurrent，是JSR 166标准规范的一个实现； 同步器(Synchronizers) 闭锁 CountDownLatch 栅栏 CyclicBarrier 信号量 Semaphore 交换器 Exchanger Phaser 显示锁 ReentrantLock ReentrantReadWriteLock StampedLock 原子变量类(Atomic Variables) 并发集合(Concurrent Collections) Executor框架（线程池、 Callable 、Future） Fork/Join并行计算框架 BlockingQueue（阻塞队列） TimeUnit枚举]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-gossip]]></title>
    <url>%2F2018%2F03%2F29%2Fredis%2Fstudy-gossip%2F</url>
    <content type="text"><![CDATA[https://github.com/aCoder2013/blog/issues/2 Cassandraredis]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql-master-slave]]></title>
    <url>%2F2018%2F03%2F29%2Fmysql%2Fmysql-master-slave%2F</url>
    <content type="text"><![CDATA[什么是Mysql主从复制MySQL主从复制是其最重要的功能之一。主从复制是指一台服务器充当主数据库服务器，另一台或多台服务器充当从数据库服务器，主服务器中的数据自动复制到从服务器之中。对于多级复制，数据库服务器即可充当主机，也可充当从机。MySQL主从复制的基础是主服务器对数据库修改记录二进制日志，从服务器通过主服务器的二进制日志自动执行更新。 Mysq主从复制的类型基于语句的复制(Statement)：主服务器上面执行的语句在从服务器上面再执行一遍，在MySQL-3.23版本以后支持。 存在的问题：时间上可能不完全同步造成偏差，执行语句的用户也可能是不同一个用户。 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。) 缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同 的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题(如sleep()函数， last_insert_id()，以及user-defined functions(udf)会出现问题). 使用以下函数的语句也无法被复制： LOAD_FILE() UUID() USER() FOUND_ROWS() SYSDATE() (除非启动时启用了 –sysdate-is-now 选项) 同时在INSERT …SELECT 会产生比 RBR 更多的行级锁 基于行的复制(Row)：把主服务器上面改编后的内容直接复制过去，而不关心到底改变该内容是由哪条语句引发的，在MySQL-5.0版本以后引入。 存在的问题：比如一个工资表中有一万个用户，我们把每个用户的工资+1000，那么基于行的复制则要复制一万行的内容，由此造成的开销比较大，而基于语句的复制仅仅一条语句就可以了。 优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题 缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。 混合类型的复制：是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。 Binlog基本配制与格式设定1.基本配制Mysql BInlog日志格式可以通过mysql的my.cnf文件的属性binlog_format指定。如以下： binlog_format = MIXED //binlog日志格式 log_bin =目录/mysql-bin.log //binlog日志名 expire_logs_days = 7 //binlog过期清理时间 max_binlog_size 100m //binlog每个日志文件大小 2.Binlog日志格式选择Mysql默认是使用Statement日志格式，推荐使用MIXED. 由于一些特殊使用，可以考虑使用ROWED，如自己通过binlog日志来同步数据的修改，这样会节省很多相关操作。对于binlog数据处理会变得非常轻松,相对mixed，解析也会很轻松(当然前提是增加的日志量所带来的IO开销在容忍的范围内即可)。 3.mysqlbinlog格式选择mysql对于日志格式的选定原则:如果是采用 INSERT，UPDATE，DELETE 等直接操作表的情况，则日志格式根据 binlog_format 的设定而记录,如果是采用 GRANT，REVOKE，SET PASSWORD 等管理语句来做的话，那么无论如何 都采用 SBR 模式记录。 Mysql主从复制的过程MySQL主从复制的两种情况：同步复制和异步复制，实际复制架构中大部分为异步复制。 复制的基本过程如下： Slave上面的IO进程连接上Master，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。 Master接收到来自Slave的IO进程的请求后，负责复制的IO进程会根据请求信息读取日志指定位置之后的日志信息，返回给Slave的IO进程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息已经到Master端的bin-log文件的名称以及bin-log的位置。 Slave的IO进程接收到信息后，将接收到的日志内容依次添加到Slave端的relay-log文件的最末端，并将读取到的Master端的 bin-log的文件名和位置记录到master-info文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我”。 Slave的Sql进程检测到relay-log中新增加了内容后，会马上解析relay-log的内容成为在Master端真实执行时候的那些可执行的内容，并在自身执行。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群]]></title>
    <url>%2F2018%2F03%2F28%2Fredis%2Fredis-cluster%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/u011204847/article/details/51307044http://www.redis.cn/topics/cluster-tutorial.htmlhttps://www.jianshu.com/p/04dd90ea08f5 简介Redis Cluster是Redis官方在Redis 3.0版本正式推出的高可用以及分布式的解决方案。 Redis Cluster由多个Redis实例组成的整体，数据按照槽(slot)存储分布在多个Redis实例上，通过Gossip协议来进行节点之间通信。 Redis Cluster实现的功能： • 将数据分片到多个实例(按照slot存储)； • 集群节点宕掉会自动failover； • 提供相对平滑扩容(缩容)节点。 Redis Cluster暂未有的： • 实时同步 • 强一致性 redis集群是一个无中心的分布式Redis存储架构，可以在多个节点之间进行数据共享，解决了Redis高可用、可扩展等问题。redis集群提供了以下两个好处 1、将数据自动切分(split)到多个节点2、当集群中的某一个节点故障时，redis还可以继续处理客户端的请求。 一个 Redis 集群包含 16384 个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽。集群中的每一个节点负责处理一部分哈希槽。 Redis 集群的数据分片Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念. Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点 A 包含 0 到 5500号哈希槽.节点 B 包含5501 到 11000 号哈希槽.节点 C 包含11001 到 16384号哈希槽.这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我想移除节点A,需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. 何处维护hash槽的绑定关系 cap理论Redis Cluster集群功能推出已经有一段时间了。在单机版的Redis中，每个Master之间是没有任何通信的，所以我们一般在Jedis客户端或者Codis这样的代理中做Pre-sharding。按照CAP理论来说，单机版的Redis属于保证CP(Consistency &amp; Partition-Tolerancy)而牺牲A(Availability)，也就说Redis能够保证所有用户看到相同的数据（一致性，因为Redis不自动冗余数据）和网络通信出问题时，暂时隔离开的子系统能继续运行（分区容忍性，因为Master之间没有直接关系，不需要通信），但是不保证某些结点故障时，所有请求都能被响应（可用性，某个Master结点挂了的话，那么它上面分片的数据就无法访问了）。 有了Cluster功能后，Redis从一个单纯的NoSQL内存数据库变成了分布式NoSQL数据库，CAP模型也从CP变成了AP。也就是说，通过自动分片和冗余数据，Redis具有了真正的分布式能力，某个结点挂了的话，因为数据在其他结点上有备份，所以其他结点顶上来就可以继续提供服务，保证了Availability。然而，也正因为这一点，Redis无法保证曾经的强一致性了。这也是CAP理论要求的，三者只能取其二。 集群中的主从复制集群中的每个节点都有1个至N个复制品，其中一个为主节点，其余的为从节点，如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点，继续工作。这样集群就不会因为一个主节点的下线而无法正常工作。 注意： 1、如果某一个主节点和他所有的从节点都下线的话，redis集群就会停止工作了。redis集群不保证数据的强一致性，在特定的情况下，redis集群会丢失已经被执行过的写命令 2、使用异步复制（asynchronous replication）是 Redis 集群可能会丢失写命令的其中一个原因，有时候由于网络原因，如果网络断开时间太长，redis集群就会启用新的主节点，之前发给主节点的数据就会丢失。 Redis Cluster分片实现一般分片（Sharding）实现的方式有list、range和hash(或者基于上述的组合方式)等方式。而Redis的实现方式是基于hash的分片方式，具体是虚拟槽分区。 虚拟槽分区 槽(slot):使用分散度良好的hash函数把所有数据映射到一个固定范围的整数集合中，这个整数集合就是槽。 Redis Cluster槽: Redis Cluster槽的范围是0 ~ 16383。槽是集群内数据管理和迁移的基本单位。 Hash标签哈希标签(hash tags)，在Redis集群分片中，可以通过哈希标签来实现指定两个及以上的Key在同一个slot中。只要Key包含“{…}”这种模式，Redis就会根据第一次出现的’{’和第一次出现的’}’之间的字符串进行哈希计算以获取相对应的slot数。如上Redis源码实现。 所以如果要指定某些Key存储到同一个slot中，只需要在命令Key的之后指定相同的“{…}”命名模式即可。 集群节点和槽当Redis Cluster中的16384个槽都有节点在处理时，集群处于上线状态(ok)； 如果Redis Cluster中有任何一个槽没有得到处理(或者某一分片的最后一个节点挂了)，那么集群处于下线状态(fail)。（info cluster中的：cluster_state状态）。那整个集群就不能对外提供服务。 Redis-3.0.0.rc1加入cluster-require-full-coverage参数，默认关闭，打开集群容忍部分失败。 但是如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态。 节点IDRedis Cluster每个节点在集群中都有唯一的ID，该ID是由40位的16进制字符组成，具体是节点第一次启动由linux的/dev/urandom生成。具体信息会保存在node.cnf配置文件中(该文件有Redis Cluster自动维护，可以通过参数cluster-config-file来指定路径和名称)，如果该文件被删除，节点ID将会重新生成。（删除以后所有的cluster和replication信息都没有了）或者通过Cluster Reset强制请求硬重置。 节点ID用于标识集群中的每个节点，包括指定Replication Master。只要节点ID不改变，哪怕节点的IP和端口发生了改变，Redis Cluster可以自动识别出IP和端口的变化，并将变更的信息通过Gossip协议广播给其他节点。 ClusterNode Master 节点维护这一个16384/8字节的位序列，Master节点用bit来标识对于某个槽自己是否拥有。(判断索引是不是为1即可) slots属性是一个二进制位数组(bit arry)，这个数组的长度为16384/8 = 2048个字节，共包含16384个二进制。 Redis Cluster对slots数组中的16384个二进制位进行编号：从0为起始索引，16383为终止索引。 根据索引i上的二进制位的值来判断节点是否负责处理槽i： •slots数组在索引i上的二进制位的值为1，即表示该节点负责处理槽i； •slots数组在索引i上的二进制位的值为0，即表示该节点不负责处理槽i； 示例1：（如下节点负责处理slot0-slot7） 即在Redis Cluster中Master节点使用bit(0)和bit(1)来标识对某个槽是否拥有，而Master只要判断序列第二位的值是不是1即可，时间复杂度为O(1)。 numslots属性记录节点负责处理的槽的数量，也就是slots数组中值为1的二进制位的数量。上图中节点处理的槽数量为8个。 ClusterState集群中所有槽的分配信息都保存在ClusterState数据结构的slots数组中，程序要检查槽i是否已经被分配或者找出处理槽i的节点，只需要访问clusterState.slots[i]的值即可，时间复杂度为O(1)。 slots数组包含16384个项，每个数组项都是一个指向clusterNode结构的指针： •如果slots[i]指针指向null，那么表示槽i尚未指派给任何节点； •如果slots[i]指针指向一个clusterNode结构，那么表示槽i已经指派给了clusterNode结构所代表的节点。 示例2： slots[0]至slots[4999]的指针都指向端口为6381的节点，即槽0到4999都由节点6381负责处理； slots[5000]至slots[9999]的指针都指向端口为6382的节点，即槽5000到9999都由节点6382负责处理； slots[10000]至slots[16383]的指针都指向端口为6383的节点，即槽10000到16384都由节点6383负责处理。 数组 clusterNode.slots和clusterState.slots：• clusterNode.slots数组记录了clusterNode结构所代表的节点的槽指派信息（每个节点负责哪些槽）。 • clusterState.slots数组记录了集群中所有槽的指派信息。 • 如果需要查看某个节点的槽指派信息，只需要将相应节点的clusterNode.slots数组整个发送出去即可。 • 但是如果需要查看槽i是否被分配或者分配给了哪个节点，就需要遍历clusterState.nodes字典中所有clusterNode结构，检查这些结构的slots数组，直到遍历到负责处理槽i的节点为止，这个过程的时间复杂度为O(N)，N是clusterState.nodes字典保存的clusterNode结构的数量。 • 引入clusterState.slots ,将所有槽的指派信息保存在clusterState.slots数组里面，程序要检查槽i是否已经被指派，或者查看负责处理槽i的节点，只需要访问clusterState.slots[i]的值即可，这个操作的时间复杂度为O(1)。 • 如果只使用clusterState.slots数组(不引入clusterNode.slots)，如果要将节点A的槽指派信息传播给其他节点时，必须先遍历整个clusterState.slots数组，记录节点A负责处理哪些槽，然后再发送给其他节点。比直接发送clusterNode.slots数组要低效的多。 Redis Cluster节点通信Redis Cluster节点通信Redis Cluster采用P2P的Gossip协议，Gossip协议的原理就是每个节点与其他节点间不断通信交换信息，一段时间后节点信息一致，每个节点都知道集群的完整信息。 Redis Cluster通信过程： (1)集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000； (2)每个节点在固定周期内通过特定规则选择几个节点发送ping消息； (3)接收到ping消息的节点用pong消息作为响应。 集群中每个节点通过一定规则挑选要通信的节点，每个节点可能知道全部节点，也可能仅知道部分节点， 只要这些节点彼此可以正常通信，最终它们会达到一致的状态。当节点出故障、新节点加入、主从角色变化、槽信息变更等事件发生时，通过不断的ping/pong消息通信，经过一段时间后所有的节点都会知道整个集群全部节点的最新状态，从而达到集群状态同步的目的。 Gossip消息Gossip协议的主要职责就是信息交换，信息交换的载体就是节点彼此发送的Gossip消息，常用的Gossip消息可分为： • meet消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换； • ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送ping消息，用于检测节点是否在线和交换彼此状态信息。ping消息发送封装了自身节点和部分其他节点的状态数据。 • pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。 • fail消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。 消息格式： 所有的消息格式划分为：消息头和消息体。 消息头包含发送节点自身状态数据，接收节点根据消息头就可以获取到发送节点的相关数据。]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis主从复制]]></title>
    <url>%2F2018%2F03%2F28%2Fredis%2Fredis-master-slave%2F</url>
    <content type="text"><![CDATA[概述1、redis的复制功能是支持多个数据库之间的数据同步。一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 2、通过redis的复制功能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。 重要方面：Redis 使用异步复制。 从 Redis 2.8 开始， 从服务器会以每秒一次的频率向主服务器报告复制流（replication stream）的处理进度。 一个主服务器可以有多个从服务器。 不仅主服务器可以有从服务器， 从服务器也可以有自己的从服务器， 多个从服务器之间可以构成一个图状结构。 复制功能不会阻塞主服务器： 即使有一个或多个从服务器正在进行初次同步， 主服务器也可以继续处理命令请求。 复制功能也不会阻塞从服务器： 只要在 redis.conf 文件中进行了相应的设置， 即使从服务器正在进行初次同步， 服务器也可以使用旧版本的数据集来处理命令查询。不过， 在从服务器删除旧版本数据集并载入新版本数据集的那段时间内， 连接请求会被阻塞。你还可以配置从服务器， 让它在与主服务器之间的连接断开时， 向客户端发送一个错误。 复制功能可以单纯地用于数据冗余（data redundancy）， 也可以通过让多个从服务器处理只读命令请求来提升扩展性（scalability）： 比如说， 繁重的 SORT 命令可以交给附属节点去运行。 可以通过复制功能来让主服务器免于执行持久化操作： 只要关闭主服务器的持久化功能， 然后由从服务器去执行持久化操作即可。 过程：1：当一个从数据库启动时，会向主数据库发送sync命令， 2：主数据库接收到sync命令后会开始在后台保存快照（执行rdb操作），并将保存期间接收到的命令缓存起来 3：当快照完成后，redis会将快照文件和所有缓存的命令发送给从数据库。 4：从数据库收到后，会载入快照文件并执行收到的缓存的命令。 方式配置方式手动方式 注意事项如果你使用主从复制，那么要确保你的master激活了持久化，或者确保它不会在当掉后自动重启。原因： slave是master的完整备份，因此如果master通过一个空数据集重启，slave也会被清掉。 在配置redis复制功能的时候如果主数据库设置了密码，需要在从数据的配置文件中通过masterauth参数设置主数据库的密码，这样从数据库在连接主数据库时就会自动使用auth命令认证了。相当于做了一个免密码登录。 复制功能的运作原理完整重同步无论是初次连接还是重新连接， 当建立一个从服务器时， 从服务器都将向主服务器发送一个 SYNC 命令。 接到 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。 当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件， 并将文件中的数据载入到内存中。 之后主服务器会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给从服务器。 你可以通过 telnet 命令来亲自验证这个同步过程： 首先连上一个正在处理命令请求的 Redis 服务器， 然后向它发送 SYNC 命令， 过一阵子， 你将看到 telnet 会话（session）接收到服务器发来的大段数据（.rdb 文件）， 之后还会看到， 所有在服务器执行过的写命令， 都会重新发送到 telnet 会话来。 即使有多个从服务器同时向主服务器发送 SYNC ， 主服务器也只需执行一次 BGSAVE 命令， 就可以处理所有这些从服务器的同步请求。 从服务器可以在主从服务器之间的连接断开时进行自动重连， 在 Redis 2.8 版本之前， 断线之后重连的从服务器总要执行一次完整重同步（full resynchronization）操作， 但是从 Redis 2.8 版本开始， 从服务器可以根据主服务器的情况来选择执行完整重同步还是部分重同步（partial resynchronization）。 部分重同步从 Redis 2.8 开始， 在网络连接短暂性失效之后， 主从服务器可以尝试继续执行原有的复制进程（process）， 而不一定要执行完整重同步操作。 这个特性需要主服务器为被发送的复制流创建一个内存缓冲区（in-memory backlog）， 并且主服务器和所有从服务器之间都记录一个复制偏移量（replication offset）和一个主服务器 ID （master run id）， 当出现网络连接断开时， 从服务器会重新连接， 并且向主服务器请求继续执行原来的复制进程： 如果从服务器记录的主服务器 ID 和当前要连接的主服务器的 ID 相同， 并且从服务器记录的偏移量所指定的数据仍然保存在主服务器的复制流缓冲区里面， 那么主服务器会向从服务器发送断线时缺失的那部分数据， 然后复制工作可以继续执行。否则的话， 从服务器就要执行完整重同步操作。Redis 2.8 的这个部分重同步特性会用到一个新增的 PSYNC 内部命令， 而 Redis 2.8 以前的旧版本只有 SYNC 命令， 不过， 只要从服务器是 Redis 2.8 或以上的版本， 它就会根据主服务器的版本来决定到底是使用 PSYNC 还是 SYNC ： 如果主服务器是 Redis 2.8 或以上版本，那么从服务器使用 PSYNC 命令来进行同步。如果主服务器是 Redis 2.8 之前的版本，那么从服务器使用 SYNC 命令来进行同步。 redis的Sentinelredis的sentinel系统用于管理多个redis服务器，该系统主要执行三个任务：监控、提醒、自动故障转移。 1、监控（Monitoring）： Redis Sentinel实时监控主服务器和从服务器运行状态，并且实现自动切换。 2、提醒（Notification）：当被监控的某个 Redis 服务器出现问题时， Redis Sentinel 可以向系统管理员发送通知， 也可以通过 API 向其他程序发送通知。 3、自动故障转移（Automatic failover）： 当一个主服务器不能正常工作时，Redis Sentinel 可以将一个从服务器升级为主服务器， 并对其他从服务器进行配置，让它们使用新的主服务器。当应用程序连接Redis 服务器时， Redis Sentinel会告之新的主服务器地址和端口。 注意：在使用sentinel监控主从节点的时候，从节点需要是使用动态方式配置的，如果直接修改配置文件，后期sentinel实现故障转移的时候会出问题。]]></content>
  </entry>
  <entry>
    <title><![CDATA[为什么废弃thread类的stop方法及java中的中断概念]]></title>
    <url>%2F2018%2F03%2F28%2Fjava_thread%2Fjava-deprecated-thread-stop%2F</url>
    <content type="text"><![CDATA[对比测试12345678910111213141516171819202122232425262728293031323334package com.example.demo.thread;public class ThreadStopTest &#123; public static void main(String[] args) &#123; try &#123; System.out.println(&quot;try&quot;); Thread thread = new MyThread(); thread.start(); Thread.sleep(700L); thread.stop();// thread.interrupt(); &#125; catch (Exception e) &#123; System.out.println(&quot;exception&quot;); &#125; finally &#123; System.out.println(&quot;finally&quot;); &#125; &#125;&#125;class MyThread extends Thread &#123; public void run() &#123; try &#123; System.out.println(&quot;run&quot;); Thread.sleep(1000L); throw new Exception(); &#125; catch (Exception e) &#123; System.out.println(&quot;exception &quot;); &#125; &#125;&#125; console输出的结果是：tryrunfinally 可以看到，stop终结一个线程，并且释放监控线程的所有资源。对于主线程来说，并不能再跟踪线程的运行状况，当线程出现异常也不能被捕获。而其他线程并不知道被stop的线程出现了异常。这样导致状态不一致的情况产生。 注释掉stop 一行，换用interrupt,进行测试。输出结果是：tryfinallyrunexception catch部分无法处理ThreadDeath异常 探究##stop方法内部实现: 12345stop0(new ThreadDeath());public class ThreadDeath extends Error &#123; private static final long serialVersionUID = -4417128565033088268L;&#125; ThreadDeath 悄无声息的杀死及其他线程。因此，用户得不到程序可能会崩溃的警告。崩溃会在真正破坏发生后的任意时刻显现，甚至在数小时或数天之后。 为何不正确首先应该明确一点：一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止。所以Thread.stop(),（同样的原因还有Thread.suspend(), Thread.resume()）都已经被废弃了。 一、资源回收问题线程A调用线程B的stop方法去停止线程B，调用这个方法的时候线程A其实并不知道线程B执行的具体情况，这种突然地停止会导致线程B的一些清理工作无法完成。 比如说假如线程B正在执行数据库操作，线程A突然就把线程B给stop掉了，那么线程B中的数据库链接该怎么关闭呢？线程B中方法才执行到一半，那些局部变量要怎么释放呢？ 二、数据不同步问题执行stop方法后线程B会马上释放锁，这有可能会引发数据不同步问题。 数据不一致1假如一个线程正在执行：synchronized void &#123; x = 3; y = 4;&#125; 由于方法是同步的，多个线程访问时总能保证x,y被同时赋值，而如果一个线程正在执行到x = 3;时，被调用了 stop()方法，即使在同步块中，它也干脆地stop了，这样就产生了不完整的残废数据。而多线程编程中最最基础的条件要保证数据的完整性，所以请忘记线程的stop方法，以后我们再也不要说“停止线程”了。而且如果对象处于一种不连贯状态，那么其他线程能在那种状态下检查和修改它们。结果 很难检查出真正的问题所在。 锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package test;public class testLock &#123; public static void main(String[] args) &#123; final Object lock = new Object(); Thread thread1 = new Thread() &#123; public void run() &#123; try &#123; synchronized (lock) &#123; System.out.println(&quot;thread1 acquire lock&quot;); System.out.println(&quot;thread1 release lock&quot;); &#125; &#125; catch (ThreadDeath e) &#123; // TODO: handle exception e.printStackTrace(); &#125; &#125; &#125;; Thread thread2 = new Thread() &#123; public void run() &#123; synchronized (lock) &#123; System.out.println(&quot;thread2 acquire lock&quot;); System.out.println(&quot;thread2 release lock&quot;); &#125; &#125; &#125;; thread1.start(); thread1.stop(); thread2.start(); &#125;&#125; 如果不使用stop方法，结果为：1234thread1 acquire lockthread1 release lockthread2 acquire lockthread2 release lock 这说明thread1和thread2都在正确地征用同一个锁对象。先是thread1获得了lock，然后释放lock。然后thread2获得了lock，然后释放lock。但是如果使用了stop方法，那么结果为： 12345thread2 acquire lockthread2 release lockjava.lang.ThreadDeath at java.lang.Thread.stop(Thread.java:850) at test.testLock.main(testLock.java:44) 可以看到thread1抛出了java.lang.ThreadDeath错误。同时thread的lock被破坏掉了，只有thread2获得了lock。因为锁被破坏，所以当前线程可能不安全。 线程中断在Java中没有办法立即停止一条线程，然而停止线程却显得尤为重要，如取消一个耗时操作。因此，Java提供了一种用于停止线程的机制——中断。 中断只是一种协作机制，Java没有给中断增加任何语法，中断的过程完全需要程序员自己实现。若要中断一个线程，你需要手动调用该线程的interrupted方法，该方法也仅仅是将线程对象的中断标识设成true；接着你需要自己写代码不断地检测当前线程的标识位；如果为true，表示别的线程要求这条线程中断，此时究竟该做什么需要你自己写代码实现。 每个线程对象中都有一个标识，用于表示线程是否被中断；该标识位为true表示中断，为false表示未中断； 通过调用线程对象的interrupt方法将该线程的标识位设为true；可以在别的线程中调用，也可以在自己的线程中调用。 相关方法中断的相关方法public void interrupt() 将调用者线程的中断状态设为true。public boolean isInterrupted() 判断调用者线程的中断状态。public static boolean interrupted 只能通过Thread.interrupted()调用。 它会做两步操作：返回当前线程的中断状态；将当前线程的中断状态设为false； 正确用法1.设置中断监听2.触发中断 参考 http://ibruce.info/2013/12/19/how-to-stop-a-java-thread/ https://blog.csdn.net/wei_ya_wen/article/details/8626880 http://www.xie4ever.com/2017/03/03/java-%E7%A6%81%E6%AD%A2%E4%BD%BF%E7%94%A8thread-stop%E6%96%B9%E6%B3%95/]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ffp2 ffp3 n95 n99差别]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%85%B6%E4%BB%96%2Fgauze-mask-comparison%2F</url>
    <content type="text"><![CDATA[最近打算买口罩,发现了FPP和N两种 度量的标准,以下是两种计量单位之间的比较 等级 Penetration 渗透率 捕集率 Resistant 阻抗 FFP1 20% ≥80% 21mm H2O FFP2 6% ≥94% 24mm H2O FFP3 1% ≥99% 30mm H2O 等级 Penetration渗透率 捕集率 Resistant 阻抗 N95 5% ≥95% 35mm H2O N99 1% ≥99% 35mm H2O N100 0.03% ≥99.97% 35mm H2O]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>口罩</tag>
        <tag>pm2.5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java对象字节码占用计算]]></title>
    <url>%2F2018%2F03%2F27%2Fjava_jvm%2Fjava-object-menory-compute%2F</url>
    <content type="text"><![CDATA[参考https://www.jianshu.com/p/91e398d5d17chttps://www.jianshu.com/p/12a3c97dc2b7 对象内存结构各种类型分别占多少个字节(bytes)： 计算方式： ① 对象头（Header）② 实例数据（Instance Data）③ 对齐填充 （Padding） 对象头（Header）HotSpot 虚拟机的对象头包括两部分信息：Mark Word 和 类型指针；如果是数组对象的话，还有第三部分（option）信息：数组长度 Mark Word这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit 和64bit。Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。对象头信息是与对象定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的信息，它会根据对象的状态复用自己的存储空间。 类型指针（Class Pointer）是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 数组长度（Length）[option]如果对象时一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据。因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。 实例数据（Instance Data）实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果CompactFields参数值为true（默认为true），那子类之中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充 （Padding）对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。 占用空间普通对象占用内存情况： 32 位系统 64 位系统(+UseCompressedOops) 64 位系统(-UseCompressedOops) Mark Word 4 bytes 8 bytes 8 bytes Class Pointer 4 bytes 4 bytes 8 bytes 对象头 8 bytes 12 bytes 16 bytes 数组对象占用内存情况： 32 位系统 64 位系统(+UseCompressedOops) 64 位系统(-UseCompressedOops) Mark Word 4 bytes 8 bytes 8 bytes Class Pointer 4 bytes 4 bytes 8 bytes Length 4 bytes 4 bytes 4 bytes 对象头 12 bytes 16 bytes 20 bytes 基本类型 Type 32 位系统 64 位系统(+UseCompressedOops) 64 位系统(-UseCompressedOops) double 8 bytes 8 bytes 8 bytes long 8 bytes 8 bytes 8 bytes float 4 bytes 4 bytes 4 bytes int 4 bytes 4 bytes 4 bytes char 2 bytes 2 bytes 2 bytes short 2 bytes 2 bytes 2 bytes byte 1 bytes 1 bytes 1 bytes boolean 1 bytes 1 bytes 1 bytes oops(ordinary object pointers) 4 bytes 4 bytes 8 bytes 注意：JVM默认是开启压缩参数的-XX:+UseCompressedOops 计算对象本身占用大小和对象总空间占用大小的区别： 1.本身占用大小，对象中除了基本类型之外，其他类型都按照引用来计算，不要计算引用中对象的大小。 2.总空间占用大小，要计算对象中每一个对象的大小，引用中的对象也要计算，再累加获得总空间。 包装类型 +useCompressedOops -useCompressedOops Byte, Boolean 16 bytes 24 bytes Short, Character 16 bytes 24 bytes Integer, Float 16 bytes 24 bytes Long, Double 24 bytes 24 bytes]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis中获取全部的方法]]></title>
    <url>%2F2018%2F03%2F27%2Fredis%2Fredis-getall%2F</url>
    <content type="text"><![CDATA[StringhashHGETALL1234567891011redis&gt; HSET people jack &quot;Jack Sparrow&quot;(integer) 1redis&gt; HSET people gump &quot;Forrest Gump&quot;(integer) 1redis&gt; HGETALL people1) &quot;jack&quot; # 域(key)2) &quot;Jack Sparrow&quot; # 值(value)3) &quot;gump&quot;4) &quot;Forrest Gump&quot; List(链表)LRANGELRANGE key start stop 返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定。 下标(index)参数 start 和 stop 都以 0 为底，也就是说，以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 注意LRANGE命令和编程语言区间函数的区别 假如你有一个包含一百个元素的列表，对该列表执行 LRANGE list 0 10 ，结果是一个包含11个元素的列表，这表明 stop 下标也在 LRANGE 命令的取值范围之内(闭区间)，这和某些语言的区间函数可能不一致，比如Ruby的 Range.new 、 Array#slice 和Python的 range() 函数。 超出范围的下标 超出范围的下标值不会引起错误。 如果 start 下标比列表的最大下标 end ( LLEN list 减去 1 )还要大，那么 LRANGE 返回一个空列表。 如果 stop 下标比 end 下标还要大，Redis将 stop 的值设置为 end 。 时间复杂度:O(S+N)， S 为偏移量 start ， N 为指定区间内元素的数量。返回值:一个列表，包含指定区间内的元素。 123456789101112redis&gt; RPUSH fp-language lisp(integer) 1redis&gt; LRANGE fp-language 0 01) &quot;lisp&quot;redis&gt; RPUSH fp-language scheme(integer) 2redis&gt; LRANGE fp-language 0 11) &quot;lisp&quot;2) &quot;scheme&quot; setSMEMBERSSMEMBERS key 返回集合 key 中的所有成员。 不存在的 key 被视为空集合。 时间复杂度:O(N)， N 为集合的基数。返回值:集合中的所有成员。 123456789101112131415161718# key 不存在或集合为空redis&gt; EXISTS not_exists_key(integer) 0redis&gt; SMEMBERS not_exists_key(empty list or set)# 非空集合redis&gt; SADD language Ruby Python Clojure(integer) 3redis&gt; SMEMBERS language1) &quot;Python&quot;2) &quot;Ruby&quot;3) &quot;Clojure&quot; sortsetZRANGE返回有序集 key 中，指定区间内的成员。 其中成员的位置按 score 值递增(从小到大)来排序。 具有相同 score 值的成员按字典序(lexicographical order )来排列。 如果你需要成员按 score 值递减(从大到小)来排列，请使用 ZREVRANGE 命令。 下标参数 start 和 stop 都以 0 为底，也就是说，以 0 表示有序集第一个成员，以 1 表示有序集第二个成员，以此类推。你也可以使用负数下标，以 -1 表示最后一个成员， -2 表示倒数第二个成员，以此类推。超出范围的下标并不会引起错误。比如说，当 start 的值比有序集的最大下标还要大，或是 start &gt; stop 时， ZRANGE 命令只是简单地返回一个空列表。另一方面，假如 stop 参数的值比有序集的最大下标还要大，那么 Redis 将 stop 当作最大下标来处理。可以通过使用 WITHSCORES 选项，来让成员和它的 score 值一并返回，返回列表以 value1,score1, …, valueN,scoreN 的格式表示。客户端库可能会返回一些更复杂的数据类型，比如数组、元组等。 123456789101112131415161718192021222324redis &gt; ZRANGE salary 0 -1 WITHSCORES # 显示整个有序集成员1) &quot;jack&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;boss&quot;6) &quot;10086&quot;redis &gt; ZRANGE salary 1 2 WITHSCORES # 显示有序集下标区间 1 至 2 的成员1) &quot;tom&quot;2) &quot;5000&quot;3) &quot;boss&quot;4) &quot;10086&quot;redis &gt; ZRANGE salary 0 200000 WITHSCORES # 测试 end 下标超出最大下标时的情况1) &quot;jack&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;boss&quot;6) &quot;10086&quot;redis &gt; ZRANGE salary 200000 3000000 WITHSCORES # 测试当给定区间不存在于有序集时的情况(empty list or set) ZRANGEBYSCOREZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 具有相同 score 值的成员按字典序(lexicographical order)来排列(该属性是有序集提供的，不需要额外的计算)。 可选的 LIMIT 参数指定返回结果的数量及区间(就像SQL中的 SELECT LIMIT offset, count )，注意当 offset 很大时，定位 offset 的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N) 时间。 可选的 WITHSCORES 参数决定结果集是单单返回有序集的成员，还是将有序集成员及其 score 值一起返回。该选项自 Redis 2.0 版本起可用。区间及无限 min 和 max 可以是 -inf 和 +inf ，这样一来，你就可以在不知道有序集的最低和最高 score 值的情况下，使用 ZRANGEBYSCORE 这类命令。 默认情况下，区间的取值使用闭区间 (小于等于或大于等于)，你也可以通过给参数前增加 ( 符号来使用可选的开区间 (小于或大于)。 12345678910111213141516171819202122232425262728redis&gt; ZADD salary 2500 jack # 测试数据(integer) 0redis&gt; ZADD salary 5000 tom(integer) 0redis&gt; ZADD salary 12000 peter(integer) 0redis&gt; ZRANGEBYSCORE salary -inf +inf # 显示整个有序集1) &quot;jack&quot;2) &quot;tom&quot;3) &quot;peter&quot;redis&gt; ZRANGEBYSCORE salary -inf +inf WITHSCORES # 显示整个有序集及成员的 score 值1) &quot;jack&quot;2) &quot;2500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;peter&quot;6) &quot;12000&quot;redis&gt; ZRANGEBYSCORE salary -inf 5000 WITHSCORES # 显示工资 &lt;=5000 的所有成员1) &quot;jack&quot;2) &quot;2500&quot;3) &quot;tom&quot;4) &quot;5000&quot;redis&gt; ZRANGEBYSCORE salary (5000 400000 # 显示工资大于 5000 小于等于 400000 的成员1) &quot;peter&quot;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis移除过期时间的命令]]></title>
    <url>%2F2018%2F03%2F27%2Fredis%2Fredis-key-persist%2F</url>
    <content type="text"><![CDATA[PERSIST mykey123起始版本：2.2.0时间复杂度：O(1) 移除给定key的生存时间，将这个 key 从『易失的』(带生存时间 key )转换成『持久的』(一个不带生存时间、永不过期的 key )。 ##返回值 integer-reply, 只有以下两种值: 当生存时间移除成功时，返回 1 .如果 key 不存在或 key 没有设置生存时间，返回 0 . ##例子 1234567891011redis&gt; SET mykey &quot;Hello&quot;OKredis&gt; EXPIRE mykey 10(integer) 1redis&gt; TTL mykey(integer) 10redis&gt; PERSIST mykey(integer) 1redis&gt; TTL mykey(integer) -1redis&gt;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-https]]></title>
    <url>%2F2018%2F03%2F27%2Fhttp%2Fstudy-https%2F</url>
    <content type="text"><![CDATA[一、HTTP和HTTPS的基本概念HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。 HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 HTTPS协议的主要作用可以分为两种： 一种是建立一个信息安全通道，来保证数据传输的安全； 另一种就是确认网站的真实性。 二、HTTP与HTTPS有什么区别？HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。 简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。 HTTPS和HTTP的区别主要如下： 1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 HTTPS的工作原理1、客户端发起HTTPS请求 这个没什么好说的，就是用户在浏览器里输入一个https网址，然后连接到server的443端口。 2、服务端的配置 采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl就是个不错的选择，有1年的免费服务)。 这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 3、传送证书 这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 4、客户端解析证书(验证公钥) 这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。 如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密，就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 5、传送加密信息 这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 6、服务段解密信息 服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密，所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 7、传输加密后的信息 这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。 8、客户端解密信息 客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。x]]></content>
  </entry>
  <entry>
    <title><![CDATA[常见用来保证幂等的手段]]></title>
    <url>%2F2018%2F03%2F27%2Fdesign%2Fstudy-idempotence%2F</url>
    <content type="text"><![CDATA[幂等性定义数学定义在数学里，幂等有两种主要的定义： 在某二元运算下，幂等元素是指被自己重复运算(或对于函数是为复合)的结果等于它自己的元素。例如，乘法下唯一两个幂等实数为0和1。 即 s *s = s某一元运算为幂等的时，其作用在任一元素两次后会和其作用一次的结果相同。例如，高斯符号便是幂等的，即f(f(x)) = f(x)。 HTTP规范的定义HTTP的幂等性指的是一次和多次请求某一个资源应该具有相同的副作用。如通过PUT接口将数据的Status置为1，无论是第一次执行还是多次执行，获取到的结果应该是相同的，即执行完成之后Status =1。 何种接口提供幂等性在HTTP规范中定义GET,PUT和DELETE方法应该具有幂等性。 重要 安全？ 幂等？ GET 是 是 DELETE 否 是 PUT 否 是 POST 否 否 常见用来保证幂等的手段:1.查询性质(天然支持) 查询的API，可以说是天然的幂等性，因为你查询一次和查询两次，对于系统来讲，没有任何数据的变更，所以，查询一次和查询多次一样的； 2.MVCC方案 多版本并发控制，update with condition更新带条件，这也是在系统设计的时候，合理的选择乐观锁，通过version或者其他条件，来做乐观锁，这样保证更新及时在并发的情况下，也不会有太大的问题。 例如update table_xxx set name=#name#,version=version+1 where version=#version# ,或者是 update table_xxx set quality=quality-#subQuality# where quality-#subQuality# &gt;= 0 3.插入数据的唯一索引(单库单表可行) 插入数据的唯一性，可以通过业务主键来进行约束，例如一个特定的业务场景，三个字段肯定确定唯一性，那么，可以在数据库表添加唯一索引来进行标示。 3.1 select + insert (并发不高的情况下,分库分表支持) 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了。注意：核心高并发流程不要用这种方法 3.2 select + insert + 锁 (并发高的情况下,分库分表支持) 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了。注意：核心高并发流程不要用这种方法 4.分布式锁 还是拿插入数据的例子，如果是分布是系统，构建唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多个系统，也就是分布式系统中得解决思路； 5.状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等 6.token机制，防止页面重复提交 业务要求：页面的数据只能被点击提交一次 发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交 其他通常，客户端只需要在500（InternalErrorInternalError）或503（ServiceUnavailable）错误、或者无法得到响应结果的情况下进行重试操作。返回结果是200时，重试可以得到上次相同的结果，但不会对服务端状态带来任何影响。而对4xx的返回错误，除非提示信息里明确出现“try it later”，通常重试也是不能成功的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis数据类型]]></title>
    <url>%2F2018%2F03%2F26%2Fredis%2Fredis-data-type%2F</url>
    <content type="text"><![CDATA[在Redis中有五种数据类型** String———-字符串 Hash————字典 List————-列表 Set————–集合 Sorted Set——有序集合 一 数据类型String—字符串string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。string类型是Redis最基本的数据类型，一个键最大能存储512MB。** String 数据结构是简单的 key-value 类型，value 不仅可以是 String，也可以是数字（当数字类型用 Long 可以表示的时候encoding 就是整型，其他都存储在 sdshdr 当做字符串）。使用 Strings 类型，可以完全实现目前 Memcached 的功能，并且效率更高。还可以享受 Redis 的定时持久化（可以选择 RDB 模式或者 AOF 模式），操作日志及 Replication 等功能。除了提供与 Memcached 一样的 get、set、incr、decr 等操作外，Redis 还提供了下面一些操作： 1.LEN：O(1)获取字符串长度2.APPEND ：往字符串 append 内容，而且采用智能分配内存（每次2倍）3.设置和获取字符串的某一段内容4.设置及获取字符串的某一位（bit）5.批量设置一系列字符串的内容6.原子计数器7.GET SET 命令的妙用，请于清空旧值的同时设置一个新值，配合原子计数器使用 Hash——字典(哈希)Hash是一个健值对集合，是一个String类型的key与value的映射表，特别适合用于存储对象。使用场景：存储、读取、修改用户属性在 Memcached 中，我们经常将一些结构化的信息打包成 hashmap，在客户端序列化后存储为一个字符串的值（一般是 JSON 格式），比如用户的昵称、年龄、性别、积分等。这时候在需要修改其中某一项时，通常需要将字符串（JSON）取出来，然后进行反序列化，修改某一项的值，再序列化成字符串（JSON）存储回去。简单修改一个属性就干这么多事情，消耗必定是很大的，也不适用于一些可能并发操作的场合（比如两个并发的操作都需要修改积分）。而 Redis 的 Hash 结构可以使你像在数据库中 Update 一个属性一样只修改某一项属性值。 List——列表使用场景：微博 TimeLine、消息队列*List 说白了就是链表（redis 使用双端链表实现的 List），相信学过数据结构知识的人都应该能理解其结构。使用 List 结构，我们可以轻松地实现最新消息排行等功能（比如新浪微博的 TimeLine ）。List 的另一个应用就是消息队列，可以利用 List 的 \PUSH 操作，将任务存在 List 中，然后工作线程再用 POP 操作将任务取出进行执行。Redis 还提供了操作 List 中某一段元素的 API，你可以直接查询，删除 List 中某一段的元素 Set——集合集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)使用场景：1.共同好友、二度好友 2.利用唯一性，可以统计访问网站的所有独立 IP 3.好友推荐的时候，根据 tag 求交集，大于某个 threshold 就可以推荐Set 就是一个集合，集合的概念就是一堆不重复值的组合。利用 Redis 提供的 Set 数据结构，可以存储一些集合性的数据。比如在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。因为 Redis 非常人性化的为集合提供了求交集、并集、差集等操作**，那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。 Sorted Set——有序集合使用场景：1.带有权重的元素，比如一个游戏的用户得分排行榜 2.比较复杂的数据结构，一般用到的场景不算太多**和Sets相比，Sorted Sets是将 Set 中的元素增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，比如一个存储全班同学成绩的 Sorted Sets，其集合 value 可以是同学的学号，而 score 就可以是其考试得分，这样在数据插入集合的时候，就已经进行了天然的排序。另外还可以用 Sorted Sets 来做带权重的队列，比如普通消息的 score 为1，重要消息的 score 为2，然后工作线程可以选择按 score 的倒序来获取工作任务。让重要的任务优先执行。 二 redis 其他功能使用场景订阅-发布系统Pub/Sub 从字面上理解就是发布（Publish）与订阅（Subscribe），在 Redis 中，你可以设定对某一个 key 值进行消息发布及消息订阅，当一个 key 值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 事务——Transactions谁说 NoSQL 都不支持事务，虽然 Redis 的 Transactions 提供的并不是严格的 ACID 的事务（比如一串用 EXEC 提交执行的命令，在执行中服务器宕机，那么会有一部分命令执行了，剩下的没执行），但是这个 Transactions 还是提供了基本的命令打包执行的功能（在服务器不出问题的情况下，可以保证一连串的命令是顺序在一起执行的，中间不会有其它客户端命令插进来执行）。Redis 还提供了一个 Watch 功能，你可以对一个 key 进行 Watch，然后再执行 Transactions，在这过程中，如果这个 Watched 的值进行了修改，那么这个 Transactions 会发现并拒绝执行。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis过期淘汰机制]]></title>
    <url>%2F2018%2F03%2F26%2Fredis%2Fredis-key-timeout%2F</url>
    <content type="text"><![CDATA[参考 https://yq.aliyun.com/articles/257459 背景Redis作为一个高性能的内存NoSQL数据库，其容量受到最大内存限制的限制。 用户在使用阿里云Redis时，除了对性能，稳定性有很高的要求外，对内存占用也比较敏感。在使用过程中，有些用户会觉得自己的线上实例内存占用比自己预想的要大。 事实上，实例中的内存除了保存原始的键值对所需的开销外，还有一些运行时产生的额外内存，包括： 垃圾数据和过期Key所占空间 字典渐进式Rehash导致未及时删除的空间 Redis管理数据，包括底层数据结构开销，客户端信息，读写缓冲区等 主从复制，bgsave时的额外开销 其它 本系列文章主要分析这些在Redis中产生的原因，带来的影响和规避的方式。 本文主要分析第一项Redis过期策略对内存的影响。 Redis过期数据清理策略过期数据清理时机为了防止一次性清理大量过期Key导致Redis服务受影响，Redis只在空闲时清理过期Key。 具体Redis逐出过期Key的时机为: 访问Key时，会判断Key是否过期，逐出过期Key; CPU空闲时在定期serverCron任务中，逐出部分过期Key; 每次事件循环执行的时候，逐出部分过期Key; 过期数据清理算法Redis过期Key清理的机制对清理的频率和最大时间都有限制，在尽量不影响正常服务的情况下，进行过期Key的清理，以达到长时间服务的性能最优. Redis会周期性的随机测试一批设置了过期时间的key并进行处理。测试到的已过期的key将被删除。具体的算法如下: Redis配置项hz定义了serverCron任务的执行周期，默认为10，即CPU空闲时每秒执行10次; 每次过期key清理的时间不超过CPU时间的25%，即若hz=1，则一次清理时间最大为250ms，若hz=10，则一次清理时间最大为25ms; 清理时依次遍历所有的db; 从db中随机取20个key，判断是否过期，若过期，则逐出; 若有5个以上key过期，则重复步骤4，否则遍历下一个db; 在清理过程中，若达到了25%CPU时间，退出清理过程; 这是一个基于概率的简单算法，基本的假设是抽出的样本能够代表整个key空间，redis持续清理过期的数据直至将要过期的key的百分比降到了25%以下。这也意味着在长期来看任何给定的时刻已经过期但仍占据着内存空间的key的量最多为每秒的写操作量除以4. 由于算法采用的随机取key判断是否过期的方式，故几乎不可能清理完所有的过期Key; 调高hz参数可以提升清理的频率，过期key可以更及时的被删除，但hz太高会增加CPU时间的消耗;Redis作者关于hz参数的一些讨论 代码分析如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125voidactiveExpireCycle(inttype)&#123;.../* We can use at max ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC percentage of CPU time* per iteration. Since this function gets called with a frequency of* server.hz times per second, the following is the max amount of* microseconds we can spend in this function. */// 最多允许25%的CPU时间用于过期Key清理// 若hz=1，则一次activeExpireCycle最多只能执行250ms// 若hz=10，则一次activeExpireCycle最多只能执行25mstimelimit =1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;...// 遍历所有dbfor(j =0; j&lt;dbs_per_call; j++) &#123;intexpired;redisDb *db = server.db+(current_db % server.dbnum);/* Increment the DB now so we are sure if we run out of time* in the current DB we&apos;ll restart from the next. This allows to* distribute the time evenly across DBs. */current_db++;/* Continue to expire if at the end of the cycle more than 25%* of the keys were expired. */do&#123;...// 一次取20个Key，判断是否过期if(num&gt;ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;while(num--) &#123;dictEntry *de;longlongttl;if((de = dictGetRandomKey(db-&gt;expires)) ==NULL)break;ttl = dictGetSignedIntegerVal(de)-now;if(activeExpireCycleTryExpire(db,de,now)) expired++;&#125;if((iteration&amp;0xf) ==0) &#123;/* check once every 16 iterations. */longlongelapsed = ustime()-start;latencyAddSampleIfNeeded(&quot;expire-cycle&quot;,elapsed/1000);if(elapsed&gt;timelimit) timelimit_exit =1;&#125;if(timelimit_exit)return;/* We don&apos;t repeat the cycle if there are less than 25% of keys* found expired in the current DB. */// 若有5个以上过期Key，则继续直至时间超过25%的CPU时间// 若没有5个过期Key，则跳过。&#125;while(expired&gt;ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);&#125;&#125; Redis数据逐出策略数据逐出时机123456789101112131415161718192021// 执行命令intprocessCommand(redisClient *c)&#123;.../* Handle the maxmemory directive.**First we try to free some memory if possible (if there are volatile* keys in the dataset). If there are not the only thing we can do* is returning an error. */if(server.maxmemory) &#123;intretval = freeMemoryIfNeeded();...&#125;...&#125; 数据逐出算法在逐出算法中，根据用户设置的逐出策略，选出待逐出的key，直到当前内存小于最大内存值为主. 默认的策略为noeviction策略 可选逐出策略如下： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用 的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数 据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据 淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 具体代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216intfreeMemoryIfNeeded()&#123;...// 计算mem_usedmem_used = zmalloc_used_memory();.../* Check if we are over the memory limit. */if(mem_used&lt;= server.maxmemory)returnREDIS_OK;// 如果禁止逐出，返回错误if(server.maxmemory_policy == REDIS_MAXMEMORY_NO_EVICTION)returnREDIS_ERR;/* We need to free memory, but policy forbids. */mem_freed =0;mem_tofree = mem_used - server.maxmemory;longlongstart = ustime();latencyStartMonitor(latency);while(mem_freed&lt;mem_tofree) &#123;intj, k, keys_freed =0;for(j =0; j&lt;server.dbnum; j++) &#123;// 根据逐出策略的不同，选出待逐出的数据longbestval =0;/* just to prevent warning */sds bestkey =NULL;structdictEntry *de;redisDb *db = server.db+j;dict *dict;if(server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM)&#123;dict = server.db[j].dict;&#125;else&#123;dict = server.db[j].expires;&#125;if(dictSize(dict) ==0)continue;/* volatile-random and allkeys-random policy */if(server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM ||server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_RANDOM)&#123;de = dictGetRandomKey(dict);bestkey = dictGetKey(de);&#125;/* volatile-lru and allkeys-lru policy */elseif(server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)&#123;for(k =0; k&lt;server.maxmemory_samples; k++) &#123;sds thiskey;longthisval;robj *o;de = dictGetRandomKey(dict);thiskey = dictGetKey(de);/* When policy is volatile-lru we need an additional lookup* to locate the real key, as dict is set to db-&gt;expires. **/if(server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)de = dictFind(db-&gt;dict, thiskey);o = dictGetVal(de);thisval = estimateObjectIdleTime(o);/* Higher idle time is better candidate for deletion */if(bestkey ==NULL|| thisval&gt;bestval) &#123;bestkey = thiskey;bestval = thisval;&#125;&#125;&#125;/* volatile-ttl */elseif(server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_TTL) &#123;for(k =0; k&lt;server.maxmemory_samples; k++) &#123;sds thiskey;longthisval;de = dictGetRandomKey(dict);thiskey = dictGetKey(de);thisval = (long) dictGetVal(de);/* Expire sooner (minor expire unix timestamp) is better* candidate for deletion **/if(bestkey ==NULL|| thisval&lt;bestval) &#123;bestkey = thiskey;bestval = thisval;&#125;&#125;&#125;/* Finally remove the selected key. **/// 逐出挑选出的数据if(bestkey ) &#123;...delta = (longlong) zmalloc_used_memory();dbDelete(db,keyobj);delta -= (longlong) zmalloc_used_memory();mem_freed += delta;...&#125;&#125;...&#125;...returnREDIS_OK;&#125; 相关最佳实践 不要放垃圾数据，及时清理无用数据 实验性的数据和下线的业务数据及时删除; key尽量都设置过期时间 对具有时效性的key设置过期时间，通过redis自身的过期key清理策略来降低过期key对于内存的占用，同时也能够减少业务的麻烦，不需要定期手动清理了. 单Key不要过大 给用户排查问题时遇到过单个string的value有43M的，也有一个list 100多万个大成员占了1G多内存的。这种key在get的时候网络传输延迟会比较大，需要分配的输出缓冲区也比较大，在定期清理的时候也容易造成比较高的延迟. 最好能通过业务拆分，数据压缩等方式避免这种过大的key的产生。 不同业务如果公用一个业务的话，最好使用不同的逻辑db分开 从上面的分析可以看出，Redis的过期Key清理策略和强制淘汰策略都会遍历各个db。将key分布在不同的db有助于过期Key的及时清理。另外不同业务使用不同db也有助于问题排查和无用数据的及时下线. 如何选择淘汰策略但是这个值填什么呢？为解决这个问题，我们需要了解我们的应用请求对于Redis中存储的数据集的访问方式以及我们的诉求是什么。同时Redis也支持Runtime修改淘汰策略，这使得我们不需要重启Redis实例而实时的调整内存淘汰策略。 下面看看几种策略的适用场景： allkeys-lru：如果我们的应用对缓存的访问符合幂律分布（也就是存在相对热点数据），或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择allkeys-lru策略。 allkeys-random：如果我们的应用对于缓存key的访问概率相等，则可以使用这个策略。 volatile-ttl：这种策略使得我们可以向Redis提示哪些key更适合被eviction。 另外，volatile-lru策略和volatile-random策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个Redis实例来达到相同的效果，值得一提的是将key设置过期时间实际上会消耗更多的内存，因此我们建议使用allkeys-lru策略从而更有效率的使用内存。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 快的原因]]></title>
    <url>%2F2018%2F03%2F26%2Fredis%2Fredis-fast%2F</url>
    <content type="text"><![CDATA[Redis 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 C 语言编写。官方提供的数据是可以达到100000+的 qps。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差。 Redis 快的主要原因有： 完全基于内存； 数据结构简单，对数据操作也简单； 使用多路 I/O 复用模型； 第一、二点不细讲，主要围绕第三点采用多路 I/O 复用技术来展开。 多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了 Redis 具有很高的吞吐量。 和 Memcached 不同，Redis 并没有直接使用 Libevent，而是自己完成了一个非常轻量级的对 select、epoll、evport、kqueue 这些通用的接口的实现。在不同的系统调用选用适合的接口，linux 下默认是 epoll。因为 Libevent 比较重，更通用，代码量也就很庞大，拥有很多 Redis 用不上的功能，Redis 为了追求“轻巧”并且去除依赖，就选择自己去封装了一套。 单进程单线程好处 代码更清晰，处理逻辑更简单 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 不存在多进程或者多线程导致的切换而消耗 CPU 单进程单线程弊端 无法发挥多核 CPU 性能，不过可以通过在单机开多个 Redis 实例来完善； 其他一些优秀的开源软件采用的模型 多进程单线程模型：Nginx 单进程多线程模型：Memcached]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化方式]]></title>
    <url>%2F2018%2F03%2F26%2Fredis%2Fredis-persist%2F</url>
    <content type="text"><![CDATA[为防止数据丢失，需要将 Redis 中的数据从内存中 dump 到磁盘，这就是持久化。Redis 提供两种持久化方式：RDB 和 AOF。Redis 允许两者结合，也允许两者同时关闭。 RDB 可以定时备份内存中的数据集。服务器启动的时候，可以从 RDB 文件中恢复数据集。 AOF(append only file) 可以记录服务器的所有写操作。在服务器重新启动的时候，会把所有的写操作重新执行一遍，从而实现数据备份。当写操作集过大（比原有的数据集还大），Redis 会重写写操作集。 为什么称为 append only file 呢？AOF 持久化是类似于生成一个关于 Redis 写操作的文件，写操作（增删）总是以追加的方式追加到文件中。 因此，在 RDB 持久化的时候可以将 RDB 保存到磁盘中，也可以保存到内存中，当然保存到内存中就不是持久化了。 RDB 持久化的运作机制(快照模式) Redis 支持两种方式进行 RDB 持久化：当前进程执行和后台执行（BGSAVE）。RDB BGSAVE 策略是 fork 出一个子进程，把内存中的数据集整个 dump 到硬盘上。两个场景举例： Redis 服务器初始化过程中，设定了定时事件，每隔一段时间就会触发持久化操作； 进入定时事件处理程序中，就会 fork 产生子进程执行持久化操作。 Redis 服务器预设了 save 指令，客户端可要求服务器进程中断服务，执行持久化操作。 这里主要展开的内容是 RDB 持久化操作的写文件过程，读过程和写过程相反。子进程的产生发生在 rdbSaveBackground() 中，真正的 RDB 持久化操作是在 rdbSave()，想要直接进行 RDB 持久化，调用 rdbSave() 即可。 RDB 的优点 RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中。 RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。RDB 的缺点 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。 RDB 快照在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。 你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。 你也可以通过调用 SAVE 或者 BGSAVE ， 手动让 Redis 进行数据集保存操作。 比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集： save 60 1000这种持久化方式被称为快照（snapshot）。 快照的运作方式当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作： Redis 调用 fork() ，同时拥有父进程和子进程。子进程将数据集写入到一个临时 RDB 文件中。当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。 AOF 持久化运作机制(日志模式)和 redis RDB 持久化运作机制不同，redis AOF 有后台执行和边服务边备份两种方式。 1）AOF 后台执行的方式和 RDB 有类似的地方，fork 一个子进程，主进程仍进行服务，子进程执行AOF 持久化，数据被dump 到磁盘上。与 RDB 不同的是，后台子进程持久化过程中，主进程会记录期间的所有数据变更（主进程还在服务），并存储在 server.aof_rewrite_buf_blocks 中；后台子进程结束后，Redis 更新缓存追加到 AOF 文件中，是 RDB 持久化所不具备的。 来说说更新缓存这个东西。Redis 服务器产生数据变更的时候，譬如 set name Jhon，不仅仅会修改内存数据集，也会记录此更新（修改）操作，记录的方式就是上面所说的数据组织方式。 更新缓存可以存储在 server.aof_buf 中，你可以把它理解为一个小型临时中转站，所有累积的更新缓存都会先放入这里，它会在特定时机写入文件或者插入到server.aof_-rewrite_buf_blocks 下链表（下面会详述）；server.aof_buf 中的数据在 propagrate() 添加，在涉及数据更新的地方都会调用propagrate() 以累积变更。更新缓存也可以存储在 server.aof_-rewrite_buf_blocks，这是一个元素类型为 struct aofrwblock 的链表，你可以把它理解为一个仓库，当后台有AOF 子进程的时候，会将累积的更新缓存（在 server.aof_buf 中）插入到链表中，而当 AOF 子进程结束，它会被整个写入到文件。两者是有关联的。 这里的意图即是不用每次出现数据变更的时候都触发一个写操作，可以将写操作先缓存到内存中，待到合适的时机写入到磁盘，如此避免频繁的写操作。当然，完全可以实现让数据变更及时更新到磁盘中。两种做法的好坏就是一种博弈了。 Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。 AOF 的优点 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。 AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。AOF 的缺点 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。 AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识消息队列]]></title>
    <url>%2F2018%2F03%2F25%2Fmessages%2Fmessage-simple%2F</url>
    <content type="text"><![CDATA[参考https://tech.meituan.com/mq-design.html 消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发的Notify、MetaQ、RocketMQ等。 何时需要消息队列当你需要使用消息队列时，首先需要考虑它的必要性。可以使用mq的场景有很多，最常用的几种，是做业务解耦/最终一致性/广播/错峰流控等。反之，如果需要强一致性，关注业务逻辑的处理结果，则RPC显得更为合适。 解耦解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。比如在美团旅游，我们有一个产品中心，产品中心上游对接的是主站、移动后台、旅游供应链等各个数据源；下游对接的是筛选系统、API系统等展示系统。当上游的数据发生变更的时候，如果不使用消息系统，势必要调用我们的接口来更新数据，就特别依赖产品中心接口的稳定性和处理能力。但其实，作为旅游的产品中心，也许只有对于旅游自建供应链，产品中心更新成功才是他们关心的事情。而对于团购等外部系统，产品中心更新成功也好、失败也罢，并不是他们的职责所在。他们只需要保证在信息变更的时候通知到我们就好了。而我们的下游，可能有更新索引、刷新缓存等一系列需求。对于产品中心来说，这也不是我们的职责所在。说白了，如果他们定时来拉取数据，也能保证数据的更新，只是实时性没有那么强。但使用接口方式去更新他们的数据，显然对于产品中心来说太过于“重量级”了，只需要发布一个产品ID变更的通知，由下游系统来处理，可能更为合理。再举一个例子，对于我们的订单系统，订单最终支付成功之后可能需要给用户发送短信积分什么的，但其实这已经不是我们系统的核心流程了。如果外部系统速度偏慢（比如短信网关速度不好），那么主流程的时间会加长很多，用户肯定不希望点击支付过好几分钟才看到结果。那么我们只需要通知短信系统“我们支付成功了”，不一定非要等待它处理完成。 最终一致性最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。当然有个时间限制，理论上越快越好，但实际上在各种异常的情况下，可能会有一定延迟达到最终一致状态，但最后两个系统的状态是一样的。业界有一些为“最终一致性”而生的消息队列，如Notify（阿里）、QMQ（去哪儿）等，其设计初衷，就是为了交易系统中的高可靠通知。以一个银行的转账过程来理解最终一致性，转账的需求很简单，如果A系统扣钱成功，则B系统加钱一定成功。反之则一起回滚，像什么都没发生一样。然而，这个过程中存在很多可能的意外： A扣钱成功，调用B加钱接口失败。A扣钱成功，调用B加钱接口虽然成功，但获取最终结果时网络异常引起超时。A扣钱成功，B加钱失败，A想回滚扣的钱，但A机器down机。可见，想把这件看似简单的事真正做成，真的不那么容易。所有跨VM的一致性问题，从技术的角度讲通用的解决方案是： 强一致性，分布式事务，但落地太难且成本太高，后文会具体提到。 最终一致性，主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。回到刚才的例子，系统在A扣钱成功的情况下，把要给B“通知”这件事记录在库里（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止。整个这个模型依然可以基于RPC来做，但可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。具体来说，本地事务维护业务变化和通知消息，一起落地（失败则一起回滚），然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。另外，所有不保证100%不丢消息的消息队列，理论上无法实现最终一致性。好吧，应该说理论上的100%，排除系统严重故障和bug。像Kafka一类的设计，在设计层面上就有丢消息的可能（比如定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确。 广播消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。比如本文开始提到的产品中心发布产品变更的消息，以及景点库很多去重更新的消息，可能“关心”方有很多个，但产品中心和景点库只需要发布变更消息即可，谁关心谁接入。 错峰与流控试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端。这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。 总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。]]></content>
  </entry>
  <entry>
    <title><![CDATA[阿里消息队列服务]]></title>
    <url>%2F2018%2F03%2F25%2Fmessages%2F2018-03-25-ali-message%2F</url>
    <content type="text"><![CDATA[顺序消息全局顺序对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景： 性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景。 举例说明： 【例一】证券处理中，以人民币兑换美元为 Topic，在价格相同的情况下，先出价者优先处理，则可以通过全局顺序的方式按照 FIFO 的方式进行发布和订阅。 分区顺序对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景： 性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。 举例说明： 【例一】用户注册需要发送发验证码，以用户 ID 作为 sharding key， 那么同一个用户发送的消息都会按照先后顺序来发布和订阅。 【例二】电商的订单创建，以订单 ID 作为 sharding key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照先后顺序来发布和订阅。 阿里巴巴集团内部电商系统均使用此种分区顺序消息，既保证业务的顺序，同时又能保证业务的高性能。 全局顺序与分区顺序对比在控制台创建顺序消息使用的 Topic，各种类型 Topic 对比如下。 消息类型对比 Topic 类型 支持事务消息 支持定时消息 性能 无序消息 是 是 最高 分区顺序 否 否 高 全局顺序 否 否 一般 发送方式对比 消息类型 支持可靠同步发送 支持可靠异步发送 支持 Oneway 发送 无序消息 是 是 是 分区顺序 是 否 否 全局顺序 是 否 否]]></content>
  </entry>
  <entry>
    <title><![CDATA[netty线程模型]]></title>
    <url>%2F2018%2F03%2F25%2Fjava_netty%2Fnetty_thread_model%2F</url>
    <content type="text"><![CDATA[Proactor和Reactor是两种经典的多路复用I/O模型，主要用于在高并发、高吞吐量的环境中进行I/O处理。]]></content>
  </entry>
  <entry>
    <title><![CDATA[atom设置本地代理]]></title>
    <url>%2F2018%2F03%2F24%2Ftools%2F2018-03-24-atom-proxy-set%2F</url>
    <content type="text"><![CDATA[atom设置proxy12apm config set strict-ssl falseapm config set https-proxy http://localhost:1087]]></content>
      <tags>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化mysql排序]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimizie-sql-order-by%2F</url>
    <content type="text"><![CDATA[mysql排序方式:常规排序 a 从表t1中获取满足WHERE条件的记录 b 对于每条记录，将记录的主键+排序键(id,col2)取出放入sort buffer c 如果sort buffer可以存放所有满足条件的(id,col2)对，则进行排序；否则sort buffer满后，进行排序并固化到临时文件中。(排序算法采用的是快速排序算法) d 若排序中产生了临时文件，需要利用归并排序算法，保证临时文件中记录是有序的 e 循环执行上述过程，直到所有满足条件的记录全部参与排序 f 扫描排好序的(id,col2)对，并利用id去捞取SELECT需要返回的列(col1,col2,col3) g 将获取的结果集返回给用户。 从上述流程来看，是否使用文件排序主要看sort buffer是否能容下需要排序的(id,col2)对，这个buffer的大小由sort_buffer_size参数控制。此外一次排序需要两次IO，一次是捞(id,col2),第二次是捞(col1,col2,col3)，由于返回的结果集是按col2排序，因此id是乱序的，通过乱序的id去捞(col1,col2,col3)时会产生大量的随机IO。对于第二次MySQL本身一个优化，即在捞之前首先将id排序，并放入缓冲区，这个缓存区大小由参数read_rnd_buffer_size控制，然后有序去捞记录，将随机IO转为顺序IO。 优化排序常规排序方式除了排序本身，还需要额外两次IO。优化的排序方式相对于常规排序，减少了第二次IO。主要区别在于，放入sort buffer不是(id,col2),而是(col1,col2,col3)。由于sort buffer中包含了查询需要的所有字段，因此排序完成后可以直接返回，无需二次捞数据。这种方式的代价在于，同样大小的sort buffer，能存放的(col1,col2,col3)数目要小于(id,col2)，如果sort buffer不够大，可能导致需要写临时文件，造成额外的IO。当然MySQL提供了参数max_length_for_sort_data，只有当排序元组小于max_length_for_sort_data时，才能利用优化排序方式，否则只能用常规排序方式。 优先队列排序为了得到最终的排序结果，无论怎样，我们都需要将所有满足条件的记录进行排序才能返回。那么相对于优化排序方式，是否还有优化空间呢？5.6版本针对Order by limit M，N语句，在空间层面做了优化，加入了一种新的排序方式:优先队列，这种方式采用堆排序实现。堆排序算法特征正好可以解limit M，N 这类排序的问题，虽然仍然需要所有元素参与排序，但是只需要M+N个元组的sort buffer空间即可，对于M，N很小的场景，基本不会因为sort buffer不够而导致需要临时文件进行归并排序的问题。对于升序，采用大顶堆，最终堆中的元素组成了最小的N个元素，对于降序，采用小顶堆，最终堆中的元素组成了最大的N的元素。 对比页数比较大的情况低效率: 高效率: 针对limit 优化有很多种方式1 前端加缓存、搜索，减少落到库的查询操作。比如海量商品可以放到搜索里面，使用瀑布流的方式展现数据，很多电商网站采用了这种方式。2 优化SQL 访问数据的方式，直接快速定位到要访问的数据行。3 使用书签方式 ，记录上次查询最新/大的id值，向后追溯 M行记录。 快速定位对于第二种方式 我们推荐使用”延迟关联”的方法来优化排序操作，何谓”延迟关联” ：通过使用覆盖索引查询返回需要的主键,再根据主键关联原表获得需要的数据。3.1 延迟关联123root@xxx 12:33:48&gt;explain SELECT id, cu_id, name, info, biz_type, gmt_create, gmt_modified,start_time, end_time, market_type, back_leaf_category,item_status,picuture_url FROM relation where biz_type =&apos;0&apos; AND end_time &gt;=&apos;2014-05-29&apos; ORDER BY id asc LIMIT 149420 ,20;explain SELECT a.* FROM relation a, (select id from relation where biz_type =&apos;0&apos; AND end_time &gt;=&apos;2014-05-29&apos; ORDER BY id asc LIMIT 149420 ,20 ) b where a.id=b.id; 书签方式首先要获取复合条件的记录的最大 id和最小id(默认id是主键)1select max(id) as maxid ,min(id) as minid from t where kid=2333 and type=1; 其次 根据id 大于最小值或者小于最大值 进行遍历。 123select xx,xx from t where kid=2333 and type=1 and id &gt;=min_id order by id asc limit 100;select xx,xx from t where kid=2333 and type=1 and id &lt;=max_id order by id desc limit 100; 使用延迟关联查询数据510ms ，使用基于书签模式的解决方法减少到10ms以内 绝对是一个质的飞跃。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql-killer]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fsql-killer%2F</url>
    <content type="text"><![CDATA[每个oltp数据库实例上设置一个sql-killer进程用于kill掉执行时间超过一定阈值测sql,并发邮件报警]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软删除唯一索引解决]]></title>
    <url>%2F2018%2F03%2F24%2Fegenie_bugfix%2Floft-delete-unquie-key%2F</url>
    <content type="text"><![CDATA[软件中使用软删除is_usable=1改为0来代表删除，但是遇到唯一索引时，例如：username+is_usable的唯一索引第二次删除则会失败，解决办法，将is_usable 改为其他不重复的数字及可]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-cap]]></title>
    <url>%2F2018%2F03%2F23%2F%E5%88%86%E5%B8%83%E5%BC%8F%2Fstudy-cap%2F</url>
    <content type="text"><![CDATA[CAP（Consistency一致性、Availability可用性、Partition-tolerance分区可容忍性）理论普遍被看成是大数据技术的理论基础。同时，凭据该理论，业界有一种极度流行、极度“专业”的认识，那就是：关系型数据库设计选择了C（一致性）与A（可用性），NoSQL数据库设计则差别。其中，HBase选择了C（一致性）与P（分区可容忍性），Cassandra选择了A（可用性）与P（分区可容忍性）。 Consistency一致性：你的客户再次来电时总能查到他们刚来电更新的信息，不论相隔多短 Availability可用性：不论你和你妻子谁来工作，记忆公司总能接听来电，处理客户请求 Partition-tolerance分区可容忍性：即便你和你妻子失联，记忆公司依然能正常运转 ● 一致性(C): 在分布式系统中的所有数据备份，在同一时刻是否同样的值。(等同于所有节点访问同一份最新的数据副本) ● 可用性(A): 在集群中一部分节点故障后，集群整体是否还能响应客户端 的读写请求。(对数据更新具备高可用性) ● 分区容忍性(P): 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前 操作在 C 和 A 之间做出选择。(分区状态可以理解为部分机器不连通了，比如机器挂了，繁忙失去响应，单机房故障等) Partition 字面意思是网络分区，即因网络因素将系统分隔为多个单独的部 分，有人可能会说，网络分区的情况发生概率非常小啊，是不是不用考虑 P， 保证 CA 就好。要理解 P，我们看回 CAP 证明中 P 的定义: In order to model partition tolerance, the network will be allowed to lose arbitrarily many messages sent from one node to another。 网络分区的情况符合该定义，网络丢包的情况也符合以上定义，另外节点宕 机，其他节点发往宕机节点的包也将丢失，这种情况同样符合定义。现实情况 下我们面对的是一个不可靠的网络、有一定概率宕机的设备，这两个因素都会 导致 Partition，因而分布式系统实现中 P 是一个必须项，而不是可选项。 解读CP without A:如果不要求 A(可用)，相当于每个请求都需要在 Server 之间 强一致，而 P(分区)会导致同步时间无限延长，如此 CP 也是可以保证的。很 多传统的数据库分布式事务都属于这种模式。 AP wihtout C:要高可用并允许分区，则需放弃一致性。一旦分区发生，节点 之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的 NoSQL 都属于此类。 伪命题“三选二”是一个伪命题 不是为了 P(分区容忍性)，要在 A 和 C 之间选择一个。分区很少出现，CAP 在大多数时候允许完美的 C 和 A。但当分区存在或可感知其影响的情况下，就要预备一种策略去探知分区并显式处理其影响。 应用 Feature Consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https支持（弱） — spring cloud集成 已支持 已支持 已支持 已支持 特性 HBase Cassandra 语言 Java Java 出发点 BigTable BigTable and Dynamo License Apache Apache Protocol HTTP/REST (also Thrift) Custom, binary (Thrift) 数据分布 表划分为多个region存在不同region server上 改进的一致性哈希（虚拟节点） 存储目标 大文件 小文件 一致性 强一致性 最终一致性，Quorum NRW策略 架构 master/slave p2p 高可用性 NameNode是HDFS的单点故障点 P2P和去中心化设计，不会出现单点故障 伸缩性 Region Server扩容，通过将自身发布到Master，Master均匀分布Region 扩容需在Hash Ring上多个节点间调整数据分布 读写性能 数据读写定位可能要通过最多6次的网络RPC，性能较低。 数据读写定位非常快 数据冲突处理 乐观并发控制（optimistic concurrency control） 向量时钟 临时故障处理 Region Server宕机，重做HLog 数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。 永久故障恢复 Region Server恢复，master重新给其分配region Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性 成员通信及错误检测 Zookeeper 基于Gossip CAP 1，强一致性，0数据丢失。2，可用性低。3，扩容方便。 1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。 cap 有这样两种情况：一种情况是要求节点A、B、C的三份数据完全一致后返回。也就是说，这时从任何一个网络节点读取的数据都是一样的，这就是所谓的强一致性读。很明显，这时数据读取的Latency要高一些（由于要等数据在网络中的复制），同时A、B、C三个节点中任何一个宕机，都会导致数据不行用。也就是说，要保证强一致性，网络中的副本越多，数据的可用性就越差； 另一种情况是，允许读操作立刻返回，容忍B节点的读取与A节点的读取不一致的情况发生。这样一来，可用性显然获得了提高，网络中的副本也可以多一些，唯一得不到保证的是数据一致性。当然，对写操作同样也有多个节点一致性的情况，在此不再赘述。 cap 分布式系统分区容忍肯定是要保证的，因为总会有网络延迟，网络波动导致每个节点互相有短暂或长时间的通讯不通。所以我们在这个基础上，如果我们解决了一致性问题，也就是我们在网络波动和延迟的时候也让每个节点的数据是一样的，保证同时从任意节点取到的数据是一样的。 那么我们就得舍弃可用性，也就是说我们在网络波动或者延迟的时候让整个分布式系统不可用，等到数据都同步完了，每个节点的数据都一样了，这时候我们在让分布式系统可用。这就是舍弃了可用性。 那什么是舍弃一致性呢？就是在有网络延迟的时候，我整个的分布式系统还对外提供服务，这时就有可能短暂的出现获取的数据不是一致的。这就是舍弃了一致性。所以一般来说我们都是保证可用性，虽然有短暂的数据不一致，但我们只要最终保证了一致性在有些时候也是可以满足需要的。 解读http://kongchen.github.io/how-cap-defines-avaiability/C容易理解，所有节点上的数据都一样。P是说一旦集群因为内部通信故障发生分裂，集群还能正常运转。 关键是这个A。 说白了就是，CAP里的A指的是，只要是活着的节点能返回响应，那么就认为它是availability的。 用汽车来做个比喻：汽车一切良好，故障灯一个都不亮，能开能刹，这是我们理解的传统的Available。只要是出了任何问题，例如车胎爆了，发动机坏了，或者是没油开不动了，这都已经是不可用了。 CAP理论里，车不能开不要紧，只要是这车车门还能打开，那就是Available的：车胎破了能从胎压监测里看到，发动机坏了打火打不着，没油了油表灯会亮……这都是车返回的response，只要是有response，那么就是”可用的“。 理解了A的真正含义以后再来看CAP。 只满足CA的系统根据P的定义： 一旦集群因为内部通信故障发生分裂，集群还能正常运转。 舍弃P意味着一旦集群发生分裂，整个集群都将无法运转。这是符合A的，因为这是的节点是fail的，不需要给任何响应。单机服务器显然是CA的，只要结点活着，那自然是C+A。而结点一旦挂了，整个集群也就没了，符合舍弃P的选择。 只满足CP的系统一旦集群内部因为内部通信故障发生分裂（假设分裂成两部分），为了满足P，集群需要提供服务。而为了满足C，只能保留其中一部分提供服务，让另一部分整体退役。 只满足AP的系统整个最容易理解，一旦集群内部因为内部通信故障发生分裂（假设分裂成两部分），为了满足P，而又不需要满足C，那么可以让分裂出来的两部分都提供服务，因为暂时数据不一致没关系。 CAP 的意义在系统架构时，应该根据具体的业务场景，来权衡 CAP。比如，对于大多数互联网应用来说（如门户网站），因为机器数量庞大，部署节点分散，网络故障是常态，可用性是必须需要保证的，所以只有舍弃一致性来保证服务的 AP。而对于银行等，需要确保一致性的场景，通常会权衡 CA 和 CP 模型，CA 模型网络故障时完全不可用，CP 模型具备部分可用性。 参考https://yq.aliyun.com/articles/552548?spm=a2c4e.11153959.teamhomeleft.38.63cb356fpQ5C54]]></content>
  </entry>
  <entry>
    <title><![CDATA[data-warehouse-build]]></title>
    <url>%2F2018%2F03%2F21%2Fdata_warehouse%2Fdata-warehouse-build%2F</url>
    <content type="text"><![CDATA[https://tech.meituan.com/tag/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93 https://tech.meituan.com/mtdp_travel_yydp_present.html 架构图 领域内常见的建模方法① 3NF模型 3NF模型（又叫“范式模型”）是数据仓库之父Inmon提出的，它用实体加关系的数据模型描述业务架构，在范式理论上符合3NF，是站在全局角度面向主题的抽象。它更多的是面向数据的一致性治理。 3NF模型最基本的要素是实体、属性和关系： 实体：相同特征和性质的属性抽象，用抽象的实体名和属性名集合共同刻画的逻辑实体；关系：实体之间的关系；属性：实体的某种特性，一般实体具有多个属性。② 维度模型 维度模型是Kimball提出的。维度模型多为分析和决策提供服务，因此它重点解决快速完成分析，同时提供大规模复杂查询的响应性能（预聚合），更直接地面向业务。例如熟知的星形模型，以及特殊场景的雪花模型。 维度建模最基本的要素是事实和维度： 事实表：一般由两部分组成，纬度和指标，通常理解为“某人在某时间某地点通过某手段做了什么事情”的事实记录，它体现了业务流程的核心内容；维度表：看待事实的角度，用以描述和还原事实发生的场景，比如通过地址、时间等维度还原业务场景。③ DV模型（DataVault） DataVault是Dan Linstedt发起的，是一种介于3NF和维度建模之间的建模方法。它的设计主要是满足灵活性、可扩展性、一致性和对需求的适应性。它强调建立一个可审计的基础数据层，主要包括Hub（核心实体）、Link（关系）、Satellite（实体属性）三个要素。 ④ Anchor模型 Anchor模型由Lars. Rönnbäck提出，是DataVault模型的进一步范式化处理，核心思想是只添加、不修改的可扩展模型，Anchor模型构建的表极窄，类似于K-V结构化模型。它主要包括Anchors（实体且只有主键），Atributes（属性），Ties（关系），Knots（公用枚举属性)）。Anchor是应用中比较少的建模方法，只有传统企业和少数几家互联网公司有应用，例如：蚂蜂窝等。 运营专题数据如何构建随着促销系统不断发展，平台趋于稳定，再结合各活动类型，及对需求的整理和进一步产品化，选择了3NF+维度建模为基础的模型方法论，对数据进行合理划分和整合，构建了运营专题数据体系。 ① 数据规范制定 数据规范的制定也是指标字典和服务层规则引擎抽象的基础。首先同业务达成共识，制定数据一致性标准，统一口径。同时将核心指标和个性化指标进行抽象，抽取统一规范定义，例如：月初到月末的整体交易类GMV和补贴类GMV，其原子指标是GMV，其它要素都属于指标的修饰。 ② 数仓模型架构 将数据分为ODS层、BAS层、FACT层、TOPIC层。 ODS层主要功能 从分布式消息队列中消费Binlog和Click-log，并对埋点数据进行清洗和业务库数据还原，并根据需要增量或全量同步到Hive，同时积累历史数据并保存。 BAS层主要功能 采用3NF建模方法，对整体业务进行概念抽象及适当冗余，在保证数据一致的同时将同属性实体归纳整合到同一逻辑域。BAS层主要是为了减少数据的不一致，减少存储空间，响应业务系统的变化，避免更新异常。 FACT层主要功能 采用维度建模方法，根据活动特点及事实场景，对代金券、现金券、促销等的事件进一步整合。经过对维度的预处理，在使用信息的时候，不但减少时间成本、提高数据的提取效率，又为用户在Ad-Hoc平台查询提供很好的支撑，同时它成为了上层数据应用的关键出口。 TOPIC层主要功能 该层建设不是必须的，是针对业务中个性化诉求，根据需要建设专题数据。服务小范围业务群体和用户，用来支撑核心业务指标外的某一块个性化指标和应用。 如图所示，数仓模型整体架构图。通过构建运营专题的底层数据，针对数据一致性等问题，在数仓层面上得到了很好的解决，同时在数据提取效率上有很大的提升。数仓建设为接下来的业务支撑打好了充分的基础。 多维预计算层预计算层是连接数据和应用之间的管道，是应用层垂直模块的专项支持。它是在Fact层数据之上的预聚合，强依赖于数仓模型中事实和维度的构建以及预关联。预计算采用Kylin引擎构建Cube聚合组，来解决取数门槛和数据处理耗时等问题，同是提供多维分析的能力，不但提供了新的Ad-Hoc(Query Engine)平台，在提高查询响应的同时，又能为产品带来更流畅的交互，增强用户体验。例如：创建一个交易数据cube，它包含日期（datakey）、用户（userid）、付款方式（paytype）、购买城市（city）。为满足不同消费方式在不同城市的应用情况和查看用户在不同城市的消费行为，建立以下两个聚合组，包含的维度和方式如图所示： 中台服务层数据预计算之后，需要分别对PC和移动端提供计算和装载，并且要针对不同端的特定模块做特定的开发，为了应对多变的业务逻辑，以及未来的可扩展能力，需要提供可插拔的、统一的服务层，该层主要可以解决如下问题： 服务与预计算数据同步，数据模型的修改只影响到预计算层，同时服务层还可以完全感知预计算数据的变化，不需要对服务做开发调整，实现数据变更的同步响应； 服务与端解耦，针对不同端产品提供统一数据服务，避免重复开发，同时产品的迭代升级与服务层隔离，应对多变的业务发展和增长； 服务扩展能力增强，支持服务的横向扩展，不影响正常业务的同时提高服务能力，同时在该层实现可抽象通用操作以及规范管理。 总体 整个服务由独立的Web应用端发起请求，通过权限验证后对中台发起调用，然后读取配置中心的配置，由计算引擎对数据进行并行计算，同时规则引擎按业务线和指标修饰词等生产衍生指标，然后将引擎完成的数据按周期进行快照，存入备忘录，同时关联指标字典将数据与文案返回前台，最后按功能再对数据做可视化处理。下面分别对服务中交互的几个模块做简单的介绍。]]></content>
  </entry>
  <entry>
    <title><![CDATA[data-warehouse-layering]]></title>
    <url>%2F2018%2F03%2F21%2Fdata_warehouse%2Fdata-warehouse-layering%2F</url>
    <content type="text"><![CDATA[传统分层 阿里数据分层https://oss-cn-hangzhou.aliyuncs.com/yqfiles/ceea30ef3e4db4ec980c5a3fb8dee73d.pdf?spm=a2c4e.11153959.blogcont69316.176.367f2caePvjO9h&amp;file=ceea30ef3e4db4ec980c5a3fb8dee73d.pdf 基础层 数据中间层 数据集市层 流式数据集 美团分层https://tech.meituan.com/traffic_data_product.html A层（也称ODS层），包含美团App的大搜日志、页面流量日志、模块事件日志以及描述埋点内容的信息日志。公共维度，其中重要的流量入口维度、页面维度都是从具有统一规则的埋点标记日志中，抽象形成的维度。B3层（酒旅基础明细层），通过对A层的抽取转换，初步形成只含酒旅业务所需的基础流量日志。B2层（酒旅多维模型层），对已有的基础层数据和公共维度的轻加工，扩展出业务常用的维度信息，例如页面类型、商家门店、产品、城市，以及平台等。B1层（主题宽表层），主题宽表层主要是对多维模型层的聚合计算，包括多个复杂业务口径的输出、少数维度的深加工，以及来源入口的增加，保证数据的一致性。App层，该层是针对各自的流量应用（流量罗盘）设计的，满足该产品应用所需且具有一定扩展容量的聚合模型结构。视图层，作为App层与Kylin cube的缓冲层，依靠其本身视图的特性，能够很好地解决顶层扩展、查询延时、资源分配，以及表意理解等多个问题。cube层，每个Kylin cube是由单个视图与多个维度的雪花组合，输出计算数据给罗盘后台服务。后台服务层，包含查询引擎和配置模块两部分的内容。处理前端的查询请求。权限层，对各个业务线分平台和终端控制权限。前端展示层，与用户交互并提交用户的查询请求。 数据仓库分层的原因1通过数据预处理提高效率，因为预处理，所以会存在冗余数据 2如果不分层而业务系统的业务规则发生变化，就会影响整个数据清洗过程，工作量巨大 3通过分层管理来实现分步完成工作，这样每一层的处理逻辑就简单了 标准的数据仓库分层： ods（临时存储层） pdw（数据仓库层） mid（数据集市层） 轻度汇总(宽表几百个字段) app（应用层）OLAP/OLAM/app 1234567中间层是数据仓库最重要的一层。直接决定了数据仓库的性能。一般的做法是：1）数据汇总。将底层数据按维度进行小颗粒度汇总2）信息聚合。将多张表的信息聚合在一个表中。这样的好处，是避免使用表关联，提高查询性能。 ods：历史存储层，它和源系统数据是同构的，而且这一层数据粒度是最细的，这层的表分为两种，一种是存储当前需要加载的数据，一种是用于存储处理完后的数据。 pdw：数据仓库层，它的数据是干净的数据，是一致的准确的，也就是清洗后的数据，它的数据一般都遵循数据库第三范式，数据粒度和ods的粒度相同，它会保存bi系统中所有历史数据 mid：数据集市层，它是面向主题组织数据的，通常是星状和雪花状数据，从数据粒度将，它是轻度汇总级别的数据，已经不存在明细的数据了，从广度来说，它包含了所有业务数量。从分析角度讲，大概就是近几年 app：应用层，数据粒度高度汇总，倒不一定涵盖所有业务数据，只是mid层数据的一个子集。 数据仓库的目的是构建面向分析的集成化数据环境，为企业提供决策支持。数据仓库的context也可以理解为：数据源，数据仓库，数据应用 数据仓库可以理解为中间集成化数据管理的一个平台 etl（抽取extra，转化transfer，装载load）是数据仓库的流水线，也可以认为是数据仓库的血液。 数据仓库的存储并不需要存储所有原始数据，因为比如你存储冗长的文本数据完全没必要，但需要存储细节数据，因为需求是多变的，而且数据仓库是导入数据必须经过整理和转换使它面向主题，因为前台数据库的数据是基于oltp操作组织优化的，这些可能不适合做分析，面向主题的组织形式才有利于分析。 多维数据模型就是说可以多维度交叉查询和细分，应用一般都是基于联机分析处理（online analytical process OLAP），面向特定需求群体的数据集市会基于多位数据模型构建 而报表展示就是将聚合数据和多维分析数据展示到报表，提供简单和直观的数据。 元数据，也叫解释性数据，或者数据字典，会记录数据仓库中模型的定义，各层级之间的映射关系，监控数据仓库的数据状态和etl的任务运行状态。一般通过元数据资料库来统一存储和管理元数据。 概念数据来源层日志或者关系型数据库，并通过Flume、Sqoop、Kettle等etl工具导入到HDFS，并映射到HIVE的数据仓库表中。 事实表是数据仓库结构中的中央表，它包含联系事实与维度表的数字度量值和键。事实数据表包含描述业务（例如产品销售）内特定事件的数据。 维度表是维度属性的集合。是分析问题的一个窗口。是人们观察数据的特定角度，是考虑问题时的一类属性，属性的集合构成一个维。数据库结构中的星型结构，该结构在位于结构中心的单个事实数据表中维护数据，其它维度数据存储在维度表中。每个维度表与事实数据表直接相关，且通常通过一个键联接到事实数据表中。星型架构是数据仓库比较流向的一种架构 主题表：主题（Subject）是在较高层次上将企业信息系统中的数据进行综合、归类和分析利用的一个抽象概念，每一个主题基本对应一个宏观的分析领域。在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。例如“销售分析”就是一个分析领域，因此这个数据仓库应用的主题就是“销售分析”。 面向主题的数据组织方式，就是在较高层次上对分析对象数据的一个完整并且一致的描述，能刻画各个分析对象所涉及的企业各项数据，以及数据之间的联系。所谓较高层次是相对面向应用的数据组织方式而言的，是指按照主题进行数据组织的方式具有更高的数据抽象级别。与传统数据库面向应用进行数据组织的特点相对应，数据仓库中的数据是面向主题进行组织的。例如，一个生产企业的数据仓库所组织的主题可能有产品订货分析和货物发运分析等。而按应用来组织则可能为财务子系统、销售子系统、供应子系统、人力资源子系统和生产调度子系统。 汇总数据层(周报、月报、季报、年报)聚合原子粒度事实表及维度表，为满足固定分析需求，以提高查询性能为目的，形成的高粒度表，如周报、月报、季报、年报等。 应用层：为应用层，这层数据是完全为了满足具体的分析需求而构建的数据，也是星形结构的数据。应用层为前端应用的展现提现数据，可以为关系型数据库组成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[catch异常但是仍然回滚]]></title>
    <url>%2F2018%2F03%2F21%2Fegenie_bugfix%2Fbugfix-exception-try-catch%2F</url>
    <content type="text"><![CDATA[上代码方式1:1234567891011public void insert() &#123; long insuranceId = IdGenerator.generateId(&quot;insurance&quot;); String sql = String.format(&quot;insert into a (id) values(%s)&quot;, insuranceId); int update = jdbcTemplate.update(sql); try &#123; hrow new RuntimeException(); &#125; catch (RuntimeException e) &#123; e.printStackTrace(); &#125;&#125; 方式2:1234567891011@Service@Transactional(readOnly = false)public class ExService2 &#123; @Autowired JdbcTemplate jdbcTemplate; public void ex() &#123; throw new RuntimeException(); &#125;&#125; 1234567891011public void insert() &#123; long insuranceId = IdGenerator.generateId(&quot;insurance&quot;); String sql = String.format(&quot;insert into a (id) values(%s)&quot;, insuranceId); int update = jdbcTemplate.update(sql);try &#123; exService2.ex();// throw new RuntimeException(); &#125; catch (RuntimeException e) &#123; e.printStackTrace(); &#125;&#125; 测试结果看似同样的逻辑,但是对于事务的回滚影响却截然不同 方式1:未回滚+一个异常日志方式2:回滚:两个异常日志+Transaction rolled back because it has been marked as rollback-only 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505120861 [http-nio-9991-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only] with root causeorg.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:724) at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:485) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:291) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) at cn.egenie.admin.domain.controller.ExService$$EnhancerBySpringCGLIB$$c69282d3.insert(&lt;generated&gt;) at cn.egenie.admin.domain.controller.ExceptionController.info(ExceptionController.java:25) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:832) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:743) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:961) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:895) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:967) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:858) at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:843) at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:292) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:522) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1095) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:672) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1502) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1458) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) 原理 spring 具备多种事务传播机制，最常用的是REQUIRED，即如果不存在事务，则新建一个事务；如果存在事务，则加入现存的事务中。` public void A() { querySomething(…)； try { B() } catch () { } saveSomethinf()；} public void B() { throw Exception()}`此时B会和A存在一个事务中。如果B抛出异常没有捕获，即使在A中捕获并处理，仍会发生异常：Transaction rolled back because it has been marked as rollback-only 因为spring会在A捕获异常之前提前捕获到异常，并将当前事务设置为rollback-only，而A觉得对异常进行了捕获，它仍然继续commit，当TransactionManager发现状态为设置为rollback-only时， 则会抛出UnexpectedRollbackException 相关代码在AbstractPlatformTransactonManager.java中： `public final void commit(TransactionStatus status) throws TransactionException { if (status.isCompleted()) { throw new IllegalTransactionStateException( “Transaction is already completed - do not call commit or rollback more than once per transaction”); } DefaultTransactionStatus defStatus = (DefaultTransactionStatus) status; if (defStatus.isLocalRollbackOnly()) { if (defStatus.isDebug()) { logger.debug(&quot;Transactional code has requested rollback&quot;); } processRollback(defStatus); return; } if (!shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) { if (defStatus.isDebug()) { logger.debug(&quot;Global transaction is marked as rollback-only but transactional code requested commit&quot;); } processRollback(defStatus); // Throw UnexpectedRollbackException only at outermost transaction boundary // or if explicitly asked to. if (status.isNewTransaction() || isFailEarlyOnGlobalRollbackOnly()) { throw new UnexpectedRollbackException( &quot;Transaction rolled back because it has been marked as rollback-only&quot;); } return; } processCommit(defStatus); }`]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql分库分表]]></title>
    <url>%2F2018%2F03%2F21%2Fmysql%2Fstudy-sharding-mysql%2F</url>
    <content type="text"><![CDATA[参考https://tech.meituan.com/dianping_order_db_sharding.htmlhttps://help.aliyun.com/knowledge_list/52171.html?spm=a2c4g.11186623.6.702.CJt75Chttp://shardingjdbc.io/docs_cn/02-guide/sharding/https://github.com/MyCATApache/Mycat-doc/blob/master/%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/mycat%E5%88%86%E7%89%87%E8%A7%84%E5%88%99%20.docx 水平切分切分策略查询切分将ID和库的Mapping关系记录在一个单独的库中。优点：ID和库的Mapping算法可以随意更改。缺点：引入额外的单点。 范围切分比如按照时间区间或ID区间来切分。优点：单表大小可控，天然水平扩展。缺点：无法解决集中写入瓶颈的问题。 3. Hash切分 按照订单号来做hash分散订单数据 均匀分散 如果要查询某用户的所有订单呢？由于是根据订单号来分散数据的。他的订单分散在了多个库、多个表中。总不能去所有的库，所有的表扫描吧。这样效率很低。 取模切分(较多) 要扩容的时候，为了减少迁移的数据量，一般扩容是以倍数的形式增加。比如原来是8个库，扩容的时候，就要增加到16个库，再次扩容，就增加到32个库。这样迁移的数据量，就小很多了。这个问题不算很大问题，毕竟一次扩容，可以保证比较长的时间，而且使用倍数增加的方式，已经减少了数据迁移量。 为了保持性能，每张表的数据量要控制。单表可以维持在一千万-5千万行的数据。1024*一千万。哇，可以表示很多数据了。 一般采用Mod来切分，下面着重讲一下Mod的策略。 数据水平切分后我们希望是一劳永逸或者是易于水平扩展的，所以推荐采用mod 2^n这种一致性Hash。 以统一订单库为例，我们分库分表的方案是32*32的，即通过UserId后四位mod 32分到32个库中，同时再将UserId后四位整除32后 Mod 32将每个库分为32个表，共计分为1024张表。线上部署情况为8个集群(主从)，每个集群4个库。 为什么说这种方式是易于水平扩展的呢？我们分析如下两个场景。 场景一：数据库性能达到瓶颈方法一按照现有规则不变，可以直接扩展到32个数据库集群。 方法二如果32个集群也无法满足需求，那么将分库分表规则调整为(322^n)(32/2^n)，可以达到最多1024个集群。 查询需求的考虑 思路：既然是根据订单号分散订单数据，如果需要知道某个用户所有的订单。只要我能知道了a用户的所有的订单号，那么就可以根据订单号定位到表名称了。 思路：既然是根据用户id来分散订单数据的。那么只要知道了这个订单号是谁的(得到了用户id)，就能知道去哪个库、哪个表查询数据了。 那怎么知道是谁的呢？建立一个索引关系表，暂且叫做订单用户关系索引表order_user_idx。咱们命名为了保持维护性，还是一看能够知道是干嘛用的。 存储的数据包括两项：订单号、用户编号。 这样输入订单号，可以去查询索引关系表，获取到用户编号。 得到了用户编号，问题解决了。订单信息是根据用户编号分库分表的，可以直接定位到x库x表了。 当创建订单的时候，就要把关系插入到表里面去了。保存关系记录时，为了减低用户等待时间，不需要实时，做成异步。加入到消息队列中去操作。 唯一ID方案其他方案 事务支持：我们是将整个订单领域聚合体切分，维度一致，所以对聚合体的事务是支持的。 复杂查询：垂直切分后，就跟join说拜拜了；水平切分后，查询的条件一定要在切分的维度内，比如查询具体某个用户下的各位订单等；禁止不带切分的维度的查询，即使中间件可以支持这种查询，可以在内存中组装，但是这种需求往往不应该在在线库查询，或者可以通过其他方法转换到切分的维度来实现。 场景二：单表容量达到瓶颈（或者1024已经无法满足你） 方法： 假如单表都已突破200G，2001024=200T（按照现有的订单模型算了算，大概一万千亿订单，相信这一天，嗯，指日可待！），没关系，32(32*2^n)，这时分库规则不变，单库里的表再进行裂变，当然，在目前订单这种规则下（用userId后四位 mod）还是有极限的，因为只有四位，所以最多拆8192个表，至于为什么只取后四位，后面会有篇幅讲到。 另外一个维度是通过ShopID进行切分，规则8*8和UserID比较类似，就不再赘述，需要注意的是Shop库我们仅存储了订单主表，用来满足Shop维度的查询。 数据迁移（从单表–切换到分表的过程）数据库拆分一般是业务发展到一定规模后的优化和重构，为了支持业务快速上线，很难一开始就分库分表，垂直拆分还好办，改改数据源就搞定了，一旦开始水平拆分，数据清洗就是个大问题，为此，我们经历了以下几个阶段。 第一阶段数据库双写（事务成功以老模型为准），查询走老模型。每日job数据对账（通过DW），并将差异补平。通过job导历史数据。 第二阶段历史数据导入完毕并且数据对账无误。依然是数据库双写，但是事务成功与否以新模型为准，在线查询切新模型。每日job数据对账，将差异补平。 第三阶段其他场景思考一、b2b平台的订单分卖家和买家的时候，选择什么字段来分库分表呢？上面讨论的情况是，b2c平台。订单的卖家就一个，就是平台自己。b2b平台，上面支持开店，买家和卖家都要能够登陆看到自己的订单。先来看看，分表使用买家id分库分表和根据卖家id分库分表，两种办法出现的问题如果按买家id来分库分表。有卖家的商品，会有n个用户购买，他所有的订单，会分散到多个库多个表中去了，卖家查询自己的所有订单，跨库、跨表扫描，性能低下。 如果按卖家id分库分表。买家会在n个店铺下单。订单就会分散在多个库、多个表中。买家查询自己所有订单，同样要去所有的库、所有的表搜索，性能低下。 所以，无论是按照买家id切分订单表，还是按照卖家id切分订单表。两边都不讨好。 淘宝的做法是拆分买家库和卖家库，也就是两个库：买家库、卖家库。 买家库，按照用户的id来分库分表。卖家库，按照卖家的id来分库分表。 实际上是通过数据冗余解决的：一个订单，在买家库里面有，在卖家库里面也存储了一份。下订单的时候，要写两份数据。先把订单写入买家库里面去，然后通过消息中间件来同步订单数据到卖家库里面去。 买家库的订单a修改了后，要发异步消息，通知到卖家库去，更改状态。 思考二：那可以按订单号来分库分表吗?这样分库分表的话，用户有10个订单，订单不见得都在一个库、一个表里面。查询a用户的所有订单，就会变得麻烦了。尤其是要进行分页展示，分散在不同的表，甚至不同的数据库服务器，也比较耗费性能。 那么订单号里面，最好是要有分库分表信息。淘宝的是在订单号里面添加了卖家id末2位、买家id末2位。这样的好处是干嘛呢？直接定位到具体的库、具体的表去了？ 怎么根据这个呢。因为分库、分表的规则，买家库是按照卖家id末尾2位数分，卖家库是按照卖家id末尾两位分。 所以，只要从订单号里面拿到了这些数字信息，就知道在哪个库，哪个表了。 这种办法，与微信的红包订单号是类似的，末尾三位数包含了库信息、表信息。 按照这样，其实就没必要使用订单号来计算了？ 如果是按照用户id的后4位数取模分散订单数据。那么订单号的生成，可以在后面加上用户id的后4位数。 那么，虽然是按照用户id来对订单表分库分表的。其实可以直接根据订单号，知道这个订单在哪个库哪个表了。 如果是b2b系统，涉及到卖家和买家。那么可以把卖家和买家的id后面4位都加进去。不过是不是订单号太长了？ 思考三、按照订单的时间来分表如何?一月一张表。一年一张表。用户的所有订单，会分散在不同的库、不同的表中。 按照时间分，在切分订单数据的时候，业界用得比较少。 出现如下两个问题： 1、如果需要分页查询某个用户的所有订单数据，就会出现跨库、跨表查询。效率低。 可以做折中：限制只能查一个范围内的订单，比如一次只能查询，一年以内或者一个月以内的订单。 2、某个时间集中写入数据，出现瓶颈。如一个月一张表。这个月的订单量暴涨呢。那么写入新的订单数据都会操作这张表。造成性能低下。影响整个业务系统交易。 真正好的分表方案，尽量将写数据分散到多个表去，达到分流效果，系统的并发能力就提高了。 分库分表需要解决的问题事务问题方案一：使用分布式事务优点：交由数据库管理，简单有效缺点：性能代价高，特别是shard越来越多时方案二：由应用程序和数据库共同控制原理：将一个跨多个数据库的分布式事务分拆成多个仅处 于单个数据库上面的小事务，并通过应用程序来总控 各个小事务。优点：性能上有优势缺点：需要应用程序在事务控制上做灵活设计。如果使用 了spring的事务管理，改动起来会面临一定的困难。 跨节点Join的问题只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 跨节点的count,order by,group by以及聚合函数问题这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 数据迁移，容量规划，扩容等问题来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 事务ID问题跨分片的排序分页分库策略分库数量路由透明使用框架还是自主研发如何选择分片数DRDS 中的水平拆分有两个层次：分库和分表。每个 RDS 实例上默认会创建8个物理分库，每个物理分库上可以创建一个或多个物理分表。分表数通常也被称为分片数。 一般情况下，建议单个物理分表的容量不超过500万行数据。通常可以预估1到2年的数据增长量，用估算出的总数据量除以总的物理分库数，再除以建议的最大数据量500万，即可得出每个物理分库上需要创建的物理分表数： 物理分库上的物理分表数 = 向上取整(估算的总数据量 / (RDS 实例数 * 8) / 5,000,000) 如何选择拆分键拆分键即分库/分表字段，是在水平拆分过程中用于生成拆分规则的数据表字段。DRDS 根据拆分键的值将数据表水平拆分到每个 RDS 实例上的物理分库中。 数据表拆分的首要原则，就是要尽可能找到数据表中的数据在业务逻辑上的主体，并确定大部分（或核心的）数据库操作都是围绕这个主体的数据进行，然后可使用该主体对应的字段作为拆分键，进行分库分表。 业务逻辑上的主体，通常与业务的应用场景相关，下面的一些典型应用场景都有明确的业务逻辑主体，可用于拆分键： 面向用户的互联网应用，都是围绕用户维度来做各种操作，那么业务逻辑主体就是用户，可使用用户对应的字段作为拆分键； 侧重于卖家的电商应用，都是围绕卖家维度来进行各种操作，那么业务逻辑主体就是卖家，可使用卖家对应的字段作为拆分键； 游戏类的应用，是围绕玩家维度来做各种操作，那么业务逻辑主体就是玩家，可使用玩家对应的字段作为拆分键； 车联网方面的应用，则是基于车辆信息进行操作，那么业务逻辑主体就是车辆，可使用车辆对应的字段作为拆分键； 税务类的应用，主要是基于纳税人的信息来开展前台业务，那么业务逻辑主体就是纳税人，可使用纳税人对应的字段作为拆分键。以此类推，其它类型的应用场景，大多也能找到合适的业务逻辑主体作为拆分键的选择。 如果确实找不到合适的业务逻辑主体作为拆分键，那么可以考虑下面的方法来选择拆分键： 根据数据分布和访问的均衡度来考虑拆分键，尽量将数据表中的数据相对均匀地分布在不同的物理分库/分表中，适用于大量分析型查询的应用场景（查询并发度大部分能维持为1）； 按照数字（字符串）类型与时间类型字段相结合作为拆分键，进行分库和分表，适用于日志检索类的应用场景。 http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/pic/29659/cn_zh/1497859380824/DRDS_overview.png]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-nginx-statistics]]></title>
    <url>%2F2018%2F03%2F20%2F%E8%BF%90%E7%BB%B4%2Fstudy-nginx-statistics%2F</url>
    <content type="text"><![CDATA[根据nginx日志,查询访问最频繁的IP 1.根据访问IP统计UV1awk &apos;&#123;print $1&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |wc -l 2.统计访问URL统计PV1awk &apos;&#123;print $7&#125;&apos; /var/log/nginx/access.log|wc -l 3.查询访问最频繁的URL1awk &apos;&#123;print $7&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |sort -n -k 1 -r|more 4.查询访问最频繁的IP1awk &apos;&#123;print $1&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |sort -n -k 1 -r|more]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-spring-concurrent]]></title>
    <url>%2F2018%2F03%2F19%2Fjava_spring%2Fstudy-spring-concurrent%2F</url>
    <content type="text"><![CDATA[Spring并发访问的线程安全性问题 只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。那么对于有状态的bean呢？Spring对一些（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态的bean采用ThreadLocal进行处理，让它们也成为线程安全的状态，因此有状态的Bean就可以在多线程中共享了。 如果用有状态的bean，也可以使用用prototype模式，每次在注入的时候就重新创建一个bean，在多线程中互不影响。 RequestContextHolder我们可以知道HttpServletRequest是在执行doService方法之前，也就是具体的业务逻辑前进行设置的，然后在执行完业务逻辑或者抛出异常时重置RequestContextHolder移除当前的HttpServletRequest。]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix-duplicate-key]]></title>
    <url>%2F2018%2F03%2F19%2Fegenie_bugfix%2Fbugfix-duplicate-key%2F</url>
    <content type="text"><![CDATA[一次bugfix的经历过 步骤异常信息1234567891011121314java.lang.IllegalStateException: Duplicate key at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133) ~[?:1.8.0_92] at java.util.HashMap.merge(HashMap.java:1253) ~[?:1.8.0_92] at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320) ~[?:1.8.0_92] at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ~[?:1.8.0_92] at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[?:1.8.0_92] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_92] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[?:1.8.0_92] at 报错代码1Map&lt;Long, PmsDailyPurchase&gt; result = all.stream().collect(Collectors.toMap(PmsDailyPurchase::getSaleOrderId, Function.identity())); 对于ToMap方法没有做兼容,优点是方便问题的排查逻辑上讲应该是不会出现Duplicate key 的 主要逻辑先查询,如果不存在就插入 问题总结 dubbo默认容错机制:dubbo默认的2次重复调用(加起来3次) provider提供的接口没有幂等性 注解配置问题:项目中AvoidRepeatInvoke注解会对重复的调用进行处理 未调用过:真正执行,保存调用结果 调用过:直接返回调用结果 调用的凭证是60s超时的,对于响应大于60s的会自动过期,但实际上还在执行,导致问题的发生 大事务:最近上线读写分离,在整个大方的外部添加了事务注解,导致无法自动提交,当并发时,可能查不到其他事务,已经insert但是没有提交的内容(此处也有幻读的风险,但是使用阿里rds测试后,没有发生) 反思 修改项目级别的默认容错机制, retries=0 超时时间设定 统计监控微服务的方法级别超时时间,修改方法级别 批量接口,限制最大数量,否则调用时间会太长 事务的范围,需要仔细考虑,不能有过大的事务]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix类转换异常]]></title>
    <url>%2F2018%2F03%2F13%2Fegenie_bugfix%2Fbugfix-class-cast-exception%2F</url>
    <content type="text"><![CDATA[异常信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181192018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204):eateNum=null,planCreateDate=null,version=null,cumulativeDefectNum=0,creator=null,createdAt=null,lastUpdater=null,lastUpdated=null,tenantId=null,isUsable=null]]2018-03-13 15:36:51.395 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 新建并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.399 [DubboServerHandler-10.47.124.90:20888-thread-100] WARN com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 存在重复锁[msi_fp_pms-1035108456]2018-03-13 15:36:51.401 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.404 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms1289336139]2018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor270.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70):eateNum=null,planCreateDate=null,version=null,cumulativeDefectNum=0,creator=null,createdAt=null,lastUpdater=null,lastUpdated=null,tenantId=null,isUsable=null]]2018-03-13 15:36:51.395 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 新建并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.399 [DubboServerHandler-10.47.124.90:20888-thread-100] WARN com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 存在重复锁[msi_fp_pms-1035108456]2018-03-13 15:36:51.401 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.404 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms1289336139]2018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor270.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$EnhancerBySpringCGLIB$$41b3ba70.generatePurchaseOrderAndDetails(&lt;generated&gt;) at sun.reflect.GeneratedMethodAccessor283.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) at com.sun.proxy.$Proxy77.generatePurchaseOrderAndDetails(Unknown Source) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$ToPurchaseOrder.invoke(OutOfStockOrderServiceImpl.java:931) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.getToPurchaseOrderResult(OutOfStockOrderServiceImpl.java:250) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.generateOOSPurchaseOrder(OutOfStockOrderServiceImpl.java:215) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.generateOOSPurchaseOrder(OutOfStockOrderServiceImpl.java:125) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$$FastClassBySpringCGLIB$$5a5ccc6a.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$$EnhancerBySpringCGLIB$$c7b6bc32.generateOOSPurchaseOrder(&lt;generated&gt;) at com.alibaba.dubbo.common.bytecode.Wrapper56.invokeMethod(Wrapper56.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:70) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:132) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:113) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 排查步骤 1.排查最近的代码改动,没有相关的修改 2.在代码中加入debug信息,逐行查找变化 3.排查发现可能是aop的代码导致 1@AvoidRepeatInvoke(prefix = &quot;pms&quot;) 4.原先的逻辑 1234if (kvCacher.exist(footprint)) &#123; //判断redis是否存在调用过的足迹,如有,直接返回上一次的结果 LOGGER.warn(&quot;存在重复锁[&#123;&#125;]&quot;, footprint); return JSON.parseObject(kvCacher.get(fpVal), retClass); 5.fastjson中对于带泛型的反持久化应该用type的方式https://github.com/alibaba/fastjson/wiki/TypeReference 6.试验 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Reflect &#123; public List&lt;A&gt; hello() &#123; return null; &#125; public static void main(String[] args) throws NoSuchMethodException, NoSuchFieldException, IllegalAccessException &#123; Class&lt;Reflect&gt; reflectClass = Reflect.class; Method hello = reflectClass.getMethod(&quot;hello&quot;, null); Type genericReturnType = hello.getGenericReturnType(); System.out.println(genericReturnType); ArrayList&lt;A&gt; list = new ArrayList&lt;&gt;(); list.add(new A(&quot;AA1&quot;)); list.add(new A(&quot;AA2&quot;)); list.add(new A(&quot;AA3&quot;)); list.add(new A(&quot;AA4&quot;)); String json = JSON.toJSONString(list); //传统方式// List&lt;A&gt; as = JSON.parseObject(json, new TypeReference&lt;List&lt;A&gt;&gt;() &#123;&#125;.getType()); //反射方式 List&lt;A&gt; as = JSON.parseObject(json, new TypeReference4Reflect(genericReturnType).getType()); System.out.println(as); &#125; public static class A implements Serializable &#123; String name; public A(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; final StringBuffer sb = new StringBuffer(&quot;A&#123;&quot;); sb.append(&quot;name=&apos;&quot;).append(name).append(&apos;\&apos;&apos;); sb.append(&apos;&#125;&apos;); return sb.toString(); &#125; &#125; static public class TypeReference4Reflect&lt;T&gt; extends TypeReference&lt;T&gt; &#123; public TypeReference4Reflect(T t) throws IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException &#123; Class&lt;?&gt; cla = TypeReference.class; Field field = cla.getDeclaredField(&quot;type&quot;); field.setAccessible(true); field.set(this, t); &#125; &#125;&#125; 7.改造 参考:http://www.iteye.com/problems/80586 1234567891011 return JSON.parseObject(cacheResult, new TypeReference4Reflect(genericReturnType).getType());static public class TypeReference4Reflect&lt;T&gt; extends TypeReference&lt;T&gt; &#123; public TypeReference4Reflect(T t) throws IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException &#123; Class&lt;?&gt; cla = TypeReference.class; Field field = cla.getDeclaredField(&quot;type&quot;); field.setAccessible(true); field.set(this, t); &#125;&#125; 反思 日志中可能会有细节,要注意观察 排查步骤,要全面,逐步深入,debug信息表示调用行数]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql锁超时处理]]></title>
    <url>%2F2018%2F03%2F10%2Fegenie_bugfix%2Fbugfix-mysql-lock-timeout%2F</url>
    <content type="text"><![CDATA[问题生成采购单逻辑,一直报错,锁等待超时手动删除这个记录也是报错,应该是锁了pms_daily_group的id为101958的记录 解决123select l.* from ( select &apos;Blocker&apos; role, p.id, p.user, left(p.host, locate(&apos;:&apos;, p.host) - 1) host, tx.trx_id, tx.trx_state, tx.trx_started, timestampdiff(second, tx.trx_started, now()) duration, lo.lock_mode, lo.lock_type, lo.lock_table, lo.lock_index, tx.trx_query, lw.requesting_thd_id Blockee_id, lw.requesting_trx_id Blockee_trx from information_schema.innodb_trx tx, information_schema.innodb_lock_waits lw, information_schema.innodb_locks lo, information_schema.processlist p where lw.blocking_trx_id = tx.trx_id and p.id = tx.trx_mysql_thread_id and lo.lock_id = lw.blocking_lock_id union select &apos;Blockee&apos; role, p.id, p.user, left(p.host, locate(&apos;:&apos;, p.host) - 1) host, tx.trx_id, tx.trx_state, tx.trx_started, timestampdiff(second, tx.trx_started, now()) duration, lo.lock_mode, lo.lock_type, lo.lock_table, lo.lock_index, tx.trx_query, null, null from information_schema.innodb_trx tx, information_schema.innodb_lock_waits lw, information_schema.innodb_locks lo, information_schema.processlist p where lw.requesting_trx_id = tx.trx_id and p.id = tx.trx_mysql_thread_id and lo.lock_id = lw.requested_lock_id) l order by role desc, trx_state desc;kill 184631781 发现了未提交的事务 roleiduserhosttrx_idtrx_statetrx_starteddurationlock_modelock_typelock_tablelock_indextrx_queryBlockee_idBlockee_trxBlocker184631781egeniekn10.26.109.1404994407160RUNNING2018-03-10 10:39:224996XRECORDegenie_kn.pms_daily_groupPRIMARYNULL1846004244996523486Blockee184600424egeniekn10.25.241.2034996523486LOCK WAIT2018-03-10 12:02:326XRECORDegenie_kn.pms_daily_groupPRIMARY/ ApplicationName=DataGrip 2017.3 / UPDATE egenie_kn.pms_daily_group t SET t.is_usable = 0 WHERE t.pms_daily_group_id = 101958NULLNULL]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-binary-heap]]></title>
    <url>%2F2018%2F03%2F05%2Fjava_data_structure%2Fstudy-binary-heap%2F</url>
    <content type="text"><![CDATA[什么是二叉堆简介 二叉堆故名思议是一种特殊的堆，二叉堆具有堆的性质（父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值），二叉堆又具有二叉树的性质（二叉堆是完全二叉树或者是近似完全二叉树）。当父节点的键值大于或等于（小于或等于）它的每一个子节点的键值时我们称它为最大堆（最小堆）。 二叉堆多数是以数组作为它们底层元素的存储，根节点在数组中的索引是1，存储在第n个位置的父节点它的子节点在数组中的存储位置为2n与2n+1。可以借用网上的一幅图来标示这种存储结构。其中数字表明节点在数组中的存储位置。 1234567 1 / \ 2 3 / \ / \ 4 5 6 7 / \ / \ 8 9 10 11 二叉堆支持的操作二叉堆通常支持以下操作：删除，插入节点,创建二叉堆。这些操作复杂对都是O(log2n) 二叉堆也可以支持这些操作：查找。O(n)复杂度。 二叉堆的特点二叉堆是专门为取出最大或最小节点而设计点数据结构，这种数据结构在查找一般元素方面性能和一般数组是没有多大区别的。二叉堆在取出最大或最最小值的性能表现是O(1)，取出操作完成之后，二叉堆需要一次整形操作，以便得到下一个最值，这个操作复杂度O(log2n)。这是一个相当理想的操作时间。但是二叉堆也有一个缺点，就是二叉堆对存储在内存中的数据操作太过分散，这导致了二叉堆在cpu高速缓存的利用与内存击中率上面表现不是很好，这也是一个二叉堆理想操作时间所需要付出的代价。 二叉堆的实现二叉堆的应用]]></content>
  </entry>
  <entry>
    <title><![CDATA[draft-blockchain]]></title>
    <url>%2F2018%2F03%2F04%2Fblockchain%2Fdraft-blockchain%2F</url>
    <content type="text"><![CDATA[区块链的本质分布式数据库 首先，区块链的主要作用是储存信息。任何需要保存的信息，都可以写入区块链，也可以从里面读取，所以它是数据库。 其次，任何人都可以架设服务器，加入区块链网络，成为一个节点。区块链的世界里面，没有中心节点，每个节点都是平等的，都保存着整个数据库。你可以向任何一个节点，写入/读取数据，因为所有节点最后都会同步，保证区块链一致。 区块链的最大特点分布式数据库并非新发明，市场上早有此类产品。但是，区块链有一个革命性特点。 区块链没有管理员，它是彻底无中心的。其他的数据库都有管理员，但是区块链没有。如果有人想对区块链添加审核，也实现不了，因为它的设计目标就是防止出现居于中心地位的管理当局。 正是因为无法管理，区块链才能做到无法被控制。否则一旦大公司大集团控制了管理权，他们就会控制整个平台，其他使用者就都必须听命于他们了。 但是，没有了管理员，人人都可以往里面写入数据，怎么才能保证数据是可信的呢？被坏人改了怎么办？请接着往下读，这就是区块链奇妙的地方。 区块区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。 每个区块包含两个部分。 12区块头（Head）：记录当前区块的特征值区块体（Body）：实际数据 区块头包含了当前区块的多项特征值。 1234生成时间实际数据（即区块体）的哈希上一个区块的哈希... 这里，你需要理解什么叫哈希（hash），这是理解区块链必需的。 所谓”哈希”就是计算机可以对任意内容，计算出一个长度相同的特征值。区块链的 哈希长度是256位，这就是说，不管原始内容是什么，最后都会计算出一个256位的二进制数字。而且可以保证，只要原始内容不同，对应的哈希一定是不同的。 举例来说，字符串123的哈希是a8fdc205a9f19cc1c7507a60c4f01b13d11d7fd0（十六进制），转成二进制就是256位，而且只有123能得到这个哈希。（理论上，其他字符串也有可能得到这个哈希，但是概率极低，可以近似认为不可能发生。） 因此，就有两个重要的推论。 12推论1：每个区块的哈希都是不一样的，可以通过哈希标识区块。推论2：如果区块的内容变了，它的哈希一定会改变。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ReetrantLock源码]]></title>
    <url>%2F2018%2F02%2F28%2Fjava_thread%2FJUC-ReetrantLock%2F</url>
    <content type="text"><![CDATA[Lock接口1234567Lock lock = new ReentrantLock();lock.lock();try&#123; //临界区......&#125;finally&#123; lock.unlock();&#125; 正如代码所显示(ReentrantLock是Lock的实现类，稍后分析)，当前线程使用lock()方法与unlock()对临界区进行包围，其他线程由于无法持有锁将无法进入临界区直到当前线程释放锁，注意unlock()操作必须在finally代码块中，这样可以确保即使临界区执行抛出异常，线程最终也能正常释放锁，Lock接口还提供了锁以下相关方法 1234567891011121314151617181920ublic interface Lock &#123; //加锁 void lock(); //解锁 void unlock(); //可中断获取锁，与lock()不同之处在于可响应中断操作，即在获 //取锁的过程中可中断，注意synchronized在获取锁时是不可中断的 void lockInterruptibly() throws InterruptedException; //尝试非阻塞获取锁，调用该方法后立即返回结果，如果能够获取则返回true，否则返回false boolean tryLock(); //根据传入的时间段获取锁，在指定时间内没有获取锁则返回false，如果在指定时间内当前线程未被中并断获取到锁则返回true boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //获取等待通知组件，该组件与当前锁绑定，当前线程只有获得了锁 //才能调用该组件的wait()方法，而调用后，当前线程将释放锁。 Condition newCondition(); 可见Lock对象锁还提供了synchronized所不具备的其他同步特性，如可中断锁的获取(synchronized在等待获取锁时是不可中的)，超时中断锁的获取，等待唤醒机制的多条件变量Condition等，这也使得Lock锁在使用上具有更大的灵活性。下面进一步分析Lock的实现类重入锁ReetrantLock。 重入锁ReetrantLock重入锁ReetrantLock，JDK 1.5新增的类，实现了Lock接口，作用与synchronized关键字相当，但比synchronized更加灵活。ReetrantLock本身也是一种支持重进入的锁，即该锁可以支持一个线程对资源重复加锁，同时也支持公平锁与非公平锁。所谓的公平与非公平指的是在请求先后顺序上，先对锁进行请求的就一定先获取到锁，那么这就是公平锁，反之，如果对于锁的获取并没有时间上的先后顺序，如后请求的线程可能先获取到锁，这就是非公平锁，一般而言非，非公平锁机制的效率往往会胜过公平锁的机制，但在某些场景下，可能更注重时间先后顺序，那么公平锁自然是很好的选择。需要注意的是ReetrantLock支持对同一线程重加锁，但是加锁多少次，就必须解锁多少次，这样才可以成功释放锁。下面看看ReetrantLock的简单使用案例： 123456789101112131415161718192021222324252627282930import java.util.concurrent.locks.ReentrantLock;public class ReenterLock implements Runnable&#123; public static ReentrantLock lock=new ReentrantLock(); public static int i=0; @Override public void run() &#123; for(int j=0;j&lt;10000000;j++)&#123; lock.lock(); //支持重入锁 lock.lock(); try&#123; i++; &#125;finally&#123; //执行两次解锁 lock.unlock(); lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ReenterLock tl=new ReenterLock(); Thread t1=new Thread(tl); Thread t2=new Thread(tl); t1.start();t2.start(); t1.join();t2.join(); //输出结果：20000000 System.out.println(i); &#125;&#125; 代码非常简单，我们使用两个线程同时操作临界资源i，执行自增操作，使用ReenterLock进行加锁，解决线程安全问题，这里进行了两次重复加锁，由于ReenterLock支持重入，因此这样是没有问题的，需要注意的是在finally代码块中，需执行两次解锁操作才能真正成功地让当前执行线程释放锁，从这里看ReenterLock的用法还是非常简单的，除了实现Lock接口的方法，ReenterLock其他方法说明如下 1234567891011121314151617181920212223242526272829303132333435//查询当前线程保持此锁的次数。int getHoldCount()//返回目前拥有此锁的线程，如果此锁不被任何线程拥有，则返回 null。 protected Thread getOwner();//返回一个 collection，它包含可能正等待获取此锁的线程，其内部维持一个队列，这点稍后会分析。 protected Collection&lt;Thread&gt; getQueuedThreads();//返回正等待获取此锁的线程估计数。 int getQueueLength();// 返回一个 collection，它包含可能正在等待与此锁相关给定条件的那些线程。protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition);//返回等待与此锁相关的给定条件的线程估计数。 int getWaitQueueLength(Condition condition);// 查询给定线程是否正在等待获取此锁。 boolean hasQueuedThread(Thread thread);//查询是否有些线程正在等待获取此锁。 boolean hasQueuedThreads();//查询是否有些线程正在等待与此锁有关的给定条件。 boolean hasWaiters(Condition condition);//如果此锁的公平设置为 true，则返回 true。 boolean isFair()//查询当前线程是否保持此锁。 boolean isHeldByCurrentThread()//查询此锁是否由任意线程保持。 boolean isLocked() 并发基础组件AQS与ReetrantLockAQS工作原理概要AbstractQueuedSynchronizer又称为队列同步器(后面简称AQS)，它是用来构建锁或其他同步组件的基础框架，内部通过一个int类型的成员变量state来控制同步状态,当state=0时，则说明没有任何线程占有共享资源的锁，当state=1时，则说明有线程目前正在使用共享变量，其他线程必须加入同步队列进行等待，AQS内部通过内部类Node构成FIFO的同步队列来完成线程获取锁的排队工作，同时利用内部类ConditionObject构建等待队列，当Condition调用wait()方法后，线程将会加入等待队列中，而当Condition调用signal()方法后，线程将从等待队列转移动同步队列中进行锁竞争。注意这里涉及到两种队列，一种的同步队列，当线程请求锁而等待的后将加入同步队列等待，而另一种则是等待队列(可有多个)，通过Condition调用await()方法释放锁后，将加入等待队列。关于Condition的等待队列我们后面再分析，这里我们先来看看AQS中的同步队列模型，如下 同步队列(竞争锁) 等待队列(await方法) 12345678910111213141516/** * AQS抽象类 */public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer&#123;//指向同步队列队头private transient volatile Node head;//指向同步的队尾private transient volatile Node tail;//同步状态，0代表锁未被占用，1代表锁已被占用private volatile int state;//省略其他代码......&#125; head和tail分别是AQS中的变量，其中head指向同步队列的头部，注意head为空结点，不存储信息。而tail则是同步队列的队尾，同步队列采用的是双向链表的结构这样可方便队列进行结点增删操作。state变量则是代表同步状态，执行当线程调用lock方法进行加锁后，如果此时state的值为0，则说明当前线程可以获取到锁(在本篇文章中，锁和同步状态代表同一个意思)，同时将state设置为1，表示获取成功。如果state已为1，也就是当前锁已被其他线程持有，那么当前执行线程将被封装为Node结点加入同步队列等待。其中Node结点是对每一个访问同步代码的线程的封装，从图中的Node的数据结构也可看出，其包含了需要同步的线程本身以及线程的状态，如是否被阻塞，是否等待唤醒，是否已经被取消等。每个Node结点内部关联其前继结点prev和后继结点next，这样可以方便线程释放锁后快速唤醒下一个在等待的线程，Node是AQS的内部类，其数据结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static final class Node &#123; //共享模式 static final Node SHARED = new Node(); //独占模式 static final Node EXCLUSIVE = null; //标识线程已处于结束状态 static final int CANCELLED = 1; //等待被唤醒状态 static final int SIGNAL = -1; //条件状态， static final int CONDITION = -2; //在共享模式中使用表示获得的同步状态会被传播 static final int PROPAGATE = -3; //等待状态,存在CANCELLED、SIGNAL、CONDITION、PROPAGATE 4种 volatile int waitStatus; //同步队列中前驱结点 volatile Node prev; //同步队列中后继结点 volatile Node next; //请求锁的线程 volatile Thread thread; //等待队列中的后继结点，这个与Condition有关，稍后会分析 Node nextWaiter; //判断是否为共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; //获取前驱结点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; //.....&#125; 其中SHARED和EXCLUSIVE常量分别代表共享模式和独占模式，所谓共享模式是一个锁允许多条线程同时操作，如信号量Semaphore采用的就是基于AQS的共享模式实现的，而独占模式则是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待，如ReentranLock。变量waitStatus则表示当前被封装成Node结点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE。 CANCELLED：值为1，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。 SIGNAL：值为-1，被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消，将会通知该后继结点的线程执行。说白了，就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。 CONDITION：值为-2，与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 0状态：值为0，代表初始化状态。 pre和next，分别指向当前Node结点的前驱结点和后继结点，thread变量存储的请求锁的线程。nextWaiter，与Condition相关，代表等待队列中的后继结点，关于这点这里暂不深入，后续会有更详细的分析，嗯，到此我们对Node结点的数据结构也就比较清晰了。总之呢，AQS作为基础组件，对于锁的实现存在两种不同的模式，即共享模式(如Semaphore)和独占模式(如ReetrantLock)，无论是共享模式还是独占模式的实现类，其内部都是基于AQS实现的，也都维持着一个虚拟的同步队列，当请求锁的线程超过现有模式的限制时，会将线程包装成Node结点并将线程当前必要的信息存储到node结点中，然后加入同步队列等会获取锁，而这系列操作都有AQS协助我们完成，这也是作为基础组件的原因，无论是Semaphore还是ReetrantLock，其内部绝大多数方法都是间接调用AQS完成的，下面是AQS整体类图结构 这里以ReentrantLock为例，简单讲解ReentrantLock与AQS的关系 AbstractOwnableSynchronizer：抽象类，定义了存储独占当前锁的线程和获取的方法 AbstractQueuedSynchronizer：抽象类，AQS框架核心类，其内部以虚拟队列的方式管理线程的锁获取与锁释放，其中获取锁(tryAcquire方法)和释放锁(tryRelease方法)并没有提供默认实现，需要子类重写这两个方法实现具体逻辑，目的是使开发人员可以自由定义获取锁以及释放锁的方式。 Node：AbstractQueuedSynchronizer 的内部类，用于构建虚拟队列(链表双向链表)，管理需要获取锁的线程。 Sync：抽象类，是ReentrantLock的内部类，继承自AbstractQueuedSynchronizer，实现了释放锁的操作(tryRelease()方法)，并提供了lock抽象方法，由其子类实现。 NonfairSync：是ReentrantLock的内部类，继承自Sync，非公平锁的实现类。 FairSync：是ReentrantLock的内部类，继承自Sync，公平锁的实现类。 ReentrantLock：实现了Lock接口的，其内部类有Sync、NonfairSync、FairSync，在创建时可以根据fair参数决定创建NonfairSync(默认非公平锁)还是FairSync。 ReentrantLock内部存在3个实现类，分别是Sync、NonfairSync、FairSync，其中Sync继承自AQS实现了解锁tryRelease()方法，而NonfairSync(非公平锁)、 FairSync(公平锁)则继承自Sync，实现了获取锁的tryAcquire()方法，ReentrantLock的所有方法调用都通过间接调用AQS和Sync类及其子类来完成的。从上述类图可以看出AQS是一个抽象类，但请注意其源码中并没一个抽象的方法，这是因为AQS只是作为一个基础组件，并不希望直接作为直接操作类对外输出，而更倾向于作为基础组件，为真正的实现类提供基础设施，如构建同步队列，控制同步状态等，事实上，从设计模式角度来看，AQS采用的模板模式的方式构建的，其内部除了提供并发操作核心方法以及同步队列操作外，还提供了一些模板方法让子类自己实现，如加锁操作以及解锁操作，为什么这么做？这是因为AQS作为基础组件，封装的是核心并发操作，但是实现上分为两种模式，即共享模式与独占模式，而这两种模式的加锁与解锁实现方式是不一样的，但AQS只关注内部公共方法实现并不关心外部不同模式的实现，所以提供了模板方法给子类使用，也就是说实现独占锁，如ReentrantLock需要自己实现tryAcquire()方法和tryRelease()方法，而实现共享模式的Semaphore，则需要实现tryAcquireShared()方法和tryReleaseShared()方法，这样做的好处是显而易见的，无论是共享模式还是独占模式，其基础的实现都是同一套组件(AQS)，只不过是加锁解锁的逻辑不同罢了，更重要的是如果我们需要自定义锁的话，也变得非常简单，只需要选择不同的模式实现不同的加锁和解锁的模板方法即可，AQS提供给独占模式和共享模式的模板方法如下 1234567891011121314151617181920212223242526272829//AQS中提供的主要模板方法，由子类实现。public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer&#123; //独占模式下获取锁的方法 protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; //独占模式下解锁的方法 protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125; //共享模式下获取锁的方法 protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; //共享模式下解锁的方法 protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; //判断是否为持有独占锁 protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException(); &#125;&#125; 基于ReetrantLock分析AQS独占模式实现过程ReetrantLock中非公平锁AQS同步器的实现依赖于内部的同步队列(FIFO的双向链表对列)完成对同步状态(state)的管理，当前线程获取锁(同步状态)失败时，AQS会将该线程以及相关等待信息包装成一个节点(Node)并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会将头结点head中的线程唤醒，让其尝试获取同步状态。关于同步队列和Node结点，前面我们已进行了较为详细的分析，这里重点分析一下获取同步状态和释放同步状态以及如何加入队列的具体操作，这里从ReetrantLock入手分析AQS的具体实现，我们先以非公平锁为例进行分析。 12345678910111213//默认构造，创建非公平锁NonfairSyncpublic ReentrantLock() &#123; sync = new NonfairSync();&#125;//根据传入参数创建锁类型public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125;//加锁操作public void lock() &#123; sync.lock();&#125; 123456789101112131415161718192021222324252627/** * 非公平锁实现 */static final class NonfairSync extends Sync &#123; //加锁 final void lock() &#123; //执行CAS操作，获取同步状态 if (compareAndSetState(0, 1)) //成功则将独占锁线程设置为当前线程 setExclusiveOwnerThread(Thread.currentThread()); else //否则再次请求同步状态 acquire(1); &#125;&#125;/** * 公平锁实现 */static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; &#125; 这里获取锁时，首先对同步状态执行CAS操作，尝试把state的状态从0设置为1，如果返回true则代表获取同步状态成功，也就是当前线程获取锁成，可操作临界资源，如果返回false，则表示已有线程持有该同步状态(其值为1)，获取锁失败，注意这里存在并发的情景，也就是可能同时存在多个线程设置state变量，因此是CAS操作保证了state变量操作的原子性。返回false后，执行 acquire(1)方法，该方法是AQS中的方法，它对中断不敏感，即使线程获取同步状态失败，进入同步队列，后续对该线程执行中断操作也不会从同步队列中移出，方法如下 123456public final void acquire(int arg) &#123; //再次尝试获取同步状态 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这里传入参数arg表示要获取同步状态后设置的值(即要设置state的值)，因为要获取锁，而status为0时是释放锁，1则是获取锁，所以这里一般传递参数为1，进入方法后首先会执行tryAcquire(arg)方法，在前面分析过该方法在AQS中并没有具体实现，而是交由子类实现，因此该方法是由ReetrantLock类内部实现的 12345678910111213141516171819202122232425262728293031323334353637//NonfairSync类static final class NonfairSync extends Sync &#123; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125;//Sync类abstract static class Sync extends AbstractQueuedSynchronizer &#123; //nonfairTryAcquire方法 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //判断同步状态是否为0，并尝试再次获取同步状态 if (c == 0) &#123; //执行CAS操作 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程已获取锁，属于重入锁，再次获取锁后将status值加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); //设置当前同步状态，当前只有一个线程持有锁，因为不会发生线程安全问题，可以直接执行 setState(nextc); setState(nextc); return true; &#125; return false; &#125; //省略其他代码&#125; 从代码执行流程可以看出，这里做了两件事，一是尝试再次获取同步状态，如果获取成功则将当前线程设置为OwnerThread，否则失败，二是判断当前线程current是否为OwnerThread，如果是则属于重入锁，state自增1，并获取锁成功，返回true，反之失败，返回false，也就是tryAcquire(arg)执行失败，返回false。需要注意的是nonfairTryAcquire(int acquires)内部使用的是CAS原子性操作设置state值，可以保证state的更改是线程安全的，因此只要任意一个线程调用nonfairTryAcquire(int acquires)方法并设置成功即可获取锁，不管该线程是新到来的还是已在同步队列的线程，毕竟这是非公平锁，并不保证同步队列中的线程一定比新到来线程请求(可能是head结点刚释放同步状态然后新到来的线程恰好获取到同步状态)先获取到锁，这点跟后面还会讲到的公平锁不同。ok~，接着看之前的方法acquire(int arg) 123456public final void acquire(int arg) &#123; //再次尝试获取同步状态 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 如果tryAcquire(arg)返回true，acquireQueued自然不会执行，这是最理想的，因为毕竟当前线程已获取到锁，如果tryAcquire(arg)返回false，则会执行addWaiter(Node.EXCLUSIVE)进行入队操作,由于ReentrantLock属于独占锁，因此结点类型为Node.EXCLUSIVE，下面看看addWaiter方法具体实现（先执行里面的方法） 12345678910111213141516171819private Node addWaiter(Node mode) &#123; //将请求同步状态失败的线程封装成结点 Node node = new Node(Thread.currentThread(), mode); Node pred = tail; //如果是第一个结点加入肯定为空，跳过。 //如果非第一个结点则直接执行CAS入队操作，尝试在尾部快速添加 if (pred != null) &#123; node.prev = pred; //使用CAS执行尾部结点替换，尝试在尾部快速添加 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //如果第一次加入或者CAS操作没有成功执行enq入队操作 enq(node); return node;&#125; 创建了一个Node.EXCLUSIVE类型Node结点用于封装线程及其相关信息，其中tail是AQS的成员变量，指向队尾(这点前面的我们分析过AQS维持的是一个双向的链表结构同步队列)，如果是第一个结点，则为tail肯定为空，那么将执行enq(node)操作，如果非第一个结点即tail指向不为null，直接尝试执行CAS操作加入队尾，如果CAS操作失败还是会执行enq(node)，继续看enq(node)： 123456789101112131415161718private Node enq(final Node node) &#123; //死循环 for (;;) &#123; Node t = tail; //如果队列为null，即没有头结点 if (t == null) &#123; // Must initialize //创建并使用CAS设置头结点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123;//队尾添加新结点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 这个方法使用一个死循环进行CAS操作，可以解决多线程并发问题。这里做了两件事，一是如果还没有初始同步队列则创建新结点并使用compareAndSetHead设置头结点，tail也指向head，二是队列已存在，则将新结点node添加到队尾。注意这两个步骤都存在同一时间多个线程操作的可能，如果有一个线程修改head和tail成功，那么其他线程将继续循环，直到修改成功，这里使用CAS原子操作进行头结点设置和尾结点tail替换可以保证线程安全，从这里也可以看出head结点本身不存在任何数据，它只是作为一个牵头结点，而tail永远指向尾部结点(前提是队列不为null)。 添加到同步队列后，结点就会进入一个自旋过程，即每个结点都在观察时机待条件满足获取同步状态，然后从同步队列退出并结束自旋，回到之前的acquire()方法，自旋过程是在acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法中执行的，代码如下 12345678910111213141516171819202122232425262728final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; //自旋，死循环 for (;;) &#123; //获取前驱结点 final Node p = node.predecessor(); 当且仅当p为头结点才尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //将node设置为头结点 setHead(node); //清空原来头结点的引用便于GC p.next = null; // help GC failed = false; return interrupted; &#125; //如果前驱结点不是head，判断是否挂起线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) //最终都没能获取同步状态，结束该线程的请求 cancelAcquire(node); &#125;&#125; 当前线程在自旋(死循环)中获取同步状态，当且仅当前驱结点为头结点才尝试获取同步状态，这符合FIFO的规则，即先进先出，其次head是当前获取同步状态的线程结点，只有当head释放同步状态唤醒后继结点，后继结点才有可能获取到同步状态，因此后继结点在其前继结点为head时，才进行尝试获取同步状态，其他时刻将被挂起。进入if语句后调用setHead(node)方法，将当前线程结点设置为head 1234567//设置为头结点private void setHead(Node node) &#123; head = node; //清空结点数据 node.thread = null; node.prev = null;&#125; 设置为node结点被设置为head后，其thread信息和前驱结点将被清空，因为该线程已获取到同步状态(锁)，正在执行了，也就没有必要存储相关信息了，head只有保存指向后继结点的指针即可，便于head结点释放同步状态后唤醒后继结点，执行结果如下图 从图可知更新head结点的指向，将后继结点的线程唤醒并获取同步状态，调用setHead(node)将其替换为head结点，清除相关无用数据。当然如果前驱结点不是head，那么执行如下 12345678910111213141516171819202122232425262728293031323334//如果前驱结点不是head，判断是否挂起线程if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt()) interrupted = true;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取当前结点的等待状态 int ws = pred.waitStatus; //如果为等待唤醒（SIGNAL）状态则返回true if (ws == Node.SIGNAL) return true; //如果ws&gt;0 则说明是结束状态， //遍历前驱结点直到找到没有结束状态的结点 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果ws小于0又不是SIGNAL状态， //则将其设置为SIGNAL状态，代表该结点的线程正在等待唤醒。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;private final boolean parkAndCheckInterrupt() &#123; //将当前线程挂起 LockSupport.park(this); //获取线程中断状态,interrupted()是判断当前中断状态， //并非中断线程，因此可能true也可能false,并返回 return Thread.interrupted();&#125; shouldParkAfterFailedAcquire()方法的作用是判断当前结点的前驱结点是否为SIGNAL状态(即等待唤醒状态)，如果是则返回true。如果结点的ws为CANCELLED状态(值为1&gt;0),即结束状态，则说明该前驱结点已没有用应该从同步队列移除，执行while循环，直到寻找到非CANCELLED状态的结点。倘若前驱结点的ws值不为CANCELLED，也不为SIGNAL(当从Condition的条件等待队列转移到同步队列时，结点状态为CONDITION因此需要转换为SIGNAL)，那么将其转换为SIGNAL状态，等待被唤醒。若shouldParkAfterFailedAcquire()方法返回true，即前驱结点为SIGNAL状态同时又不是head结点，那么使用parkAndCheckInterrupt()方法挂起当前线程，称为WAITING状态，需要等待一个unpark()操作来唤醒它，到此ReetrantLock内部间接通过AQS的FIFO的同步队列就完成了lock()操作，这里我们总结成逻辑流程图 关于获取锁的操作，这里看看另外一种可中断的获取方式，即调用ReentrantLock类的lockInterruptibly()或者tryLock()方法，最终它们都间接调用到doAcquireInterruptibly() 1234567891011121314151617181920212223private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //直接抛异常，中断线程的同步状态请求 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 最大的不同是1234if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //直接抛异常，中断线程的同步状态请求 throw new InterruptedException(); 检测到线程的中断操作后，直接抛出异常，从而中断线程的同步状态请求，移除同步队列，ok~,加锁流程到此。下面接着看unlock()操作 123456789101112131415161718192021222324252627282930313233343536//ReentrantLock类的unlockpublic void unlock() &#123; sync.release(1);&#125;//AQS类的release()方法public final boolean release(int arg) &#123; //尝试释放锁 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒后继结点的线程 unparkSuccessor(h); return true; &#125; return false;&#125;//ReentrantLock类中的内部类Sync实现的tryRelease(int releases)protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //判断状态是否为0，如果是则说明已释放同步状态 if (c == 0) &#123; free = true; //设置Owner为null setExclusiveOwnerThread(null); &#125; //设置更新同步状态 setState(c); return free; &#125; 释放同步状态的操作相对简单些，tryRelease(int releases)方法是ReentrantLock类中内部类自己实现的，因为AQS对于释放锁并没有提供具体实现，必须由子类自己实现。释放同步状态后会使用unparkSuccessor(h)唤醒后继结点的线程，这里看看unparkSuccessor(h) 12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒&#125; 从代码执行操作来看，这里主要作用是用unpark()唤醒同步队列中最前边未放弃线程(也就是状态为CANCELLED的线程结点s)。此时，回忆前面分析进入自旋的函数acquireQueued()，s结点的线程被唤醒后，会进入acquireQueued()函数的if (p == head &amp;&amp; tryAcquire(arg))的判断，如果p!=head也不会有影响，因为它会执行shouldParkAfterFailedAcquire()，由于s通过unparkSuccessor()操作后已是同步队列中最前边未放弃的线程结点，那么通过shouldParkAfterFailedAcquire()内部对结点状态的调整，s也必然会成为head的next结点，因此再次自旋时p==head就成立了，然后s把自己设置成head结点，表示自己已经获取到资源了，最终acquire()也返回了，这就是独占锁释放的过程。ok~，关于独占模式的加锁和释放锁的过程到这就分析完，总之呢，在AQS同步器中维护着一个同步队列，当线程获取同步状态失败后，将会被封装成Node结点，加入到同步队列中并进行自旋操作，当当前线程结点的前驱结点为head时，将尝试获取同步状态，获取成功将自己设置为head结点。在释放同步状态时，则通过调用子类(ReetrantLock中的Sync内部类)的tryRelease(int releases)方法释放同步状态，释放成功则唤醒后继结点的线程。 ReetrantLock中公平锁了解完ReetrantLock中非公平锁的实现后，我们再来看看公平锁。与非公平锁不同的是，在获取锁的时，公平锁的获取顺序是完全遵循时间上的FIFO规则，也就是说先请求的线程一定会先获取锁，后来的线程肯定需要排队，这点与前面我们分析非公平锁的nonfairTryAcquire(int acquires)方法实现有锁不同，下面是公平锁中tryAcquire()方法的实现 123456789101112131415161718192021//公平锁FairSync类中的实现protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //注意！！这里先判断同步队列是否存在结点 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 该方法与nonfairTryAcquire(int acquires)方法唯一的不同是在使用CAS设置尝试设置state值前，调用了hasQueuedPredecessors()判断同步队列是否存在结点，如果存在必须先执行完同步队列中结点的线程，当前线程进入等待状态。这就是非公平锁与公平锁最大的区别，即公平锁在线程请求到来时先会判断同步队列是否存在结点，如果存在先执行同步队列中的结点线程，当前线程将封装成node加入同步队列等待。而非公平锁呢，当线程请求到来时，不管同步队列是否存在线程结点，直接尝试获取同步状态，获取成功直接访问共享资源，但请注意在绝大多数情况下，非公平锁才是我们理想的选择，毕竟从效率上来说非公平锁总是胜于公平锁。 以上便是ReentrantLock的内部实现原理，这里我们简单进行小结，重入锁ReentrantLock，是一个基于AQS并发框架的并发控制类，其内部实现了3个类，分别是Sync、NoFairSync以及FairSync类，其中Sync继承自AQS，实现了释放锁的模板方法tryRelease(int)，而NoFairSync和FairSync都继承自Sync，实现各种获取锁的方法tryAcquire(int)。ReentrantLock的所有方法实现几乎都间接调用了这3个类，因此当我们在使用ReentrantLock时，大部分使用都是在间接调用AQS同步器中的方法，这就是ReentrantLock的内部实现原理,最后给出张类图结构 关于synchronized 与ReentrantLock在JDK 1.6之后，虚拟机对于synchronized关键字进行整体优化后，在性能上synchronized与ReentrantLock已没有明显差距，因此在使用选择上，需要根据场景而定，大部分情况下我们依然建议是synchronized关键字，原因之一是使用方便语义清晰，二是性能上虚拟机已为我们自动优化。而ReentrantLock提供了多样化的同步特性，如超时获取锁、可以被中断获取锁（synchronized的同步是不能中断的）、等待唤醒机制的多个条件变量(Condition)等，因此当我们确实需要使用到这些功能是，可以选择ReentrantLock ReentrantLock: 超时获取锁 可以被中断获取锁（synchronized的同步是不能中断的） 等待唤醒机制的多条件变量 神奇的Condition关于Condition接口在并发编程中，每个Java对象都存在一组监视器方法，如wait()、notify()以及notifyAll()方法，通过这些方法，我们可以实现线程间通信与协作（也称为等待唤醒机制），如生产者-消费者模式，而且这些方法必须配合着synchronized关键字使用，关于这点，如果想有更深入的理解，可观看博主另外一篇博文【 深入理解Java并发之synchronized实现原理】，与synchronized的等待唤醒机制相比Condition具有更多的灵活性以及精确性，这是因为notify()在唤醒线程时是随机(同一个锁)，而Condition则可通过多个Condition实例对象建立更加精细的线程控制，也就带来了更多灵活性了，我们可以简单理解为以下两点 通过Condition能够精细的控制多线程的休眠与唤醒。 对于一个锁，我们可以为多个线程间建立不同的Condition。 Condition是一个接口类，其主要方法如下： 1234567891011121314151617181920212223242526272829303132public interface Condition &#123; /** * 使当前线程进入等待状态直到被通知(signal)或中断 * 当其他线程调用singal()或singalAll()方法时，该线程将被唤醒 * 当其他线程调用interrupt()方法中断当前线程 * await()相当于synchronized等待唤醒机制中的wait()方法 */ void await() throws InterruptedException; //当前线程进入等待状态，直到被唤醒，该方法不响应中断要求 void awaitUninterruptibly(); //调用该方法，当前线程进入等待状态，直到被唤醒或被中断或超时 //其中nanosTimeout指的等待超时时间，单位纳秒 long awaitNanos(long nanosTimeout) throws InterruptedException; //同awaitNanos，但可以指明时间单位 boolean await(long time, TimeUnit unit) throws InterruptedException; //调用该方法当前线程进入等待状态，直到被唤醒、中断或到达某个时 //间期限(deadline),如果没到指定时间就被唤醒，返回true，其他情况返回false boolean awaitUntil(Date deadline) throws InterruptedException; //唤醒一个等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notify()相同 void signal(); //唤醒所有等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notifyAll()相同 void signalAll();&#125; 关于Condition的实现类是AQS的内部类ConditionObject，关于这点我们稍后分析，这里先来看一个Condition的使用案例，即经典消费者生产者模式 Condition的使用案例-生产者消费者模式conditon使唤醒的更加精细,更目标化 这里我们通过一个卖烤鸭的案例来演示多生产多消费者的案例，该场景中存在两条生产线程t1和t2，用于生产烤鸭，也存在两条消费线程t3，t4用于消费烤鸭，4条线程同时执行，需要保证只有在生产线程产生烤鸭后，消费线程才能消费，否则只能等待，直到生产线程产生烤鸭后唤醒消费线程，注意烤鸭不能重复消费。ResourceByCondition类中定义product()和consume()两个方法，分别用于生产烤鸭和消费烤鸭，并且定义ReentrantLock锁，用于控制product()和consume()的并发，由于必须在烤鸭生成完成后消费线程才能消费烤鸭，否则只能等待，因此这里定义两组Condition对象，分别是producer_con和consumer_con，前者拥有控制生产线程，后者拥有控制消费线程，这里我们使用一个标志flag来控制是否有烤鸭，当flag为true时，代表烤鸭生成完毕，生产线程必须进入等待状态同时唤醒消费线程进行消费，消费线程消费完毕后将flag设置为false，代表烤鸭消费完成，进入等待状态，同时唤醒生产线程生产烤鸭，具体代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.zejian.concurrencys;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by zejian on 2017/7/22. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class ResourceByCondition &#123; private String name; private int count = 1; private boolean flag = false; //创建一个锁对象。 Lock lock = new ReentrantLock(); //通过已有的锁获取两组监视器，一组监视生产者，一组监视消费者。 Condition producer_con = lock.newCondition(); Condition consumer_con = lock.newCondition(); /** * 生产 * @param name */ public void product(String name) &#123; lock.lock(); try &#123; while(flag)&#123; try&#123;producer_con.await();&#125;catch(InterruptedException e)&#123;&#125; &#125; this.name = name + count; count++; System.out.println(Thread.currentThread().getName()+&quot;...生产者5.0...&quot;+this.name); flag = true; consumer_con.signal();//直接唤醒消费线程 &#125; finally &#123; lock.unlock(); &#125; &#125; /** * 消费 */ public void consume() &#123; lock.lock(); try &#123; while(!flag)&#123; try&#123;consumer_con.await();&#125;catch(InterruptedException e)&#123;&#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;...消费者.5.0.......&quot;+this.name);//消费烤鸭1 flag = false; producer_con.signal();//直接唤醒生产线程 &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;执行代码package com.zejian.concurrencys;/** * Created by zejian on 2017/7/22. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class Mutil_Producer_ConsumerByCondition &#123; public static void main(String[] args) &#123; ResourceByCondition r = new ResourceByCondition(); Mutil_Producer pro = new Mutil_Producer(r); Mutil_Consumer con = new Mutil_Consumer(r); //生产者线程 Thread t0 = new Thread(pro); Thread t1 = new Thread(pro); //消费者线程 Thread t2 = new Thread(con); Thread t3 = new Thread(con); //启动线程 t0.start(); t1.start(); t2.start(); t3.start(); &#125;&#125;/** * @decrition 生产者线程 */class Mutil_Producer implements Runnable &#123; private ResourceByCondition r; Mutil_Producer(ResourceByCondition r) &#123; this.r = r; &#125; public void run() &#123; while (true) &#123; r.product(&quot;北京烤鸭&quot;); &#125; &#125;&#125;/** * @decrition 消费者线程 */class Mutil_Consumer implements Runnable &#123; private ResourceByCondition r; Mutil_Consumer(ResourceByCondition r) &#123; this.r = r; &#125; public void run() &#123; while (true) &#123; r.consume(); &#125; &#125;&#125; 正如代码所示，我们通过两者Condition对象单独控制消费线程与生产消费，这样可以避免消费线程在唤醒线程时唤醒的还是消费线程，如果是通过synchronized的等待唤醒机制实现的话，就可能无法避免这种情况，毕竟同一个锁，对于synchronized关键字来说只能有一组等待唤醒队列，而不能像Condition一样，同一个锁拥有多个等待队列。synchronized的实现方案如下， 123456789101112131415161718192021222324252627282930313233343536public class KaoYaResource &#123; private String name; private int count = 1;//烤鸭的初始数量 private boolean flag = false;//判断是否有需要线程等待的标志 /** * 生产烤鸭 */ public synchronized void product(String name)&#123; while(flag)&#123; //此时有烤鸭，等待 try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; this.name=name+count;//设置烤鸭的名称 count++; System.out.println(Thread.currentThread().getName()+&quot;...生产者...&quot;+this.name); flag=true;//有烤鸭后改变标志 notifyAll();//通知消费线程可以消费了 &#125; /** * 消费烤鸭 */ public synchronized void consume()&#123; while(!flag)&#123;//如果没有烤鸭就等待 try&#123;this.wait();&#125;catch(InterruptedException e)&#123;&#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;...消费者........&quot;+this.name);//消费烤鸭1 flag = false; notifyAll();//通知生产者生产烤鸭 &#125;&#125; 如上代码，在调用notify()或者 notifyAll()方法时，由于等待队列中同时存在生产者线程和消费者线程，所以我们并不能保证被唤醒的到底是消费者线程还是生产者线程，而Codition则可以避免这种情况。嗯，了解完Condition的使用方式后，下面我们将进一步探讨Condition背后的实现机制 Condition的实现原理Condition的具体实现类是AQS的内部类ConditionObject，前面我们分析过AQS中存在两种队列，一种是同步队列，一种是等待队列，而等待队列就相对于Condition而言的。注意在使用Condition前必须获得锁，同时在Condition的等待队列上的结点与前面同步队列的结点是同一个类即Node，其结点的waitStatus的值为CONDITION。在实现类ConditionObject中有两个结点分别是firstWaiter和lastWaiter，firstWaiter代表等待队列第一个等待结点，lastWaiter代表等待队列最后一个等待结点，如下 1234567 public class ConditionObject implements Condition, java.io.Serializable &#123; //等待队列第一个等待结点 private transient Node firstWaiter; //等待队列最后一个等待结点 private transient Node lastWaiter; //省略其他代码.......&#125; 每个Condition都对应着一个等待队列，也就是说如果一个锁上创建了多个Condition对象，那么也就存在多个等待队列。等待队列是一个FIFO的队列，在队列中每一个节点都包含了一个线程的引用，而该线程就是Condition对象上等待的线程。当一个线程调用了await()相关的方法，那么该线程将会释放锁，并构建一个Node节点封装当前线程的相关信息加入到等待队列中进行等待，直到被唤醒、中断、超时才从队列中移出。Condition中的等待队列模型如下 正如图所示，Node节点的数据结构，在等待队列中使用的变量与同步队列是不同的，Condtion中等待队列的结点只有直接指向的后继结点并没有指明前驱结点，而且使用的变量是nextWaiter而不是next，这点我们在前面分析结点Node的数据结构时讲过。firstWaiter指向等待队列的头结点，lastWaiter指向等待队列的尾结点，等待队列中结点的状态只有两种即CANCELLED和CONDITION，前者表示线程已结束需要从等待队列中移除，后者表示条件结点等待被唤醒。再次强调每个Codition对象对于一个等待队列，也就是说AQS中只能存在一个同步队列，但可拥有多个等待队列。下面从代码层面看看被调用await()方法(其他await()实现原理类似)的线程是如何加入等待队列的，而又是如何从等待队列中被唤醒的 123456789101112131415161718192021222324252627public final void await() throws InterruptedException &#123; //判断线程是否被中断 if (Thread.interrupted()) throw new InterruptedException(); //创建新结点加入等待队列并返回 Node node = addConditionWaiter(); //释放当前线程锁即释放同步状态 int savedState = fullyRelease(node); int interruptMode = 0; //判断结点是否同步队列(SyncQueue)中,即是否被唤醒 while (!isOnSyncQueue(node)) &#123; //挂起线程 LockSupport.park(this); //判断是否被中断唤醒，如果是退出循环。 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //被唤醒后执行自旋操作争取获得锁，同时判断线程是否被中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // clean up if cancelled if (node.nextWaiter != null) //清理等待队列中不为CONDITION状态的结点 unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 执行addConditionWaiter()添加到等待队列。 1234567891011121314151617private Node addConditionWaiter() &#123; Node t = lastWaiter; // 判断是否为结束状态的结点并移除 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //创建新结点状态为CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); //加入等待队列 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; await()方法主要做了3件事，一是调用addConditionWaiter()方法将当前线程封装成node结点加入等待队列，二是调用fullyRelease(node)方法释放同步状态并唤醒后继结点的线程。三是调用isOnSyncQueue(node)方法判断结点是否在同步队列中，注意是个while循环，如果同步队列中没有该结点就直接挂起该线程，需要明白的是如果线程被唤醒后就调用acquireQueued(node, savedState)执行自旋操作争取锁，即当前线程结点从等待队列转移到同步队列并开始努力获取锁。 接着看看唤醒操作singal()方法 123456789public final void signal() &#123; //判断是否持有独占锁，如果不是抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; //唤醒等待队列第一个结点的线程 if (first != null) doSignal(first);&#125; 这里signal()方法做了两件事，一是判断当前线程是否持有独占锁，没有就抛出异常，从这点也可以看出只有独占模式先采用等待队列，而共享模式下是没有等待队列的，也就没法使用Condition。二是唤醒等待队列的第一个结点，即执行doSignal(first) 123456789101112131415161718192021222324252627282930313233private void doSignal(Node first) &#123; do &#123; //移除条件等待队列中的第一个结点， //如果后继结点为null，那么说没有其他结点将尾结点也设置为null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; //如果被通知节点没有进入到同步队列并且条件等待队列还有不为空的节点，则继续循环通知后续结点 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125;//transferForSignal方法final boolean transferForSignal(Node node) &#123; //尝试设置唤醒结点的waitStatus为0，即初始化状态 //如果设置失败，说明当期结点node的waitStatus已不为 //CONDITION状态，那么只能是结束状态了，因此返回false //返回doSignal()方法中继续唤醒其他结点的线程，注意这里并 //不涉及并发问题，所以CAS操作失败只可能是预期值不为CONDITION， //而不是多线程设置导致预期值变化，毕竟操作该方法的线程是持有锁的。 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //加入同步队列并返回前驱结点p Node p = enq(node); int ws = p.waitStatus; //判断前驱结点是否为结束结点(CANCELLED=1)或者在设置 //前驱节点状态为Node.SIGNAL状态失败时，唤醒被通知节点代表的线程 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) //唤醒node结点的线程 LockSupport.unpark(node.thread); return true; &#125; 注释说得很明白了，这里我们简单整体说明一下，doSignal(first)方法中做了两件事，从条件等待队列移除被唤醒的节点，然后重新维护条件等待队列的firstWaiter和lastWaiter的指向。二是将从等待队列移除的结点加入同步队列(在transferForSignal()方法中完成的)，如果进入到同步队列失败并且条件等待队列还有不为空的节点，则继续循环唤醒后续其他结点的线程。到此整个signal()的唤醒过程就很清晰了，即signal()被调用后，先判断当前线程是否持有独占锁，如果有，那么唤醒当前Condition对象中等待队列的第一个结点的线程，并从等待队列中移除该结点，移动到同步队列中，如果加入同步队列失败，那么继续循环唤醒等待队列中的其他结点的线程，如果成功加入同步队列，那么如果其前驱结点是否已结束或者设置前驱节点状态为Node.SIGNAL状态失败，则通过LockSupport.unpark()唤醒被通知节点代表的线程，到此signal()任务完成，注意被唤醒后的线程，将从前面的await()方法中的while循环中退出，因为此时该线程的结点已在同步队列中，那么while (!isOnSyncQueue(node))将不在符合循环条件，进而调用AQS的acquireQueued()方法加入获取同步状态的竞争中，这就是等待唤醒机制的整个流程实现原理，流程如下图所示（注意无论是同步队列还是等待队列使用的Node数据结构都是同一个，不过是使用的内部变量不同罢了） 参考http://blog.csdn.net/javazejian/article/details/75043422]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS和Unsafe]]></title>
    <url>%2F2018%2F02%2F28%2Fjava_thread%2FJUC-4-cas-unsafe%2F</url>
    <content type="text"><![CDATA[无锁的概念在谈论无锁概念时，总会关联起乐观派与悲观派，对于乐观派而言，他们认为事情总会往好的方向发展，总是认为坏的情况发生的概率特别小，可以无所顾忌地做事，但对于悲观派而已，他们总会认为发展事态如果不及时控制，以后就无法挽回了，即使无法挽回的局面几乎不可能发生。这两种派系映射到并发编程中就如同加锁与无锁的策略，即加锁是一种悲观策略，无锁是一种乐观策略，因为对于加锁的并发程序来说，它们总是认为每次访问共享资源时总会发生冲突，因此必须对每一次数据操作实施加锁策略。而无锁则总是假设对共享资源的访问没有冲突，线程可以不停执行，无需加锁，无需等待，一旦发现冲突，无锁策略则采用一种称为CAS的技术来保证线程执行的安全性，这项CAS技术就是无锁策略实现的关键，下面我们进一步了解CAS技术的奇妙之处。 无锁的执行者-CASCASCAS的全称是Compare And Swap 即比较交换，其算法核心思想如下1执行函数：CAS(V,E,N) 如果V值等于E值，则将V的值设为N。若V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是CAS操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行CAS操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作 由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。同时从这点也可以看出，由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁。 CPU指令对CAS的支持或许我们可能会有这样的疑问，假设存在多个线程执行CAS操作并且CAS的步骤很多，有没有可能在判断V和E相同后，正要赋值时，切换了线程，更改了值。造成了数据不一致呢？答案是否定的，因为CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 鲜为人知的指针: Unsafe类Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，单从名称看来就可以知道该类是非安全的，毕竟Unsafe拥有着类似于C的指针操作，因此总是不应该首先使用Unsafe类，Java官方也不建议直接使用的Unsafe类，据说Oracle正在计划从Java 9中去掉Unsafe类，但我们还是很有必要了解该类，因为Java中CAS操作的执行依赖于Unsafe类的方法，注意Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统底层资源执行相应任务，关于Unsafe类的主要功能点如下： 内存管理Unsafe类中存在直接操作内存的方法 123456789101112131415161718192021222324//分配内存指定大小的内存public native long allocateMemory(long bytes);//根据给定的内存地址address设置重新分配指定大小的内存public native long reallocateMemory(long address, long bytes);//用于释放allocateMemory和reallocateMemory申请的内存public native void freeMemory(long address);//将指定对象的给定offset偏移量内存块中的所有字节设置为固定值public native void setMemory(Object o, long offset, long bytes, byte value);//设置给定内存地址的值public native void putAddress(long address, long x);//获取指定内存地址的值public native long getAddress(long address);//设置给定内存地址的long值public native void putLong(long address, long x);//获取指定内存地址的long值public native long getLong(long address);//设置或获取指定内存的byte值public native byte getByte(long address);public native void putByte(long address, byte x);//其他基本数据类型(long,char,float,double,short等)的操作与putByte及getByte相同//操作系统的内存页大小public native int pageSize(); 提供实例对象新途径12//传入一个对象的class并创建该实例对象，但不会调用构造方法public native Object allocateInstance(Class cls) throws InstantiationException; 类和实例对象以及变量的操作1234567891011121314151617181920212223242526272829/获取字段f在实例对象中的偏移量public native long objectFieldOffset(Field f);//静态属性的偏移量，用于在对应的Class对象中读写静态属性public native long staticFieldOffset(Field f);//返回值就是f.getDeclaringClass()public native Object staticFieldBase(Field f);//获得给定对象偏移量上的int值，所谓的偏移量可以简单理解为指针指向该变量的内存地址，//通过偏移量便可得到该对象的变量，进行各种操作public native int getInt(Object o, long offset);//设置给定对象上偏移量的int值public native void putInt(Object o, long offset, int x);//获得给定对象偏移量上的引用类型的值public native Object getObject(Object o, long offset);//设置给定对象偏移量上的引用类型的值public native void putObject(Object o, long offset, Object x);//其他基本数据类型(long,char,byte,float,double)的操作与getInthe及putInt相同//设置给定对象的int值，使用volatile语义，即设置后立马更新到内存对其他线程可见public native void putIntVolatile(Object o, long offset, int x);//获得给定对象的指定偏移量offset的int值，使用volatile语义，总能获取到最新的int值。public native int getIntVolatile(Object o, long offset);//其他基本数据类型(long,char,byte,float,double)的操作与putIntVolatile及getIntVolatile相同，引用类型putObjectVolatile也一样。//与putIntVolatile一样，但要求被操作字段必须有volatile修饰public native void putOrderedInt(Object o,long offset,int x); 下面通过一个简单的Demo来演示上述的一些方法以便加深对Unsafe类的理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class UnSafeDemo &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException &#123; // 通过反射得到theUnsafe对应的Field对象 Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); // 设置该Field为可访问 field.setAccessible(true); // 通过Field得到该Field对应的具体对象，传入null是因为该Field为static的 Unsafe unsafe = (Unsafe) field.get(null); System.out.println(unsafe); //通过allocateInstance直接创建对象 User user = (User) unsafe.allocateInstance(User.class); Class userClass = user.getClass(); Field name = userClass.getDeclaredField(&quot;name&quot;); Field age = userClass.getDeclaredField(&quot;age&quot;); Field id = userClass.getDeclaredField(&quot;id&quot;); //获取实例变量name和age在对象内存中的偏移量并设置值 unsafe.putInt(user,unsafe.objectFieldOffset(age),18); unsafe.putObject(user,unsafe.objectFieldOffset(name),&quot;android TV&quot;); // 这里返回 User.class， Object staticBase = unsafe.staticFieldBase(id); System.out.println(&quot;staticBase:&quot;+staticBase); //获取静态变量id的偏移量staticOffset long staticOffset = unsafe.staticFieldOffset(userClass.getDeclaredField(&quot;id&quot;)); //获取静态变量的值 System.out.println(&quot;设置前的ID:&quot;+unsafe.getObject(staticBase,staticOffset)); //设置值 unsafe.putObject(staticBase,staticOffset,&quot;SSSSSSSS&quot;); //获取静态变量的值 System.out.println(&quot;设置前的ID:&quot;+unsafe.getObject(staticBase,staticOffset)); //输出USER System.out.println(&quot;输出USER:&quot;+user.toString()); long data = 1000; byte size = 1;//单位字节 //调用allocateMemory分配内存,并获取内存地址memoryAddress long memoryAddress = unsafe.allocateMemory(size); //直接往内存写入数据 unsafe.putAddress(memoryAddress, data); //获取指定内存地址的数据 long addrData=unsafe.getAddress(memoryAddress); System.out.println(&quot;addrData:&quot;+addrData); /** * 输出结果: sun.misc.Unsafe@6f94fa3e staticBase:class geym.conc.ch4.atomic.User 设置前的ID:USER_ID 设置前的ID:SSSSSSSS 输出USER:User&#123;name=&apos;android TV&apos;, age=18&apos;, id=SSSSSSSS&apos;&#125; addrData:1000 */ &#125;&#125;class User&#123; public User()&#123; System.out.println(&quot;user 构造方法被调用&quot;); &#125; private String name; private int age; private static String id=&quot;USER_ID&quot;; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, age=&quot; + age +&apos;\&apos;&apos; + &quot;, id=&quot; + id +&apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125;public static Unsafe getUnsafe() &#123; Class cc = sun.reflect.Reflection.getCallerClass(2); if (cc.getClassLoader() != null) throw new SecurityException(&quot;Unsafe&quot;); return theUnsafe; &#125; 虽然在Unsafe类中存在getUnsafe()方法，但该方法只提供给高级的Bootstrap类加载器使用，普通用户调用将抛出异常，所以我们在Demo中使用了反射技术获取了Unsafe实例对象并进行相关操作。 数组操作1234//获取数组第一个元素的偏移地址public native int arrayBaseOffset(Class arrayClass);//数组中一个元素占据的内存空间,arrayBaseOffset与arrayIndexScale配合使用，可定位数组中每个元素在内存中的位置public native int arrayIndexScale(Class arrayClass); CAS 操作相关CAS是一些CPU直接支持的指令，也就是我们前面分析的无锁操作，在Java中无锁操作CAS基于以下3个方法实现，在稍后讲解Atomic系列内部方法是基于下述方法的实现的。1234567//第一个参数o为给定对象，offset为对象内存的偏移量，通过这个偏移量迅速定位字段并设置或获取该字段的值，//expected表示期望值，x表示要设置的值，下面3个方法都通过CAS原子指令执行操作。public final native boolean compareAndSwapObject(Object o, long offset,Object expected, Object x); public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x);public final native boolean compareAndSwapLong(Object o, long offset,long expected,long x); 这里还需介绍Unsafe类中JDK 1.8新增的几个方法，它们的实现是基于上述的CAS方法，如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//1.8新增，给定对象o，根据获取内存偏移量指向的字段，将其增加delta， //这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值 public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; //获取内存中最新值 v = getIntVolatile(o, offset); //通过CAS操作 &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &#125;//1.8新增，方法作用同上，只不过这里操作的long类型数据 public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v; &#125; //1.8新增，给定对象o，根据获取内存偏移量对于字段，将其 设置为新值newValue， //这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值 public final int getAndSetInt(Object o, long offset, int newValue) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, newValue)); return v; &#125;// 1.8新增，同上，操作的是long类型 public final long getAndSetLong(Object o, long offset, long newValue) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, newValue)); return v; &#125; //1.8新增，同上，操作的是引用类型数据 public final Object getAndSetObject(Object o, long offset, Object newValue) &#123; Object v; do &#123; v = getObjectVolatile(o, offset); &#125; while (!compareAndSwapObject(o, offset, v, newValue)); return v; &#125; 挂起与恢复将一个线程进行挂起是通过park方法实现的，调用 park后，线程将一直阻塞直到超时或者中断等条件出现。unpark可以终止一个挂起的线程，使其恢复正常。Java对线程的挂起操作被封装在 LockSupport类中，LockSupport类中有各种版本pack方法，其底层实现最终还是使用Unsafe.park()方法和Unsafe.unpark()方法 12345//线程调用该方法，线程将一直阻塞直到超时，或者是中断条件出现。 public native void park(boolean isAbsolute, long time); //终止挂起的线程，恢复正常.java.util.concurrent包中挂起操作都是在LockSupport类实现的，其底层正是使用这两个方法， public native void unpark(Object thread); 内存屏障这里主要包括了loadFence、storeFence、fullFence等方法，这些方法是在Java 8新引入的，用于定义内存屏障，避免代码重排序 123456//在该方法之前的所有读操作，一定在load屏障之前执行完成public native void loadFence();//在该方法之前的所有写操作，一定在store屏障之前执行完成public native void storeFence();//在该方法之前的所有读写操作，一定在full屏障之前执行完成，这个内存屏障相当于上面两个的合体功能public native void fullFence(); 其他操作12345678910111213141516171819202122//获取持有锁，已不建议使用@Deprecatedpublic native void monitorEnter(Object var1);//释放锁，已不建议使用@Deprecatedpublic native void monitorExit(Object var1);//尝试获取锁，已不建议使用@Deprecatedpublic native boolean tryMonitorEnter(Object var1);//获取本机内存的页数，这个值永远都是2的幂次方 public native int pageSize(); //告诉虚拟机定义了一个没有安全检查的类，默认情况下这个类加载器和保护域来着调用者类 public native Class defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain); //加载一个匿名类public native Class defineAnonymousClass(Class hostClass, byte[] data, Object[] cpPatches);//判断是否需要加载一个类public native boolean shouldBeInitialized(Class&lt;?&gt; c);//确保类一定被加载public native void ensureClassInitialized(Class&lt;?&gt; c) 并发包中的原子操作类(Atomic系列)通过前面的分析我们已基本理解了无锁CAS的原理并对Java中的指针类Unsafe类有了比较全面的认识，下面进一步分析CAS在Java中的应用，即并发包中的原子操作类(Atomic系列)，从JDK 1.5开始提供了java.util.concurrent.atomic包，在该包中提供了许多基于CAS实现的原子操作类，用法方便，性能高效，主要分以下4种类型。 原子更新基本类型原子更新基本类型主要包括3个类： AtomicBoolean：原子更新布尔类型AtomicInteger：原子更新整型AtomicLong：原子更新长整型这3个类的实现原理和使用方式几乎是一样的，这里我们以AtomicInteger为例进行分析，AtomicInteger主要是针对int类型的数据执行原子操作，它提供了原子自增方法、原子自减方法以及原子赋值方法等，鉴于AtomicInteger的源码不多，我们直接看源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // 获取指针类Unsafe private static final Unsafe unsafe = Unsafe.getUnsafe(); //下述变量value在AtomicInteger实例对象内的内存偏移量 private static final long valueOffset; static &#123; try &#123; //通过unsafe类的objectFieldOffset()方法，获取value变量在对象内存中的偏移 //通过该偏移量valueOffset，unsafe类的内部方法可以获取到变量value对其进行取值或赋值操作 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; //当前AtomicInteger封装的int变量value private volatile int value; public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; public AtomicInteger() &#123; &#125; //获取当前最新值， public final int get() &#123; return value; &#125; //设置当前值，具备volatile效果，方法用final修饰是为了更进一步的保证线程安全。 public final void set(int newValue) &#123; value = newValue; &#125; //最终会设置成newValue，使用该方法后可能导致其他线程在之后的一小段时间内可以获取到旧值，有点类似于延迟加载 public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; //设置新值并获取旧值，底层调用的是CAS操作即unsafe.compareAndSwapInt()方法 public final int getAndSet(int newValue) &#123; return unsafe.getAndSetInt(this, valueOffset, newValue); &#125; //如果当前值为expect，则设置为update(当前值指的是value变量) public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; //当前值加1返回旧值，底层CAS操作 public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125; //当前值减1，返回旧值，底层CAS操作 public final int getAndDecrement() &#123; return unsafe.getAndAddInt(this, valueOffset, -1); &#125; //当前值增加delta，返回旧值，底层CAS操作 public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta); &#125; //当前值加1，返回新值，底层CAS操作 public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; //当前值减1，返回新值，底层CAS操作 public final int decrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, -1) - 1; &#125; //当前值增加delta，返回新值，底层CAS操作 public final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta; &#125; //省略一些不常用的方法....&#125; 通过上述的分析，可以发现AtomicInteger原子类的内部几乎是基于前面分析过Unsafe类中的CAS相关操作的方法实现的，这也同时证明AtomicInteger是基于无锁实现的，这里重点分析自增操作实现过程，其他方法自增实现原理一样。 1234//当前值加1，返回新值，底层CAS操作public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; 我们发现AtomicInteger类中所有自增或自减的方法都间接调用Unsafe类中的getAndAddInt()方法实现了CAS操作，从而保证了线程安全，关于getAndAddInt其实前面已分析过，它是Unsafe类中1.8新增的方法，源码如下 12345678//Unsafe类中的getAndAddInt方法public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &#125; 可看出getAndAddInt通过一个while循环不断的重试更新要设置的值，直到成功为止，调用的是Unsafe类中的compareAndSwapInt方法，是一个CAS操作方法。这里需要注意的是，上述源码分析是基于JDK1.8的，如果是1.8之前的方法，AtomicInteger源码实现有所不同，是基于for死循环的，如下 12345678910//JDK 1.7的源码，由for的死循环实现，并且直接在AtomicInteger实现该方法，//JDK1.8后，该方法实现已移动到Unsafe类中，直接调用getAndAddInt方法即可public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125;&#125; 原子更新引用原子更新引用类型可以同时更新引用类型，这里主要分析一下AtomicReference原子类，即原子更新引用类型。先看看其使用方式，如下 1234567891011121314151617181920212223242526272829303132333435public class AtomicReferenceDemo2 &#123; public static AtomicReference&lt;User&gt; atomicUserRef = new AtomicReference&lt;User&gt;(); public static void main(String[] args) &#123; User user = new User(&quot;zejian&quot;, 18); atomicUserRef.set(user); User updateUser = new User(&quot;Shine&quot;, 25); atomicUserRef.compareAndSet(user, updateUser); //执行结果:User&#123;name=&apos;Shine&apos;, age=25&#125; System.out.println(atomicUserRef.get().toString()); &#125; static class User &#123; public String name; private int age; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, age=&quot; + age + &apos;&#125;&apos;; &#125; &#125;&#125; 那么AtomicReference原子类内部是如何实现CAS操作的呢？ 12345678910111213141516171819202122232425262728293031323334public class AtomicReference&lt;V&gt; implements java.io.Serializable &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; //内部变量value，Unsafe类通过valueOffset内存偏移量即可获取该变量 private volatile V value;//CAS方法，间接调用unsafe.compareAndSwapObject(),它是一个//实现了CAS操作的native方法public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update);&#125;//设置并获取旧值public final V getAndSet(V newValue) &#123; return (V)unsafe.getAndSetObject(this, valueOffset, newValue); &#125; //省略其他代码......&#125;//Unsafe类中的getAndSetObject方法，实际调用还是CAS操作public final Object getAndSetObject(Object o, long offset, Object newValue) &#123; Object v; do &#123; v = getObjectVolatile(o, offset); &#125; while (!compareAndSwapObject(o, offset, v, newValue)); return v; &#125; 原子更新数组原子更新数组指的是通过原子的方式更新数组里的某个元素，主要有以下3个类 AtomicIntegerArray：原子更新整数数组里的元素AtomicLongArray：原子更新长整数数组里的元素AtomicReferenceArray：原子更新引用类型数组里的元素这里以AtomicIntegerArray为例进行分析，其余两个使用方式和实现原理基本一样，简单案例如下， 12345678910111213141516171819202122232425public class AtomicIntegerArrayDemo &#123; static AtomicIntegerArray arr = new AtomicIntegerArray(10); public static class AddThread implements Runnable&#123; public void run()&#123; for(int k=0;k&lt;10000;k++) //执行数组中元素自增操作,参数为index,即数组下标 arr.getAndIncrement(k%arr.length()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread[] ts=new Thread[10]; //创建10条线程 for(int k=0;k&lt;10;k++)&#123; ts[k]=new Thread(new AddThread()); &#125; //启动10条线程 for(int k=0;k&lt;10;k++)&#123;ts[k].start();&#125; for(int k=0;k&lt;10;k++)&#123;ts[k].join();&#125; //执行结果 //[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000] System.out.println(arr); &#125;&#125; 启动10条线程对数组中的元素进行自增操作，执行结果符合预期。使用方式比较简单，接着看看AtomicIntegerArray内部是如何实现，先看看部分源码 1234567891011121314151617181920212223242526272829303132public class AtomicIntegerArray implements java.io.Serializable &#123; //获取unsafe类的实例对象 private static final Unsafe unsafe = Unsafe.getUnsafe(); //获取数组的第一个元素内存起始地址 private static final int base = unsafe.arrayBaseOffset(int[].class); private static final int shift; //内部数组 private final int[] array; static &#123; //获取数组中一个元素占据的内存空间 int scale = unsafe.arrayIndexScale(int[].class); //判断是否为2的次幂，一般为2的次幂否则抛异常 if ((scale &amp; (scale - 1)) != 0) throw new Error(&quot;data type scale not a power of two&quot;); // shift = 31 - Integer.numberOfLeadingZeros(scale); &#125; private long checkedByteOffset(int i) &#123; if (i &lt; 0 || i &gt;= array.length) throw new IndexOutOfBoundsException(&quot;index &quot; + i); return byteOffset(i); &#125; //计算数组中每个元素的的内存地址 private static long byteOffset(int i) &#123; return ((long) i &lt;&lt; shift) + base; &#125; //省略其他代码......&#125; 通过前面对Unsafe类的分析，我们知道arrayBaseOffset方法可以获取数组的第一个元素起始地址，而arrayIndexScale方法可以获取每个数组元素占用的内存空间，由于这里是Int类型，而Java中一个int类型占用4个字节，也就是scale的值为4，那么如何根据数组下标值计算每个元素的内存地址呢？显然应该是每个数组元素的内存地址=起始地址+元素下标 * 每个元素所占用的内存空间 原子更新属性如果我们只需要某个类里的某个字段，也就是说让普通的变量也享受原子操作，可以使用原子更新字段类，如在某些时候由于项目前期考虑不周全，项目需求又发生变化，使得某个类中的变量需要执行多线程操作，由于该变量多处使用，改动起来比较麻烦，而且原来使用的地方无需使用线程安全，只要求新场景需要使用时，可以借助原子更新器处理这种场景，Atomic并发包提供了以下三个类： AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。AtomicLongFieldUpdater：原子更新长整型字段的更新器。AtomicReferenceFieldUpdater：原子更新引用类型里的字段。请注意原子更新器的使用存在比较苛刻的条件如下 操作的字段不能是static类型。 操作的字段不能是final类型的，因为final根本没法修改。 字段必须是volatile修饰的，也就是数据本身是读一致的。 属性必须对当前的Updater所在的区域是可见的，如果不是当前类内部进行原子更新器操作不能使用private，protected子类操作父类时修饰符必须是protect权限及以上，如果在同一个package下则必须是default权限及以上，也就是说无论何时都应该保证操作类与被操作类间的可见性。 下面看看AtomicIntegerFieldUpdater和AtomicReferenceFieldUpdater的简单使用方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class AtomicIntegerFieldUpdaterDemo &#123; public static class Candidate&#123; int id; volatile int score; &#125; public static class Game&#123; int id; volatile String name; public Game(int id, String name) &#123; this.id = id; this.name = name; &#125; @Override public String toString() &#123; return &quot;Game&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125; &#125; static AtomicIntegerFieldUpdater&lt;Candidate&gt; atIntegerUpdater = AtomicIntegerFieldUpdater.newUpdater(Candidate.class, &quot;score&quot;); static AtomicReferenceFieldUpdater&lt;Game,String&gt; atRefUpdate = AtomicReferenceFieldUpdater.newUpdater(Game.class,String.class,&quot;name&quot;); //用于验证分数是否正确 public static AtomicInteger allScore=new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &#123; final Candidate stu=new Candidate(); Thread[] t=new Thread[10000]; //开启10000个线程 for(int i = 0 ; i &lt; 10000 ; i++) &#123; t[i]=new Thread() &#123; public void run() &#123; if(Math.random()&gt;0.4)&#123; atIntegerUpdater.incrementAndGet(stu); allScore.incrementAndGet(); &#125; &#125; &#125;; t[i].start(); &#125; for(int i = 0 ; i &lt; 10000 ; i++) &#123; t[i].join();&#125; System.out.println(&quot;最终分数score=&quot;+stu.score); System.out.println(&quot;校验分数allScore=&quot;+allScore); //AtomicReferenceFieldUpdater 简单的使用 Game game = new Game(2,&quot;zh&quot;); atRefUpdate.compareAndSet(game,game.name,&quot;JAVA-HHH&quot;); System.out.println(game.toString()); /** * 输出结果: * 最终分数score=5976 校验分数allScore=5976 Game&#123;id=2, name=&apos;JAVA-HHH&apos;&#125; */ &#125;&#125; 我们使用AtomicIntegerFieldUpdater更新候选人(Candidate)的分数score，开启了10000条线程投票，当随机值大于0.4时算一票，分数自增一次，其中allScore用于验证分数是否正确(其实用于验证AtomicIntegerFieldUpdater更新的字段是否线程安全)，当allScore与score相同时，则说明投票结果无误，也代表AtomicIntegerFieldUpdater能正确更新字段score的值，是线程安全的。对于AtomicReferenceFieldUpdater，我们在代码中简单演示了其使用方式，注意在AtomicReferenceFieldUpdater注明泛型时需要两个泛型参数，一个是修改的类类型，一个修改字段的类型。至于AtomicLongFieldUpdater则与AtomicIntegerFieldUpdater类似，不再介绍。接着简单了解一下AtomicIntegerFieldUpdater的实现原理，实际就是反射和Unsafe类结合，AtomicIntegerFieldUpdater是个抽象类，实际实现类为AtomicIntegerFieldUpdaterImpl 123456789public abstract class AtomicIntegerFieldUpdater&lt;T&gt; &#123; public static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt; tclass, String fieldName) &#123; //实际实现类AtomicIntegerFieldUpdaterImpl return new AtomicIntegerFieldUpdaterImpl&lt;U&gt; (tclass, fieldName, Reflection.getCallerClass()); &#125; &#125; 看看AtomicIntegerFieldUpdaterImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private static class AtomicIntegerFieldUpdaterImpl&lt;T&gt; extends AtomicIntegerFieldUpdater&lt;T&gt; &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private final long offset;//内存偏移量 private final Class&lt;T&gt; tclass; private final Class&lt;?&gt; cclass; AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) &#123; final Field field;//要修改的字段 final int modifiers;//字段修饰符 try &#123; field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() &#123; public Field run() throws NoSuchFieldException &#123; return tclass.getDeclaredField(fieldName);//反射获取字段对象 &#125; &#125;); //获取字段修饰符 modifiers = field.getModifiers(); //对字段的访问权限进行检查,不在访问范围内抛异常 sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) &#123; sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); &#125; &#125; catch (PrivilegedActionException pae) &#123; throw new RuntimeException(pae.getException()); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; Class&lt;?&gt; fieldt = field.getType(); //判断是否为int类型 if (fieldt != int.class) throw new IllegalArgumentException(&quot;Must be integer type&quot;); //判断是否被volatile修饰 if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException(&quot;Must be volatile type&quot;); this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; caller != tclass) ? caller : null; this.tclass = tclass; //获取该字段的在对象内存的偏移量，通过内存偏移量可以获取或者修改该字段的值 offset = unsafe.objectFieldOffset(field); &#125; &#125; 从AtomicIntegerFieldUpdaterImpl的构造器也可以看出更新器为什么会有这么多限制条件了，当然最终其CAS操作肯定是通过unsafe完成的，简单看一个方法123456789101112131415public int incrementAndGet(T obj) &#123; int prev, next; do &#123; prev = get(obj); next = prev + 1; //CAS操作 &#125; while (!compareAndSet(obj, prev, next)); return next;&#125;//最终调用的还是unsafe.compareAndSwapInt()方法public boolean compareAndSet(T obj, int expect, int update) &#123; if (obj == null || obj.getClass() != tclass || cclass != null) fullCheck(obj); return unsafe.compareAndSwapInt(obj, offset, expect, update); &#125; CAS的ABA问题及其解决方案假设这样一种场景，当第一个线程执行CAS(V,E,U)操作，在获取到当前变量V，准备修改为新值U前，另外两个线程已连续修改了两次变量V的值，使得该值又恢复为旧值，这样的话，我们就无法正确判断这个变量是否已被修改过，如下图 这就是典型的CAS的ABA问题，一般情况这种情况发现的概率比较小，可能发生了也不会造成什么问题，比如说我们对某个做加减法，不关心数字的过程，那么发生ABA问题也没啥关系。但是在某些情况下还是需要防止的，那么该如何解决呢？在Java中解决ABA问题，我们可以使用以下两个原子类 AtomicStampedReference AtomicStampedReference原子类是一个带有时间戳的对象引用，在每次修改后，AtomicStampedReference不仅会设置新值而且还会记录更改的时间。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功，这也就解决了反复读写时，无法预知值是否已被修改的窘境，测试demo如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Created by zejian on 2017/7/2. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class ABADemo &#123; static AtomicInteger atIn = new AtomicInteger(100); //初始化时需要传入一个初始值和初始时间 static AtomicStampedReference&lt;Integer&gt; atomicStampedR = new AtomicStampedReference&lt;Integer&gt;(200,0); static Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; //更新为200 atIn.compareAndSet(100, 200); //更新为100 atIn.compareAndSet(200, 100); &#125; &#125;); static Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atIn.compareAndSet(100,500); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atIn); &#125; &#125;); static Thread t3 = new Thread(new Runnable() &#123; @Override public void run() &#123; int time=atomicStampedR.getStamp(); //更新为200 atomicStampedR.compareAndSet(100, 200,time,time+1); //更新为100 int time2=atomicStampedR.getStamp(); atomicStampedR.compareAndSet(200, 100,time2,time2+1); &#125; &#125;); static Thread t4 = new Thread(new Runnable() &#123; @Override public void run() &#123; int time = atomicStampedR.getStamp(); System.out.println(&quot;sleep 前 t4 time:&quot;+time); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atomicStampedR.compareAndSet(100,500,time,time+1); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atomicStampedR.getReference()); &#125; &#125;); public static void main(String[] args) throws InterruptedException &#123; t1.start(); t2.start(); t1.join(); t2.join(); t3.start(); t4.start(); /** * 输出结果: flag:true,newValue:500 sleep 前 t4 time:0 flag:false,newValue:200 */ &#125;&#125; 对比输出结果可知，AtomicStampedReference类确实解决了ABA的问题，下面我们简单看看其内部实现原理 123456789101112131415161718192021public class AtomicStampedReference&lt;V&gt; &#123; //通过Pair内部类存储数据和时间戳 private static class Pair&lt;T&gt; &#123; final T reference; final int stamp; private Pair(T reference, int stamp) &#123; this.reference = reference; this.stamp = stamp; &#125; static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) &#123; return new Pair&lt;T&gt;(reference, stamp); &#125; &#125; //存储数值和时间的内部类 private volatile Pair&lt;V&gt; pair; //构造器，创建时需传入初始值和时间初始值 public AtomicStampedReference(V initialRef, int initialStamp) &#123; pair = Pair.of(initialRef, initialStamp); &#125;&#125; 接着看看其compareAndSet方法的实现： 123456789101112public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) &#123; Pair&lt;V&gt; current = pair; return expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); &#125; 同时对当前数据和当前时间进行比较，只有两者都相等是才会执行casPair()方法，单从该方法的名称就可知是一个CAS方法，最终调用的还是Unsafe类中的compareAndSwapObject方法123private boolean casPair(Pair&lt;V&gt; cmp, Pair&lt;V&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val); &#125; 到这我们就很清晰AtomicStampedReference的内部实现思想了，通过一个键值对Pair存储数据和时间戳，在更新时对数据和时间戳进行比较，只有两者都符合预期才会调用Unsafe的compareAndSwapObject方法执行数值和时间戳替换，也就避免了ABA的问题。 AtomicMarkableReference类 AtomicMarkableReference与AtomicStampedReference不同的是，AtomicMarkableReference维护的是一个boolean值的标识，也就是说至于true和false两种切换状态，经过博主测试，这种方式并不能完全防止ABA问题的发生，只能减少ABA问题发生的概率。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ABADemo &#123; static AtomicMarkableReference&lt;Integer&gt; atMarkRef = new AtomicMarkableReference&lt;Integer&gt;(100,false); static Thread t5 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark=atMarkRef.isMarked(); System.out.println(&quot;mark:&quot;+mark); //更新为200 System.out.println(&quot;t5 result:&quot;+atMarkRef.compareAndSet(atMarkRef.getReference(), 200,mark,!mark)); &#125; &#125;); static Thread t6 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark2=atMarkRef.isMarked(); System.out.println(&quot;mark2:&quot;+mark2); System.out.println(&quot;t6 result:&quot;+atMarkRef.compareAndSet(atMarkRef.getReference(), 100,mark2,!mark2)); &#125; &#125;); static Thread t7 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark=atMarkRef.isMarked(); System.out.println(&quot;sleep 前 t7 mark:&quot;+mark); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atMarkRef.compareAndSet(100,500,mark,!mark); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atMarkRef.getReference()); &#125; &#125;); public static void main(String[] args) throws InterruptedException &#123; t5.start();t5.join(); t6.start();t6.join(); t7.start(); /** * 输出结果: mark:false t5 result:true mark2:true t6 result:true sleep 前 t5 mark:false flag:true,newValue:500 ----&gt;成功了.....说明还是发生ABA问题 */ &#125;&#125; 再谈自旋锁自旋锁是一种假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这种方式确实也是可以提升效率的。但问题是当线程越来越多竞争很激烈时，占用CPU的时间变长会导致性能急剧下降，因此Java虚拟机内部一般对于自旋锁有一定的次数限制，可能是50或者100次循环后就放弃，直接挂起线程，让出CPU资源。如下通过AtomicReference可实现简单的自旋锁。 1234567891011121314public class SpinLock &#123; private AtomicReference&lt;Thread&gt; sign =new AtomicReference&lt;&gt;(); public void lock()&#123; Thread current = Thread.currentThread(); while(!sign .compareAndSet(null, current))&#123; &#125; &#125; public void unlock ()&#123; Thread current = Thread.currentThread(); sign .compareAndSet(current, null); &#125;&#125; 使用CAS原子操作作为底层实现，lock()方法将要更新的值设置为当前线程，并将预期值设置为null。unlock()函数将要更新的值设置为null，并预期值设置为当前线程。然后我们通过lock()和unlock来控制自旋锁的开启与关闭，注意这是一种非公平锁。事实上AtomicInteger(或者AtomicLong)原子类内部的CAS操作也是通过不断的自循环(while循环)实现，不过这种循环的结束条件是线程成功更新对于的值，但也是自旋锁的一种。 CAS漏洞：CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。关于ABA问题参考文档: http://blog.hesey.net/2011/09/resolve-aba-by-atomicstampedreference.html 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。 参考资料http://blog.csdn.net/javazejian/article/details/72772470]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手工合并采购单分组的sql]]></title>
    <url>%2F2018%2F02%2F26%2Fegenie_business%2Fmanual-sql-separate-purchase-group%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980-- 查询出问题的采购单SELECT *FROM pms_purchase_orderWHERE pms_purchase_order_no IN (&apos;CG2018-02100061021&apos;, &apos;CG2018-02100061023&apos;);-- 订单为主表,先将要处理的订单,抽出到一个表中CREATE TABLE `tmp_0226_mlj` AS SELECT DISTINCT sale_order_id, &quot;XXXX&quot; AS group_no FROM pms_daily_purchase_detail WHERE pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 由于create table的语法限制,如果 group_no 为null,无法进行update,so 先放一个长的字符串XXXX进去DESC tmp_0226_mlj;-- 手动更新组号UPDATE tmp_0226_mljSET group_no = &apos;C&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;D&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;E&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;F&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;G&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;H&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;M&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;N&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;-- 预览手动分配的组号SELECT count(1), group_noFROM tmp_0226_mljGROUP BY group_no;SELECT * from pms_daily_purchase_detail WHERE pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 更新采购单明细UPDATE pms_daily_purchase_detail, tmp_0226_mljSET pms_daily_purchase_detail.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = pms_daily_purchase_detail.sale_order_id AND pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 更新订单UPDATE sale_order, tmp_0226_mljSET sale_order.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = sale_order.sale_order_id;-- 更新发货单UPDATE wms_order, tmp_0226_mljSET wms_order.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = wms_order.sale_order_id;]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm垃圾回收策略]]></title>
    <url>%2F2018%2F02%2F18%2Fjava_jvm%2Fjvm-gc%2F</url>
    <content type="text"><![CDATA[简介GC（Garbage Collection）的发生时机:总体来说是内存使用紧张的时候会进行GC，即新对象所需内存比剩下的内存大时发生。 Stop the worldVM thread在进行GC前，必须要让所有的Java线程阻塞，从而stop the world，开始标记，不管什么算法的收集器，都需要有这个标记的过程，只是时间长短的问题。这一步是非常关键的一步，关于这个部分的内容的介绍也比较少。 How Stop the world安全点（safe point）在准备Stop the World时，其实就是相当于设置了一个中断标志位，而安全点其实就是一些指令，在JIT执行方式下，JIT编译的时候直接把safepoint的检查代码加入了生成的本地代码，不同线程运行到这条指令时会主动去检查这个标志位是否被设置，如果设置了就将线程停顿，否则就继续运行。 安全区域（safe region）而一些Sleep或者被blocked的线程不能主动运行到safepoint。这些线程也需要在GC的时候被标记检查，JVM引入了safe region的概念。safe region是指一块区域，这块区域中的引用都不会被修改，比如线程被阻塞了，那么它的线程堆栈中的引用是不会被修改的，JVM可以安全地进行标记。线程进入到safe region的时候先标识自己进入了safe region，等它被唤醒准备离开safe region的时候，先检查能否离开，如果GC已经完成，那么可以离开，否则就在safe region呆在。 找出活的对象标记的第一步就是得先获得GC roots，也就是根节点法，引用计数法因为循环引用的问题无法解决这里就不提了。所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。GC roots是下面这些数据的集合： JVM栈的栈帧中的局部变量表里的有效的局部变量（局部变量有作用域）所引用的对象 方法区里面的类元素对象的static、常量所引用的对象 运行时方法区里面的类元素对象的运行时常量所引用的对象 本地方法栈里的引用所引用的对象 Tracing GC的根本思路就是：给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可到达的）对象就被判定为存活，其余对象（也就是没有被遍历到的）就自然被判定为死亡。 而Jvm运行时的对象很多，如果一个个去遍历必然会花费大量的时间，获取GC roots最主要的部分在解决如何快速找到JVM栈的栈帧的局部变量表中的局部变量所引用的对象。 在HotSpot里实现的方式从外部记录下类型信息，存成映射表。HotSpot把这样的数据结构叫做OopMap。要实现这种功能，需要虚拟机里的解释器和JIT编译器都有相应的支持，由它们来生成足够的元数据提供给GC。 清理的过程新生代垃圾回收SUN/Oracle 的HotSpot JVM 又把新生代进一步划分为3个区域：一个相对大点的区域，称为”伊甸园区(Eden)”；两个相对小点的区域称为”From 幸存区(survivor)”和”To 幸存区(survivor)”。按照规定,新对象会首先分配在 Eden 中(如果新对象过大，会直接分配在老年代中)。在GC中，Eden 中的对象会被移动到survivor中，直至对象满足一定的年纪(定义为熬过GC的次数),会被移动到老年代。 基于大多数新生对象都会在GC中被收回的假设。新生代的GC 使用复制算法。在GC前To 幸存区(survivor)保持清空,对象保存在 Eden 和 From 幸存区(survivor)中，GC运行时,Eden中的幸存对象被复制到 To 幸存区(survivor)。针对 From 幸存区(survivor)中的幸存对象，会考虑对象年龄,如果年龄没达到阀值(tenuring threshold)，对象会被复制到To 幸存区(survivor)。如果达到阀值对象被复制到老年代。复制阶段完成后，Eden 和From 幸存区中只保存死对象，可以视为清空。如果在复制过程中To 幸存区被填满了，剩余的对象会被复制到老年代中。最后 From 幸存区和 To幸存区会调换下名字，在下次GC时，To 幸存区会成为From 幸存区。 上图演示GC过程，黄色表示死对象，绿色表示剩余空间，红色表示幸存对象 参数设置-XX:NewSize and -XX:MaxNewSize就像可以通过参数(-Xms and -Xmx) 指定堆大小一样，可以通过参数指定新生代大小。设置 XX:MaxNewSize 参数时，应该考虑到新生代只是整个堆的一部分，新生代设置的越大，老年代区域就会减少。一般不允许新生代比老年代还大，因为要考虑GC时最坏情况，所有对象都晋升到老年代。(译者:会发生OOM错误) -XX:MaxNewSize 最大可以设置为-Xmx/2 . 考虑性能，一般会通过参数 -XX:NewSize 设置新生代初始大小。如果知道新生代初始分配的对象大小(经过监控) ，这样设置会有帮助，可以节省新生代自动扩展的消耗。 -XX:NewRatio可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=3 指定老年代/新生代为3/1. 老年代占堆大小的 3/4 ，新生代占 1/4 . 如果针对新生代,同时定义绝对值和相对值,绝对值将起作用。下面例子：$ java -XX:NewSize=32m -XX:MaxNewSize=512m -XX:NewRatio=3 MyApp 以上设置, JVM 会尝试为新生代分配四分之一的堆大小，但不会小于32MB或大于521MB 在设置新生代大小问题上，使用绝对值还是相对值，不存在通用准则 。如果了解应用的内存使用情况,设置固定大小的堆和新生代更有利，当然也可以设置相对值。如果对应用的内存使用一无所知,正确的做法是不要设置任何参数，如果应用运行良好。很好，我们不用做任何额外动作.如果遇到性能或OutOfMemoryErrors, 在调优之前，首先需要进行一系列有目的的监控测试，缩小问题的根源。 -XX:SurvivorRatio参数 -XX:SurvivorRatio 与 -XX:NewRatio 类似，作用于新生代内部区域。-XX:SurvivorRatio 指定伊甸园区(Eden)与幸存区大小比例. 例如, -XX:SurvivorRatio=10 表示伊甸园区(Eden)是 幸存区To 大小的10倍(也是幸存区From的10倍).所以,伊甸园区(Eden)占新生代大小的10/12, 幸存区From和幸存区To 每个占新生代的1/12 .注意,两个幸存区永远是一样大的.. 设定幸存区大小有什么作用? 假设幸存区相对伊甸园区(Eden)太小, 相应新生对象的伊甸园区(Eden)永远很大空间, 我们当然希望,如果这些对象在GC时全部被回收,伊甸园区(Eden)被清空,一切正常.然而,如果有一部分对象在GC中幸存下来, 幸存区只有很少空间容纳这些对象.结果大部分幸存对象在一次GC后，就会被转移到老年代 ,这并不是我们希望的.考虑相反情况, 假设幸存区相对伊甸园区(Eden)太大,当然有足够的空间，容纳GC后的幸存对象. 但是过小的伊甸园区(Eden),意味着空间将越快耗尽，增加新生代GC次数，这是不可接受的。 总之,我们希望最小化短命对象晋升到老年代的数量，同时也希望最小化新生代GC 的次数和持续时间.我们需要找到针对当前应用的折中方案, 寻找适合方案的起点是 了解当前应用中对象的年龄分布情况。 -XX:+PrintTenuringDistribution参数 -XX:+PrintTenuringDistribution 指定JVM 在每次新生代GC时，输出幸存区中对象的年龄分布。例如:Desired survivor size 75497472 bytes, new threshold 15 (max 15) age 1: 19321624 bytes, 19321624 total age 2: 79376 bytes, 19401000 total age 3: 2904256 bytes, 22305256 total 第一行说明幸存区To大小为 75 MB. 也有关于老年代阀值(tenuring threshold)的信息, 老年代阀值，意思是对象从新生代移动到老年代之前，经过几次GC(即, 对象晋升前的最大年龄). 上例中,老年代阀值为15,最大也是15. 之后行表示，对于小于老年代阀值的每一个对象年龄,本年龄中对象所占字节 (如果当前年龄没有对象,这一行会忽略). 上例中,一次 GC 后幸存对象大约 19 MB, 两次GC 后幸存对象大约79 KB , 三次GC 后幸存对象大约 3 MB .每行结尾，显示直到本年龄全部对象大小.所以,最后一行的 total 表示幸存区To 总共被占用22 MB . 幸存区To 总大小为 75 MB ,当前老年代阀值为15，可以断定在本次GC中，没有对象会移动到老年代。现在假设下一次GC 输出为： Desired survivor size 75497472 bytes, new threshold 2 (max 15) age 1: 68407384 bytes, 68407384 total age 2: 12494576 bytes, 80901960 total age 3: 79376 bytes, 80981336 total age 4: 2904256 bytes, 83885592 total 对比前一次老年代分布。明显的,年龄2和年龄3 的对象还保持在幸存区中，因为我们看到年龄3和4的对象大小与前一次年龄2和3的相同。同时发现幸存区中,有一部分对象已经被回收,因为本次年龄2的对象大小为 12MB ，而前一次年龄1的对象大小为 19 MB。最后可以看到最近的GC中，有68 MB 新对象，从伊甸园区移动到幸存区。 注意,本次GC 幸存区占用总大小 84 MB -大于75 MB. 结果,JVM 把老年代阀值从15降低到2，在下次GC时，一部分对象会强制离开幸存区，这些对象可能会被回收(如果他们刚好死亡)或移动到老年代。 -XX:InitialTenuringThreshold, -XX:MaxTenuringThreshold and -XX:TargetSurvivorRatio参数 -XX:+PrintTenuringDistribution 输出中的部分值可以通过其它参数控制。通过 -XX:InitialTenuringThreshold 和 -XX:MaxTenuringThreshold 可以设定老年代阀值的初始值和最大值。另外,可以通过参数 -XX:TargetSurvivorRatio 设定幸存区的目标使用率.例如 , -XX:MaxTenuringThreshold=10 -XX:TargetSurvivorRatio=90 设定老年代阀值的上限为10,幸存区空间目标使用率为90%。 有多种方式,设置新生代行为，没有通用准则。我们必须清楚以下2中情况：1 如果从年龄分布中发现，有很多对象的年龄持续增长，在到达老年代阀值之前。这表示 -XX:MaxTenuringThreshold 设置过大2 如果 -XX:MaxTenuringThreshold 的值大于1，但是很多对象年龄从未大于1.应该看下幸存区的目标使用率。如果幸存区使用率从未到达，这表示对象都被GC回收，这正是我们想要的。 如果幸存区使用率经常达到，有些年龄超过1的对象被移动到老年代中。这种情况，可以尝试调整幸存区大小或目标使用率。 -XX:+NeverTenure and -XX:+AlwaysTenure最后,我们介绍2个颇为少见的参数,对应2种极端的新生代GC情况.设置参数 -XX:+NeverTenure , 对象永远不会晋升到老年代.当我们确定不需要老年代时，可以这样设置。这样设置风险很大,并且会浪费至少一半的堆内存。相反设置参数 -XX:+AlwaysTenure, 表示没有幸存区,所有对象在第一次GC时，会晋升到老年代。没有合理的场景使用这个参数。可以在测试环境中，看下这样设置会发生什么有趣的事.但是并不推荐使用这些参数. 垃圾回收在实践中我们发现对于大多数的应用领域，评估一个垃圾收集(GC)算法如何根据如下两个标准： 吞吐量越高算法越好 暂停时间越短算法越好 高吞吐量最好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。 直觉上，吞吐量越高程序运行越快。 低暂停时间最好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。 这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。 因此，具有低的最大暂停时间是非常重要的，特别是对于一个交互式应用程序。 面向吞吐量-的垃圾收集算法-XX:+UseSerialGC(单核)我们使用该标志来激活串行垃圾收集器，例如单线程面向吞吐量垃圾收集器。 无论年轻代还是年老代都将只有一个线程执行垃圾收集。 该标志被推荐用于只有单个可用处理器核心的JVM。 在这种情况下，使用多个垃圾收集线程甚至会适得其反，因为这些线程将争用CPU资源，造成同步开销，却从未真正并行运行。 -XX:+UseParallelGC(并行执行年轻代垃圾收集)有了这个标志，我们告诉JVM使用多线程并行执行年轻代垃圾收集。 在我看来，Java 6中不应该使用该标志因为-XX:+UseParallelOldGC显然更合适。 需要注意的是Java 7中该情况改变了一点(详见本概述)，就是-XX:+UseParallelGC能达到-XX:+UseParallelOldGC一样的效果。 -XX:+UseParallelOldGC(并行执行老年代垃圾收集)该标志的命名有点不巧，因为”老”听起来像”过时”。 然而，”老”实际上是指年老代，这也解释了为什么-XX:+UseParallelOldGC要优于-XX:+UseParallelGC：除了激活年轻代并行垃圾收集，也激活了年老代并行垃圾收集。 当期望高吞吐量，并且JVM有两个或更多可用处理器核心时，我建议使用该标志。 作为旁注，HotSpot的并行面向吞吐量垃圾收集算法通常称为”吞吐量收集器”，因为它们旨在通过并行执行来提高吞吐量。 -XX:ParallelGCThreads通过-XX:ParallelGCThreads=我们可以指定并行垃圾收集的线程数量。 例如，-XX:ParallelGCThreads=6表示每次并行垃圾收集将有6个线程执行。 如果不明确设置该标志，虚拟机将使用基于可用(虚拟)处理器数量计算的默认值。 决定因素是由Java Runtime。availableProcessors()方法的返回值N，如果N&lt;=8，并行垃圾收集器将使用N个垃圾收集线程，如果N&gt;8个可用处理器，垃圾收集线程数量应为3+5N/8。当JVM独占地使用系统和处理器时使用默认设置更有意义。 但是，如果有多个JVM(或其他耗CPU的系统)在同一台机器上运行，我们应该使用-XX:ParallelGCThreads来减少垃圾收集线程数到一个适当的值。 例如，如果4个以服务器方式运行的JVM同时跑在在一个具有16核处理器的机器上，设置-XX:ParallelGCThreads=4是明智的，它能使不同JVM的垃圾收集器不会相互干扰。 -XX:-UseAdaptiveSizePolicy吞吐量垃圾收集器提供了一个有趣的(但常见，至少在现代JVM上)机制以提高垃圾收集配置的用户友好性。 这种机制被看做是HotSpot在Java 5中引入的”人体工程学”概念的一部分。 通过人体工程学，垃圾收集器能将堆大小动态变动像GC设置一样应用到不同的堆区域，只要有证据表明这些变动将能提高GC性能。 “提高GC性能”的确切含义可以由用户通过-XX:GCTimeRatio和-XX:MaxGCPauseMillis(见下文)标记来指定。重要的是要知道人体工程学是默认激活的。 这很好，因为自适应行为是JVM最大优势之一。 不过，有时我们需要非常清楚对于特定应用什么样的设置是最合适的，在这些情况下，我们可能不希望JVM混乱我们的设置。 每当我们发现处于这种情况时，我们可以考虑通过-XX:-UseAdaptiveSizePolicy停用一些人体工程学。 -XX:GCTimeRatio通过-XX:GCTimeRatio=我们告诉JVM吞吐量要达到的目标值。 更准确地说，-XX:GCTimeRatio=N指定目标应用程序线程的执行时间(与总的程序执行时间)达到N/(N+1)的目标比值。 例如，通过-XX:GCTimeRatio=9我们要求应用程序线程在整个执行时间中至少9/10是活动的(因此，GC线程占用其余1/10)。 基于运行时的测量，JVM将会尝试修改堆和GC设置以期达到目标吞吐量。 -XX:GCTimeRatio的默认值是99，也就是说，应用程序线程应该运行至少99%的总执行时间。 -XX:MaxGCPauseMillis通过-XX:GCTimeRatio=告诉JVM最大暂停时间的目标值(以毫秒为单位)。 在运行时，吞吐量收集器计算在暂停期间观察到的统计数据(加权平均和标准偏差)。 如果统计表明正在经历的暂停其时间存在超过目标值的风险时，JVM会修改堆和GC设置以降低它们。 需要注意的是，年轻代和年老代垃圾收集的统计数据是分开计算的，还要注意，默认情况下，最大暂停时间没有被设置。如果最大暂停时间和最小吞吐量同时设置了目标值，实现最大暂停时间目标具有更高的优先级。 当然，无法保证JVM将一定能达到任一目标，即使它会努力去做。 最后，一切都取决于手头应用程序的行为。当设置最大暂停时间目标时，我们应注意不要选择太小的值。 正如我们现在所知道的，为了保持低暂停时间，JVM需要增加GC次数，那样可能会严重影响可达到的吞吐量。 这就是为什么对于要求低暂停时间作为主要目标的应用程序(大多数是Web应用程序)，我会建议不要使用吞吐量收集器，而是选择CMS收集器。 CMS收集器是本系列下一部分的主题。 CMS收集器 处理阶段CMS收集器的GC周期由6个阶段组成。其中4个阶段(名字以Concurrent开始的)与实际的应用程序是并发执行的，而其他2个阶段需要暂停应用程序线程。 初始标记(STW initial mark) 并发标记(Concurrent marking) 并发预清理(Concurrent precleaning) 重新标记(STW remark) 并发清理(Concurrent sweeping) 并发重置(Concurrent reset) 初始标记 ：在这个阶段，需要虚拟机停顿正在执行的任务，官方的叫法STW(Stop The Word)。这个过程从垃圾回收的”根对象”开始，只扫描到能够和”根对象”直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记 ：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 并发预清理 ：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段”重新标记”的工作，因为下一个阶段会Stop The World。 重新标记 ：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从”跟对象”开始向下追溯，并处理对象关联。 并发清理 ：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。 并发重置 ：这个阶段，重置CMS收集器的数据结构，等待下一次垃圾回收。 初始标记、重新标记这两个步骤仍然需要“stop the world”，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生表动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。 尽管CMS收集器为老年代垃圾回收提供了几乎完全并发的解决方案，然而年轻代仍然通过“stop-the-world”方法来进行收集。对于交互式应用，停顿也是可接受的，背后的原理是年轻带的垃圾回收时间通常是相当短的。 gc日志分析39.910: [GC 39.910: [ParNew: 261760K-&gt;0K(261952K), 0.2314667 secs] 262017K-&gt;26386K(1048384K), 0.2318679 secs]新生代使用 (ParNew 并行)回收器。新生代容量为261952K，GC回收后占用从261760K降到0,耗时0.2314667秒。(译注：262017K-&gt;26386K(1048384K), 0.2318679 secs 表示整个堆占用从262017K 降至26386K,费时0.2318679) 40.146: [GC [1 CMS-initial-mark: 26386K(786432K)] 26404K(1048384K), 0.0074495 secs]开始使用CMS回收器进行老年代回收。初始标记(CMS-initial-mark)阶段,这个阶段标记由根可以直接到达的对象，标记期间整个应用线程会暂停。老年代容量为786432K,CMS 回收器在空间占用达到 26386K 时被触发 40.154: [CMS-concurrent-mark-start]开始并发标记(concurrent-mark-start) 阶段，在第一个阶段被暂停的线程重新开始运行，由前阶段标记过的对象出发，所有可到达的对象都在本阶段中标记。 40.683: [CMS-concurrent-mark: 0.521/0.529 secs]并发标记阶段结束，占用 0.521秒CPU时间, 0.529秒墙钟时间(也包含线程让出CPU给其他线程执行的时间) 40.683: [CMS-concurrent-preclean-start]开始预清理阶段预清理也是一个并发执行的阶段。在本阶段，会查找前一阶段执行过程中,从新生代晋升或新分配或被更新的对象。通过并发地重新扫描这些对象，预清理阶段可以减少下一个stop-the-world 重新标记阶段的工作量。 40.701: [CMS-concurrent-preclean: 0.017/0.018 secs]预清理阶段费时 0.017秒CPU时间，0.018秒墙钟时间。 40.704: [GC40.704: [Rescan (parallel) , 0.1790103 secs]40.883: [weak refs processing, 0.0100966 secs] [1 CMS-remark: 26386K(786432K)] 52644K(1048384K), 0.1897792 secs]Stop-the-world 阶段,从根及被其引用对象开始，重新扫描 CMS 堆中残留的更新过的对象。这里重新扫描费时0.1790103秒，处理弱引用对象费时0.0100966秒，本阶段费时0.1897792 秒。 40.894: [CMS-concurrent-sweep-start]开始并发清理阶段，在清理阶段，应用线程还在运行。 41.020: [CMS-concurrent-sweep: 0.126/0.126 secs]并发清理阶段费时0.126秒 41.020: [CMS-concurrent-reset-start]开始并发重置 41.147: [CMS-concurrent-reset: 0.127/0.127 secs]在本阶段，重新初始化CMS内部数据结构，以备下一轮 GC 使用。本阶段费时0.127秒 这是CMS正常运行周期打印的日志，现在让我们一起看一下其他的CMS日志记录： 197.976: [GC 197.976: [ParNew: 260872K-&gt;260872K(261952K), 0.0000688 secs]197.976: [CMS197.981: [CMS-concurrent-sweep: 0.516/0.531 secs](concurrent mode failure): 402978K-&gt;248977K(786432K), 2.3728734 secs] 663850K-&gt;248977K(1048384K), 2.3733725 secs]这段信息显示ParNew 收集器被请求进行新生代的回收，但收集器并没有尝试回收，因为 它 预计在最糟糕的情况下， CMS 老年代中没有足够的空间容纳新生代的幸存对象。我们把这个失败称之为”完全晋升担保失败”。 因为这样，并发模式的 CMS 被中断同并且在 197.981秒时，Full GC被启动。这次Full GC，采用标记-清除-整理算法，会发生stop-the-world，费时2.3733725秒。CMS 老年代占用从 402978K 降到248977K。 避免并发模式失败, 通过增加老年代空间大小或者设置参数 CMSInitiatingOccupancyFraction 同时设置UseCMSInitiatingOccupancyOnly为true。参数 CMSInitiatingOccupancyFraction 的值必须谨慎选择，设置过低会造成频繁发生 CMS 回收。 优缺点CMS是一款优秀的收集器，主要优点：并发收集、低停顿。 缺点： CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。 CMS是一款“标记–清除”算法实现的收集器，容易出现大量空间碎片。当空间碎片过多，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。 CMS收集器无法处理浮动垃圾。如果获取对象实例的频率高于收集器清除堆里死对象的频率，并发算法将再次失败。从某种程度上说，老年代将没有足够的可用空间来容纳一个从年轻代提升过来的对象。这种情况被称为“并发模式失败”，并且JVM会执行堆碎片整理：触发Full GC。当这些情形之一出现在实践中时(经常会出现在生产系统中)，经常被证实是老年代有大量不必要的对象。一个可行的办法就是增加年轻代的堆大小，以防止年轻代短生命的对象提前进入老年代。另一个办法就似乎利用分析器，快照运行系统的堆转储，并且分析过度的对象分配，找出这些对象，最终减少这些对象的申请。 CMS收集器调优相关的JVM标志参数-XX：+UseConcMarkSweepGC该标志首先是激活CMS收集器。默认HotSpot JVM使用的是并行收集器。 -XX：UseParNewGC当使用CMS收集器时，该标志激活年轻代使用多线程并行执行垃圾回收。这令人很惊讶，我们不能简单在并行收集器中重用-XX：UserParNewGC标志，因为概念上年轻代用的算法是一样的。然而，对于CMS收集器，年轻代GC算法和老年代GC算法是不同的，因此年轻代GC有两种不同的实现，并且是两个不同的标志。 注意最新的JVM版本，当使用-XX：+UseConcMarkSweepGC时，-XX：UseParNewGC会自动开启。因此，如果年轻代的并行GC不想开启，可以通过设置-XX：-UseParNewGC来关掉。 -XX：+CMSConcurrentMTEnabled当该标志被启用时，并发的CMS阶段将以多线程执行(因此，多个GC线程会与所有的应用程序线程并行工作)。该标志已经默认开启，如果顺序执行更好，这取决于所使用的硬件，多线程执行可以通过-XX：-CMSConcurremntMTEnabled禁用。 -XX：ConcGCThreads标志-XX：ConcGCThreads=(早期JVM版本也叫-XX:ParallelCMSThreads)定义并发CMS过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加CMS线程数是否真的能够带来性能的提升。 如果还标志未设置，JVM会根据并行收集器中的-XX：ParallelGCThreads参数的值来计算出默认的并行CMS线程数。该公式是ConcGCThreads = (ParallelGCThreads + 3)/4。因此，对于CMS收集器， -XX:ParallelGCThreads标志不仅影响“stop-the-world”垃圾收集阶段，还影响并发阶段。 总之，有不少方法可以配置CMS收集器的多线程执行。正是由于这个原因,建议第一次运行CMS收集器时使用其默认设置, 然后如果需要调优再进行测试。只有在生产系统中测量(或类生产测试系统)发现应用程序的暂停时间的目标没有达到 , 就可以通过这些标志应该进行GC调优。 -XX:CMSInitiatingOccupancyFraction当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对象。对于CMS收集器，长时间等待是不可取的，因为在并发垃圾收集期间应用持续在运行(并且分配对象)。因此，为了在应用程序使用完内存之前完成垃圾收集周期，CMS收集器要比并行收集器更先启动。 因为不同的应用会有不同对象分配模式，JVM会收集实际的对象分配(和释放)的运行时数据，并且分析这些数据，来决定什么时候启动一次CMS垃圾收集周期。为了引导这一过程， JVM会在一开始执行CMS周期前作一些线索查找。该线索由 -XX:CMSInitiatingOccupancyFraction=来设置，该值代表老年代堆空间的使用率。比如，value=75意味着第一次CMS垃圾收集会在老年代被占用75%时被触发。通常CMSInitiatingOccupancyFraction的默认值为68(之前很长时间的经历来决定的)。 -XX：+UseCMSInitiatingOccupancyOnly我们用-XX+UseCMSInitiatingOccupancyOnly标志来命令JVM不基于运行时收集的数据来启动CMS垃圾收集周期。而是，当该标志被开启时，JVM通过CMSInitiatingOccupancyFraction的值进行每一次CMS收集，而不仅仅是第一次。然而，请记住大多数情况下，JVM比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。 -XX:+CMSClassUnloadingEnabled相对于并行收集器，CMS收集器默认不会对永久代进行垃圾回收。如果希望对永久代进行垃圾回收，可用设置标志-XX:+CMSClassUnloadingEnabled。在早期JVM版本中，要求设置额外的标志-XX:+CMSPermGenSweepingEnabled。注意，即使没有设置这个标志，一旦永久代耗尽空间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC。 -XX:+CMSIncrementalMode该标志将开启CMS收集器的增量模式。增量模式经常暂停CMS过程，以便对应用程序线程作出完全的让步。因此，收集器将花更长的时间完成整个收集周期。因此，只有通过测试后发现正常CMS周期对应用程序线程干扰太大时，才应该使用增量模式。由于现代服务器有足够的处理器来适应并发的垃圾收集，所以这种情况发生得很少。 -XX:+ExplicitGCInvokesConcurrent and -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses如今,被广泛接受的最佳实践是避免显式地调用GC(所谓的“系统GC”)，即在应用程序中调用system.gc()。然而，这个建议是不管使用的GC算法的，值得一提的是，当使用CMS收集器时，系统GC将是一件很不幸的事，因为它默认会触发一次Full GC。幸运的是，有一种方式可以改变默认设置。标志-XX:+ExplicitGCInvokesConcurrent命令JVM无论什么时候调用系统GC，都执行CMS GC，而不是Full GC。第二个标志-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses保证当有系统GC调用时，永久代也被包括进CMS垃圾回收的范围内。因此，通过使用这些标志，我们可以防止出现意料之外的”stop-the-world”的系统GC。 -XX:+DisableExplicitGC然而在这个问题上…这是一个很好提到- XX:+ DisableExplicitGC标志的机会，该标志将告诉JVM完全忽略系统的GC调用(不管使用的收集器是什么类型)。对于我而言，该标志属于默认的标志集合中，可以安全地定义在每个JVM上运行，而不需要进一步思考。 G1收集器不同于其他的分代回收算法、G1将堆空间划分成了互相独立的区块。每块区域既有可能属于O区、也有可能是Y区，且每类区域空间可以是不连续的（对比CMS的O区和Y区都必须是连续的）。这种将O区划分成多块的理念源于：当并发后台线程寻找可回收的对象时、有些区块包含可回收的对象要比其他区块多很多。虽然在清理这些区块时G1仍然需要暂停应用线程、但可以用相对较少的时间优先回收包含垃圾最多区块。这也是为什么G1命名为Garbage First的原因： 第一时间处理垃圾最多的区块。 堆内存结构以往的垃圾回收算法，如CMS，使用的堆内存结构如下： 在G1算法中，采用了另外一种完全不同的方式组织堆内存，堆内存被划分为多个大小相等的内存块（Region），每个Region是逻辑连续的一段内存，结构如下： 每一个分配的Region，都可以分成两个部分，已分配的和未被分配的。它们之间的界限被称为top。总体上来说，把一个对象分配到Region内，只需要简单增加top的值。这个做法实际上就是bump-the-pointer。过程如下 G1具备如下特点： G1在压缩空间方面有优势 G1通过将内存空间分成区域（Region）的方式避免内存碎片问题 Eden, Survivor, Old区不再固定、在内存使用效率上来说更灵活 G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象 G1在回收内存后会马上同时做合并空闲内存的工作、而CMS默认是在STW（stop the world）的时候做 G1会在Young GC中使用、而CMS只能在O区使用 以下场景下G1更适合服务端多核CPU、JVM内存占用较大的应用（至少大于4G）应用在运行过程中会产生大量内存碎片、需要经常压缩空间想要更可控、可预期的GC停顿周期；防止高并发下应用雪崩现象 GC模式： young gc mix gc G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。 由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。 上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。 Young GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm-new-object]]></title>
    <url>%2F2018%2F02%2F10%2Fjava_jvm%2Fjvm-new-object%2F</url>
    <content type="text"><![CDATA[类的初始化类加载机制概述我们知道，一个.java文件在编译后会形成相应的一个或多个Class文件（若一个类中含有内部类，则编译后会产生多个Class文件），但这些Class文件中描述的各种信息，最终都需要加载到虚拟机中之后才能被运行和使用。事实上，虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型的过程就是虚拟机的 类加载机制。 与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载和连接都是在程序运行期间完成，这样会在类加载时稍微增加一些性能开销，但是却能为Java应用程序提供高度的灵活性，Java中天生可以动态扩展的语言特性多态就是依赖运行期动态加载和动态链接这个特点实现的。例如，如果编写一个使用接口的应用程序，可以等到运行时再指定其实际的实现。这种组装应用程序的方式广泛应用于Java程序之中。 类的生命周期Java类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using) 和 卸载(Unloading)七个阶段。其中准备、验证、解析3个部分统称为连接（Linking），如图所示： 加载：把二进制形式的Java类型读入Java虚拟机中。 连接：把装载的二进制形式的类型数据合并到虚拟机的运行时状态中去。 验证：确保Java类型数据格式正确并且适合于Java虚拟机使用。 准备：负责为该类型分配它所需内存。 解析：把常量池中的符号引用转换为直接引用。(可推迟到运行中的程序真正使用某个符号引用时再解析) 初始化：为类变量赋适当的初始值 加载（Loading） 在加载阶段（可以参考java.lang.ClassLoader的loadClass()方法），虚拟机需要完成以下三件事情： (1). 通过一个类的全限定名来获取定义此类的二进制字节流（并没有指明要从一个Class文件中获取，可以从其他渠道，譬如：网络、动态生成、数据库等）； (2). 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； (3). 在内存中(对于HotSpot虚拟就而言就是方法区)生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； Java虚拟机在识别Java class文件，产生了类型的二进制数据后，Java虚拟机必须把这些二进制数据解析为与实现相关的内部数据结构。装载的最终产品就是Class实例，它称为Java程序与内部数据结构之间的接口。要访问关于该类型的信息(存储在内部数据结构中)，程序就要调用该类型对应的Class实例的方法。这样一个过程，就是把一个类型的二进制数据解析为方法区中的内部数据结构，并在堆上建立一个Class对象的过程，这被称为”创建”类型。 加载阶段和连接阶段（Linking）的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 验证（Verification）验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范(例如，是否以魔术0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型) 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求(例如：这个类是否有父类，除了java.lang.Object之外)； 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的; 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响。如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备(Preparation)准备阶段是正式为类变量(static 成员变量)分配内存并设置类变量初始值（零值）的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： public static int value = 123; 那么，变量value在准备阶段过后的值为0而不是123。因为这时候尚未开始执行任何java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器方法()之中，所以把value赋值为123的动作将在初始化阶段才会执行。至于“特殊情况”是指：当类字段的字段属性是ConstantValue时，会在准备阶段初始化为指定的值，所以标注为final之后，value的值在准备阶段初始化为123而非0。 public static final int value = 123; 解析(Resolution)解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 初始化(Initialization)类初始化阶段是类加载过程的最后一步。在前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的java程序代码(字节码)。 在准备阶段，变量已经赋过一次系统要求的初始值(零值)；而在初始化阶段，则根据程序猿通过程序制定的主观计划去初始化类变量和其他资源，或者更直接地说：初始化阶段是执行类构造器()方法的过程。()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块static{}中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。 结束生命周期在如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载的时机那么，什么情况下虚拟机需要开始初始化一个类呢？这在虚拟机规范中是有严格规定的，虚拟机规范指明 有且只有 种情况必须立即对类进行初始化（而这一过程自然发生在加载、验证、准备之后）： 遇到new、getstatic、putstatic或invokestatic这四条字节码指令（注意，newarray指令触发的只是数组类型本身的初始化，而不会导致其相关类型的初始化，比如，new String[]只会直接触发String[]类的初始化，也就是触发对类Ljava.lang.String的初始化，而直接不会触发String类的初始化）时，如果类没有进行过初始化，则需要先对其进行初始化。生成这四条指令的最常见的Java代码场景是： 使用new关键字实例化对象的时候； 读取或设置一个类的静态字段（被final修饰，已在编译器把结果放入常量池的静态字段除外）的时候； 调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 注意，对于这五种会触发类进行初始化的场景，虚拟机规范中使用了一个很强烈的限定语：“有且只有”，这五种场景中的行为称为对一个类进行 主动引用。除此之外，所有引用类的方式，都不会触发初始化，称为 被动引用。被动引用的几种经典场景 通过子类引用父类的静态字段，不会导致子类初始化 通过数组定义来引用类，不会触发此类的初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 类加载器寻找类加载器，先来一个小例子 123456789package com.neo.classloader;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125; 运行后，输出结果： 123sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 这几种类加载器的层次关系如下图所示： 站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其它的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 JVM三种预定义类型类加载器启动（Bootstrap）类加载器：引导类加载器是用 本地代码实现的类加载器，它负责将 &lt;JAVA_HOME&gt;/lib下面的核心类库 或 -Xbootclasspath选项指定的jar包等 虚拟机识别的类库 加载到内存中。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以 不允许直接通过引用进行操作。 扩展（Extension）类加载器：扩展类加载器是由Sun的ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的，它负责将 &lt;JAVA_HOME &gt;/lib/ext或者由系统变量-Djava.ext.dir指定位置中的类库 加载到内存中。开发者可以直接使用标准扩展类加载器。 系统（System）类加载器：系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的，它负责将 用户类路径(java -classpath或-Djava.class.path变量所指的目录，即当前类所在路径及其引用的第三方类库的路径，如第四节中的问题6所述)下的类库 加载到内存中。开发者可以直接使用系统类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 1、在执行非置信代码之前，自动验证数字签名。2、动态地创建符合用户特定需要的定制化构建类。3、从特定的场所取得java class，例如数据库中和网络中。 JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 类的加载 1、命令行启动应用时候由JVM初始化加载 2、通过Class.forName()方法动态加载 3、通过ClassLoader.loadClass()方法动态加载 Class.forName()和ClassLoader.loadClass()区别 Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 类加载双亲委派机制介绍和分析 1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 123456789101112131415161718192021222324252627public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 双亲委派模型意义： 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行 自定义类加载器通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自ClassLoader类，从上面对loadClass方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.neo.classloader;import java.io.*;public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace(&apos;.&apos;, File.separatorChar) + &quot;.class&quot;; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(&quot;E:\\temp&quot;); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(&quot;com.neo.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。这里有几点需要注意： 1、这里传递的文件名需要是类的全限定性名称，即com.paddx.test.classloading.Test格式的，因为 defineClass 方法是按这种格式进行处理的。 2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3、这类Test 类本身可以被 AppClassLoader类加载，因此我们不能把com/paddx/test/classloading/Test.class放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由AppClassLoader加载，而不会通过我们自定义类加载器来加载。 类的实例化对象创建时机 使用new关键字创建对象 使用Class类的newInstance方法(反射机制) 使用Constructor类的newInstance方法(反射机制) 使用Clone方法创建对象 使用(反)序列化机制创建对象 从Java虚拟机层面看，除了使用new关键字创建对象的方式外，其他方式全部都是通过转变为invokevirtual指令直接创建对象的。 创建过程实例变量初始化我们在定义（声明）实例变量的同时，还可以直接对实例变量进行赋值或者使用实例代码块对其进行赋值。如果我们以这两种方式为实例变量进行初始化，那么它们将在构造函数执行之前完成这些初始化操作。实际上，如果我们对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后(还记得吗？Java要求构造函数的第一条语句必须是超类构造函数的调用语句)，构造函数本身的代码之前。 实例代码块初始化构造函数初始化Java要求在实例化类之前，必须先实例化其超类，以保证所创建实例的完整性。 对象初始化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Parent &#123; /* 静态变量 */ public static String p_StaticField = &quot;父类--静态变量&quot;; /* 变量 */ public String p_Field = &quot;父类--变量&quot;; protected int i = 9; protected int j = 0; /* 静态初始化块 */ static &#123; System.out.println( p_StaticField ); System.out.println( &quot;父类--静态初始化块&quot; ); &#125; /* 初始化块 */ &#123; System.out.println( p_Field ); System.out.println( &quot;父类--初始化块&quot; ); &#125; /* 构造器 */ public Parent() &#123; System.out.println( &quot;父类--构造器&quot; ); System.out.println( &quot;i=&quot; + i + &quot;, j=&quot; + j ); j = 20; &#125;&#125;public class SubClass extends Parent &#123; /* 静态变量 */ public static String s_StaticField = &quot;子类--静态变量&quot;; /* 变量 */ public String s_Field = &quot;子类--变量&quot;; /* 静态初始化块 */ static &#123; System.out.println( s_StaticField ); System.out.println( &quot;子类--静态初始化块&quot; ); &#125; /* 初始化块 */ &#123; System.out.println( s_Field ); System.out.println( &quot;子类--初始化块&quot; ); &#125; /* 构造器 */ public SubClass() &#123; System.out.println( &quot;子类--构造器&quot; ); System.out.println( &quot;i=&quot; + i + &quot;,j=&quot; + j ); &#125; /* 程序入口 */ public static void main( String[] args ) &#123; System.out.println( &quot;子类main方法&quot; ); new SubClass(); &#125;&#125; 结果: 12345678910111213父类--静态变量父类--静态初始化块子类--静态变量子类--静态初始化块子类main方法父类--变量父类--初始化块父类--构造器i=9, j=0子类--变量子类--初始化块子类--构造器i=9,j=20]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm-memory-model]]></title>
    <url>%2F2018%2F02%2F07%2Fjava_jvm%2Fjvm-memory-model%2F</url>
    <content type="text"><![CDATA[程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 虚拟机栈线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。 动画是由一帧一帧图片连续切换结果的结果而产生的，其实虚拟机的运行和动画也类似，每个在虚拟机中运行的程序也是由许多的帧的切换产生的结果，只是这些帧里面存放的是方法的局部变量，操作数栈，动态链接，方法返回地址和一些额外的附加信息组成。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 局部变量表用于存放方法参数和方法内部定义的局部变量 虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 操作栈动态链接返回地址异常本地方法栈堆 是Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 但是随着JIT 编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆” 如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代； 新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及SurvivorSpace的大小。 老年代：用于存放经过多次新生代GC仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：1、大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。2、大的数组对象，且数组中无引用外部对象。 方法区也称”永久代” 、“非堆”， 它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。 类信息常量静态变量即时编译后的代码class文件常量池运行时常量池之所以说运行时常量池关键，是因为它相对于Class文件常量池的另外一个重要特性是具备动态性，java语言并不要求常量一定只有编译器才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，比如String类的intern方法就为此类操作。运行时常量池为我们提供了一种能够在运行时动态操作常量池的方法。 方法区主要有以下几个特点：1、方法区是线程安全的。由于所有的线程都共享方法区，所以，方法区里的数据访问必须被设计成线程安全的。例如，假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待 2、方法区的大小不必是固定的，JVM可根据应用需要动态调整。同时，方法区也不一定是连续的，方法区可以在一个堆(甚至是JVM自己的堆)中自由分配。 3、方法区也可被垃圾收集，当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的的一部分。但这部分内存在项目中也会被频繁的使用，而且也可能导致OOM异常，所以我们一起进行归类。 在JDK1.4中新加入了NIO类，引入了一种基于通道与缓冲区的I/O方法，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的对象堆这块内存进行操作。 各区域参数设置 控制参数: -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。老年代空间大小=堆空间大小-年轻代大空间大小 资料http://www.ityouknow.com/jvm.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix-dubbo-channel-close]]></title>
    <url>%2F2018%2F02%2F06%2Fegenie_bugfix%2Fbugfix-dubbo-channel-close%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method findByIds in the service com.ejlerp.baseinfo.api.SkuService. Tried 3 times of the providers [10.27.215.53:20880, 10.26.109.140:20881] (2/3) from the registry 10.25.242.182:2181 on the consumer 118.178.19.115 using the dubbo version 2.8.4. Last error is: Failed to invoke remote method: findByIds, provider: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.SkuService?application=ejlerp-pms-provider&amp;check=false&amp;dubbo=2.8.4&amp;generic=false&amp;interface=com.ejlerp.baseinfo.api.SkuService&amp;methods=generateSkuNo,findSimpleSkuLikeSkuNo,batchFindByBarcode,findAll,saveAvoidDuplicate,translateSku,calculateWeight,queryAndTranslateSku,findByBarcode,updateColumn,queryByNo,findSimpleSkuLikeSellerOuterNoIsEnabled,getSkuSpec,findSkuLikeProductNo,updateNotEmptyById,findSimpleSkuLikeProductName,findSkuLikeProductName,isCombinedSku,findSimpleSkuByCategoryNo,findSimpleSKUBySKUNo,findSimpleSKULikeShortCutKey,findAllSimpleSku,findAllSimpleSkuIsEnabled,batchUpdateNotEmptyById,findSimpleSkuLikeSizeType,updateSku,batchInsert,save,findAllSkus,batchReplace,findSimpleSkuLikeSellerOuterNo,batchDelete,findSkubyColorType,findById,findCombinedSku,findPage,findSkuIdByCondition,deleteSkus,findSimpleSkuLikeProductNoIsEnabled,findSimpleSkuByProductIdAndColor,batchInsertAvoidDuplicate,getSkuInfoByCondition,updateOneColumnById,replace,addSku,findPageV2,findSkubySizeType,findSimpleSkuByIds,findSkuInfoForMatch,isHugeSku,findByProductIds,findSimpleSkuLikeProductShortcutKeyIsEnabled,queryByBarcode,findSimpleSkuLikeSpec,batchGenerateSkus,findSimpleSkuByProductIds,findByIds,findSkuLikeProductShortcutKey,findLikeSkuNo,findSimpleSkuLikeProductNameIsEnabled,findBySellerOuterNo,setCombinedSku,checkUniqueColumn,findByNo,hardDelete,findSimpleSkuLikeNoOrBarcode,getAllProduct,findSkuIdsByProductIds,batchUpdate,findOne,findByNos,findSimpleSkuLikeProductShortcutKey,findSkuNotInIds,update,batchHardDelete,delete,findByCondition,findDetailsBySkuId,findSkuByNoOrBarCode,findSimpleSkuByProductIdAndSize,setNeedSpec,findByProductId,findTranslateByIds,findSimpleSkuLikeSkuNoIsEnabled,findSimpleSKUByBarCode,updateSKUsCostPrice,queryLikeNo,deleteSku,findSimpleSkuLikeColorType,findSimpleSkuLikeProductNo,queryById&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=60000&amp;timestamp=1517844500677&amp;version=0.1, cause: message can not send, because channel is closed . url:dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1 at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:108) at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:227) at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:72) at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:52) at com.alibaba.dubbo.common.bytecode.proxy6.findByIds(proxy6.java) at com.ejlerp.pms.provider.service.agent.baseinfo.BaseInfoAgentService.findSkuByIds(BaseInfoAgentService.java:92) at com.ejlerp.pms.provider.service.StockOutReportServiceImpl.pageExecute(StockOutReportServiceImpl.java:114) at com.ejlerp.pms.provider.service.StockOutReportServiceImpl.refreshAction(StockOutReportServiceImpl.java:99) at com.alibaba.dubbo.common.bytecode.Wrapper51.invokeMethod(Wrapper51.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:70) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:132) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:113) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: com.alibaba.dubbo.remoting.RemotingException: message can not send, because channel is closed . url:dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1 at com.alibaba.dubbo.remoting.transport.AbstractClient.send(AbstractClient.java:268) at com.alibaba.dubbo.remoting.transport.AbstractPeer.send(AbstractPeer.java:51) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.request(HeaderExchangeChannel.java:112) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeClient.request(HeaderExchangeClient.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.ReferenceCountExchangeClient.request(ReferenceCountExchangeClient.java:81) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:96) at com.alibaba.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:144) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:53) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:48) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:74) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:77) ... 35 common frames omitted dubbo提供了自动重连的机制 12345678910111213141516171819202122232425262728293031323334/** * init reconnect thread */ private synchronized void initConnectStatusCheckCommand() &#123; //reconnect=false to close reconnect int reconnect = getReconnectParam(getUrl()); if (reconnect &gt; 0 &amp;&amp; (reconnectExecutorFuture == null || reconnectExecutorFuture.isCancelled())) &#123; Runnable connectStatusCheckCommand = new Runnable() &#123; public void run() &#123; try &#123; if (!isConnected()) &#123; connect(); &#125; else &#123; lastConnectedTime = System.currentTimeMillis(); &#125; &#125; catch (Throwable t) &#123; String errorMsg = &quot;client reconnect to &quot; + getUrl().getAddress() + &quot; find error . url: &quot; + getUrl(); // wait registry sync provider list if (System.currentTimeMillis() - lastConnectedTime &gt; shutdown_timeout) &#123; if (!reconnect_error_log_flag.get()) &#123; reconnect_error_log_flag.set(true); logger.error(errorMsg, t); return; &#125; &#125; if (reconnect_count.getAndIncrement() % reconnect_warning_period == 0) &#123; logger.warn(errorMsg, t); &#125; &#125; &#125; &#125;; reconnectExecutorFuture = reconnectExecutorService.scheduleWithFixedDelay(connectStatusCheckCommand, reconnect, reconnect, TimeUnit.MILLISECONDS); &#125; &#125; 日志 12345678910111213141516171819202122232018-02-06 08:10:57.798 [DubboClientReconnectTimer-thread-1] ERROR com.alibaba.dubbo.remoting.transport.AbstractClient.error - [DUBBO] client reconnect to 10.27.215.53:20880 find error . url: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1, dubbo version: 2.8.4, current host:118.178.19.115com.alibaba.dubbo.remoting.RemotingException: client(url: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1) failed to connect to server /10.27.215.53:20880 client-side timeout 3000ms (elapsed: 3001ms) from netty client 118.178.19.115 using dubbo version 2.8.4 at com.alibaba.dubbo.remoting.transport.netty.NettyClient.doConnect(NettyClient.java:147) at com.alibaba.dubbo.remoting.transport.AbstractClient.connect(AbstractClient.java:280) at com.alibaba.dubbo.remoting.transport.AbstractClient$1.run(AbstractClient.java:145) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 1234567891011121314151617181920212223242018-02-06 02:34:26.962 [DubboClientReconnectTimer-thread-1] WARN com.alibaba.dubbo.remoting.transport.AbstractClient.warn - [DUBBO] client reconnect to 10.25.242.182:20885 find error . url: dubbo://10.25.242.182:20885/com.ejlerp.baseinfo.api.VendorService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.VendorService&amp;methods=findLikeVendorNo,findByVendorTenantId,updateOneColumnById,replace,findLikeVendorShortcutKey,findPageV2,findAll,saveAvoidDuplicate,findAndSaveByVendorName,findVendorIdAndNameMap,findMyVendorOL,enableVendor,findVendorNoAndIdMap,addVendor,updateColumn,findByIds,relateVendorOL,deleteVendor,checkUniqueColumn,findByNo,findByVendorName,updateNotEmptyById,hardDelete,batchUpdateNotEmptyById,batchUpdate,batchInsert,findOne,save,batchHardDelete,update,findByPuchaserId,batchReplace,delete,updateVendor,batchDelete,vendorOLSync,findById,findTmpByVendorTenantIds,findByMobile,findPage,findLikeVendorName,disableVendor,batchInsertAvoidDuplicate,findByCategoryNo,findByVendorNames&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844500217&amp;version=0.1, dubbo version: 2.8.4, current host: 118.178.19.115com.alibaba.dubbo.remoting.RemotingException: client(url: dubbo://10.25.242.182:20885/com.ejlerp.baseinfo.api.VendorService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.VendorService&amp;methods=findLikeVendorNo,findByVendorTenantId,updateOneColumnById,replace,findLikeVendorShortcutKey,findPageV2,findAll,saveAvoidDuplicate,findAndSaveByVendorName,findVendorIdAndNameMap,findMyVendorOL,enableVendor,findVendorNoAndIdMap,addVendor,updateColumn,findByIds,relateVendorOL,deleteVendor,checkUniqueColumn,findByNo,findByVendorName,updateNotEmptyById,hardDelete,batchUpdateNotEmptyById,batchUpdate,batchInsert,findOne,save,batchHardDelete,update,findByPuchaserId,batchReplace,delete,updateVendor,batchDelete,vendorOLSync,findById,findTmpByVendorTenantIds,findByMobile,findPage,findLikeVendorName,disableVendor,batchInsertAvoidDuplicate,findByCategoryNo,findByVendorNames&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844500217&amp;version=0.1) failed to connect to server /10.25.242.182:20885 client-side timeout 3000ms (elapsed: 3000ms) from netty client 118.178.19.115 using dubbo version 2.8.4 at com.alibaba.dubbo.remoting.transport.netty.NettyClient.doConnect(NettyClient.java:147) at com.alibaba.dubbo.remoting.transport.AbstractClient.connect(AbstractClient.java:280) at com.alibaba.dubbo.remoting.transport.AbstractClient$1.run(AbstractClient.java:145) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 1java -Xmx150M -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintHeapAtGC -Xloggc:./pms-gc.log -jar ejlerp-pms-provider-0.2-SNAPSHOT.jar --spring.profiles.active=prod --regCenter.serverList=10.25.242.182:2181 --server.port=9087 --druid.url=jdbc:mysql://rm-bp1ov5155kw37fa31i.mysql.rds.aliyuncs.com:3306/egenie_kn --druid.username=egeniekn --druid.password=ejl@2302 --spring.datasource.url=jdbc:mysql://rm-bp1ov5155kw37fa31i.mysql.rds.aliyuncs.com:3306/job_hz1 --dubbo.registry.address=zookeeper://10.25.242.182:2181 --dubbo.protocol.host=10.25.242.182 --dubbo.monitor=false --provider.appKey=pmsP-hz1-s1 --goods.rest.host=http://www.runscm.com --pmsTradeIsOpen=0 &gt; /dev/null 2&gt;&amp;1 &amp;]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-id-generater]]></title>
    <url>%2F2018%2F02%2F06%2Fdesign%2Fstudy-id-generater%2F</url>
    <content type="text"><![CDATA[分布式的Unique ID的用途如此广泛，从业务对象Id到服务化体系里分布式调用链的TraceId http://ericliang.info/2015/01/18/what-kind-of-id-generator-we-need-in-business-systems.html http://calvin1978.blogcn.com/articles/uuid.html http://www.cnblogs.com/relucent/p/4955340.html https://tech.meituan.com/MT_Leaf.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[线上服务无法打印异常]]></title>
    <url>%2F2018%2F02%2F05%2Fegenie_bugfix%2Fbugfix-log-erro%2F</url>
    <content type="text"><![CDATA[线上异常无堆栈信息12342018-02-04 15:27:54.153 [DubboServerHandler-10.26.235.193:20884-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.26.235.193. service: com.ejlerp.pms.api.ArrivalRecordService, method: purchaseConfirm, exception: java.lang.NullPointerException: null, dubbo version: 2.8.4, current host: 10.26.235.193java.lang.NullPointerException: null 无任何其他异常信息 查看dubbo源码:ExceptionFilter 123logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + exception.getClass().getName() + &quot;: &quot; + exception.getMessage(), exception); 问题排查 对比每天的日志:发现升级后就出现了问题 对比其他机器是否有该问题:都有 对比生产/测试环境是否有该问题:发现hz6有问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566672018-02-02 14:12:51.230 [DubboServerHandler-10.47.124.90:20886-thread-86] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.ArrivalRecordService, method: purchaseConfirm, exception: java.lang.NullPointerException: null, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.NullPointerException: null at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl.batchUpdate(BaseDaoImpl.java:766) at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl$$FastClassBySpringCGLIB$$26be7043.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.dao.jdbc.PurchaseOrderDetailDaoImpl$$EnhancerBySpringCGLIB$$4f4f9329.batchUpdate(&lt;generated&gt;) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl.batchUpdate(PurchaseOrderDetailServiceImpl.java:963) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl$$FastClassBySpringCGLIB$$e0903e90.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl$$EnhancerBySpringCGLIB$$a4c2c1fc.batchUpdate(&lt;generated&gt;) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl.handleUniqueCodeArrive(DailyPurchaseDetailServiceImpl.java:830) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl.updatePurchaseState(DailyPurchaseDetailServiceImpl.java:773) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl$$FastClassBySpringCGLIB$$d0f852c3.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl$$EnhancerBySpringCGLIB$$5a3b675.updatePurchaseState(&lt;generated&gt;) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl.purchaseConfirm(ArrivalRecordServiceImpl.java:166) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl$$FastClassBySpringCGLIB$$eab61da4.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor266.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl$$EnhancerBySpringCGLIB$$c67e6bb8.purchaseConfirm(&lt;generated&gt;) at com.alibaba.dubbo.common.bytecode.Wrapper64.invokeMethod(Wrapper64.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) 问题问题1(业务错误)java.lang.NullPointerException: null at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl.batchUpdate(BaseDaoImpl.java:766) 问题2 jvm jit编译优化由于服务一直没有重启过,在导致过多次数的异常后,jvm对异常进行了优化 OmitStackTraceInFastThrow参数在生产环境JRE 运行在server 模式下， 从日志上看大量的NullPointException日志打印时，没有堆栈信息输出。查了一下，JIT编译会对某些异常如果大量的抛出时，会进行优化，删除堆栈信息。 这是HotSpot VM专门针对异常做的一个优化，称为fast throw，当一些异常在代码里某个特定位置被抛出很多次的话，HotSpot Server Compiler（C2）会用fast throw来优化这个抛出异常的地方，直接抛出一个事先分配好的、类型匹配的对象，这个对象的message和stack trace都被清空。 可以明确：抛出这个异常非常快，不用额外分配内存，也不用爬栈。 -XX:-OmitStackTraceInFastThrow 关闭异常堆栈优化 -Xint 以解释模式执行 加号则表示启用减号代表关闭 启动脚本里没有添加-server参数-server，在64位linux中，你想设成-client都不行的，所以写了也是白写。 在排查问题时,发现的另一个错误用法启动脚本错误: 1&gt;/dev/null 2&gt; 1 &amp; 正确 1&gt; /dev/null 2&gt;&amp;1 &amp; http://www.cnblogs.com/caolisong/archive/2007/04/25/726896.html]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
        <tag>jvm</tag>
        <tag>OmitStackTraceInFastThrow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-common]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-common%2F</url>
    <content type="text"><![CDATA[ExtensionLoader源码扩展点是Dubbo的核心，而扩展点的核心则是ExtensionLoader，这个类有点类似ClassLoader，但是ExtensionLoader是加载Dubbo的扩展点的。下面列出ExtensionLoader几个重要的属性结构。 123456789101112public class ExtensionLoader&lt;T&gt; &#123;private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;();private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; EXTENSION_INSTANCES = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;();private final Class&lt;?&gt; type;private final ExtensionFactory objectFactory;private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;Map&lt;String,Class&lt;?&gt;&gt;&gt;();private final Holder&lt;Object&gt; cachedAdaptiveInstance = new Holder&lt;Object&gt;();&#125; 可以看到EXTENSION_LOADERS属性是一个static final的，那么说明应该是一个常量，这个就是用来装载dubbo的所有扩展点的ExtensionLoader 在Dubbo中，每种类型的扩展点都会有一个与其对应的ExtensionLoader，类似jvm中每个Class都会有一个ClassLoader,每个ExtensionLoader会包含多个该扩展点的实现，类似一个ClassLoader可以加载多个具体的类，但是不同的ExtensionLoader之间是隔离的，这点也和ClassLoader类似。那么理解dubbo的ExtensionLoader可以拿ClassLoader来进行类比，这样会加快自己对它的理解。 另一个常量属性是EXTENSION_INSTANCES，他是一个具体扩展类的实体，用于缓存，防止由于扩展点比较重，导致会浪费没必要的资源，所以在实现扩展点的时候，一定要确保扩展点可单例化，否则可能会出现问题。 另一个重要的属性是type，这里的type一般是接口，用于制定扩展点的类型，因为dubbo的扩展点申明是SPI的方式，所以某一个类型扩展点，就需要申明一个扩展点接口。 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 在ExtensionLoader.getExtensionLoader(ExtensionFactory.class)之后，不是直接返回某个扩展点，而是调用getAdaptiveExtension来获取一个扩展的适配器，这是为什么呢？因为一个扩展点有多个具体扩展的实现，那么直接通过ExtensionLoader直接返回一个扩展是不可靠的，需要一个适配器来根据实际情况返回具体的扩展实现。所以这里就有了cachedAdaptiveInstance属性的存在，dubbo里面的每个扩展的ExtensionLoader都有一个cachedAdaptiveInstance，这个属性的类型必须实现ExtensionLoader.type接口，这就是设计模式中的适配器模式。比如ExtensionFactory扩展点就有AdaptiveExtensionFactory适配器。扩展点的适配器可以是自己通过@Adaptive，也可以不提供实现，由dubbo通过动态生成Adaptive来提供一个适配器类。此处需要注意：Adaptive也是扩展点的某个实现，下面例举出ExtensionFactory扩展点的适配器 cachedClasses,这个就是存储当前ExtensionLoader有哪些扩展点实现，从而可以实例化出某个具体的扩展点实体，cachedClasses声明为Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt;类型，其实可以理解为是Map&lt;String, Class&lt;?&gt;&gt;类型，Map的key是在type.getName文件中的=之前的内容，value这是这个扩展点实现的类对象了。 小结 1、一个扩展点类型一定是一个接口 2、一个扩展点一定对应一个ExtensionLoader 3、一个ExtensionLoader一定有一个Adapter 4、一个扩展点可以有多个实现，并且都是用一个ExtensionLoader进行加载 5、一个ExtensionLoader（除去ExtensionFactory扩展）都要有一个ExtensionFactory]]></content>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-filter]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-filter%2F</url>
    <content type="text"><![CDATA[dubbo中提供的Filter实现1234567891011121314echo=com.alibaba.dubbo.rpc.filter.EchoFiltergeneric=com.alibaba.dubbo.rpc.filter.GenericFiltergenericimpl=com.alibaba.dubbo.rpc.filter.GenericImplFiltertoken=com.alibaba.dubbo.rpc.filter.TokenFilteraccesslog=com.alibaba.dubbo.rpc.filter.AccessLogFilteractivelimit=com.alibaba.dubbo.rpc.filter.ActiveLimitFilterclassloader=com.alibaba.dubbo.rpc.filter.ClassLoaderFiltercontext=com.alibaba.dubbo.rpc.filter.ContextFilterconsumercontext=com.alibaba.dubbo.rpc.filter.ConsumerContextFilterexception=com.alibaba.dubbo.rpc.filter.ExceptionFilterexecutelimit=com.alibaba.dubbo.rpc.filter.ExecuteLimitFilterdeprecated=com.alibaba.dubbo.rpc.filter.DeprecatedFiltercompatible=com.alibaba.dubbo.rpc.filter.CompatibleFiltertimeout=com.alibaba.dubbo.rpc.filter.TimeoutFilter 顺序服务提供方的过滤器被调用顺序：EchoFilter-&gt;ClassLoaderFilter-&gt;GenericFilter-&gt;ContextFilter-&gt;(这4个是在代码中指定的)ExceptionFilter-&gt; TimeoutFilter -&gt;MonitorFilter-&gt; TraceFilter服务消费方的过滤器顺序：ConsumerContextFilter-&gt;FutureFilter-&gt;MonitorFilter负责加载过滤器的类ProtocolFilterWrapper 构建Filter链1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//providerpublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125;//consumerpublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); &#125;private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last; &#125; ExceptionFilter某个系统调用dubbo请求，provider端（服务提供方）抛出了自定义的业务异常，但consumer端（服务消费方）拿到的并不是自定义的业务异常。这是为什么呢？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Activate(group = Constants.PROVIDER) public class ExceptionFilter implements Filter &#123; private final Logger logger; public ExceptionFilter() &#123; this(LoggerFactory.getLogger(ExceptionFilter.class)); &#125; public ExceptionFilter(Logger logger) &#123; this.logger = logger; &#125; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; Result result = invoker.invoke(invocation); if (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; try &#123; Throwable exception = result.getException(); // 如果是checked异常，直接抛出 if (! (exception instanceof RuntimeException) &amp;&amp; (exception instanceof Exception)) &#123; return result; &#125; // 在方法签名上有声明，直接抛出 try &#123; Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes()); Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes(); for (Class&lt;?&gt; exceptionClass : exceptionClassses) &#123; if (exception.getClass().equals(exceptionClass)) &#123; return result; &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; return result; &#125; // 未在方法签名上定义的异常，在服务器端打印ERROR日志 logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + exception.getClass().getName() + &quot;: &quot; + exception.getMessage(), exception); // 异常类和接口类在同一jar包里，直接抛出 String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface()); String exceptionFile = ReflectUtils.getCodeBase(exception.getClass()); if (serviceFile == null || exceptionFile == null || serviceFile.equals(exceptionFile))&#123; return result; &#125; // 是JDK自带的异常，直接抛出 String className = exception.getClass().getName(); if (className.startsWith(&quot;java.&quot;) || className.startsWith(&quot;javax.&quot;)) &#123; return result; &#125; // 是Dubbo本身的异常，直接抛出 if (exception instanceof RpcException) &#123; return result; &#125; // 否则，包装成RuntimeException抛给客户端 return new RpcResult(new RuntimeException(StringUtils.toString(exception))); &#125; catch (Throwable e) &#123; logger.warn(&quot;Fail to ExceptionFilter when called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + e.getClass().getName() + &quot;: &quot; + e.getMessage(), e); return result; &#125; &#125; return result; &#125; catch (RuntimeException e) &#123; logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + e.getClass().getName() + &quot;: &quot; + e.getMessage(), e); throw e; &#125; &#125; &#125; http://blog.csdn.net/mj158518/article/details/51228649]]></content>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-loadbalance]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-loadbalance%2F</url>
    <content type="text"><![CDATA[负载均衡在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。 https://dubbo.gitbooks.io/dubbo-dev-book/content/impls/load-balance.html https://dubbo.gitbooks.io/dubbo-dev-book/content/impls/load-balance.html 负载均衡策略Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt; 缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt; Random试验启动两个provider,consumer新建200个线程,结果如下,总体上是平衡的 consumer程序1234567891011121314151617181920212223242526272829303132public static void main(String[] args) throws InterruptedException &#123; //Prevent to get IPV6 address,this way only work in debug mode //But you can pass use -Djava.net.preferIPv4Stack=true,then it work well whether in debug mode or not System.setProperty(&quot;java.net.preferIPv4Stack&quot;, &quot;true&quot;); ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;&quot;META-INF/spring/dubbo-demo-consumer.xml&quot;&#125;); context.start(); DemoService demoService = (DemoService) context.getBean(&quot;demoService&quot;); // get remote service proxy ExecutorService executorService = Executors.newFixedThreadPool(200); MyTask myTask = new MyTask(demoService); for (int i = 0; i &lt; 1000; i++) &#123; Thread.sleep(1000); executorService.submit(myTask); &#125; &#125; public static class MyTask implements Runnable &#123; private DemoService demoService; public MyTask(DemoService demoService) &#123; this.demoService = demoService; &#125; @Override public void run() &#123; String hello = demoService.sayHello(&quot;world&quot;); // call remote method System.out.println(hello); // get result &#125; &#125; 结果1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>loadbalance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm-jstack]]></title>
    <url>%2F2018%2F02%2F02%2Fjava_jvm%2Fjvm-jstack%2F</url>
    <content type="text"><![CDATA[jstackjstack命令的语法格式： jstack 。可以用jps查看java进程id。这里要注意的是： 不同的 JAVA虚机的线程 DUMP的创建方法和文件格式是不一样的，不同的 JVM版本， dump信息也有差别。 在实际运行中，往往一次 dump的信息，还不足以确认问题。建议产生三次 dump信息，如果每次 dump都指向同一个问题，我们才确定问题的典型性。 jstack Dump 日志文件中的线程状态dump 文件里，值得关注的线程状态有 死锁， Deadlock（重点关注） 执行中，Runnable 等待资源， Waiting on condition（重点关注） 等待获取监视器， Waiting on monitor entry（重点关注） 暂停，Suspended 对象等待中，Object.wait() 或 TIMED_WAITING 阻塞， Blocked（重点关注） 停止，Parked Dump文件中的线程状态含义及注意事项 Deadlock：死锁线程，一般指多个线程调用间，进入相互资源占用，导致一直等待无法释放的情况。 Runnable：一般指该线程正在执行状态中，该线程占用了资源，正在处理某个请求，有可能正在传递SQL到数据库执行，有可能在对某个文件操作，有可能进行数据类型等转换。 Waiting on condition：该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace来分析。最常见的情况是线程在等待网络的读写，比如当网络数据没有准备好读时，线程处于这种等待状态，而一旦有数据准备好读之后，线程会重新激活，读取并处理数据。在 Java引入 NewIO之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。 如果发现有大量的线程都在处在 Wait on condition，从线程 stack看， 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙，几 乎消耗了所有的带宽，仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒。 locked：线程阻塞，是指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源超时的线程。 Waiting for monitor entry 和 in Object.wait()：Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。 参数使用案例案例11.使用jps命令，获取需要调优的进程id为46924.2.使用top -Hp 46924命令获得最耗费资源的线程号(pid), TIME列就是各个Java线程耗费的CPU时间,这里我们选58767线程作为例子.3.使用printf “%x\n”，获得十六进制值。4.使用jstack命令，它用来输出进程46924的堆栈信息，然后根据线程ID(58767)的十六进制值grep，如下：这里就知道了最耗费时间的类是com.mchange.v2.async.ThreadPoolAsynchronousRunner$PoolThread-#2，Tomcat的线程池，方法是Object.wait()。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo线程池相关源码解析]]></title>
    <url>%2F2018%2F02%2F02%2Fjava_dubbo%2Fsource-dubbo-thread-pool%2F</url>
    <content type="text"><![CDATA[dubbo几种线程池选择http://dubbo.io/books/dubbo-user-book/demos/thread-model.htmlThreadPool fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省) cached 缓存线程池，空闲一分钟自动删除，需要时重建。 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。 读取几个参数: threads:服务线程池大小(固定大小) queues:线程池队列大小，当线程池满时，排队等待执行的队列大小，建议不要设置，当线程程池时应立即失败，重试其它服务提供机器，而不是排队，除非有特殊需求 1234567891011121314public class FixedThreadPool implements ThreadPool &#123; public Executor getExecutor(URL url) &#123; String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); int threads = url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS); int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); return new ThreadPoolExecutor(threads, threads, 0, TimeUnit.MILLISECONDS, queues == 0 ? new SynchronousQueue&lt;Runnable&gt;() : (queues &lt; 0 ? new LinkedBlockingQueue&lt;Runnable&gt;() : new LinkedBlockingQueue&lt;Runnable&gt;(queues)), new NamedThreadFactory(name, true), new AbortPolicyWithReport(name, url)); &#125;&#125; iothreads:IO线程池，接收网络读写中断，以及序列化和反序列化，不处理业务，业务线程池参见threads配置，此线程池和CPU相关，不建议配置。dubbo 中使用该参数初始化nettypublic static final int DEFAULT_IO_THREADS = Math.min(Runtime.getRuntime().availableProcessors() + 1, 32); 123456789101112131415161718192021222324252627282930313233protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(&quot;NettyServerBoss&quot;, true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(&quot;NettyServerWorker&quot;, true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(&quot;logging&quot;,new LoggingHandler(LogLevel.INFO))//for debug .addLast(&quot;decoder&quot;, adapter.getDecoder()) .addLast(&quot;encoder&quot;, adapter.getEncoder()) .addLast(&quot;handler&quot;, nettyServerHandler); &#125; &#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &#125; dubbo的线程池拒绝策略AbortPolicyWithReport: dump线程信息 打印error日志 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class AbortPolicyWithReport extends ThreadPoolExecutor.AbortPolicy &#123; protected static final Logger logger = LoggerFactory.getLogger(AbortPolicyWithReport.class); private final String threadName; private final URL url; private static volatile long lastPrintTime = 0; private static Semaphore guard = new Semaphore(1); public AbortPolicyWithReport(String threadName, URL url) &#123; this.threadName = threadName; this.url = url; &#125; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; String msg = String.format(&quot;Thread pool is EXHAUSTED!&quot; + &quot; Thread Name: %s, Pool Size: %d (active: %d, core: %d, max: %d, largest: %d), Task: %d (completed: %d),&quot; + &quot; Executor status:(isShutdown:%s, isTerminated:%s, isTerminating:%s), in %s://%s:%d!&quot;, threadName, e.getPoolSize(), e.getActiveCount(), e.getCorePoolSize(), e.getMaximumPoolSize(), e.getLargestPoolSize(), e.getTaskCount(), e.getCompletedTaskCount(), e.isShutdown(), e.isTerminated(), e.isTerminating(), url.getProtocol(), url.getIp(), url.getPort()); logger.warn(msg); dumpJStack(); throw new RejectedExecutionException(msg); &#125; private void dumpJStack() &#123; long now = System.currentTimeMillis(); //dump every 10 minutes if (now - lastPrintTime &lt; 10 * 60 * 1000) &#123; return; &#125; if (!guard.tryAcquire()) &#123; return; &#125; Executors.newSingleThreadExecutor().execute(new Runnable() &#123; @Override public void run() &#123; String dumpPath = url.getParameter(Constants.DUMP_DIRECTORY, System.getProperty(&quot;user.home&quot;)); SimpleDateFormat sdf; String OS = System.getProperty(&quot;os.name&quot;).toLowerCase(); // window system don&apos;t support &quot;:&quot; in file name if(OS.contains(&quot;win&quot;))&#123; sdf = new SimpleDateFormat(&quot;yyyy-MM-dd_HH-mm-ss&quot;); &#125;else &#123; sdf = new SimpleDateFormat(&quot;yyyy-MM-dd_HH:mm:ss&quot;); &#125; String dateStr = sdf.format(new Date()); FileOutputStream jstackStream = null; try &#123; jstackStream = new FileOutputStream(new File(dumpPath, &quot;Dubbo_JStack.log&quot; + &quot;.&quot; + dateStr)); JVMUtil.jstack(jstackStream); &#125; catch (Throwable t) &#123; logger.error(&quot;dump jstack error&quot;, t); &#125; finally &#123; guard.release(); if (jstackStream != null) &#123; try &#123; jstackStream.flush(); jstackStream.close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; lastPrintTime = System.currentTimeMillis(); &#125; &#125;); &#125;&#125; 模拟dubbo线程池满时的情景consumer程序:1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; //Prevent to get IPV6 address,this way only work in debug mode //But you can pass use -Djava.net.preferIPv4Stack=true,then it work well whether in debug mode or not System.setProperty("java.net.preferIPv4Stack", "true"); ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;"META-INF/spring/dubbo-demo-consumer.xml"&#125;); context.start(); DemoService demoService = (DemoService) context.getBean("demoService"); // get remote service proxy ExecutorService executorService = Executors.newFixedThreadPool(1000); MyTask myTask = new MyTask(demoService); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit(myTask); &#125; &#125; public static class MyTask implements Runnable &#123; private DemoService demoService; public MyTask(DemoService demoService) &#123; this.demoService = demoService; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); String hello = demoService.sayHello("world"); // call remote method System.out.println(hello); // get result &#125; &#125; provider程序:12345678910111213141516public class DemoServiceImpl implements DemoService &#123; private static final Logger logger = LoggerFactory.getLogger(DemoService.class); public String sayHello(String name) &#123; try &#123; System.out.println(Thread.currentThread().getName()); Thread.sleep(10000000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("[" + new SimpleDateFormat("HH:mm:ss").format(new Date()) + "] Hello " + name + ", request from consumer: " + RpcContext.getContext().getRemoteAddress()); return "Hello " + name + ", response form provider: " + RpcContext.getContext().getLocalAddress(); &#125;&#125; consumer日志:1234[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-39 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1562, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-30 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1561, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-59 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1560, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-57 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1559, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100 provider日志:1234567891011DubboServerHandler-192.168.0.100:20880-thread-197DubboServerHandler-192.168.0.100:20880-thread-198DubboServerHandler-192.168.0.100:20880-thread-199DubboServerHandler-192.168.0.100:20880-thread-200DubboServerHandler-192.168.0.100:20880-thread-1[02/02/18 10:53:44:044 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[0 dump的文件1-rw-r--r-- 1 victor staff 599770 2 2 13:41 Dubbo_JStack.log.2018-02-02_13:41:34 其他结论1:奇怪的现象provider启动一次,两次启动consumer,发现第二次consumer不会报错线程池满的异常 其他结论2:只有超时时间到后,才会报线程池满的异常]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>线程池</tag>
        <tag>AbortPolicy</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-Synchronized-lock]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_jvm%2Fstudy-Synchronized-lock%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728锁的实现在关于锁的面试过程中，一般主要问Synchronized和ReentrantLock的实现原理，更有甚者会问一些读写锁。场景对话：面试官：都了解Java中的什么锁？我：比如Synchronized和ReentrantLock...读写锁用的不多，就没研究了面试官：那好，你先说说Synchronized的实现原理吧我：嗯，Synchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中...&amp;&amp;@@#，（嗯，说了一大堆，面试官也没打断我）面试官：哦，嗯，理解的还挺透彻，那你说说ReentrantLock的实现吧...我：ReentrantLock是基于AQS实现的面试官：什么是AQS？我：在AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒&amp;&amp;&amp;$$（又说了一堆）面试官：能说说CAS的实现原理么？我：CAS是通过unsafe类的compareAndSwap方法实现的（心里得意的一笑）面试官：哦，好的，那你知道这个方法的参数的含义的么？我：（这是在逼我啊...努力的回想，因为我真的看过啊）我想想啊，这个方法看的时间有点久远了，第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值....（说出来之后都有点佩服自己，这个都记得，不过面试官好像还是不肯放过我...）面试官：嗯，对的，那你知道操作系统级别是如何实现的么？我：（我去你大爷...）我只记得X86中有一个cmp开头的指令，具体的我忘记了...面试官：嗯，好，你知道CAS指令有什么缺点么我：哦，CAS的缺点是存在ABA问题面试官：怎么讲？我：就是一个变量V，如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。面试官：那怎么解决？我：（有完没完了啊...我的心里是崩溃的）针对这种情况，java并发包中提供了一个带有标记的原子引用类&quot;AtomicStampedReference&quot;，它可以通过控制变量值的版本来保证CAS的正确性。本来转载自公众号 占小狼的博客作者占小狼 来自 美团点评 基础架构组 理解Java对象头与MonitorJava 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现 ACC_SYNCHRONIZED synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class Metadata Address 组成，其结构说明如下表： 其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等以下是32位JVM的Mark Word默认存储结构 由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构： 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; _WaitSet _EntryList ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因(关于这点稍后还会进行分析)，ok~，有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。 1234563: monitorenter //进入同步方法//..........省略其他 15: monitorexit //退出同步方法16: goto 24//省略其他.......21: monitorexit //退出同步方法 --抛异常时退出同步方法 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 synchronized代码块底层原理方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构(method_info Structure) 中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。下面我们看看字节码层面如何实现： 1234567891011121314151617181920212223242526272829 Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from &quot;SyncMethod.java&quot;public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10&#125;SourceFile: &quot;SyncMethod.java&quot; 从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。 Java虚拟机对synchronized的优化锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，关于重量级锁，前面我们已详细分析过，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段，这里并不打算深入到每个锁的实现和转换过程更多地是阐述Java虚拟机所提供的每个锁的核心优化思想，毕竟涉及到具体过程比较繁琐，如需了解详细过程可以查阅《深入理解Java虚拟机原理》。 偏向锁(单线程)偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。 轻量级锁(线程交替执行同步块的场合)倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁(针对线程持有锁的时间都不会太长)轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 锁消除(针对局部变量)消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 关于synchronized 可能需要了解的关键点synchronized的可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。每次重入，monitor中的计数器仍会加1。 线程中断与synchronized线程中断当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态) 除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的.应该使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。综合所述，可以简单总结一下中断两种情况，一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写： 12345678910public void run()&#123; try &#123; //判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位 while (!Thread.interrupted()) &#123; TimeUnit.SECONDS.sleep(2); &#125; &#125; catch (InterruptedException e) &#123; &#125;&#125; 中断与synchronized事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。 等待唤醒机制与synchronized所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 需要特别理解的一点是，与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。 参考http://blog.csdn.net/javazejian/article/details/72828483]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-java-lock]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_thread%2Fstudy-java-lock%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728锁的实现在关于锁的面试过程中，一般主要问Synchronized和ReentrantLock的实现原理，更有甚者会问一些读写锁。场景对话：面试官：都了解Java中的什么锁？我：比如Synchronized和ReentrantLock...读写锁用的不多，就没研究了面试官：那好，你先说说Synchronized的实现原理吧我：嗯，Synchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中...&amp;&amp;@@#，（嗯，说了一大堆，面试官也没打断我）面试官：哦，嗯，理解的还挺透彻，那你说说ReentrantLock的实现吧...我：ReentrantLock是基于AQS实现的面试官：什么是AQS？我：在AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒&amp;&amp;&amp;$$（又说了一堆）面试官：能说说CAS的实现原理么？我：CAS是通过unsafe类的compareAndSwap方法实现的（心里得意的一笑）面试官：哦，好的，那你知道这个方法的参数的含义的么？我：（这是在逼我啊...努力的回想，因为我真的看过啊）我想想啊，这个方法看的时间有点久远了，第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值....（说出来之后都有点佩服自己，这个都记得，不过面试官好像还是不肯放过我...）面试官：嗯，对的，那你知道操作系统级别是如何实现的么？我：（我去你大爷...）我只记得X86中有一个cmp开头的指令，具体的我忘记了...面试官：嗯，好，你知道CAS指令有什么缺点么我：哦，CAS的缺点是存在ABA问题面试官：怎么讲？我：就是一个变量V，如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。面试官：那怎么解决？我：（有完没完了啊...我的心里是崩溃的）针对这种情况，java并发包中提供了一个带有标记的原子引用类&quot;AtomicStampedReference&quot;，它可以通过控制变量值的版本来保证CAS的正确性。本来转载自公众号 占小狼的博客作者占小狼 来自 美团点评 基础架构组 Java 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现 ACC_SYNCHRONIZED 虚拟机位数 头对象结构 说明 32/64bit Mark Word 存储对象的hashCode、锁信息或分代年龄或GC标志等信息 32/64bit Class Metadata Address 类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例。]]></content>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo-概述]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_dubbo%2Fsource-dubbo-total%2F</url>
    <content type="text"><![CDATA[各层说明 config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封将 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 接口verion1 接口verion2 基类模板方法–&gt;链式过滤器1234567891011121314151617public abstract AbstractInvoker implements Invoker &#123; public Result invoke(Invocation inv) throws RpcException &#123; // 伪代码 active ++; if (active &gt; max) wait(); doInvoke(inv); active --; notify(); &#125; protected abstract Result doInvoke(Invocation inv) throws RpcException &#125; 123456789101112131415public abstract LimitFilter implements Filter &#123; public Result invoke(Invoker chain, Invocation inv) throws RpcException &#123; // 伪代码 active ++; if (active &gt; max) wait(); chain.invoke(inv); active --; notify(); &#125; &#125; Invoker, Exporter, InvocationHandler, FilterChain 其实都是 invoke 行为的不同阶段，完全可以抽象掉，统一为 Invoker，减少概念。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source_dubbo_invoke]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_dubbo%2Fsource-dubbo-invoke%2F</url>
    <content type="text"><![CDATA[消费方:123456789101112131415161718&quot;main@1&quot; prio=5 tid=0x1 nid=NA runnable java.lang.Thread.State: RUNNABLE at com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:69) at com.alibaba.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:142) at com.alibaba.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:73) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:74) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:53) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:47) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:52) at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:77) at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:232) at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:70) at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:51) at com.alibaba.dubbo.common.bytecode.proxy0.sayHello(proxy0.java:-1) at com.alibaba.dubbo.demo.consumer.Consumer.main(Consumer.java:35) 入口:InvokerInvocationHandlerDubboInvoker1234567891011121314151617181920212223242526272829303132333435protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); &#125; else if (isAsync) &#123; ResponseFuture future = currentClient.request(inv, timeout); RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); return new RpcResult(); &#125; else &#123; RpcContext.getContext().setFuture(null); return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, &quot;Invoke remote method timeout. method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, &quot;Failed to invoke remote method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125; &#125; 提供方1234567891011121314151617181920212223242526272829303132&quot;DubboServerHandler-192.168.1.4:20880-thread-10@3010&quot; daemon prio=5 tid=0x26 nid=NA runnable java.lang.Thread.State: RUNNABLE at com.alibaba.dubbo.demo.provider.DemoServiceImpl.sayHello(DemoServiceImpl.java:28) at com.alibaba.dubbo.common.bytecode.Wrapper1.invokeMethod(Wrapper1.java:-1) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:45) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:71) at com.alibaba.dubbo.config.invoker.DelegateProviderMetaDataInvoker.invoke(DelegateProviderMetaDataInvoker.java:48) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:52) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:61) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:74) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:41) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:77) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:71) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:131) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:99) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:168) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:50) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:79) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ChannelEventRunnable]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_map_reduce]]></title>
    <url>%2F2018%2F01%2F31%2Fdata_warehouse%2Fstudy-map-reduce%2F</url>
    <content type="text"><![CDATA[处理流程 在正式执行 Map 前，需要将输入数据进行 分片。所谓分片，就是将输入数据切分为大小相等的数据块，每一块作为单个 Map Worker 的输入被处理，以便于多个 Map Worker 同时工作。&lt; !– more –&gt; 分片完毕后，多个 Map Worker 便可同时工作。每个 Map Worker 在读入各自的数据后，进行计算处理，最终输出给 Reduce。Map Worker 在输出数据时，需要为每一条输出数据指定一个 Key，这个 Key 值决定了这条数据将会被发送给哪一个 Reduce Worker。Key 值和 Reduce Worker 是多对一的关系，具有相同 Key 的数据会被发送给同一个 Reduce Worker，单个 Reduce Worker 有可能会接收到多个 Key 值的数据。 在进入 Reduce 阶段之前，MapReduce 框架会对数据按照 Key 值排序，使得具有相同 Key 的数据彼此相邻。如果您指定了 合并操作（Combiner），框架会调用 Combiner，将具有相同 Key 的数据进行聚合。Combiner 的逻辑可以由您自定义实现。与经典的 MapReduce 框架协议不同，在 MaxCompute 中，Combiner 的输入、输出的参数必须与 Reduce 保持一致，这部分的处理通常也叫做 洗牌（Shuffle）。 接下来进入 Reduce 阶段。相同 Key 的数据会到达同一个 Reduce Worker。同一个 Reduce Worker 会接收来自多个 Map Worker 的数据。每个 Reduce Worker 会对 Key 相同的多个数据进行 Reduce 操作。最后，一个 Key 的多条数据经过 Reduce 的作用后，将变成一个值。 WordCount 操作步骤： 输入数据：对文本进行分片，将每片内的数据作为单个 Map Worker 的输入。 Map 阶段：Map 处理输入，每获取一个数字，将数字的 Count 设置为 1，并将此&lt;Word, Count&gt;对输出，此时以 Word 作为输出数据的 Key。 Shuffle &gt; 合并排序：在 Shuffle 阶段前期，首先对每个 Map Worker 的输出，按照 Key 值（即 Word 值）进行排序。排序后进行 Combiner 操作，即将 Key 值（Word 值）相同的 Count 累加，构成一个新的&lt;Word, Count&gt;对。此过程被称为合并排序。 Shuffle &gt; 分配 Reduce：在 Shuffle 阶段后期，数据被发送到 Reduce 端。Reduce Worker 收到数据后依赖 Key 值再次对数据排序。 Reduce 阶段：每个 Reduce Worker 对数据进行处理时，采用与 Combiner 相同的逻辑，将 Key 值（Word 值）相同的 Count 累加，得到输出结果。 输出结果数据。 学习资料https://help.aliyun.com/document_detail/27875.html]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source_dubbo_cluster]]></title>
    <url>%2F2018%2F01%2F31%2Fjava_dubbo%2Fsource-dubbo-cluster%2F</url>
    <content type="text"><![CDATA[cluster层在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance 各节点关系： 这里的 Invoker 是 Provider 的一个可调用 Service 的抽象，Invoker 封装了 Provider 地址及 Service 接口信息 Directory 代表多个 Invoker，可以把它看成 List&lt;Invoker&gt; ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个 Router 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选 dubbo提供的实现Failover Cluster失败自动切换，当出现失败，重试其它服务器 [^1]。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。 重试次数配置如下： 1&lt;dubbo:service retries="2" /&gt; 或 1&lt;dubbo:reference retries="2" /&gt; 或 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; Failfast Cluster快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。 Broadcast Cluster广播调用所有提供者，逐个调用，任意一台报错则报错 [^2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。 源码解析AbstractClusterInvoker的invoke方法12345678910111213141516public Result invoke(final Invocation invocation) throws RpcException &#123; checkWheatherDestoried(); LoadBalance loadbalance; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);&#125; FailoverClusterInvoker失败自动切换，当出现失败，重试其它服务器 ^1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation); int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Although retry the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot; was successful by the provider &quot; + invoker.getUrl().getAddress() + &quot;, but there have been failed providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + le.getMessage(), le); &#125; return result; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(le != null ? le.getCode() : 0, &quot;Failed to invoke the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot;. Tried &quot; + len + &quot; times of the providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + (le != null ? le.getMessage() : &quot;&quot;), le != null &amp;&amp; le.getCause() != null ? le.getCause() : le); &#125; FailbackClusterInvoker失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; checkInvokers(invokers, invocation); Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failback to invoke method &quot; + invocation.getMethodName() + &quot;, wait for retry in background. Ignored exception: &quot; + e.getMessage() + &quot;, &quot;, e); addFailed(invocation, this); return new RpcResult(); // ignore &#125;&#125; //失败重试 private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) &#123; //单例初始化一个定时任务 if (retryFuture == null) &#123; synchronized (this) &#123; if (retryFuture == null) &#123; retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // 收集统计信息 try &#123; retryFailed(); &#125; catch (Throwable t) &#123; // 防御性容错 logger.error(&quot;Unexpected error occur at collect statistic&quot;, t); &#125; &#125; &#125;, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); &#125; &#125; &#125; //将失败的调用加入到Map中 failed.put(invocation, router);&#125;//重试的Futureprivate volatile ScheduledFuture&lt;?&gt; retryFuture;private final ConcurrentMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; failed = new ConcurrentHashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;(); //真实的进行重新调用 void retryFailed() &#123; //说明没有失败任务 if (failed.size() == 0) &#123; return; &#125; //遍历失败任务 for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;( failed).entrySet()) &#123; Invocation invocation = entry.getKey(); Invoker&lt;?&gt; invoker = entry.getValue(); try &#123; invoker.invoke(invocation); failed.remove(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failed retry to invoke method &quot; + invocation.getMethodName() + &quot;, waiting again.&quot;, e); &#125; &#125;&#125; ScheduledExecutorService核心方法 schedule 接收Runnable 接收Callable scheduleAtFixedRate 基于固定时间间隔进行任务调度 固定的频率来执行某项计划，它不受计划执行时间的影响。到时间，它就执行。 每次执行时间为 :initialDelay, initialDelay+period, initialDelay+2*period, … ScheduleWithFixedDelay 基于不固定时间间隔进行任务调度 是相对任务的。即无论某个任务执行多长时间，等执行完了，我再延迟指定的时间。也就是第二个方法，它受计划执行时间的影响。 每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：initialDelay, initialDelay+executeTime+delay ScheduledExecutorService的构造方法12345public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125; ForkingClusterInvoker并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。并行调用，只要一个成功即返回，通常用于实时性要求较高的操作，但需要浪费更多服务资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private final ExecutorService executor = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;forking-cluster-timer&quot;, true));public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; checkInvokers(invokers, invocation); final List&lt;Invoker&lt;T&gt;&gt; selected; final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (forks &lt;= 0 || forks &gt;= invokers.size()) &#123; selected = invokers; &#125; else &#123; selected = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (int i = 0; i &lt; forks; i++) &#123; //在invoker列表(排除selected)后,如果没有选够,则存在重复循环问题.见select实现. Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); if(!selected.contains(invoker))&#123;//防止重复添加invoker selected.add(invoker); &#125; &#125; &#125; RpcContext.getContext().setInvokers((List)selected); final AtomicInteger count = new AtomicInteger(); //核心代码:通过阻塞队列,来收集结果 final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;Object&gt;(); for (final Invoker&lt;T&gt; invoker : selected) &#123; executor.execute(new Runnable() &#123; public void run() &#123; try &#123; Result result = invoker.invoke(invocation); ref.offer(result); &#125; catch(Throwable e) &#123; int value = count.incrementAndGet(); if (value &gt;= selected.size()) &#123; ref.offer(e); &#125; &#125; &#125; &#125;); &#125; try &#123; //只要得到一个结果,就返回 Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); if (ret instanceof Throwable) &#123; Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException)e).getCode() : 0, &quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; return (Result) ret; &#125; catch (InterruptedException e) &#123; throw new RpcException(&quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e); &#125; &#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[review-java-thread-pool]]></title>
    <url>%2F2018%2F01%2F31%2Fjava_thread%2Freview-java-thread-pool%2F</url>
    <content type="text"><![CDATA[线程池背景 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了， 频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 请求频繁，但是连接上以后读/写很少量的数据就断开连接。考虑到服务的并发问题，如果每个请求来到以后服务都为它启动一个线程，那么这对服务的资源可能会造成很大的浪费。 优点 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 核心接口ExecutorService,Executor 类 ExecutorService：真正的线程池接口。 ScheduledExecutorService:能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。 ThreadPoolExecutor:ExecutorService的默认实现。 ScheduledThreadPoolExecutor:继承ThreadPoolExecutor的- - ScheduledExecutorService接口实现，周期性任务调度的类实现。 Executors类里面提供了一些静态工厂，生成一些常用的线程池。 Executors 提供四种线程池 1）newCachedThreadPool 是一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute() 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。注意，可以使用 ThreadPoolExecutor 构造方法创建具有类似属性但细节不同（例如超时参数）的线程池。 2）newSingleThreadExecutor 创建是一个单线程池，也就是该线程池只有一个线程在工作，所有的任务是串行执行的，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 3）newFixedThreadPool 创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小，线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 4）newScheduledThreadPool 创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。 程池相关参数corePoolSize（线程池的基本大小）：当提交一个任务时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，直到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreTreads()方法，线程池就会提前创建并启动所有基本线程。 maximumPoolSize（线程最大数量）：线程池允许创建的最大线程数。如果队列已满，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。但如果使用了无界的任务队列，该参数没有效果。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。如果任务很多，且每个任务执行时间较短，可调大该值。 TimeUnit（线程活动保持时间的单位）：keepAliveTime的时间度量单位。可选天、小时、分钟、毫秒、微妙、纳秒。 BlockingQueue（任务队列）：用于保存等待执行的任务的阻塞嘟列，可以选择以下几个阻塞队列 ArrayBlockingQueue：基于数组结构的有界阻塞队列 LinkedBlockingQueue：基于链表机构的阻塞队列，吞吐量通常高于ArrayBlockingQueue，静态工厂方法Executors.newFixedThreadPool()使用该队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除，否则插入操作一直处于阻塞状态，吞吐量通常高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool()使用该队列。 PriorityBlockingQueue：具有优先级的无限阻塞队列。 ThreadFactory：创建线程的工厂。 RejectedExecutionHandler：饱和策略，即队列和线程池都满了，对于新提交的任务无法执行，这时采取的处理新来的任务的方法，有4种策略可选（也可以自定义策略—实现RejectedExecutionHandler接口，如记录日志或持久化不能处理的任务）： CallerRunsPolicy：使用调用者所在的线程来运行任务。 AbortPolicy：直接抛出RejectedExecutionException异常。（默认策略） DiscardPolicy：对新任务直接丢弃，不做任何事情 DiscardOldestPolicy：丢掉队列里最近（the oldest unhandled）的一个任务，并执行当前新任务。 线程池的关闭 ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是 shutdown() 和 shutdownNow()。 shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 核心流程 线程池规则线程池的线程执行规则跟任务队列有很大的关系。 下面都假设任务队列没有大小限制： 如果线程数量&lt;=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。 任务队列大小有限时 当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。 SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。 使用方法123456789101112131415 void execute(Runnable task) Future&lt;?&gt; submit(Runnable task) &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; 全部执行,其中一个执行结束,或异常,则取消其他Callable的运行&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合 future.isDone() //return true,false 无阻塞 future.get() // return 返回值，阻塞直到该线程运行结束 实际案例1(优化分页查询)1234567891011121314ExecutorService slaver = Executors.newSingleThreadExecutor();FutureTask&lt;List&lt;Map&lt;String, Object&gt;&gt;&gt; lastFuture = new FutureTask&lt;&gt;(countCallable);slaver.execute(lastFuture);slaver.shutdown();List&lt;Map&lt;String, Object&gt;&gt; stockFirst = jdbcTemplate.queryForList(contentSql);List&lt;Map&lt;String, Object&gt;&gt; stockLast = null;try &#123; stockLast = lastFuture.get();&#125; catch (Exception e) &#123; logger.error(&quot;错误&quot;, e);&#125; finally &#123; lastFuture.cancel(true);&#125; 实际案例2(dts抓单)123456789101112131415161718executor = new ThreadPoolExecutor(config.getMaxActive()/2+1, config.getMaxActive(), config.getTimeout4Borrow(), TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(config.getMaxActive()), this); @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; logger.error(&quot;wait too long to borrow worker: &quot; + taskOwner); try &#123; getMQService().push(getConfig().getAlertMq(), taskOwner); &#125; catch (Exception e) &#123; logger.error(&quot;mq service error: &quot;, e); &#125; logger.warn(&quot;worker &#123;&#125; need sleep &#123;&#125; millis to back to working &quot;, taskOwner, getConfig().getTimeout4Borrow()); try &#123; Thread.sleep(getConfig().getTimeout4Borrow() * 5); &#125; catch (Exception e) &#123; logger.error(&quot;thread error :&quot;, e); &#125; &#125; CompletionService接口 根据上面的介绍我们知道，现在在Java中使用多线程通常不会再使用Thread对象了。而是会用到java.util.concurrent包下的ExecutorService来初始化一个线程池供我们使用。使用ExecutorService类的时候，我们常维护一个list保存submit的callable task所返回的Future对象。然后在主线程中遍历这个list并调用Future的get()方法取到Task的返回值。 其实除了使用ExecutorService外，还可通过CompletionService包装ExecutorService，然后调用其take()方法去取Future对象。 CompletionService和ExecutorService的主要的区别在于submit的task不一定是按照加入自己维护的list顺序完成的。 ExecutorService中从list中遍历的每个Future对象并不一定处于完成状态，这时调用get()方法就会被阻塞住，如果系统是设计成每个线程完成后就能根据其结果继续做后面的事，这样对于处于list后面的但是先完成的线程就会增加了额外的等待时间。 而CompletionService的实现是维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。所以，先完成的必定先被取出。这样就减少了不必要的等待时间。 合理的配置线程池要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析： 任务的性质：CPU密集型任务，IO密集型任务和混合型任务。任务的优先级：高，中和低。任务的执行时间：长，中和短。任务的依赖性：是否依赖其他系统资源，如数据库连接。任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能小的线程，如配置Ncpu+1个线程的线程池。IO密集型任务则由于线程并不是一直在执行任务，则配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。 建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 taskCount：线程池需要执行的任务数量。completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不+ getActiveCount：获取活动的线程数。通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如： SingleThreadExecutorCachedThreadPool可缓存线程池： 线程数无限制 有空闲线程则复用空闲线程，若无空闲线程则新建线程 一定程序减少频繁创建/销毁线程，减少系统开销 ①使用无容量队列SynchronousQueue，但maxmumPoolSize无界。如果提交任务的速度大于线程处理任务的速度，将会不断创建新线程，极端情况会因为创建过多线程而耗尽CPU资源。②keepAliveTime为60s，空闲线程超过该时间将会终止。③执行完任务的某线程会执行SynchronousQueue.poll()从队列中取任务，这个取的动作会持续60s，如果在60s内有新的任务，则执行新的任务，没有任务则终止线程。因此长时间保持空闲的CachedThreadPool不会占用任何资源。④当有任务提交时，a.如果当前线程池为空或者已创建的线程都正在处理任务，则CachedThreadPool会创建新线程来执行该任务。b.如果当前线程池有空闲的线程（正在执行阻塞方法SynchronousQueue.poll()），则将任务交给该等待任务的空闲线程来执行。 CachedThreadPool适用于执行很多的短期异步任务的小程序或者是负载较轻的服务器。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; FixedThreadPool定长线程池： 可控制线程最大并发数（同时执行的线程数） 超出的线程会在队列中等待12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 排队策略直接提交工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 无界队列使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 有界队列当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 拒绝策略:RejectedExecutionHandler接口提供了对于拒绝任务的处理的自定方法的机会。在ThreadPoolExecutor中已经默认包含了4中策略 CallerRunsPolicy： 线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。 AbortPolicy： 处理程序遭到拒绝将抛出运行时 RejectedExecutionException 这种策略直接抛出异常，丢弃任务。 DiscardPolicy： 不能执行的任务将被删除 这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。 DiscardOldestPolicy： 如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。 设想:如果其他线程都还在运行，那么新来任务踢掉旧任务，缓存在queue中，再来一个任务又会踢掉queue中最老任务。 源码解析构造方法123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; ctl是ThreadPoolExecutor的一个重要属性，它记录着ThreadPoolExecutor的线程数量和线程状态。 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); Integer有32位，其中前三位用于记录线程状态，后29位用于记录线程的数量。那线程状态有哪些呢？1234567891011121314151617181920212223//线程数量占用的位数private static final int COUNT_BITS = Integer.SIZE - 3;//最大线程数private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctl//状态值就是只关心前三位的值，所以把后29位清0private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;//线程数量就是只关心后29位的值，所以把前3位清0private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;//两个数相或private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 通常你得到线程池后，会调用其中的：submit方法或execute方法去操作；其实你会发现，submit方法最终会调用execute方法来进行操作，只是他提供了一个Future来托管返回值的处理而已，当你调用需要有返回值的信息时，你用它来处理是比较好的；这个Future会包装对Callable信息，并定义一个Sync对象（），当你发生读取返回值的操作的时候，会通过Sync对象进入锁，直到有返回值的数据通知，具体细节先不要看太多，继续向下： 123456public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 我们从上面的execute代码中可以看到，当提交一个任务时，当前线程数小于corePoolSize核心线程数的时候，就新添加一个线程，即addWorker(command, true)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; addWorker有2种情况，一种就是线程数量不足核心线程数，另一种就是核心线程数已满同时任务队列已满但是线程数不足最大线程数。上述boolean core就是用来区分上述2种情况的。 addWorker首先就要对线程数量自增，即ctl的后29为进行自增。这里就涉及到多线程问题，为了解决多线程问题就采用了for循环加CAS来解决，为什么没有直接用AtomicInteger的incrementAndGet？ incrementAndGet也是内部for循环加CAS，它是要确保一定要自增成功的，而这里我们不一定要自增成功，还要判断当前线程的数量合不合法。 即如果core=true,则当前线程数量不能超过incrementAndGet，如果core=false，则当前线程数量不能超过maximumPoolSize。 如果当前线程数自增成功，下面就需要创建出Worker线程，存放到workers中，如下所述1private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 我们知道HashSet的内部实现就是通过HashMap来实现的，HashMap是线程不安全的，所以在对workers操作的时候必须要要进行加锁，这就用到了ThreadPoolExecutor的mainLock了 一旦worker新增成功就直接启动该Worker内部的线程。一旦worker新增失败则调用addWorkerFailed处理失败逻辑 创建出Worker对象时，内部分配的线程Thread为空，这个线程的创造是由线程工厂ThreadFactory负责的创造的，可能为null 在获取mainLock之后，发现当前线程池已被标记成大于SHUTDOWN状态、或者是SHUTDOWN但是firstTask不为null。当线程状态大于SHUTDOWN，当然addWorker要失败。后者怎么解释呢？这里就要详细解释下SHUTDOWN状态SHUTDOWN即不再接收新的task，但是可以继续处理队列中的task。当线程数小于核心线程数的时候，提交的task作为新创建的Worker的firstTask，即firstTask不为null。当线程数大于核心线程数后，此时addWorker中创建的Worker的firstTask就是null,它只负责从队列中取出任务。所以firstTask不为null的时候就表明是新提交的任务，SHUTDOWN状态下是不允许新提交任务的，所以这种情况也要失败123456789101112private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; Worker解析 12345678910111213141516private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; Worker是ThreadPoolExecutor的内部类Worker继承了AQS即AbstractQueuedSynchronizer，用于实现锁的机制，这里先抛出一个问题：为什么要继承AQS实现了Runnable接口，则该Worker就可以作为Thread的参数创建出Thread，线程的运行即运行该Worker的run方法，该方法中会不断的从队列中取出任务并执行我们来详细看下Worker的run过程12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask逻辑，我们从上面看到while循环中一旦getTask为null就直接退出while循环了，即Worker走向结束了，所以空闲的时候会阻塞在getTask中，一直等到获取到task或者超时。 为什么每次执行task都要获取锁 worker的退出，就不再详细说明了，各位可自行研究 getTask逻辑123456789101112131415161718192021222324252627282930313233343536373839404142private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; boolean timed; // Are workers subject to culling? for (;;) &#123; int wc = workerCountOf(c); timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) break; if (compareAndDecrementWorkerCount(c)) return null; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 从workQueue队列中获取task有2种方法，一种就是阻塞式获取直到有task任务，另一种就是阻塞一定时间，超时则就直接返回null了。此时返回null意味着Worker就要走向结束了。 当allowCoreThreadTimeOut=true即核心线程也开始timeout计时，或者wc &gt; corePoolSize即当前线程数超过了核心线程数也要开启计时，获取task就采用阻塞一定时间获取，一旦超时即该Worker在keepAliveTime时间内都没获取到task即处于空闲状态，这时候就返回null，即意味着该Worker就走向结束了 其他情况就是不用进行线程空闲计时，即可以一直阻塞直到有task来。 接下来一个重点问题就是每次执行task的时候为什么要先获取锁？ 首先该Worker的run方法只可能被一个线程来运行，即该Worker的run方法不可能出现多线程同时运行的情况。那就是Worker有一些资源是多个线程共享的，是什么呢？我们先来看看Worker继承AQS即AbstractQueuedSynchronizer的实现情况123456789101112131415161718protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false;&#125;protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true;&#125;public void lock() &#123; acquire(1); &#125;public boolean tryLock() &#123; return tryAcquire(1); &#125;public void unlock() &#123; release(1); &#125;public boolean isLocked() &#123; return isHeldExclusively(); &#125; 这里就是一个简单的独占锁，但是重点是不可重入的，重入即当前线程获取锁了，还可以再次获取锁，来简单对比下重入锁的实现12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 也就是说Worker本身就是一个简单的独占锁，并且是不可重入的。这个锁的引入到底是为了什么呢？为什么需要在每个task执行前都要获取这个锁呢？这个当时也没太理解，但是要想找出这个原因，可以有如下思路来找： 就看看哪些地方在调用Worker获取锁的方法，获取锁的方法有lock、tryLock 最终发现interruptIdleWorkers会调用tryLock方法，如下：123456789101112131415161718192021private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; 该方法就是用于中断那些空闲的Worker，怎么判断一个Worker是否空闲呢？这里就是使用w.tryLock()是否能获取锁来表示一个Worker是否空闲。当Worker在处理任务的时候即不空闲都会获取lock，所以这里就是依据Worker的锁是否被占用了来判定一个Worker是否空闲。 如当重新设置一个ThreadPoolExecutor的核心线程数的时候，如果当前线程数大于了新设置的核心线程数，就需要中断那些空闲的线程12345678910111213141516171819public void setCorePoolSize(int corePoolSize) &#123; if (corePoolSize &lt; 0) throw new IllegalArgumentException(); int delta = corePoolSize - this.corePoolSize; this.corePoolSize = corePoolSize; if (workerCountOf(ctl.get()) &gt; corePoolSize) interruptIdleWorkers(); else if (delta &gt; 0) &#123; // We don&apos;t really know how many new threads are &quot;needed&quot;. // As a heuristic, prestart enough new workers (up to new // core size) to handle the current number of tasks in // queue, but stop if queue becomes empty while doing so. int k = Math.min(delta, workQueue.size()); while (k-- &gt; 0 &amp;&amp; addWorker(null, true)) &#123; if (workQueue.isEmpty()) break; &#125; &#125;&#125; 参考https://my.oschina.net/pingpangkuangmo/blog/668520]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-study-BlockingQueue]]></title>
    <url>%2F2018%2F01%2F29%2Fjava_data_structure%2Fstudy-java-queue%2F</url>
    <content type="text"><![CDATA[BlockingQueue 阻塞队列 先进先出 有边界:当队列满时,插入的元素的线程会等待队列可有 等待队列为非空 生产者消费者&lt; !– more –&gt; 阻塞队列的主要功能并不是在于提升程序高并发时队列的性能，而是在于简化多线程间的数据共享（用于多线程间的数据传递）。 五种类ArrayBlockingQueue 有界。ArrayBlockingQueue是基于数组实现的有界阻塞队列；其能容纳的元素数量固定，一旦创建，就不能再增加其容量； FIFO。队列的获取操作作用于队列头部，添加操作作用于队列尾部，满足FIFO特性； 自动阻塞唤醒。试图向已满队列放入元素将导致操作阻塞，试图从空队列中获取元素同样将导致操作阻塞等待。 LinkedBlockingQueue 有界，也可认为是无界。LinkedBlockingQueue是基于链表实现的阻塞队列；如果在构造函数不指定容量，则默认为一个类似无限大小的容量，大小为Integer.MAX_VALUE，在此种情况下，如果生产者速度远远大于消费者速度，由于容量很大，那么系统内存有可能会被消耗殆尽；如果在构造函数指定了容量大小，则队列容纳的元素数量固定。 FIFO。队列的获取操作作用于队列头部，添加操作作用于队列尾部，满足FIFO特性 自动阻塞唤醒。put操作试图向已满队列放入元素将导致操作阻塞，直到其他线程从队列中获取元素，队列出现空闲后再唤醒操作；take操作试图从空队列中获取元素同样将导致操作阻塞等待，直到其他线程从队列中添加元素，队列中存在元素后再唤醒操作。 锁分离机制。对添加数据的操作与获取数据的操作分别采用了独立的、不同的锁来控制数据同步（ArrayBlockingQueue采用了同一把锁），即在高并发的情况下生产者和消费者可以并行的操作队列中的数据，进而提高整个队列的并发性能。 PriorityBlockingQueuePriorityBlockingQueue又称为优先级阻塞队列。其特性如下： 无界。由于容量不存在限制(最大为Integer.MAX_VALUE - 8，可基本认为是无限制)，队列就不会阻塞生产者，因为只要能生产数据，就可以把数据放入队列中；如果生产者速度远远大于消费者速度，由于容量无限，那么系统内存有可能会被消耗殆尽。 元素必须实现Comparable接口。在实现的CompareTo方法中，如果返回值为负数，则表明当前对象this的优先级越高；返回值为正数，则表明当前对象this的优先级越低。 实现了有序列表。优先级的判断通过构造函数传入的Compator对象实现队列元素的自定义排序；如果Compator为空，则按对象的比较方法进行排序。队列中元素的优先级依次降低，优先级最高的排在队首。默认情况下元素采取自然顺序排序，也可以通过比较器comparator来指定元素的排序规则。 仅阻塞消费者。当队列中无数据时，会阻塞消费者。 DelayQueueDelayQueue又称为延时队列。一个使用优先级队列（PriorityQueue）实现的无界阻塞队列。其特性如下： 队列容量无界；不能存放null元素。 元素必须同时实现Delayed接口与Comparable接口。元素所属类中必须实现public int compareTo(To)和long getDelay(TimeUnit unit)方法。其中，Delayed接口继承了Comparable接口，因此必须实现compareTo方法；在public int compareTo(To)方法中，如果当前对象的延迟值小于参数对象的值，将返回一个小于0的值；如果当前对象的延迟值大于参数对象的值，将返回一个大于0的值；如果两者的延迟值相等则返回0。该队列的头部是延迟期满后保存时间最长的 Delayed 元素（也就是保证先过期的元素排在头部）。如果延迟都还没有期满，则队列头部不会被返回，即队列的 poll 方法将返回null。 long getDelay(TimeUnit unit)方法中，是返回到激活日期的剩余时间；当返回值为0或者负数时，表面该元素已经可以被获取了；单位由单位参数指定。TimeUnit类是一个由下列常量组成的枚举类型：DAYS、HOURS、MICROSECONDS、MILLISECONDS、MINUTES、NANOSECONDS和SECONDES。 只有在延迟期满时才能从队列中提取元素；Delayed接口使得对象成为了延迟对象，它使得队列中的元素对象具有了延迟期。由于DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作永远不会被阻塞，而只有获取数据的操作才会被阻塞。适用场景： 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从队列中获取元素时候，表示缓存有效期到了。 定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间。一旦从队列中获取到任务就开始执行，比如TimerQueue就是用DelayQueue实现的。 SynchronousQueueSynchronousQueue又称为同步队列。一个不存储元素的阻塞队列。其特性如下： 是一个无缓冲的等待队列。队列本身不存储任何元素，每一个put操作必须等待一个take操作，否则不能继续添加元素。 支持公平与非公平两种操作模式。如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，体现了“先来先服务，后来则排队”的公平策略；如果采用非公平模式（SynchronousQueue默认选项），则配合一个LIFO队列来管理多余的生产者和消费者，体现了“无视当前排队，即来即抢占服务”的不公平策略，但是，在该种模式下，如果生产者和消费者的处理速度有差距，可能有某些生产者或者消费者永远都得不到处理（因为一直被抢占，一直被欺负）。 与其他阻塞队列不同，其他阻塞队列维护的是一组元素，SynchronousQueue则是维护了两组线程（一组生产者线程，一组消费者线程），实现两者之间的数据传递。举个列子，有A、B两位同事，A需要将一些资料交给B。如果是A把文件直接交到B手中，那么就是SynchronousQueue实现模式；如果A通过发邮件的形式把资料给B，那么就是其他阻塞队列的实现模式。 SyncchronousQueue吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。 适用场景：创建线程池。 LinkedTransferQueueLinkedTransferQueue又称为链表传输队列。一个由链表结构组成的无界阻塞队列。其特性如下： 一个无界队列。 具备FIFO特性。 特别的阻塞：LinkedTransferQueue实现了TransferQueue接口，TransferQueue又继承了BlockingQueue；这两个接口的区别在于：BlockingQueue：当生产者向满队列添加元素时则会被阻塞；当消费者从空队列中获取元素时则会被阻塞；TransferQueue：相比于BlockingQueue，生产者会一直阻塞直到所添加到队列的元素被某一个消费者所消费（不只是把元素添加到队列中），其接口中的transfer方法实现了该功能。顾名思义，就是发生在元素从一个线程transfer到另一个线程的过程中，它有效地实现了元素在线程之间的传递（以建立Java内存模型中的happens-before关系的方式）。 适用场景：生产者-消费者高并发的业务场景。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[data-Archiving-research]]></title>
    <url>%2F2018%2F01%2F25%2Fegenie_business%2Fdata-archiving-research%2F</url>
    <content type="text"><![CDATA[归档目的 主要处于性能考虑,减少查找的范围 归档需求 同时要求系统中可以查询到之前的数据,不能归档到非结构化系统中 要求条件需要多表进行关联,并添加自定义条件,保证业务 要求主子表归档具有一致性,主子表不能分离 已经归档过一次 稳定性 可追溯 数据一致性 定时自动执行 跨数据库,最好支持到不同的数据源 &lt; !–more–&gt; 归档流程梳理 复制指定条件的旧数据 删除旧数据(是否需要人工介入?)后续自动 读取归档数据 归档方案思路:1.建立归档表_archive这种方式是通过建立一个以_archive结尾的归档表来实施的。如果使用这种方式，那么一般需要在业务层进行查询的分离改造，比如基于我们的特定归档规则 ，对业务端核心代码改造或者使用proxy方案等来决定是使用主表还是归档表。同时我们还需要一个数据归档过程，当数据过时或者变成冷数据时，将该数据从主表迁移到归档表中。 在业务层查询时，我们可以通过时间字段来进行查询判断，例如将90天之前的数据在归档表中查询，否则就在主表查询。另一种方式可以通过增加status列去判断查询主表还是归档表，如果是inactive则查询归档表，否则就在主表查询。 mysql分区为了让优化器能将查询发送到正确的分区键，在创建分区表的时候，我们需要将分区键添加到主键里，并且理想情况下，该分区键能被包含在所有select/update/delete等语句的where条件里面，否则的话，你的查询将会按照顺序查找表对应的每个分区，这种情况下查询性能就没有那么好了。 根据日期进行分区这种方式是通过对表进行分区来实现，虽然这是一种不同的物理数据模型，但是确实有助于将表的数据进行拆分到不同的物理磁盘，并且不需要代码的任何改造。作为DBA，一般对表进行分区是比较常用的方式，我们可以通过日期字段很容易确定哪些是冷数据，并根据日期将不同日期的时间分配到不同的分区中，在查询的时候，我们可以通过日期来从分区中快速定位到对应的数据，同时建立分区表也比较利于DBA对大表进行管理操作。 我们根据数据行的创建时间，按年将数据放入到不同的分区，这里需要注意的是在2020年以后，我们还需要在表里添加新的年份，当然我们可以提前加更多的分区或者部署脚本来自动化创建新的分区。 通过状态进行分区我们也可以通过status状态列来进行分区，这种情况下，通常状态列会包含active/inactive两种状态，然后通过update进行状态列的更新（使用replace或者insert+delete也是可以的），将数据放入到正确的分区当中。请看下面的示例 通过ID进行分区具体方案复制表并且按照条件插入数据（此种方法除了主键索引不包括其他索引）–&gt;手动sqlhttp://blog.csdn.net/bluestarf/article/details/49641047 123CREATE TABLE lime_survey_549656_20151001 as select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; ALTER TABLE lime_survey_549656_20151001 change id id int primary key auto_increment; 创建一张空表，结构和索引和原表一样 –&gt;手动sql12create table lime_survey_549656_20151001 like lime_survey_549656; INSERT INTO lime_survey_549656_20151001 select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; 存储过程来归档问题无法跨数据库备份 分区实现问题 表中有全文索引,无法分区 分区的话,需要修改业务sql,改动较大–&gt;待确定 pt-archvier(mysql percona工具集) 基础教程 https://yq.aliyun.com/articles/277145 是否可归档多表 https://www.percona.com/forums/questions-discussions/percona-toolkit/32449-pt-archiver-multiple-dependent-tables 可以多表条件,但是无法如果中途失败,无法继续归档 https://stackoverflow.com/questions/47203831/turn-mysql-query-into-percona-pt-archiver-string mysql_archiver (python实现+pt-archvier)https://github.com/dbarun/mysql_archiver MySQL_archiver基本上实现了数据归档的自动运转，统一的归档任务调度管理、自动监控和预警、自动生成报表。在一定程度上节约了生产力，提高了运维效率。 要知道每个归档任务成功与否、跑了多长时间、归档了多少数据JavaDataArchiver (java实现)https://github.com/Sunshow/JavaDataArchiver 问题下载源码后,发现未实现 阿里云maxcompute优点相对稳定,成本低,多数据源,可视化直接操作,无需开发,只需要配置 问题 多表之间的id无法直接传递,需要使用join 同时过滤主表和字表的条件,例如sale_order和sale_order_detail(严重) 0226 delete的条件传递 in (ids) delete的效率问题(性能) 0226 是否需要跨数据库备份 阿里云maxcompute+归档字段 先多表关联,将要归档的记录设置上需归档的状态 各表根据归档状态,单标归档 删除原表 问题数据量太大,可能update会锁表 阿里云maxcompute+归档记录 先多表关联,将要归档的记录设置上需归档的状态 各表根据归档状态,单标归档 删除原表 问题待试验 外部程序实现结论 使用: mysql_archiver !!!!!!后续开发读取归档数据,同时不能影响生产库的性能(最好先定下来,否则目标 会不是mysql) target 也需要分区 目标库选择 nogsql mysql my maxcompute 废弃分表策略,对于v_sale_order和v_sale_order_detail结论 采用阿里云数据集成,跑归档任务 在数据集成任务结束后的回调函数,可以配置删除归档数据的任务 暂时目标库,还是mysql,后续的查询采用ElasticSearch进行查询,(阿里云提供1个月的免费试用,待研究确认后执行)]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-java-thread-local]]></title>
    <url>%2F2018%2F01%2F24%2Fjava_thread%2Fstudy-java-thread-local%2F</url>
    <content type="text"><![CDATA[Thread Local的作用提供了一种将实例绑定到当前线程的机制，类似于隔离的效果. SoftReference、Weak Reference和PhantomRefrence强引用默认1234Object o=new Object(); Object o1=o;o=null;o1=null; 如果显式地设置o和o1为null，或超出范围，则gc认为该对象不存在引用，这时就可以收集它了。可以收集并不等于就一会被收集，什么时候收集这要取决于gc的算法，这要就带来很多不确定性。 其他12345String abc=new String(&quot;abc&quot;); //1 SoftReference&lt;String&gt; abcSoftRef=new SoftReference&lt;String&gt;(abc); //2 WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(abc); //3 abc=null; //4 abcSoftRef.clear();//5 上面的代码中： 第一行在heap对中创建内容为“abc”的对象，并建立abc到该对象的强引用,该对象是强可及的。 第二行和第三行分别建立对heap中对象的软引用和弱引用，此时heap中的对象仍是强可及的。 第四行之后heap中对象不再是强可及的，变成软可及的。同样第五行执行之后变成弱可及的。 软引用被 Soft Reference 指到的对象，即使没有任何 Direct Reference，也不会被清除。一直要到 JVM 内存不足且 没有 Direct Reference 时才会清除 SoftReference 是用来设计 object-cache 之用的。如此一来 SoftReference 不但可以把对象 cache 起来，也不会造成内存不足的错误 （OutOfMemoryError）。我觉得 Soft Reference 也适合拿来实作 pooling 的技巧。 如果一个对象只具有软引用，那就类似于可有可物的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 软引用可以加速JVM对垃圾内存的回收速度 , 维护系统的运行安全 , 防止产生内存溢出的问题 弱引用可以用来观察是否被gc掉 gc收集弱可及对象的执行过程和软可及一样，只是gc不会根据内存情况来决定是不是收集该对象。 如果你希望能随时取得某对象的信息，但又不想影响此对象的垃圾收集，那么你应该用 Weak Reference 来记住此对象，而不是用一般的 reference。 如果一个对象只具有弱引用，那就类似于可有可物的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 12C c = new C(b);b = null; 当 b 被设置成null时，那么是否意味这一段时间后GC工作可以回收 b 所分配的内存空间呢？答案是否定的，因为即使 b 被设置成null，但 c 仍然持有对 b 的引用，而且还是强引用，所以GC不会回收 b 原先所分配的空间，既不能回收，又不能使用，这就造成了 内存泄露。可以通过c = null;，也可以使用弱引用WeakReference w = new WeakReference(b);。因为使用了弱引用WeakReference，GC是可以回收 b 原先所分配的空间的。如果是强引用,且thread依旧存活, Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 永远无法回收，造成内存泄漏。ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 虚引用 “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解 被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 方法123456789101112131415161718192021222324252627282930public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 内部结构存储在Thread中的 java.lang.ThreadLocal.ThreadLocalMap类型的内部成员变量其中 的Entry是弱引用: static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; ThreadLocal为什么使用WeakReference ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏（参考ThreadLocal 内存泄露的实例分析）。 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 如果使用强引用则会,不remove,一直引用着key无法回收掉 第一步WeakReference弱引用,的使得ey可以被回收为null 在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value 但是如果不get(),set(),remove()就会出问题 so: 弱引用,解决了无其他引用时,有get(),set(),remove()调用的问题 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 即使设计上最大程度上减少了内存泄漏发生的概率,但是仍然不能100%保证,还是得靠程序员来协调]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql下划线关键字]]></title>
    <url>%2F2018%2F01%2F24%2Fmysql%2Fmysql-debug%2F</url>
    <content type="text"><![CDATA[问题sql1234567 SELECT *FROM v_sale_orderWHERE 1 = 1 AND v_sale_order.is_usable = 1 AND v_sale_order.tenant_id = 100046 AND 1 = 1 AND archive_state IN (0, 1) AND# v_sale_order.buyer_nick LIKE '肆无忌惮演江山%' v_sale_order.buyer_nick LIKE 't_150175568%'ORDER BY v_sale_order.last_update_time DESC; 如果查询内容带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsosrefidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_idIDX_original_order_id6const,const837216Using where; Using filesort1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sos.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsorrefidx_sale_order_id,idx_buyer_nickidx_sale_order_id9egenie_kn.sos.sale_order_id1Using where1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL 如果查询内容不带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsorrangeidx_sale_order_id,idx_buyer_nickidx_buyer_nick303NULL7Using index condition; Using where; Using temporary; Using filesort1SIMPLEsoseq_refidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_ididx_sale_order_id8egenie_kn.sor.sale_order_id1Using where1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sor.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL 原因 %代表任意多个字符 _代表一个字符 如果想搜索 _ 就要用到转义符 “\” 解决1value = value.replaceAll("\\_", "\\\\_");]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>like</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_quick_sort]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_sort%2Fstudy-quick-sort%2F</url>
    <content type="text"><![CDATA[视频地址:https://visualgo.net/en/sorting 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class QuickSort &#123; public static void main(String[] args) throws Exception &#123; int[] ints = &#123;5, 3, 9, 1, 6, 7, 2, 4, 0, 8&#125;; int[] result = new QuickSort().sort(ints); System.out.println(Arrays.toString(result)); &#125; public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); return quickSort(arr, 0, arr.length - 1); &#125; private int[] quickSort(int[] arr, int left, int right) &#123; if (left &lt; right) &#123; int partitionIndex = partition(arr, left, right); System.out.println(partitionIndex); quickSort(arr, left, partitionIndex - 1); quickSort(arr, partitionIndex + 1, right); &#125; return arr; &#125; private int partition(int[] arr, int left, int right) &#123; // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) &#123; if (arr[i] &lt; arr[pivot]) &#123; swap(arr, i, index); index++; &#125; &#125; swap(arr, pivot, index - 1); return index - 1; &#125; private void swap(int[] arr, int i, int j) &#123; if (i == j) &#123; return; &#125; System.out.println(&quot;swap&quot; + i + &quot;----&quot; + j); int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(原理篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_spring%2Fstudy-springboot-springmvc%2F</url>
    <content type="text"><![CDATA[springboot如何配置DispatcherServlet?org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration中完成的 在springboot项目中,进行springmvc配置的新的方式12345678910111213141516171819202122232425@Configurationpublic class SpringMvcConfigure extends WebMvcConfigurerAdapter &#123; @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(&quot;/WEB-INF/jsp/&quot;); viewResolver.setSuffix(&quot;.jsp&quot;); // viewResolver.setViewClass(JstlView.class); // 这个属性通常并不需要手动配置，高版本的Spring会自动检测 return viewResolver; &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new Interceptor1()).addPathPatterns(&quot;/**&quot;); registry.addInterceptor(new Interceptor2()).addPathPatterns(&quot;/users&quot;).addPathPatterns(&quot;/users/**&quot;); super.addInterceptors(registry); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; // addResourceHandler指的是访问路径，addResourceLocations指的是文件放置的目录 registry.addResourceHandler(&quot;/**&quot;).addResourceLocations(&quot;classpath:/res/&quot;); &#125;&#125; HTTP序列化/反序列化@RestController中有@ResponseBody，可以帮我们把User序列化到resp.body中。@RequestBody可以帮我们把req.body的内容转化为User对象。如果是开发Web应用，一般这两个注解对应的就是Json序列化和反序列化的操作。这里实际上已经体现了Http序列化/反序列化这个过程，只不过和普通的对象序列化有些不一样，Http序列化/反序列化的层次更高，属于一种Object2Object之间的转换。 有过Netty使用经验的对这个应该比较了解，Netty中的Decoder和Encoder就有两种基本层次，层次低的一种是Byte Message，二进制与程序内部消息对象之间的转换，就是常见的序列化/反序列化；另外一种是 Message Message，程序内部对象之间的转换，比较高层次的序列化/反序列化。 Http协议的处理过程，TCP字节流 HttpRequest/HttpResponse 内部对象，就涉及这两种序列化。在springmvc中第一步已经由Servlet容器（tomcat等等）帮我们处理了，第二步则主要由框架帮我们处理。上面所说的Http序列化/反序列化就是指的这第二个步骤，它是controller层框架的核心功能之一，有了这个功能，就能大大减少代码量，让controller的逻辑更简洁清晰，就像上面示意的代码那样，方法中只有一行代码。 spirngmvc进行第二步操作，也就是Http序列化和反序列化的核心是HttpMessageConverter。用过老版本springmvc的可能有些印象，那时候需要在xml配置文件中注入MappingJackson2HttpMessageConverter这个类型的bean，告诉springmvc我们需要进行Json格式的转换，它就是HttpMessageConverter的一种实现。 几种实现 json:gson,fastjson,jackson Protobuf java序列化 HttpMessageConverter优先级另外有很重要的一点需要说明一下，springmvc可以同时配置多个Converter，根据一定的规则（主要是Content-Type、Accept、controller方法的consumes/produces、Converter.mediaType以及Converter的排列顺序这四个属性）来选择到底是使用哪一个，这使得springmvc能够一个接口支持多种报文格式。 默认的converters12345678910ByteArrayHttpMessageConverter – converts byte arraysStringHttpMessageConverter – converts StringsResourceHttpMessageConverter – converts org.springframework.core.io.Resource for any type of octet streamSourceHttpMessageConverter – converts javax.xml.transform.SourceFormHttpMessageConverter – converts form data to/from a MultiValueMap&lt;String, String&gt;.Jaxb2RootElementHttpMessageConverter – converts Java objects to/from XML (added only if JAXB2 is present on the classpath)MappingJackson2HttpMessageConverter – converts JSON (added only if Jackson 2 is present on the classpath)MappingJacksonHttpMessageConverter – converts JSON (added only if Jackson is present on the classpath)AtomFeedHttpMessageConverter – converts Atom feeds (added only if Rome is present on the classpath)RssChannelHttpMessageConverter – converts RSS feeds (added only if Rome is present on the classpath) 源码中的调用栈1234567891011com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter.write(FastJsonHttpMessageConverter.java:185) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:231) at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:203) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:81) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:113) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at 常见的contentType 1.text/html 2.text/plain 3.text/css 4.text/javascript 5.application/x-www-form-urlencoded 6.multipart/form-data 7.application/json 8.application/xml]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(实战篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_common%2Fstudy-fastjson-formatter%2F</url>
    <content type="text"><![CDATA[背景老的方式:controller的参数与返回值123456public JsonResult queryDrillDetail(@RequestBody String body) &#123;List&lt;Map&lt;String, Object&gt;&gt; detailMapList = new ArrayList&lt;&gt;();.......return new JsonResult(JsonResult.SUCCESSFUL, new PagedList&lt;&gt;(query.getPage() + 1, pageable.getPageSize(), query.getTotalCount(), detailMapList));&#125; 老的方式:问题 入参不明确 返回值类型不明确 Map的key只有在运行时,才会知道,且不知道类型 期望的方式:使用vo改造步骤:1.在使用converters的最后一个优先级,添加FastJsonHttpMessageConverter 1234567891011121314@Componentpublic class MyWebAppConfigurer extends WebMvcConfigurerAdapter &#123; // 添加converter的第三种方式 // 同一个WebMvcConfigurerAdapter中的configureMessageConverters方法先于extendMessageConverters方法执行 // 可以理解为是三种方式中最后执行的一种，不过这里可以通过add指定顺序来调整优先级，也可以使用remove/clear来删除converter，功能强大 // 使用converters.add(xxx)会放在最低优先级（List的尾部） // 使用converters.add(0,xxx)会放在最高优先级（List的头部） @Override public void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; converters.add(new FastJsonHttpMessageConverter()); &#125;&#125; 2.model遵循老的接口原则,转为下划线分割的 1234567891011@JSONType(naming = PropertyNamingStrategy.SnakeCase)public class PurchaseDetailDrillVo &#123; private Long pmsPurchaseOrderId; private Long pmsPurchaseOrderDetailId; private String pmsPurchaseOrderNo; private Integer productType; private String deliverAddress; private Long provinceId; ....&#125; 3.使用@RequestBody注解,类型改为vo 测试,接受参数和返回参数都是vo,而接口的字段映射依然为下划线, 以下为项目本身的问题4.pom文件中排除jackson的依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;com.ejlerp&lt;/groupId&gt; &lt;artifactId&gt;ejlerp-common&lt;/artifactId&gt; &lt;version&gt;3.2.0-SNAPSHOT&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 5.fastjason默认支持所有的contentType,及*, 与springmvc校验相冲突,so需要声明fastjason能支持的contentType,在初始化FastJsonHttpMessageConverter,注入参数1234567891011@Overridepublic void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); ArrayList&lt;MediaType&gt; supportedMediaTypes = Lists.newArrayList(); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_PLAIN); fastJsonHttpMessageConverter.setSupportedMediaTypes(supportedMediaTypes); converters.add(fastJsonHttpMessageConverter);&#125; fastjson官网https://github.com/alibaba/fastjson/issues/1555https://github.com/alibaba/fastjson/wiki/PropertyNamingStrategy_cn]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>fastjson</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_equals_and_hashCode]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_common%2Fstudy-equals-and-hashCode%2F</url>
    <content type="text"><![CDATA[https://www.ibm.com/developerworks/cn/java/j-jtp05273/index.html 为什么 Override equals()和hashCode()? 如果 Integer 不 Override equals() 和 hashCode() 情况又将如何?如果我们从未在 HashMap 或其它基于散列的集合中使用 Integer 作为关键字的话，什么也不会发生。但是，如果我们在 HashMap中 使用这类 Integer 对象作为关键字，我们将不能够可靠地检索相关的值，除非我们在 get() 调用中使用与 put() 调用中极其类似的 Integer 实例。这要求确保在我们的整个程序中，只能使用对应于特定整数值的 Integer 对象的一个实例。不用说，这种方法极不方便而且错误频频。 Object 的interface contract要求如果根据 equals() 两个对象是相等的，那么它们必须有相同的 hashCode() 值。当其识别能力整个包含在 equals() 中时，为什么我们的根对象类需要 hashCode() ？ 如果重写了equals方法，则一定要重写hashCode方法。 hashCode() 方法纯粹用于提高效率。Java平台设计人员预计到了典型Java应用程序中基于散列的集合类（Collection Class)的重要性–如 Hashtable 、 HashMap 和 HashSet ，并且使用 equals() 与许多对象进行比较在计算方面非常昂贵。使所有Java对象都能够支持 hashCode() 并结合使用基于散列的集合，可以实现有效的存储和检索。 hashCode方法 如果重写了equals方法，则一定要重写hashCode方法。 重写hashCode方法的原则如下： 在程序执行期间，只要equals方法的比较操作用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法必须始终如一地返回同一个整数 如果两个对象通过equals方法比较得到的结果是相等的，那么对这两个对象进行hashCode得到的值应该相同 两个不同的对象，hashCode的结果可能是相同的，这就是哈希表中的冲突。为了保证哈希表的效率，哈希算法应尽可能的避免冲突 关于相应的哈希算法，一个简单的算法如下: 永远不要让哈希算法返回一个常值，这时哈希表将退化成链表，查找时间复杂度也从 O(1)O(1) 退化到 O(N)O(N) 如果参数是boolean型，计算(f ? 1 : 0) 如果参数是byte, char, short或者int型，计算(int) f 如果参数是long型，计算(int) (f ^ (f &gt;&gt;&gt; 32)) 如果参数是float型，计算Float.floatToIntBits(f) 如果参数是double型，计算Double.doubleToLongBits(f)得到long类型的值，再根据公式计算出相应的hash值 如果参数是Object型，那么应计算其有用的成员变量的hash值，并按照下面的公式计算最终的hash值 如果参数是个数组，那么把数组中的每个值都当做单独的值，分别按照上面的方法单独计算hash值，最后按照下面的公式计算最终的hash值 组合公式：result = 31 * result + c String类的hashCode方法如下（JDK 1.8）：1234567891011public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; 举个自定义类的hashCode例子：123456789101112131415161718192021222324252627282930class Duck &#123; private int id; private String name; private double weight; private float height; private String note; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Duck duck = (Duck) o; if (id != duck.id) return false; if (Double.compare(duck.weight, weight) != 0) return false; if (Float.compare(duck.height, height) != 0) return false; if (name != null ? !name.equals(duck.name) : duck.name != null) return false; return !(note != null ? !note.equals(duck.note) : duck.note != null); &#125; @Override public int hashCode() &#123; int result; long temp; result = id; result = 31 * result + (name != null ? name.hashCode() : 0); temp = Double.doubleToLongBits(weight); result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); result = 31 * result + (height != +0.0f ? Float.floatToIntBits(height) : 0); result = 31 * result + (note != null ? note.hashCode() : 0); return result; &#125;&#125; BTW 回顾一下 hashmap内部的实现e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[review_spring]]></title>
    <url>%2F2018%2F01%2F19%2Fjava_spring%2Freview-spring%2F</url>
    <content type="text"><![CDATA[Spring的优点 轻量级：相较于EJB容器，Spring采用的IoC容器非常的轻量级，基础版本的Spring框架大约只有2MB。Spring可以让开发者们仅仅使用POJO(Plain Old Java Object，相对于EJB)就能够开发出企业级的应用。这样做的好处是，你不需要使用臃肿庞大的 EJB容器(应用服务器)，你只需要轻量的servlet容器(如Tomcat)。尤其在一些开发当中，很稀缺内存和CPU资源时，采用Spring比EJB无论是开发还是部署应用都更节约资源。 控制反转(IOC)：Spring使用控制反转技术实现了松耦合。依赖被注入到对象，而不是创建或寻找依赖对象。 面向切面编程(AOP)： Spring支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。 MVC框架：Spring MVC是一个非常好的MVC框架，可以替换其他web框架诸如Struts。 集成性：Spring非常容易和其他的流行框架一起集成开发，这些框架包括：ORM框架，logging框架，JEE, Quartz，以及Struts等表现层框架。 事务管理：Spring强大的事务管理功能，能够处理本地事务(一个数据库)或是全局事务(多个数据，采用JTA)。 模块分离：Spring框架是由模块构成的。虽然已经有太多的包和类了，但它们都按照模块分好类了，你只需要考虑你会用到的模块，而不用理其他的模块。 异常处理：由于Java的JDBC，Hibernate等API中有很多方法抛出的是checked exception，而很多开发者并不能很好的处理异常。Spring提供了统一的API将这些checked exception的异常转换成Spring的unchecked exception。 单元测试：Spring写出来的代码非常容易做单元测试，可以采用依赖注射(Dependency Injection)将测试的数据注射到程序中。 IOC就是典型的工厂模式，通过sessionfactory去注入实例。 AOP就是典型的代理模式的体现。 IOC概念IOC解耦引进了中间位置的“第三方”，也就是IOC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了 通过引入IOC容器，利用依赖关系注入的方式，实现对象之间的解耦。 IOC为我们带来了什么好处我们还是从USB的例子说起，使用USB外部设备比使用内置硬盘，到底带来什么好处？ 第一、USB设备作为电脑主机的外部设备，在插入主机之前，与电脑主机没有任何的关系，只有被我们连接在一起之后，两者才发生联系，具有相关性。所以，无论两者中的任何一方出现什么的问题，都不会影响另一方的运行。这种特性体现在软件工程中，就是可维护性比较好，非常便于进行单元测试，便于调试程序和诊断故障。代码中的每一个Class都可以单独测试，彼此之间互不影响，只要保证自身的功能无误即可，这就是组件之间低耦合或者无耦合带来的好处。 第二、USB设备和电脑主机的之间无关性，还带来了另外一个好处，生产USB设备的厂商和生产电脑主机的厂商完全可以是互不相干的人，各干各事，他们之间唯一需要遵守的就是USB接口标准。这种特性体现在软件开发过程中，好处可是太大了。每个开发团队的成员都只需要关心实现自身的业务逻辑，完全不用去关心其它的人工作进展，因为你的任务跟别人没有任何关系，你的任务可以单独测试，你的任务也不用依赖于别人的组件，再也不用扯不清责任了。所以，在一个大中型项目中，团队成员分工明确、责任明晰，很容易将一个大的任务划分为细小的任务，开发效率和产品质量必将得到大幅度的提高。 第三、同一个USB外部设备可以插接到任何支持USB的设备，可以插接到电脑主机，也可以插接到DV机，USB外部设备可以被反复利用。在软件工程中，这种特性就是可复用性好，我们可以把具有普遍性的常用组件独立出来，反复利用到项目中的其它部分，或者是其它项目，当然这也是面向对象的基本特征。显然，IOC不仅更好地贯彻了这个原则，提高了模块的可复用性。符合接口标准的实现，都可以插接到支持此标准的模块中。 第四、同USB外部设备一样，模块具有热插拔特性。IOC生成对象的方式转为外置方式，也就是把对象生成放在配置文件里进行定义，这样，当我们更换一个实现子类将会变得很简单，只要修改配置文件就可以了，完全具有热插拨的特性。 IOC容器的一些产品spring EJB Spring的IOC(将一个类实例化成对象的技术)IOC技术第一个解释叫做控制反转(IOC)，它还有个解释就是依赖注入(DI)，这两个名字很难从字面理解，但是当你理解它的原理后就会发现它们的描述是何等准确。IOC技术的本质就是构建对象的技术换句话说就是将一个类实例化成对象的技术。 耦合具有两面性。一方面，紧密耦合的代码难以测试，难以复用，难以理解，并且表现出“打地鼠”式的bug特性（修复一个bug，导致出现一个新的或者甚至更多的bug）。另一方面，一定程度的耦合又是必须的，完全没有耦合的代码什么也做不了。为了完成有实际意义的工作，不同的类必须以适当的方式进行交互。总而言之，耦合是必须的，但应当小心谨慎的管理它。通过控制反转或者依赖注入，对象的依赖关系将由负责协调系统中各个对象的第三方组件在创建对象时设定。对象无需自行创建或管理它们的依赖关系，依赖关系将被自动注入到需要它们的对象中去。 我们通过实际生活中的一个例子来解释一下IOC： 例如我们有个roo对象作用是完成打猎的操作，那么打猎这个对象内部包含两个辅助对象：人和枪，只有人和枪赋予了打猎这个对象，那么打猎对象才能完成打猎的操作，但是构建一个人和枪的对象并不是看起来那么简单，这里以枪为例，要创造一把枪我们需要金属，需要机床，需要子弹，而机床和子弹又是两个新对象，这些对象一个个相互嵌套相互关联，大伙试想下如果我们在java代码里构建一个枪的对象那是何其的复杂，假如我们要构造的不是简单的枪对象而是更加复杂的航空母舰，那么构造这个对象的成本之高是让人难以想象的，怎么来消除这种对象相互嵌套相互依赖的关系了？ Spring提供了一种方式，这种方式就是Spring提供一个容器，我们在xml文件里定义各个对象的依赖关系，由容器完成对象的构建，当我们Java代码里需要使用某个实例的时候就可以从容器里获取，那么对象的构建操作就被Spring容器接管，所以它被称为控制反转。 控制反转的意思就是本来属于java程序里构建对象的功能交由容器接管，依赖注入就是当程序要使用某个对象时候，容器会把它注入到程序里。在Java开发里我们想使用某个类提供的功能，有两种方式：一种就是构造一个新的类，新的类继承该类，另一种方式则是将某个类定义在新类里，那么两个类之间就建立一种关联关系，Spring的IOC容器就是实现了这种关联关系。 通过上面这段内容，相信大家应该会对IOC有个比较清晰的了解了。关于Spring中IOC部分是如何实现以及使用，就不进行讨论了，本文的目的也是能从整体上把握一下。但可以稍微提一点，Spring的IOC功能其实就是依赖于Java的反射机制。直白点说，当你在xml文件中配置好了bean（bean需要提供全类名）之后，Spring通过自己的类对xml文件进行解析，然后利用反射机制将对象创建出来，然后放到自己的数据结构中，比如Map。然后键就是bean中的id属性的值，值就是创建的对象。 Spring的AOP在设计模式里有一种代理模式，代理模式将继承模式和关联模式结合在一起使用，代理模式就是继承模式和关联模式的综合体，不过这个综合体的作用倒不是解决对象注入的问题，而是为具体操作对象找到一个保姆或者是秘书，这就和小说里的二号首长一样，这个二号首长对外代表了具体的实例对象，实例对象的入口和出口都是通过这个二号首长，具体的实例对象是一号首长，一号首长是要干大事的，所以一些事务性，重复性的工作例如泡茶，安排车子，这样的工作是不用劳烦一号首长的大驾，而是二号首长帮忙解决的，这就是AOP的思想。AOP解决程序开发里事务性，和核心业务无关的问题，但这些问题对于业务场景的实现是很有必要的，在实际开发里AOP也是节省代码的一种方式。 AOP将应用系统分为两部分，核心业务逻辑（Core business concerns）及横向的通用逻辑，也就是所谓的方面Crosscutting enterprise concerns，例如，所有大中型应用都要涉及到的持久化管理（Persistent）、事务管理（Transaction Management）、安全管理（Security）、日志管理（Logging）和调试管理（Debugging）等。 实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。 过程1. 初始化大致单步跟了下Spring IOC的初始化过程，整个脉络很庞大，初始化的过程主要就是读取XML资源，并解析，最终注册到Bean Factory中： 2. 注入依赖当完成初始化IOC容器后，如果bean没有设置lazy-init(延迟加载)属性，那么bean的实例就会在初始化IOC完成之后，及时地进行初始化。初始化时会先建立实例，然后根据配置利用反射对实例进行进一步操作，具体流程如下所示： 创建bean的实例 注入bean的属性 AOP术语 Join Point: Spring AOP中，join point就是一个方法。（通俗来讲就是起作用的那个方法）。 Pointcut: 用来指定join point（通俗来讲就是描述的一组符合某个条件的join point）。通常使用pointcut表达式来限定joint point，Spring默认使用AspectJ pointcut expression language。 Advice: 在join point上特定的时刻执行的操作，Advice有几种不同类型，下文将会讨论（通俗地来讲就是起作用的内容和时间点）。 Introduction：给对象增加方法或者属性。 Target object: Advice起作用的那个对象。 AOP proxy: 为实现AOP所生成的代理。在Spring中有两种方式生成代理:JDK代理和CGLIB代理。 Aspect: 组合了Pointcut与Advice，在Spring中有时候也称为Advisor。某些资料说Advisor是一种特殊的Aspect，其区别是Advisor只能包含一对pointcut和advice，但是aspect可以包含多对。AOP中的aspect可以类比于OOP中的class。 Weaving：将Advice织入join point的这个过程。 静态代理静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。实现静态代理常用的方法是通过AspectJ，AspectJ 是一个基于 Java 语言的 AOP 框架，提供了强大的 AOP 功能，主要包含两个部分，第一个部分定义了如何表达、定义 AOP 编程中的语法规范；另一个部分是工具部分，包括编译器、调试工具等。Aspectj实现了独有的编译器，在编译时生成代理类文件 Spring的AOP代理对象的生成spring支持AspectJ风格的AOP还是动态的，标注中用到的JoinPoint等类都来自aspectj包 Spring提供了两种方式来生成代理对象: JDKProxy和Cglib，具体使用哪种方式生成由AopProxyFactory根据AdvisedSupport对象的配置来决定。默认的策略是如果目标类是接口，则使用JDK动态代理技术，否则使用Cglib来生成代理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;@Component@Aspectpublic class SimpleAspect &#123; @Pointcut(&quot;execution(* cn.outofmemory.spring_aop_aspect.*Service*.*(..))&quot;) public void pointCut() &#123; &#125; @After(&quot;pointCut()&quot;) public void after(JoinPoint joinPoint) &#123; System.out.println(&quot;after aspect executed&quot;); &#125; @Before(&quot;pointCut()&quot;) public void before(JoinPoint joinPoint) &#123; //如果需要这里可以取出参数进行处理 //Object[] args = joinPoint.getArgs(); System.out.println(&quot;before aspect executing&quot;); &#125; @AfterReturning(pointcut = &quot;pointCut()&quot;, returning = &quot;returnVal&quot;) public void afterReturning(JoinPoint joinPoint, Object returnVal) &#123; System.out.println(&quot;afterReturning executed, return result is &quot; + returnVal); &#125; @Around(&quot;pointCut()&quot;) public void around(ProceedingJoinPoint pjp) throws Throwable &#123; System.out.println(&quot;around start..&quot;); try &#123; pjp.proceed(); &#125; catch (Throwable ex) &#123; System.out.println(&quot;error in around&quot;); throw ex; &#125; System.out.println(&quot;around end&quot;); &#125; @AfterThrowing(pointcut = &quot;pointCut()&quot;, throwing = &quot;error&quot;) public void afterThrowing(JoinPoint jp, Throwable error) &#123; System.out.println(&quot;error:&quot; + error); &#125;&#125; jdkProxyJDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。 核心是InvocationHandler接口和Proxy类。 java.lang.reflect.Proxy，这是Java动态代理机制生成的所有动态代理类的父类，它提供静态方法来为一组接口动态地生成代理类及其对象。 java.lang.reflect.InvocationHandler，这是调用处理器接口，它自定义了一个invoke方法，用于实现代理逻辑、转发请求给对原始类对象。 继承了Proxy类，实现了代理的接口，由于java不能多继承，这里已经继承了Proxy类了，不能再继承其他的类，所以JDK的动态代理不支持对实现类的代理，只支持接口的代理 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // prefix for all proxy class names private static final String proxyClassNamePrefix = &quot;$Proxy&quot;; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + &quot; is not visible from class loader&quot;); &#125; /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + &quot; is not an interface&quot;); &#125; /* * Verify that this interface is not a duplicate. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( &quot;repeated interface: &quot; + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf(&apos;.&apos;); String pkg = ((n == -1) ? &quot;&quot; : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( &quot;non-public interfaces from different packages&quot;); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + &quot;.&quot;; &#125; /* * Choose a name for the proxy class to generate. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; 1234567apply:639, Proxy$ProxyClassFactory &#123;java.lang.reflect&#125;apply:557, Proxy$ProxyClassFactory &#123;java.lang.reflect&#125;get:230, WeakCache$Factory &#123;java.lang.reflect&#125;get:127, WeakCache &#123;java.lang.reflect&#125;getProxyClass0:419, Proxy &#123;java.lang.reflect&#125;newProxyInstance:719, Proxy &#123;java.lang.reflect&#125;main:11, ProxyTest &#123;com.example.demo.proxy.jdk&#125; 获取的对象是$Proxy对象,里面持有了真正的原始对象 cglib核心是MethodInterceptor接口和Enhancer类对于final方法，无法进行代理(不报错,正常执行原方法) 123456789101112131415161718192021222324252627282930public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); public Object getProxy(Class clazz)&#123; //设置需要创建子类的类 enhancer.setSuperclass(clazz); enhancer.setCallback(this); //通过字节码技术动态创建子类实例 return enhancer.create(); &#125; //实现MethodInterceptor接口方法 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;前置代理&quot;); //通过代理类调用父类中的方法 Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;后置代理&quot;); return result; &#125;&#125;public class DoCGLib &#123; public static void main(String[] args) &#123; CglibProxy proxy = new CglibProxy(); //通过生成子类的方式创建代理类 HelloWorldImpl proxyImp = (HelloWorldImpl)proxy.getProxy(HelloWorldImpl.class); proxyImp.sayHello(&quot;wing&quot;);&#125;&#125; spring生命周期 1.Spring对Bean进行实例化（相当于程序中的new Xx()） 2.Spring将值和Bean的引用注入进Bean对应的属性中 3.如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的） 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等） 5.如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把y应用上下文作为参数传入.(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory ) 6.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization（预初始化）方法（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能） 7.如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。 8.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization（后初始化）方法（作用与6的一样，只不过6是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 ) 9.经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 10.如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。 Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类： 1、Bean自身的方法 ： 这个包括了Bean本身调用的方法和通过配置文件中的init-method和destroy-method指定的方法 2、Bean级生命周期接口方法 ： 这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法 3、容器级生命周期接口方法 ： 这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。 4、工厂后处理器接口方法 ： 这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器 接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 1.类级别生命周期回调 1.1 init-method xml配置 1.2 InitializingBean接口 1.3 PostConstruct注解2.容器级别扩展 2.1BeanPostProcessor接口bean实例初始化后处理器及后处理器链实例初始化后处理器多用于对实例的一些代理操作。Spring中一些使用到AOP的特性也是通过后处理器的方式实现的。实例初始化后处理器链 是多个后处理器，就会有执行顺序的问题，可以通过实现Ordered接口，指定后处理的执行顺序，Ordered接口声明了getOrder方法，方法返回值越小，后处理的优先级越高，越早执行。在通过实现BeanPostProcessor接口自定义实例初始化后处理器的时候，建议也实现Ordered接口，指定优先级。 2.2 BeanFactoryPostProcessor接口2.2.1 bean factory后处理器BeanFactoryPostProcessors接口在bean实例化前处理bean的配置元数据，BeanPostProcessor接口在bean实例化后处理bean的实例 https://www.cnblogs.com/zrtqsk/p/3735273.html springbean是否线程安全我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。 无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。 spring 的优点？1.降低了组件之间的耦合性 ，实现了软件各层之间的解耦 2.可以使用容易提供的众多服务，如事务管理，消息服务等 3.容器提供单例模式支持 4.容器提供了AOP技术，利用它很容易实现如权限拦截，运行期监控等功能 5.容器提供了众多的辅助类，能加快应用的开发 6.spring对于主流的应用框架提供了集成支持，如hibernate，JPA，Struts等 7.spring属于低侵入式设计，代码的污染极低 8.独立于各种应用服务器 9.spring的DI机制降低了业务对象替换的复杂性 10.Spring的高度开放性，并不强制应用完全依赖于Spring，开发者可以自由选择spring的部分或全部]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[desin_pattern]]></title>
    <url>%2F2018%2F01%2F19%2Fdesign_pattern%2Fdesin-pattern%2F</url>
    <content type="text"><![CDATA[模板方法（Template Method ）定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。Template Method模式一般是需要继承的。这里想要探讨另一种对Template Method的理解。spring中的JdbcTemplate，在用这个类时并不想去继承这个类，因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。这可能是Template Method不需要继承的另一种实现方式吧。 策略（Strategy ）观察者（Observer ）定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。spring中Observer模式常用的地方是listener的实现。如ApplicationListener。 包装器（Decorator ）在我们的项目中遇到这样一个问题：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。我们以往在spring和hibernate框架中总是配置一个数据源，因而sessionFactory的dataSource属性总是指向这个数据源并且恒定不变，所有DAO在使用sessionFactory的时候都是通过这个数据源访问数据库。但是现在，由于项目的需要，我们的DAO在访问sessionFactory的时候都不得不在多个数据源中不断切换，问题就出现了：如何让sessionFactory在执行数据持久化的时候，根据客户的需求能够动态切换不同的数据源？我们能不能在spring的框架下通过少量修改得到解决？是否有什么设计模式可以利用呢？首先想到在spring的applicationContext中配置所有的dataSource。这些dataSource可能是各种不同类型的，比如不同的数据库：Oracle、SQL Server、MySQL等，也可能是不同的数据源：比如apache 提供的org.apache.commons.dbcp.BasicDataSource、spring提供的org.springframework.jndi.JndiObjectFactoryBean等。然后sessionFactory根据客户的每次请求，将dataSource属性设置成不同的数据源，以到达切换数据源的目的。spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。基本上都是动态地给一个对象添加一些额外的职责。 代理（Proxy ）为其他对象提供一种代理以控制对这个对象的访问。 从结构上来看和Decorator模式类似，但Proxy是控制，更像是一种对功能的限制，而Decorator是增加职责。spring的Proxy模式在aop中有体现，比如JdkDynamicAopProxy和Cglib2AopProxy。 单例模式（Singleton ）保证一个类仅有一个实例，并提供一个访问它的全局访问点。spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是是任意的java对象。核心提示点：Spring下默认的bean均为singleton，可以通过singleton=“true|false” 或者 scope=“？”来指定 适配器（Adapter ）在Spring的Aop中，使用的Advice（通知）来增强被代理类的功能。Spring实现这一AOP功能的原理就使用代理模式（1、JDK动态代理。2、CGLib字节码生成技术代理。）对类进行方法级别的切面增强，即，生成被代理类的代理类， 并在代理类的方法前，设置拦截器，通过执行拦截器重的内容增强了代理方法的功能，实现的面向切面编程。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reivew_spring_mvc]]></title>
    <url>%2F2018%2F01%2F18%2Fjava_spring%2Freivew-spring-mvc%2F</url>
    <content type="text"><![CDATA[springmvc是什么 Spring Web MVC是一种基于Java的实现了Web MVC设计模式的请求驱动类型的轻量级Web框架 将web层进行职责解耦 工作者模式的实现???帮我们做什么 让我们能非常简单的设计出干净的Web层和薄薄的Web层； 进行更简洁的Web层的开发； 天生与Spring框架集成（如IoC容器、AOP等）； 提供强大的约定大于配置的契约式编程支持； 能简单的进行Web层的单元测试； 支持灵活的URL到页面控制器的映射； 非常容易与其他视图技术集成，如Velocity、FreeMarker等等，因为模型数据不放在特定的API里，而是放在一个Model里（Map数据结构实现，因此很容易被其他框架使用）； 非常灵活的数据验证、格式化和数据绑定机制，能使用任何对象进行数据绑定，不必实现特定框架的API； 提供一套强大的JSP标签库，简化JSP开发； 支持灵活的本地化、主题等解析； 更加简单的异常处理； 对静态资源的支持； 支持Restful风格。 架构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//前端控制器分派方法 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try &#123; ModelAndView mv; boolean errorView = false; try &#123; //检查是否是请求是否是multipart（如文件上传），如果是将通过MultipartResolver解析 processedRequest = checkMultipart(request); //步骤2、请求到处理器（页面控制器）的映射，通过HandlerMapping进行映射 mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; //步骤3、处理器适配，即将我们的处理器包装成相应的适配器（从而支持多种类型的处理器） HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 304 Not Modified缓存支持 //此处省略具体代码 // 执行处理器相关的拦截器的预处理（HandlerInterceptor.preHandle） //此处省略具体代码 // 步骤4、由适配器执行处理器（调用处理器相应功能处理方法） mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) &#123; mv.setViewName(getDefaultViewName(request)); &#125; // 执行处理器相关的拦截器的后处理（HandlerInterceptor.postHandle） //此处省略具体代码 &#125; catch (ModelAndViewDefiningException ex) &#123; logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, ex); mv = ex.getModelAndView(); &#125; catch (Exception ex) &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); &#125; //步骤5 步骤6、解析视图并进行视图的渲染 //步骤5 由ViewResolver解析View（viewResolver.resolveViewName(viewName, locale)） //步骤6 视图在渲染时会把Model传入（view.render(mv.getModelInternal(), request, response);） if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, processedRequest, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Null ModelAndView returned to DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;: assuming HandlerAdapter completed request handling&quot;); &#125; &#125; // 执行处理器相关的拦截器的完成后处理（HandlerInterceptor.afterCompletion） //此处省略具体代码 catch (Exception ex) &#123; // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; catch (Error err) &#123; ServletException ex = new NestedServletException(&quot;Handler processing failed&quot;, err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; finally &#123; // Clean up any resources used by a multipart request. if (processedRequest != request) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; 核心架构的具体流程步骤如下： 1、 首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制； 2、 DispatcherServlet——&gt;HandlerMapping， HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略； 3、 DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器； 4、 HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）； 5、 ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术； 6、 View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术； 7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 此处我们只是讲了核心流程，没有考虑拦截器、本地解析、文件上传解析等，后边再细述。 hello world DispatcherServlet：Spring提供的前端控制器，所有的请求都有经过它来统一分发。在DispatcherServlet将请求分发给Spring Controller之前，需要借助于Spring提供的HandlerMapping定位到具体的Controller。 HandlerMapping：能够完成客户请求到Controller映射。 Controller：需要为并发用户处理上述请求，因此实现Controller接口时，必须保证线程安全并且可重用。Controller将处理用户请求，这和Struts Action扮演的角色是一致的。一旦Controller处理完用户请求，则返回ModelAndView对象给DispatcherServlet前端控制器，ModelAndView中包含了模型（Model）和视图（View）。从宏观角度考虑，DispatcherServlet是整个Web应用的控制器；从微观考虑，Controller是单个Http请求处理过程中的控制器，而ModelAndView是Http请求过程中返回的模型（Model）和视图（View）。 ViewResolver：Spring提供的视图解析器（ViewResolver）在Web应用中查找View对象，从而将相应结果渲染给客户。 DispatcherServlet与HttpMessageConverter的关系//TODO http://sishuok.com/forum/blogPost/list/5160.html]]></content>
      <categories>
        <category>springmvc</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[btrace-study]]></title>
    <url>%2F2018%2F01%2F18%2Fjava_tools%2Fbtrace-study%2F</url>
    <content type="text"><![CDATA[btrace概念: Probe Point: “location” or “event” at which a set of tracing statements are executed. Probe point is “place” or “event” of interest where we want to execute some tracing statements.（探测点，就是我们想要执行一些追踪语句的地方或事件） Trace Actions or Actions: Trace statements that are executed whenever a probe “fires”.（当探测触发时执行追踪语句） Action Methods: BTrace trace statements that are executed when a probe fires are defined inside a static method a class. Such methods are called “action” methods.（当在类的静态方法中定义了探测触发时执行的BTrace跟踪语句。这种方法被称为“操作”方法。） 学习的博客:http://mgoann.iteye.com/blog/1409685http://calvin1978.blogcn.com/articles/btrace1.htmlhttp://codepub.cn/2017/09/22/btrace-uses-tutorials/ byteman局部变量http://codepub.cn/2017/09/22/byteman-uses-tutorials/ github地址:https://github.com/btraceio/btrace 可运行包 下载地址https://github.com/btraceio/btrace/releases/tag/v1.3.10]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo需求]]></title>
    <url>%2F2018%2F01%2F17%2Fjava_dubbo%2Fstudy-dubbo%2F</url>
    <content type="text"><![CDATA[需求流程图服务授权服务降级软负载均衡服务路由服务编排服务质量协定服务容量服务注册与发现服务质量协定 其他需求 服务注册中心 替代 f5负载均衡服务器(内部使用) 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。 应用依赖 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。 这时，需要自动画出应用间的依赖关系图，以帮助架构师理清理关系。 调用(调用量,响应时间)监控 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？ 为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阀值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 架构]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful-API概念学习]]></title>
    <url>%2F2018%2F01%2F15%2Fhttp%2Fadvantage-api%2F</url>
    <content type="text"><![CDATA[RESTful API 透明性，暴露资源存在。 充分利用 HTTP 协议本身语义。 无状态，这点非常重要。在调用一个接口（访问、操作资源）的时候，可以不用考虑上下文，不用考虑当前状态，极大的降低了复杂度 HTTP 本身提供了丰富的内容协商手段，无论是缓存，还是资源修改的乐观并发控制，都可以以业务无关的中间件来实现 理解RESTful架构 Representational State Transfer REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 最常见的一种设计错误，就是URI包含动词。因为”资源”表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。 因为不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。版本号可以在HTTP请求头信息的Accept字段中进行区分http://www.ruanyifeng.com/blog/2011/09/restful.html RESTful API 设计指南 协议 域名 版本（Versioning） 路径（Endpoint）在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 HTTP动词 过滤信息（Filtering） 状态码（Status Codes） 错误处理 返回结果 Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 其他 （1）API的身份认证应该使用OAuth 2.0框架。 （2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。 http://www.ruanyifeng.com/blog/2014/05/restful_api.html]]></content>
      <categories>
        <category>HTTP协议</category>
      </categories>
      <tags>
        <tag>HTTP协议</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口文档编写规范]]></title>
    <url>%2F2018%2F01%2F15%2Fhttp%2Fapi-doc%2F</url>
    <content type="text"><![CDATA[接口描述请求参数名称 类型 是否必需 描述(取值范围) 返回参数数据类型示例请求参数返回实例错误码 错误代码 错误信息 HTTP 状态码 说明 Account.Arrearage Your account has an outstanding payment. 400 账号已经欠费。 EncryptedOption.Conflict Encryption value of disk and snapshot conflict. 400 磁盘的加密属性和快照的加密属性不一致。 IncorrectVSwitchStatus The current status of virtual switch does not support this operation. 400 指定的VSwitch状态不正确。 InstanceDiskCategoryLimitExceed The specified DataDisk.n.Size beyond the permitted range, or the capacity of snapshot exceeds the size limit of the specified disk category. 400 指定的磁盘大小超过了该类型磁盘上限。 InstanceDiskNumber.LimitExceed The total number of specified disk in an instance exceeds. 400 镜像中包含的数据盘和数据盘参数合并后，数据盘的总数超出限制。 InvalidDataDiskSize.ValueNotSupported The specified DataDisk.n.Size beyond the permitted range, or the capacity of snapshot exceeds the size limit of the specified disk category. 400 指定的DataDisk.n.Size不合法（超出范围）。 InvalidDescription.Malformed The specified parameter Description is not valid. 400 指定的Description格式不合法。 InvalidDiskCategory.ValueNotSupported The specified parameter DiskCategory is not valid. 400 指定的DiskCategory不合法。 InvalidDiskDescription.Malformed The specified parameter SystemDisk.DiskDescription or DataDisk.n.Description is not valid. 400 指定的参数SystemDisk.DiskDescription或参数DataDisk.n.Description不合法。 InvalidDiskName.Malformed The specified parameter SystemDisk.DiskName or DataDisk.n.DiskName is not valid. 400 指定的参数SystemDisk.DiskName或DataDisk.n.DiskName不合法。 InvalidHostName.Malformed The specified parameter HostName is not valid. 400 指定的HostName格式不合法。 InvalidInstanceName.Malformed The specified parameter InstanceName is not valid. 400 指定的InstanceName格式不合法。 InvalidInstanceType.ValueNotSupported The specified InstanceType beyond the permitted range. 400 指定的InstanceType不合法（超出可选范围）。 InvalidInstanceType.ValueUnauthorized The specified InstanceType is not authorized. 400 指定的InstanceType未授权使用。 InvalidInternetChargeType.ValueNotSupported The specified InternetChargeType is not valid. 400 指定的 InternetChargeType 不存在。 InvalidIoOptimizedValue.ValueNotSupported IoOptimized value not supported. 400 指定的IoOptimized参数不支持。 InvalidNetworkType.Mismatch Specified parameter InternetMaxBandwidthIn or InternetMaxBandwidthOut conflict with instance network type. 400 指定的InternetMaxBandwidthIn或InternetMaxBandwidthOut与实例网络类型不符合。 InvalidNetworkType.Mismatch Specified parameter InternetChargeType conflict with instance network type. 400 指定的InternetChargeType与实例网络类型不符合。 InvalidParameter The specified parameter InternetMaxBandwidthOut is not valid. 400 指定的InternetMaxBandwidthOut不合法（不是数字或超出范围）。 InvalidParameter The specified instance bandwidth is not valid. 400 指定的带宽值不合法。 InvalidParameter The specified parameter Amount is not valid. 400 指定的Amount参数不合法。(范围：[1,100]) InvalidParameter.Bandwidth The specified parameter Bandwidth is not valid. 400 指定的带宽值不合法。 InvalidParameter.Conflict The specified image does not support the specified instance type. 400 指定的InstanceType上不允许使用该指定的镜像。 InvalidParameter.Encrypted.KmsNotEnabled The encrypted disk need enable KMS. 400 账户未开通KMS服务（需用户主动开通KMS服务）。 InvalidParameter.EncryptedIllegal The value of parameter Encrypted is illegal. 400 传入的参数Encrypted非法。 InvalidParameter.EncryptedNotSupported Encrypted disk is not support in this region. 400 所选择的region不支持加密特性。 InvalidParameter.EncryptedNotSupported Corresponding data disk category does not support encryption. 400 对应的磁盘category不支持加密。 InvalidParameter.Mismatch Specified security group and virtual switch are not in the same VPC. 400 指定安全组与VSwitch不属于同一个VPC。 InvalidParameter.Mismatch Specified virtual switch is not in the specified zone. 400 指定的VSwitch不在指定Zone。 InvalidPassword.Malformed The specified parameter Password is not valid. 400 指定的Password格式不合法。 InvalidSnapshotId.BasedSnapshotTooOld The specified snapshot is created before 2013-07-15. 400 使用了2013-07-15之前创建的快照。 InvalidSpotAliUid The specified UID is not authorized to use SPOT instance. 400 该账号不能使用spot instance。 InvalidSpotAuthorized The specified Spot param is unauthorized. 400 该账号没有授权创建竞价实例。 InvalidSpotPrepaid The specified Spot type is not support PrePay Instance. 400 竞价实例不支持预付费。 InvalidSpotPriceLimit The specified SpotPriceLimitis not valid. 400 SpotPriceLimit参数不合法。 InvalidSpotPriceLimit.LowerThanPublicPrice The specified parameter spotPriceLimit can’t be lower than current public price. 400 出价低于当前系统公允价格。 InvalidSpotStrategy The specified SpotStrategy is not valid. 400 SpotStrategy参数不合法。 InvalidSystemDiskCategory.ValueNotSupported The specified parameter SystemDisk.Category is not valid. 400 指定的参数SystemDisk.Category不合法。 InvalidUserData.NotSupported The specified parameter UserData only support the vpc and IoOptimized Instance. 400 UserData只能使用在VPC和I/O优化实例上。 InvalidUserData.SizeExceeded The specified parameter UserData exceeds the size. 400 指定的UserData过长。 InvalidHpcClusterId.NotFound The specified HpcClusterId is not found. 400 指定的HpcClusterId不存在。 InvalidHpcClusterId.Creating The specified HpcClusterId is creating. 400 指定的HpcClusterId正在创建中。 InvalidHpcClusterId.Unnecessary The specified HpcClusterId is unnecessary. 400 只有部分实例规格InstanceType支持指定E-HPC集群 ID。 InvalidVSwitchId.Necessary The HpcClusterId is necessary. 400 该实例规格InstanceType需要指定E-HPC集群 ID，您需要传入HpcClusterId。 MissingParameter The input parameter VSwitchId that is mandatory for processing this request is not supplied. 400 缺少必填参数VSwitchId。 QuotaExceed.AfterpayInstance The maximum number of Pay-As-You-Go instances is exceeded. 400 用户的按量付费实例个数达到上限。 QuotaExceeded Living instances quota exceeded in this VPC. 400 VPC中实例数量超限。 ResourceNotAvailable Resource you requested is not available in this region or zone. 400 指定Region或Zone内该资源不可用。 CategoryNotSupported The specified zone does not offer the specified disk category. 403 该可用区无权创建指定种类的磁盘。 DeleteWithInstance.Conflict The specified disk is not a portable disk and cannot be set to DeleteWithInstance attribute. 403 该磁盘不支持挂载与卸载。 DependencyViolation.WindowsInstance The instance creating is window, cannot use ssh key pair to login. 403 Windows 实例不能使用SSH密钥对。 Forbidden User not authorized to operate on the specified resource. 403 用户没有权限操作。 ImageNotSubscribed The specified image has not be subscribed. 403 没有订阅镜像市场的镜像。 ImageNotSupportInstanceType The specified image don’t support the InstanceType instance. 403 指定镜像不支持该实例类型。 ImageRemovedInMarket The specified market image is not available, or the specified custom image includes product code because it is based on an image subscribed from marketplace, and that image in marketplace including exact the same product code has been removed. 403 镜像市场的镜像已下架，或者自定义镜像中包含的product code对应的镜像市场镜像已经下架。 InstanceDiskCategoryLimitExceed The total size of specified disk category in an instance exceeds. 403 指定的磁盘种类超过了单实例的最大容量。 InstanceDiskNumLimitExceed The number of specified disk in an instance exceeds. 403 指定实例已经达到可挂载磁盘的最大值。 InvalidDiskCategory.Mismatch The specified disk categories combination is not supported. 403 指定的磁盘类型组合不支持。 InvalidDiskCategory.NotSupported The specified disk category is not support the specified instance type. 403 指定的磁盘类型不支持该实例类型。 InvalidDiskSize.TooSmall Specified disk size is less than the size of snapshot. 403 指定的磁盘小于指定快照大小。 InvalidInstanceType.ZoneNotSupported The specified zone does not support this InstanceType. 403 指定Zone不支持该实例类型。 InvalidNetworkType.MismatchRamRole Ram role cannot be attached to instances of Classic network type. 403 实例RAM角色不能被用于经典网络。 InvalidPayMethod The specified billing method is not valid. 403 指定的付费类型不存在。 InvalidResourceType.NotSupported This resource type is not supported; please try other resource types. 403 创建实例的配置暂无可用区支持，请选择其他配置创建。 InvalidSnapshotId.NotDataDiskSnapshot The specified snapshot is system disk snapshot. 403 系统盘快照不能创建数据盘。 InvalidSnapshotId.NotReady The specified snapshot has not completed yet. 403 快照没有完成。 InvalidSystemDiskCategory.ValueUnauthorized The disk category is not authorized. 403 磁盘种类未被授权使用。 InvalidUser.PassRoleForbidden The RAM user does not have the privilege to pass a role. 403 RAM用户不具有PassRole的权限。 InvalidUserData.Forbidden User not authorized to input the parameter UserData, please apply for permission UserData. 403 用户没有权限使用UserData。 InvalidVSwitchId.NotFound The VSwitchId provided does not exist in our records. 403 指定的VSwitchId不存在。 IoOptimized.NotSupported The specified image is not support IoOptimized Instance. 403 指定的镜像不支持I/O优化实例。 IoOptimized.NotSupported Vpc is not support IoOptimized instance. 403 VPC不支持I/O优化实例。 OperationDenied The specified snapshot is not allowed to create disk. 403 特定磁盘的快照不能创建磁盘或者快照不能创建磁盘。 OperationDenied The creation of Instance to the specified Zone is not allowed. 403 该可用区无权创建实例或者Zone和Region不匹配。 OperationDenied The specified Image is disabled or is deleted. 403 指定的镜像找不到。 OperationDenied Sales of this resource are temporarily suspended in the specified region; please try again later. 403 Region暂时停售按量付费（Pay-As-You-Go）实例。 OperationDenied The capacity of snapshot exceeds the size limit of the specified disk category or the specified category is not authorized. 403 指定的DataDisk.n.Size不合法（超出范围）或者磁盘种类未被授权使用。 OperationDenied The type of the disk does not support the operation. 403 指定磁盘类型不支持该操作。 OperationDenied.NoStock Sales of this resource are temporarily suspended in the specified region; please try again later. 403 库存不足，请尝试其它系列或者其它可用区/地域的实例。 QuotaExceed.BuyImage The specified image is from the image market, You have not bought it or your quota has been exceeded. 403 指定镜像没有购买或超过限制。 QuotaExceed.PortableCloudDisk The quota of portable cloud disk exceeds. 403 可挂载的云磁盘数量已经达到上限（最多16块）。 RegionUnauthorized There is no authority to create instance in the specified region. 403 用户无权使用该Region。 SecurityGroupInstanceLimitExceed The maximum number of instances in a security group is exceeded. 403 该安全组内的Instance数量已经达到上限。 Zone.NotOnSale The specified zone is not available for purchase. 403 创建实例的可用区已经关闭售卖，请更换其他可用区/地域。（VPC类型实例的交换机会限制购买可用区）。 Zone.NotOpen The specified zone is not granted to you to buy resources yet. 403 创建实例的可用区没有对该用户开放售卖。 ZoneId.NotFound The specified zone does not exists. 403 指定Zone不存在。 DependencyViolation.IoOptimized The specified InstanceType must be IoOptimized instance. 404 指定的实例规格必须是I/O优化实例。 HOSTNAME_ILLEGAL hostname is not valid. 404 指定的HostName参数不合法。 InvalidDataDiskSnapshotId.NotFound The specified parameter DataDisk.n.SnapshotId is not valid. 404 指定的DataDisk.n.SnapshotId没找到。 InvalidImageId.NotFound The specified ImageId does not exist. 404 指定的镜像不存在。 InvalidInstanceChargeType.NotFound The InstanceChargeType does not exist in our records. 404 指定的InstanceChargeType不存在。 InvalidKeyPairName.NotFound The specified KeyPairName does not exist in our records. 404 指定的KeyPairName不存在。 InvalidRamRole.NotFound The specified RamRoleName does not exist. 404 指定的RamRoleName不存在。 InvalidRegionId.NotFound The specified RegionId does not exist. 404 指定的RegionId不存在。 InvalidSecurityGroupId The specified SecurityGroupId is invalid or does not exist. 404 指定的SecurityGroupId不合法或不存在（实际情况也可能是该用户无权使用此SecurityGroup）。 InvalidSystemDiskSize The specified parameter SystemDisk.Size is invalid. 404 指定的SystemDisk.Size不合法。 InvalidSystemDiskSize.LessThanImageSize The specified parameter SystemDisk.Size is less than the image size. 404 指定的SystemDisk.Size小于镜像大小。 InvalidSystemDiskSize.LessThanMinSize The specified parameter SystemDisk.Size is less than the min size. 404 指定的SystemDisk.Size小于磁盘大小下限。 InvalidSystemDiskSize.MoreThanMaxSize The specified parameter SystemDisk.Size is more than the max size. 404 指定的SystemDisk.Size大于磁盘大小上限。 InvalidVSwitchId.NotFound Specified virtual switch does not exist. 404 指定的VSwitch不存在。 InvalidZoneId.NotFound The specified ZoneId does not exist. 404 指定Zone不存在。 IoOptimized.NotSupported The specified InstanceType is not support IoOptimized instance. 404 指定的实例类型不支持 I/O 优化实例。 OperationDenied Another Instance is being created. 404 正在创建另外的实例。 PaymentMethodNotFound No billing method has been registered on the account. 404 该账号下没有付款方式。 InternalError The request processing has failed due to some unknown error,exception or failure. 500 内部错误。]]></content>
      <categories>
        <category>HTTP协议</category>
      </categories>
      <tags>
        <tag>HTTP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-线程复习]]></title>
    <url>%2F2018%2F01%2F13%2Fjava_thread%2Freview-java-thread%2F</url>
    <content type="text"><![CDATA[线程创建线程有两种方式：一、继承 Thread 类，扩展线程。二、实现 Runnable 接口。 Callable接口Future接口FutureTask实现了 Future 接口FutureTask 的好处是 FutureTask 是为了弥补 Thread 的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果。FutureTask 是一种可以取消的异步的计算任务，它的计算是通过 Callable 实现的，它等价于可以携带结果的 Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。 多线程多线程的概念很好理解就是多条线程同时存在，但要用好多线程确不容易，涉及到多线程间通信，多线程共用一个资源等诸多问题。 synchronized解决多个线程之间访问资源的同步性 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 锁提供了两种主要特性：互斥（mutual exclusion） 和可见性（visibility）。互斥即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。可见性要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题。 volatile解决变量在多个线程之间的可见性 出于简易性或可伸缩性的考虑，您可能倾向于使用 volatile 变量而不是锁。当使用 volatile 变量而非锁时，某些习惯用法（idiom）更加易于编码和阅读。此外，volatile 变量不会像锁那样造成线程阻塞，因此也很少造成可伸缩性问题。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。 正确使用 volatile 变量的条件您只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件： 对变量的写操作不依赖于当前值。该变量没有包含在具有其他变量的不变式中。实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使 x 的值在操作期间保持不变，而 volatile 变量无法实现这点。（然而，如果将值调整为只从单个线程写入，那么可以忽略第一个条件。） 大多数编程情形都会与这两个条件的其中之一冲突，使得 volatile 变量不能像 synchronized 那样普遍适用于实现线程安全。清单 1 显示了一个非线程安全的数值范围类。它包含了一个不变式 —— 下界总是小于或等于上界。 小结与锁相比，Volatile 变量是一种非常简单但同时又非常脆弱的同步机制，它在某些情况下将提供优于锁的性能和伸缩性。如果严格遵循 volatile 的使用条件 —— 即变量真正独立于其他变量和自己以前的值 —— 在某些情况下可以使用 volatile 代替 synchronized 来简化代码。然而，使用 volatile 的代码往往比使用锁的代码更加容易出错。本文介绍的模式涵盖了可以使用 volatile 代替 synchronized 的最常见的一些用例。遵循这些模式（注意使用时不要超过各自的限制）可以帮助您安全地实现大多数用例，使用 volatile 变量获得更佳性能。 wait()、notify()、notifyAll()wait():我的部分已经做完了,等别人让我做的时候再做,释放锁notify():等我做完了,释放锁后,让其他一个人做wait() 与 Thread.sleep(long time) 的区别:sleep傻等,sleep不释放锁 1234567891011121314作者：孙立伟链接：https://www.zhihu.com/question/23328075/answer/24228413来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。首先，要记住这个差别，“sleep是Thread类的方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。线程的状态参考 Thread.State的定义。新创建的但是没有执行（还没有调用start())的线程处于“就绪”，或者说Thread.State.NEW状态。Thread.State.BLOCKED（阻塞）表示线程正在获取锁时，因为锁不能获取到而被迫暂停执行下面的指令，一直等到这个锁被别的线程释放。BLOCKED状态下线程，OS调度机制需要决定下一个能够获取锁的线程是哪个，这种情况下，就是产生锁的争用，无论如何这都是很耗时的操作。 ThreadLocal 变量线程隔离InheritableTreadLocal让子线程获取父线程中取得值 join() 方法等待线程对象销毁等待子进程执行完,我再执行Thread.yield() 方法 ReentrantLocklock()unlock()condition等待/通知 awiate() 相当于Object类中的wait()方法 await(long time,TImeUnit unit) 相当于Object类中的wait()方法 signal() 相当于Object类中的notify()方法 sigalAll() 相当于Object类中的notifyAll()方法 通知部分线程Lock lock=new Reentrantock();Condition conditionA=lock.newCondition();Condition conditionB=lock.newCondition(); 公平锁,非公平锁 获取锁的顺序是按照线程加锁的顺序来分配的,及先来先得的FIFO先进先出顺序 getHoldCount(),getQueueLength(),getWaiteQueueLength() getHoldCount()查询当前线程保持此锁定的个数,调用lock()方法的次数 getQueueLength()返回正在等待次锁定的线程估计数 getWaiteQueueLength(Condition condition)返回等待与此锁定翔安的给定条件Condition的线程估计数 线程状态切换 监视器代表synchronized lock代表锁 AtomicInteger类ReentrantReadWriteLock参考https://www.ibm.com/developerworks/cn/java/j-jtp06197.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk1.9-maven-fix]]></title>
    <url>%2F2018%2F01%2F08%2Fjava_tools%2Fjdk1-9-maven-fix%2F</url>
    <content type="text"><![CDATA[背景在安装了多个jdk版本后,发现maven命令不好使了 现象 maven-compiler-plugin:3.1:compile (default-compile) @ report 出现异常12345678910111213141516171819202122[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ report ---[INFO] Changes detected - recompiling the module![INFO] Compiling 60 source files to /Users/victor/code/egenieProjects/report/target/classesWARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by lombok.javac.apt.Processor to field com.sun.tools.javac.processing.JavacProcessingEnvironment.processorClassLoaderWARNING: Please consider reporting this to the maintainers of lombok.javac.apt.ProcessorWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.198 s[INFO] Finished at: 2018-01-08T14:04:55+08:00[INFO] Final Memory: 35M/115M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project report: Fatal error compiling: java.lang.NoSuchFieldError: pid -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 解决 1.9 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 9.0.1, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/HomeDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 执行命令 1echo -n &quot;JAVA_HOME=`/usr/libexec/java_home -v 1.8`&quot; &gt; ~/.mavenrc 1.8 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 1.8.0_151, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 思考虽然此种方法解决了这个问题,但具体是什么原因导致的此问题,还需进一步研究 参考http://geeekr.com/fix-maven-java-version-mac-osx/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>JDK1.9</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-sql-update-lock]]></title>
    <url>%2F2018%2F01%2F06%2Fegenie_bugfix%2Ferror-sql-update-lock%2F</url>
    <content type="text"><![CDATA[com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction 事务没有提交导致 锁等待 https://www.jianshu.com/p/0b4aaa93e7f6]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenv安装(管理多个jdk版本)]]></title>
    <url>%2F2018%2F01%2F06%2Fjava_tools%2Finstall-jenv%2F</url>
    <content type="text"><![CDATA[1.安装jenv1brew install jenv 2.oracle官网下载各版本jdk 3.安装本地123jenv add /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home 4.列表jdk1jenv versions system (set by /Users/victor/.jenv/version)1.71.7.0.801.81.8.0.1519.09.0.1oracle64-1.7.0.80oracle64-1.8.0.151oracle64-9.0.1 5.选择jdk12jenv global 1.7java -version java version “1.7.0_80”Java(TM) SE Runtime Environment (build 1.7.0_80-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BI-olap技术选型]]></title>
    <url>%2F2018%2F01%2F05%2Fdata_warehouse%2FBI-olap-tool%2F</url>
    <content type="text"><![CDATA[备选列表: 阿里云-分析性数据库 GreePlum Presto Kylin 阿里云-分析性数据库 GreePlum Greenplum采用Postgresl作为底层引擎，良好的兼容了Postgresql的功能 Greenplum的艺术，一切皆并行（Parallel Everything） Greenplum建立在Share-nothing无共享架构上，让每一颗CPU和每一块磁盘IO都运转起来，无共享架构将这种并行处理发挥到极致。相比一些其它传统数据仓库的Sharedisk架构，后者最大瓶颈就是在IO吞吐上，在大规模数据处理时，IO无法及时feed数据给到CPU，CPU资源处于wait 空转状态，无法充分利用系统资源，导致SQL效率低下 得益于Postgresql的良好扩展性（这里是extension，不是scalability），Greenplum 可以采用各种开发语言来扩展用户自定义函数（UDF） Greenplum MPP 与 Hadoop相同点 分布式存储数据在多个节点服务器上 采用分布式并行计算框架 支持横向扩展来提高整体的计算能力和存储容量 都支持X86开放集群架构 差异点 MPP按照关系数据库行列表方式存储数据（有模式），Hadoop按照文件切片方式分布式存储（无模式） 两者采用的数据分布机制不同，MPP采用Hash分布，计算节点和存储紧密耦合，数据分布粒度在记录级的更小粒度（一般在1k以下）；Hadoop FS按照文件切块后随机分配，节点和数据无耦合，数据分布粒度在文件块级（缺省64MB）。 MPP采用SQL并行查询计划，Hadoop采用Mapreduce框架 Presto Facebook贡献的开源MPP OLAP引擎。 这是一个红酒的名字，因为开发组所有的人都喜欢喝这个牌子的红酒，所以把它命名为这个名字。作为MPP引擎，它的处理方式是把所有的数据Scan出来，通过Hash的方法把数据变成更小的块，让不同的节点并发，处理完结果后快速地返回给用户。我们看到它的逻辑架构也是这样，发起一个SQL，然后找这些数据在哪些HDFS节点上，然后分配后做具体的处理，最后再把数据返回。 Kylin Kylin是由eBay开源的一个引擎，Kylin把数据读出来做计算，结算的结果会被存在HBase里，通过HBase做Ad-hoc的功能。HBase的好处是有索引的，所以做Ad-hoc的性能非常好。]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>olap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java集合并发修改]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_common%2Fstudy-ConcurrentModificationException%2F</url>
    <content type="text"><![CDATA[并发修改当一个或多个线程正在遍历一个集合Collection，此时另一个线程修改了这个集合的内容（添加，删除或者修改）.这就是并发修改 快速失败（fail—fast） “快速失败”，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出ConcurrentModificationException 异常，从而产生fail-fast机制。 何时触发快速失败 无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。所以我们这里可以初步判断由于expectedModCount得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。 安全失败（fail—safe） 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 p.s.迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的 快速失败和安全失败的比较 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModification Exception Yes No Clone object No Yes Memory Overhead No Yes Examples HashMap,Vector,ArrayList,HashSet CopyOnWriteArrayList,ConcurrentHashMap 产生fail-fast的是在java.util包中的collection实现类；产生fail-safe的是在java.util.concurrent包中的collection实现类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发修改</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-skip-list]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-skip-list%2F</url>
    <content type="text"><![CDATA[跳跃表 一种基于有序链表的扩展 利用类似索引的思想,找到关键点 删除 自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。O（logN） 删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）。O（logN） 区别 跳跃表 维持平衡的成本较低,完全靠随机 二叉树需要靠rebalance来重新调整结构 应用Redis当中的Sorted-set]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>跳跃表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-b-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-b-tree%2F</url>
    <content type="text"><![CDATA[b-树 数据库索引使用b-树 二叉树查找的时间复杂度O(logN) 问题:磁盘IO 最坏的情况下,磁盘IO等于索引树的高度 把原来”瘦高”的树结构变得”矮胖”就是b-树的特征之一 B树是一种多路平衡查找树 B树与红黑树最大的不同在于，B树的结点可以有许多子女，从几个到几千个。 定义 树中每个结点最多含有m个孩子（m&gt;=2）； 除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子（其中ceil(x)是一个取上限的函数）； 根结点至少有2个孩子（除非B树只包含一个结点：根结点）； 所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询失败的结点，指向这些结点的指针都为null)；（注：叶子节点只是没有孩子和指向孩子的指针，这些节点也存在，也有元素。类似红黑树中，每一个NULL指针即当做叶子结点，只是没画出来而已）。 每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，……，Kn，Pn)。其中：a) Ki (i=1…n)为关键字，且关键字按顺序升序排序K(i-1)&lt; Ki。b) Pi为指向子树根的结点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。c) 关键字的个数n必须满足： [ceil(m / 2)-1]&lt;= n &lt;= m-1。比如有j个孩子的非叶结点恰好有j-1个关键码。 应用 文件系统 数据库索引 b+树 1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 b+树种,只有叶子节点带有卫星信息,其余中间节点仅仅是索引,没有任何数据关联 在数据库的聚集索引（Clustered Index）中，叶子节点直接包含卫星数据。在非聚集索引（NonClustered Index）中，叶子节点带有指向卫星数据的指针。 B+树的优势：1.单一节点存储更多的元素，使得查询的IO次数更少。2.所有查询都要查找到叶子节点，查询性能稳定。3.所有叶子节点形成有序链表，便于范围查询。 引用 mysql的b树索引的物理文件 B*树 B-tree是B+-tree的变体，在B+树的基础上(所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针)，B树中非根和非叶子结点再增加指向兄弟的指针；B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）。 B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针。 B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。 所以，B*树分配新结点的概率比B+树要低，空间使用率更高； 总结通过以上介绍，大致将B树，B+树，B*树总结如下： B树：有序数组+平衡多叉树； B+树：有序数组链表+平衡多叉树； B*树：一棵丰满的B+树。 顺便说一句，无论是B树，还是B+树、b树，由于根或者树的上面几层被反复查询，所以这几块可以存在内存中，换言之，B树、B+树、B树的根结点和部分顶层数据在内存中，大部分下层数据在磁盘上。 mysql中InnoDB索引和MyISAM索引的区别： myISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。 InnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。使用辅助索引需要查找 两次索引。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组&lt;a1, a2, …, an&gt;，其中各个元素均为数据表的一列。 主索引的区别，InnoDB的数据文件本身就是索引文件。而MyISAM的索引和数据是分开的。 辅助索引的区别：InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。 聚簇索引 非聚簇索引 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.02.md]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>b-tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-red–black-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-red%E2%80%93black-tree%2F</url>
    <content type="text"><![CDATA[二叉搜索树由于红黑树本质上就是一棵二叉查找树，所以在了解红黑树之前，咱们先来看下二叉查找树。 二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 因为，一棵由n个结点，随机构造的二叉查找树的高度为lgn，所以顺理成章，一般操作的执行时间为O（lgn）.（至于n个结点的二叉树高度为lgn的证明，可参考算法导论 第12章 二叉查找树 第12.4节）。 但二叉树若退化成了一棵具有n个结点的线性链后，则此些操作最坏情况运行时间为O（n）。后面我们会看到一种基于二叉查找树-红黑树，它通过一些性质使得树相对平衡，使得最终查找、插入、删除的时间复杂度最坏情况下依然为O（lgn）。 红黑树特性前面我们已经说过，红黑树，本质上来说就是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。 但它是如何保证一棵n个结点的红黑树的高度始终保持在h = logn的呢？这就引出了红黑树的5条性质： 1）每个结点要么是红的，要么是黑的。 2）根结点是黑的。 3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 4）如果一个结点是红的，那么它的俩个儿子都是黑的。 5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度，从而也就解释了上面我们所说的“红黑树的查找、插入、删除的时间复杂度最坏为O(log n)”这一结论的原因。 如下图所示，即是一颗红黑树(下图引自wikipedia：http://t.cn/hgvH1l)： 应用 treemap treeset 1.8中的hashset https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK- MashMap 学习]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_common%2Fstudy-hashmap%2F</url>
    <content type="text"><![CDATA[hashmap数据结构12345678910//链表static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125;//数组transient Node&lt;K,V&gt;[] table; HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干。 HashMap 使用后台数组（backing array）作为桶，并使用链表（linked list）存储键／值对。 通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Factor则resize为原来的2倍)。 获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。 如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。HashMap存储着Entry(hash, key, value, next)对象。 当key==null时，存在table[0]即第一个桶中，hash值为0。HashMap对key==null的键值对会做单独处理 Capacity的默认值为16： static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; 负载因子的默认值为0.75： static final float DEFAULT_LOAD_FACTOR = 0.75f; 简单的说，Capacity就是bucket的大小，Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话不要把Capacity设置过大，也不要把load factor设置过小。当bucket中的entries的数目大于capacity*load factor时就需要调整bucket的大小为当前的2倍。 可以设置初始容量Capacity，但是在HashMap处理过程中，是会把Capacity扩充成2的倍数 HashMap中有一个成员变量modCount，这个用来实现“fast-fail”机制（也就是快速失败）。所谓快速失败就是在并发集合中，其进行迭代操作时，若有其他线程对其结构性的修改，这是迭代器会立马感知到，并且立刻抛出ConcurrentModificationException异常，而不是等待迭代完成之后才告诉你已经出错。 get方法 取key的hashCode值 高位运算 取模运算jdk1.7的hash方法12345678910final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; jdk1.8的hash方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 混合原始哈希码的高位和低位，以此来加大低位的随机性 而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来 图片出处:https://www.zhihu.com/question/20733617 indexFor方法(根据上一步hash结果,计算数组的下表)1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; getNode/getEntry–在链表中确定元素12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; hashmap的初始长度 16,长度必须是2的幂 之所以16是为了服务于哈希函数 index = HashCode（Key） &amp; （Length - 1） 与运算，101110001110101110 1001 &amp; 1111 = 1001，十进制是9，所以 index=9。 Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位 效果上等同于取模,而且大大提高了性能 put方法 先插找 如果已存在,则替换 如果不存在,插入 检查是否需要rehash rehash用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。 hashmap在扩容时候的步骤之一 衡量HashMap是否进行Resize的条件如下： HashMap.Size &gt;= Capacity * LoadFactor 具体两个步骤 1.扩容:创建一个新的Entry空数组，长度是原数组的2倍。 2.ReHash:遍历原Entry数组，把所有的Entry重新Hash到新数组 1.7源码123456789101112131415161718192021222324252627282930 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置 在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 其他博客中resize的错误表述:1对于原bullet中的链表中的数据在扩容之后肯定还在一个链表中，因为hash值是一样的 此描述是错误的,在一个链表中,不一定代表hash是一样的,只是代表hash&amp;(length-1)计算后的结果是一样的 并发问题 ReHash在并发的情况下可能会形成链表环。 让下一次循环出现死循环 ConcurrentHashMap 避免hashmap的方法有:hashtable,Collections.sysnchronizedMap 但是上面的都有性能问题,导致阻塞 Sement 可以说，ConcurrentHashMap是一个二级哈希表。在一个总的哈希表下面，有若干个子哈希表。这样的二级结构，和数据库的水平拆分有些相似。 不同Segment的写入是可以并发执行的。 同一Segment的一写一读 同一Segment的并发写入 12345678910111213141516171819202122Get方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.再次通过hash值，定位到Segment当中数组的具体位置。Put方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.获取可重入锁4.再次通过hash值，定位到Segment当中数组的具体位置。5.插入或覆盖HashEntry对象。6.释放锁。 如果在统计Segment元素数量的过程中，已统计过的Segment瞬间插入新的元素，这时候该怎么办呢？ 123456789101112131415ConcurrentHashMap的Size方法是一个嵌套循环，大体逻辑如下：1.遍历所有的Segment。2.把Segment的元素数量累加起来。3.把Segment的修改次数累加起来。4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。7.释放锁，统计结束。 为了尽量不锁住所有Segment，首先乐观地假设Size过程中不会有修改。当尝试一定次数，才无奈转为悲观锁，锁住所有Segment保证强一致性。 jdk 1.8hashmap HashMap采用的是数组+链表+红黑树的形式。 什么时候链表转化为红黑树？当数组大小已经超过64并且链表中的元素个数超过默认设定（8个）时，将链表转化为红黑树 jdk 1.8ConcurrentHashMap与hashTable的区别 继承的父类不同:Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类， 线程安全性不同:Hashtable 中的方法是Synchronize的 是否提供contains方法:HashMap把Hashtable的contains方法去掉了 key和value是否允许null值:Hashtable中，key和value都不允许出现null值。HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。 两个遍历方式的内部实现上不同:Hashtable还使用了Enumeration的方式 。 hash值不同:哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。 内部实现使用的数组初始化和扩容方式不同:Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 数据结构要知道hashmap是什么，首先要搞清楚它的数据结构，在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，hashmap也不例外。Hashmap实际上是一个数组和链表的结合体（在数据结构中，一般称之为“链表散列“） 哈希冲突概念 hashcode通过hash算法得到有限的地址区间 哈希冲突：由于哈希算法被计算的数据是无限的，而计算后的结果范围有限，因此总会存在不同的数据经过计算后得到的值相同，这就是哈希冲突。 解决哈希冲突的方法 1.开放定址法 开放定址法需要的表长度要大于等于所需要存放的元素。 2.线行探查法 它从发生冲突的单元起，依次判断下一个单元是否为空，当达到最后一个单元时，再从表首依次判断。直到碰到空闲的单元或者探查完全部单元为止。 3.平方探查法 4.双散列函数探查法 5.链地址法（拉链法） 注：在java中，链接地址法也是HashMap解决哈希冲突的方法之一，jdk1.7完全采用单链表来存储同义词，jdk1.8则采用了一种混合模式，对于链表长度大于8的，会转换为红黑树存储。 6.再哈希法 就是同时构造多个不同的哈希函数,发生冲突时，再用H2 = RH2(key) 进行计算，直到冲突不再产生，这种方法不易产生聚集，但是增加了计算时间。 7.建立公共溢出区 将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。 1.8源码hash算法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 混合高位和地位,以此来加大地位的随机性 数组的位置: (n - 1) &amp; hash 确定数组后,链表中确定相同的方法: e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))) always check first node 在一个数组中,不代表hash是一样的,so必须判断 数组的长度:因为16是2的整数次幂的原因,n-1 二进制中都是x个1,这样,更能减少key之间的碰撞 位运算符(知识补充)左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; )位与、位或、位异或、位非 123456789101112131415161718192021222324255&lt;&lt;20000 0000 0000 0000 0000 0000 0000 0101 然后左移2位后，低位补0：0000 0000 0000 0000 0000 0000 0001 0100 换算成10进制为205&gt;&gt;2还是先将5转为2进制表示形式：0000 0000 0000 0000 0000 0000 0000 0101 然后右移2位，高位补0：0000 0000 0000 0000 0000 0000 0000 0001-5&gt;&gt;&gt;3-5换算成二进制： 1111 1111 1111 1111 1111 1111 1111 1011-5无符号右移3位后的结果 536870911 换算成二进制： 0001 1111 1111 1111 1111 1111 1111 1111 // (用0进行补位)------------位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为05 &amp; 35转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 00111转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 0001位异或：第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为05 ^ 35转换为二进制：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制：0000 0000 0000 0000 0000 0000 0000 00116转换为二进制：0000 0000 0000 0000 0000 0000 0000 0110 参考http://blog.csdn.net/u013256816/article/details/50912762https://tech.meituan.com/java-hashmap.htmlhttps://bestswifter.com/hashtable/ 更新日志 2018.01.22:终于理解这段的代码:e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>数据结构</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-线性回归]]></title>
    <url>%2F2018%2F01%2F03%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study-linear-regression%2F</url>
    <content type="text"><![CDATA[概念 线性回归假设输出变量是若干输入变量的线性组合,并根据这一关系求解线性组合中的最优系数. 误差 在线性回归中,误差误差是以军方误差来定义的 求解 当线性回归的模型为二维平面上的直线时,军方误差就是预测输出和真实输出之间的欧几里得距离 求解方法是:最小二乘法 防止过拟合 存在多个最优解,意味着存在拟合,要解决过拟合问题,常见的做法是正则化,即添加额外的惩罚项,可分为两种:灵回过和LASSO回归 岭回归又被称作”参数衰减” LASSO回归,全程是”最小绝对缩减和选择算子” 与岭回归相比,LASSO回归的特点在于稀疏性的引入,时间花复杂问题的常用方法,在数据压缩,信号处理等其他领域中已有广泛的应用]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-机器学习概率]]></title>
    <url>%2F2018%2F01%2F02%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study-outline%2F</url>
    <content type="text"><![CDATA[概念 经验学习:从大量现象中提取反复出现的规律和模式 计算机给予数据构建概率统计模型并与应用模型对数据进行预测与分析的学科 根据输入输出类型的不行,预测问题分为三类 分类问题:输出离散变量 回归问题:连续变量 标注问题:序列 实际中就会存在误差,机器学习也是一样(误差性能) 误差并定义为学习器的实际预测与样本真实输出之间的差异 误差分为训练误差和测试误差 典型的过拟合现象:训练误差较低,但是训练误差较低 欠拟合:学习能力太弱 整体来看,测试误差与模型复杂度之间呈现得是抛物线的关系 交叉验证法,重复利用有限的样本,不同模型中平均测试误差最小的模型就是最有模型 调参:性能和效率之间的这种 根据训练数据是否有标签信息,可以将机器学习的任务分为三类 监督学习 无监督学习 半监督学习 监督学习分为: 生成方法:更快的收敛速度和更广的应用范围 判别方法:更高的准确性和更简单的使用方式 生成/判别方法 https://www.zhihu.com/question/20446337 有监督机器学习方法可以分为生成方法和判别方法 常见的生成方法有混合高斯模型、朴素贝叶斯法和隐形马尔科夫模型等 常见的判别方法有SVM、LR等 生成模型的求解思路是：联合分布——-&gt;求解类别先验概率和类别条件概率 判别模型求解的思路是：条件分布——&gt;模型参数后验概率最大——-&gt;（似然函数\cdot 参数先验）最大——-&gt;最大似然 生成模型:要知道原始数据的概率密度（或者估计参数得到），然后习惯用bayes理论去做预测 判别模型是不需要知道原始数据概率密度，比较粗线条 wiki例子 假设有四个samples： 生成式模型的世界是这个样子： 而判定式模型的世界是这个样子：]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-saleorder]]></title>
    <url>%2F2017%2F12%2F28%2Fegenie_bugfix%2Ferror-saleorder%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## An error report file with more information is saved as:# /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#Process finished with exit code 134 (interrupted by signal 6: SIGABRT) /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log中的文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#--------------- T H R E A D ---------------Current thread (0x00007fae5502f800): VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251]siginfo: si_signo: 11 (SIGSEGV), si_code: 1 (SEGV_MAPERR), si_addr: 0x00007f2e56b22522Registers:RAX=0x000000010c14e578, RBX=0x000000010c5c9148, RCX=0x0000000000330006, RDX=0x000000000000060aRSP=0x000070000d787430, RBP=0x000070000d787430, RSI=0x0000000000000000, RDI=0x00007f2e56b22520R8 =0x0000000000000007, R9 =0x00007fae56abe9c0, R10=0x000007fae56abee1, R11=0x0000000000000008R12=0x00000000000007d0, R13=0x000000010c5c9148, R14=0x000000000000034d, R15=0x0000000000000001RIP=0x000000010146e882, EFLAGS=0x0000000000010246, ERR=0x0000000000000004 TRAPNO=0x000000000000000eTop of Stack: (sp=0x000070000d787430)0x000070000d787430: 000070000d787450 000000010111c8970x000070000d787440: 000000010c5c9148 000000010c5c91480x000070000d787450: 000070000d787470 000000010112057c0x000070000d787460: 00007fae54611360 000000010c5c91480x000070000d787470: 000070000d787490 00000001011205f90x000070000d787480: 000000010c5c9148 00007fae546113600x000070000d787490: 000070000d7874c0 00000001010c46560x000070000d7874a0: 0000000000000003 0000000101518ec80x000070000d7874b0: 00007fae54611360 00000000000000030x000070000d7874c0: 000070000d787500 00000001010c8e640x000070000d7874d0: 000000010137f91e 00007fae546113600x000070000d7874e0: 000000010182d590 00000000000000000x000070000d7874f0: 000000010182d501 00007fae54502d100x000070000d787500: 000070000d787520 00000001010c8ec60x000070000d787510: 0000000000000000 00000000000000000x000070000d787520: 000070000d787550 00000001010c8f500x000070000d787530: 000070000d787550 00000001010c831b0x000070000d787540: 000000010182d501 000000010182d5010x000070000d787550: 000070000d787590 00000001010c8ff20x000070000d787560: 0000000000000000 000000010182d5900x000070000d787570: 0000000000000000 00007fae553f3ce00x000070000d787580: 000000010182d590 000070000d7876e00x000070000d787590: 000070000d7875b0 0000000101474c300x000070000d7875a0: 000070000d787690 000000010182d5900x000070000d7875b0: 000070000d787760 00000001013ff48b0x000070000d7875c0: 000000010182d810 000000000000001c0x000070000d7875d0: 0000000000000000 00000000000003a50x000070000d7875e0: 0000000000000172 00000000000000110x000070000d7875f0: 000000010151e9b3 00000000000000800x000070000d787600: 000070000d787640 00007fff6764d5620x000070000d787610: 000070000d787728 00000000000000000x000070000d787620: 00000000000003a5 0000000000000172 Instructions: (pc=0x000000010146e882)0x000000010146e862: 4c 89 e6 e8 c8 d0 f5 ff 49 ff c7 0f b7 03 41 390x000000010146e872: c7 7c e2 48 8d 35 25 da 0a 00 eb a5 55 48 89 e50x000000010146e882: 66 83 7f 02 00 79 02 5d c3 48 83 c7 02 5d e9 f70x000000010146e892: 74 b9 ff 90 55 48 89 e5 66 83 7f 02 00 79 02 5d Register to memory mapping:RAX=0x000000010c14e578 is pointing into metadataRBX=0x000000010c5c9148 is pointing into metadataRCX=0x0000000000330006 is an unknown valueRDX=0x000000000000060a is an unknown valueRSP=0x000070000d787430 is an unknown valueRBP=0x000070000d787430 is an unknown valueRSI=0x0000000000000000 is an unknown valueRDI=0x00007f2e56b22520 is an unknown valueR8 =0x0000000000000007 is an unknown valueR9 =0x00007fae56abe9c0 is an unknown valueR10=0x000007fae56abee1 is an unknown valueR11=0x0000000000000008 is an unknown valueR12=0x00000000000007d0 is an unknown valueR13=0x000000010c5c9148 is pointing into metadataR14=0x000000000000034d is an unknown valueR15=0x0000000000000001 is an unknown valueStack: [0x000070000d688000,0x000070000d788000], sp=0x000070000d787430, free space=1021kNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4V [libjvm.dylib+0x1e2897] ConstantPool::unreference_symbols()+0x29V [libjvm.dylib+0x1e657c] ConstantPool::release_C_heap_structures()+0x12V [libjvm.dylib+0x1e65f9] ConstantPool::deallocate_contents(ClassLoaderData*)+0x51V [libjvm.dylib+0x18a656] void MetadataFactory::free_metadata&lt;ConstantPool*&gt;(ClassLoaderData*, ConstantPool*)+0x44V [libjvm.dylib+0x18ee64] ClassLoaderData::free_deallocate_list()+0x96V [libjvm.dylib+0x18eec6] ClassLoaderDataGraph::free_deallocate_lists()+0x1aV [libjvm.dylib+0x18ef50] ClassLoaderDataGraph::clean_metaspaces()+0x5cV [libjvm.dylib+0x18eff2] ClassLoaderDataGraph::do_unloading(BoolObjectClosure*, bool)+0x90V [libjvm.dylib+0x53ac30] SystemDictionary::do_unloading(BoolObjectClosure*, bool)+0x12V [libjvm.dylib+0x4c548b] PSParallelCompact::marking_phase(ParCompactionManager*, bool, ParallelOldTracer*)+0x52fV [libjvm.dylib+0x4c6977] PSParallelCompact::invoke_no_policy(bool)+0x41bV [libjvm.dylib+0x4c6f8b] PSParallelCompact::invoke(bool)+0x57V [libjvm.dylib+0x19eef6] CollectedHeap::collect_as_vm_thread(GCCause::Cause)+0x5eV [libjvm.dylib+0x5b2cb4] VM_CollectForMetadataAllocation::doit()+0xb0V [libjvm.dylib+0x5b9b29] VM_Operation::evaluate()+0x4fV [libjvm.dylib+0x5b8195] VMThread::evaluate_operation(VM_Operation*)+0xdfV [libjvm.dylib+0x5b85e2] VMThread::loop()+0x328V [libjvm.dylib+0x5b7f01] VMThread::run()+0x79V [libjvm.dylib+0x48bbb2] java_start(Thread*)+0xf6C [libsystem_pthread.dylib+0x36c1] _pthread_body+0x154C [libsystem_pthread.dylib+0x356d] _pthread_body+0x0C [libsystem_pthread.dylib+0x2c5d] thread_start+0xdVM_Operation (0x0000700016e3fbd8): CollectForMetadataAllocation, mode: safepoint, requested by thread 0x00007fae55a24000--------------- P R O C E S S ---------------Java Threads: ( =&gt; current thread ) 0x00007fae5638a000 JavaThread &quot;JMX server connection timeout 320&quot; daemon [_thread_blocked, id=128775, stack(0x0000700016838000,0x0000700016938000)] 0x00007fae55a24000 JavaThread &quot;RMI TCP Connection(10)-192.168.0.123&quot; daemon [_thread_blocked, id=88323, stack(0x0000700016d47000,0x0000700016e47000)] 0x00007fae55353000 JavaThread &quot;JMX server connection timeout 317&quot; daemon [_thread_blocked, id=129027, stack(0x0000700016c44000,0x0000700016d44000)] 0x00007fae55808800 JavaThread &quot;RMI TCP Connection(9)-192.168.0.123&quot; daemon [_thread_blocked, id=129283, stack(0x0000700016b41000,0x0000700016c41000)] 0x00007fae55352800 JavaThread &quot;RMI TCP Connection(8)-127.0.0.1&quot; daemon [_thread_in_native, id=129795, stack(0x0000700016a3e000,0x0000700016b3e000)] 0x00007fae5638f000 JavaThread &quot;RMI TCP Connection(7)-127.0.0.1&quot; daemon [_thread_in_native, id=130051, stack(0x000070001693b000,0x0000700016a3b000)] 0x00007fae54c28800 JavaThread &quot;DestroyJavaVM&quot; [_thread_blocked, id=4611, stack(0x000070000d073000,0x000070000d173000)] 0x00007fae5534f000 JavaThread &quot;Thread-149&quot; [_thread_blocked, id=87315, stack(0x0000700016735000,0x0000700016835000)] 0x00007fae54c23000 JavaThread &quot;RMI TCP Connection(6)-192.168.0.123&quot; daemon [_thread_in_native, id=65027, stack(0x0000700016632000,0x0000700016732000)] 0x00007fae5532b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-41&quot; daemon [_thread_blocked, id=65539, stack(0x000070001652f000,0x000070001662f000)] 0x00007fae56310800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-40&quot; daemon [_thread_blocked, id=66051, stack(0x000070001642c000,0x000070001652c000)] 0x00007fae5532a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-39&quot; daemon [_thread_blocked, id=64259, stack(0x0000700016329000,0x0000700016429000)] 0x00007fae55cc4000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-38&quot; daemon [_thread_blocked, id=63747, stack(0x0000700016226000,0x0000700016326000)] 0x00007fae55335800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-37&quot; daemon [_thread_blocked, id=66567, stack(0x0000700016123000,0x0000700016223000)] 0x00007fae54c22000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-36&quot; daemon [_thread_blocked, id=63235, stack(0x0000700016020000,0x0000700016120000)] 0x00007fae54c21800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-35&quot; daemon [_thread_blocked, id=66819, stack(0x0000700015f1d000,0x000070001601d000)] 0x00007fae56502800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-34&quot; daemon [_thread_blocked, id=67075, stack(0x0000700015e1a000,0x0000700015f1a000)] 0x00007fae55cc3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-33&quot; daemon [_thread_blocked, id=62467, stack(0x0000700015d17000,0x0000700015e17000)] 0x00007fae562fc000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-32&quot; daemon [_thread_blocked, id=67587, stack(0x0000700015c14000,0x0000700015d14000)] 0x00007fae55bd9000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-31&quot; daemon [_thread_blocked, id=67843, stack(0x0000700015b11000,0x0000700015c11000)] 0x00007fae55335000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-30&quot; daemon [_thread_blocked, id=68359, stack(0x0000700015a0e000,0x0000700015b0e000)] 0x00007fae562fa000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-29&quot; daemon [_thread_blocked, id=61443, stack(0x000070001590b000,0x0000700015a0b000)] 0x00007fae54f20800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-28&quot; daemon [_thread_blocked, id=68611, stack(0x0000700015808000,0x0000700015908000)] 0x00007fae55334000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-27&quot; daemon [_thread_blocked, id=60679, stack(0x0000700015705000,0x0000700015805000)] 0x00007fae54f1f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-26&quot; daemon [_thread_blocked, id=60467, stack(0x0000700015602000,0x0000700015702000)] 0x00007fae5631e000 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-4&quot; daemon [_thread_blocked, id=60163, stack(0x00007000154ff000,0x00007000155ff000)] 0x00007fae55cc1800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-3&quot; daemon [_thread_blocked, id=69635, stack(0x00007000153fc000,0x00007000154fc000)] 0x00007fae54d20000 JavaThread &quot;job-event-8&quot; daemon [_thread_blocked, id=70163, stack(0x00007000152f9000,0x00007000153f9000)] 0x00007fae5631f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-25&quot; daemon [_thread_blocked, id=59683, stack(0x00007000151f6000,0x00007000152f6000)] 0x00007fae55383800 JavaThread &quot;job-event-7&quot; daemon [_thread_blocked, id=59399, stack(0x00007000150f3000,0x00007000151f3000)] 0x00007fae56316800 JavaThread &quot;job-event-6&quot; daemon [_thread_blocked, id=58883, stack(0x0000700014ff0000,0x00007000150f0000)] 0x00007fae54d06800 JavaThread &quot;job-event-5&quot; daemon [_thread_blocked, id=58379, stack(0x0000700014eed000,0x0000700014fed000)] 0x00007fae56316000 JavaThread &quot;DubboResponseTimeoutScanTimer&quot; daemon [_thread_blocked, id=70915, stack(0x0000700014dea000,0x0000700014eea000)] 0x00007fae56409800 JavaThread &quot;job-event-3&quot; daemon [_thread_blocked, id=71171, stack(0x0000700014ce7000,0x0000700014de7000)] 0x00007fae5594e800 JavaThread &quot;job-event-4&quot; daemon [_thread_blocked, id=57859, stack(0x0000700014be4000,0x0000700014ce4000)] 0x00007fae5594d800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-2&quot; daemon [_thread_blocked, id=71683, stack(0x0000700014ae1000,0x0000700014be1000)] 0x00007fae56406800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-1&quot; daemon [_thread_blocked, id=71939, stack(0x00007000149de000,0x0000700014ade000)] 0x00007fae54cfa800 JavaThread &quot;job-event-2&quot; daemon [_thread_blocked, id=72195, stack(0x00007000148db000,0x00007000149db000)] 0x00007fae56405000 JavaThread &quot;job-event-1&quot; daemon [_thread_blocked, id=72723, stack(0x00007000147d8000,0x00007000148d8000)] 0x00007fae54d48800 JavaThread &quot;RMI TCP Connection(5)-192.168.0.123&quot; daemon [_thread_in_native, id=73223, stack(0x00007000146d5000,0x00007000147d5000)] 0x00007fae55341000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=73739, stack(0x00007000145d2000,0x00007000146d2000)] 0x00007fae55362800 JavaThread &quot;Curator-TreeCache-6&quot; daemon [_thread_blocked, id=56839, stack(0x00007000144cf000,0x00007000145cf000)] 0x00007fae55361800 JavaThread &quot;Timer-6&quot; daemon [_thread_blocked, id=56323, stack(0x00007000143cc000,0x00007000144cc000)] 0x00007fae5644d800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=56067, stack(0x00007000142c9000,0x00007000143c9000)] 0x00007fae5644d000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_Worker-1&quot; [_thread_blocked, id=55555, stack(0x00007000141c6000,0x00007000142c6000)] 0x00007fae55361000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=55311, stack(0x00007000140c3000,0x00007000141c3000)] 0x00007fae552de000 JavaThread &quot;Curator-TreeCache-5&quot; daemon [_thread_blocked, id=55047, stack(0x0000700013fc0000,0x00007000140c0000)] 0x00007fae54ca0800 JavaThread &quot;Timer-5&quot; daemon [_thread_blocked, id=54531, stack(0x0000700013ebd000,0x0000700013fbd000)] 0x00007fae54ca0000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_QuartzSchedulerThread&quot; [_thread_blocked, id=75011, stack(0x0000700013dba000,0x0000700013eba000)] 0x00007fae552dd000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_Worker-1&quot; [_thread_blocked, id=54019, stack(0x0000700013cb7000,0x0000700013db7000)] 0x00007fae5534b800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=75779, stack(0x0000700013bb4000,0x0000700013cb4000)] 0x00007fae55a1c000 JavaThread &quot;Curator-TreeCache-4&quot; daemon [_thread_blocked, id=76295, stack(0x0000700013ab1000,0x0000700013bb1000)] 0x00007fae5534b000 JavaThread &quot;Timer-4&quot; daemon [_thread_blocked, id=76547, stack(0x00007000139ae000,0x0000700013aae000)] 0x00007fae55a3b000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=53507, stack(0x00007000138ab000,0x00007000139ab000)] 0x00007fae54c96000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_Worker-1&quot; [_thread_blocked, id=52999, stack(0x00007000137a8000,0x00007000138a8000)] 0x00007fae5644a000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=52743, stack(0x00007000136a5000,0x00007000137a5000)] 0x00007fae56449000 JavaThread &quot;Curator-TreeCache-3&quot; daemon [_thread_blocked, id=77323, stack(0x00007000135a2000,0x00007000136a2000)] 0x00007fae54c95800 JavaThread &quot;Timer-3&quot; daemon [_thread_blocked, id=52227, stack(0x000070001349f000,0x000070001359f000)] 0x00007fae54c94800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=51971, stack(0x000070001339c000,0x000070001349c000)] 0x00007fae54c94000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_Worker-1&quot; [_thread_blocked, id=51459, stack(0x0000700013299000,0x0000700013399000)] 0x00007fae564e6800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=78351, stack(0x0000700013196000,0x0000700013296000)] 0x00007fae54c92800 JavaThread &quot;Curator-TreeCache-2&quot; daemon [_thread_blocked, id=51207, stack(0x0000700013093000,0x0000700013193000)] 0x00007fae562ef800 JavaThread &quot;Timer-2&quot; daemon [_thread_blocked, id=79107, stack(0x0000700012f90000,0x0000700013090000)] 0x00007fae562ef000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=79363, stack(0x0000700012e8d000,0x0000700012f8d000)] 0x00007fae54c91800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_Worker-1&quot; [_thread_blocked, id=79895, stack(0x0000700012d8a000,0x0000700012e8a000)] 0x00007fae5533d000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80131, stack(0x0000700012c87000,0x0000700012d87000)] 0x00007fae552a6800 JavaThread &quot;Curator-TreeCache-1&quot; daemon [_thread_blocked, id=50187, stack(0x0000700012b84000,0x0000700012c84000)] 0x00007fae55a3d800 JavaThread &quot;Timer-1&quot; daemon [_thread_blocked, id=49667, stack(0x0000700012a81000,0x0000700012b81000)] 0x00007fae55a3c800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_QuartzSchedulerThread&quot; [_thread_blocked, id=49411, stack(0x000070001297e000,0x0000700012a7e000)] 0x00007fae55be1000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_Worker-1&quot; [_thread_blocked, id=49155, stack(0x000070001287b000,0x000070001297b000)] 0x00007fae55be0800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80915, stack(0x0000700012778000,0x0000700012878000)] 0x00007fae56400000 JavaThread &quot;Curator-TreeCache-0&quot; daemon [_thread_blocked, id=81411, stack(0x0000700012675000,0x0000700012775000)] 0x00007fae563ff800 JavaThread &quot;Timer-0&quot; daemon [_thread_blocked, id=48643, stack(0x0000700012572000,0x0000700012672000)] 0x00007fae56112800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_QuartzSchedulerThread&quot; [_thread_blocked, id=48387, stack(0x000070001246f000,0x000070001256f000)] 0x00007fae562bf800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_Worker-1&quot; [_thread_blocked, id=82439, stack(0x000070001236c000,0x000070001246c000)] 0x00007fae54ae4800 JavaThread &quot;DubboClientHandler-192.168.0.157:20881-thread-1&quot; daemon [_thread_blocked, id=82703, stack(0x0000700012269000,0x0000700012369000)] 0x00007fae5533e800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-24&quot; daemon [_thread_blocked, id=82947, stack(0x0000700012166000,0x0000700012266000)] 0x00007fae54a64800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-23&quot; daemon [_thread_blocked, id=47363, stack(0x0000700012063000,0x0000700012163000)] 0x00007fae560f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-22&quot; daemon [_thread_blocked, id=83459, stack(0x0000700011f60000,0x0000700012060000)] 0x00007fae54b1b800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-21&quot; daemon [_thread_blocked, id=83971, stack(0x0000700011e5d000,0x0000700011f5d000)] 0x00007fae54b1a800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-20&quot; daemon [_thread_blocked, id=84227, stack(0x0000700011d5a000,0x0000700011e5a000)] 0x00007fae563f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-19&quot; daemon [_thread_blocked, id=46595, stack(0x0000700011c57000,0x0000700011d57000)] 0x00007fae54b1a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-18&quot; daemon [_thread_blocked, id=46083, stack(0x0000700011b54000,0x0000700011c54000)] 0x00007fae54b7f000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-17&quot; daemon [_thread_blocked, id=45831, stack(0x000070001194e000,0x0000700011a4e000)] 0x00007fae563f2000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-16&quot; daemon [_thread_blocked, id=84739, stack(0x0000700011a51000,0x0000700011b51000)] 0x00007fae54b7e000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-15&quot; daemon [_thread_blocked, id=45571, stack(0x000070001184b000,0x000070001194b000)] 0x00007fae54a3f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-14&quot; daemon [_thread_blocked, id=85507, stack(0x0000700011748000,0x0000700011848000)] 0x00007fae562a7000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-13&quot; daemon [_thread_blocked, id=45059, stack(0x0000700011645000,0x0000700011745000)] 0x00007fae54a54800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-12&quot; daemon [_thread_blocked, id=86275, stack(0x0000700011542000,0x0000700011642000)] 0x00007fae54a54000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-11&quot; daemon [_thread_blocked, id=44547, stack(0x000070001143f000,0x000070001153f000)] 0x00007fae54b76000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-10&quot; daemon [_thread_blocked, id=44035, stack(0x000070001133c000,0x000070001143c000)] 0x00007fae551ee800 JavaThread &quot;Druid-ConnectionPool-Destroy-2073021938&quot; daemon [_thread_blocked, id=86787, stack(0x0000700011239000,0x0000700011339000)] 0x00007fae55202800 JavaThread &quot;Druid-ConnectionPool-Create-2073021938&quot; daemon [_thread_blocked, id=87051, stack(0x0000700011136000,0x0000700011236000)] 0x00007fae564b8000 JavaThread &quot;Abandoned connection cleanup thread&quot; daemon [_thread_blocked, id=32003, stack(0x0000700011033000,0x0000700011133000)] 0x00007fae54976000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-9&quot; daemon [_thread_blocked, id=31763, stack(0x0000700010f30000,0x0000700011030000)] 0x00007fae552c4000 JavaThread &quot;DubboClientHandler-192.168.0.134:20880-thread-1&quot; daemon [_thread_blocked, id=31495, stack(0x0000700010e2d000,0x0000700010f2d000)] 0x00007fae54b36800 JavaThread &quot;DubboClientHandler-192.168.0.157:20887-thread-1&quot; daemon [_thread_blocked, id=31003, stack(0x0000700010d2a000,0x0000700010e2a000)] 0x00007fae5622d000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-8&quot; daemon [_thread_blocked, id=30723, stack(0x0000700010c27000,0x0000700010d27000)] 0x00007fae54b91000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-7&quot; daemon [_thread_blocked, id=33031, stack(0x0000700010b24000,0x0000700010c24000)] 0x00007fae54b8b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-6&quot; daemon [_thread_blocked, id=33283, stack(0x0000700010a21000,0x0000700010b21000)] 0x00007fae56231800 JavaThread &quot;DubboClientHandler-192.168.0.157:20883-thread-1&quot; daemon [_thread_blocked, id=29955, stack(0x000070001091e000,0x0000700010a1e000)] 0x00007fae559ae000 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-2&quot; daemon [_thread_blocked, id=29443, stack(0x000070001081b000,0x000070001091b000)] 0x00007fae552a3800 JavaThread &quot;DubboClientHandler-192.168.0.126:20882-thread-1&quot; daemon [_thread_blocked, id=34067, stack(0x0000700010718000,0x0000700010818000)] 0x00007fae56228000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-5&quot; daemon [_thread_blocked, id=28939, stack(0x0000700010615000,0x0000700010715000)] 0x00007fae56200000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-4&quot; daemon [_thread_blocked, id=34307, stack(0x0000700010512000,0x0000700010612000)] 0x00007fae54bbf800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-3&quot; daemon [_thread_blocked, id=28431, stack(0x000070001040f000,0x000070001050f000)] 0x00007fae56421800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-2&quot; daemon [_thread_blocked, id=28163, stack(0x000070001030c000,0x000070001040c000)] 0x00007fae54b66000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-1&quot; daemon [_thread_blocked, id=35339, stack(0x0000700010209000,0x0000700010309000)] 0x00007fae54bf4800 JavaThread &quot;dubbo-remoting-server-heartbeat-thread-1&quot; daemon [_thread_blocked, id=27651, stack(0x0000700010106000,0x0000700010206000)] 0x00007fae54bf3800 JavaThread &quot;New I/O server boss #12&quot; daemon [_thread_in_native, id=27139, stack(0x0000700010003000,0x0000700010103000)] 0x00007fae54b63000 JavaThread &quot;New I/O worker #11&quot; daemon [_thread_in_native, id=35843, stack(0x000070000ff00000,0x0000700010000000)] 0x00007fae54bf3000 JavaThread &quot;New I/O worker #10&quot; daemon [_thread_in_native, id=36099, stack(0x000070000fdfd000,0x000070000fefd000)] 0x00007fae54bf2000 JavaThread &quot;New I/O worker #9&quot; daemon [_thread_in_native, id=26371, stack(0x000070000fcfa000,0x000070000fdfa000)] 0x00007fae56421000 JavaThread &quot;New I/O worker #8&quot; daemon [_thread_in_native, id=36611, stack(0x000070000fbf7000,0x000070000fcf7000)] 0x00007fae54bf1800 JavaThread &quot;New I/O worker #7&quot; daemon [_thread_in_native, id=37139, stack(0x000070000faf4000,0x000070000fbf4000)] 0x00007fae54c5f800 JavaThread &quot;DubboClientReconnectTimer-thread-2&quot; daemon [_thread_blocked, id=26131, stack(0x000070000f9f1000,0x000070000faf1000)] 0x00007fae563e4800 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-1&quot; daemon [_thread_blocked, id=37891, stack(0x000070000f8ee000,0x000070000f9ee000)] 0x00007fae563e4000 JavaThread &quot;DubboClientHandler-192.168.0.157:20880-thread-1&quot; daemon [_thread_blocked, id=25859, stack(0x000070000f7eb000,0x000070000f8eb000)] 0x00007fae54c3c800 JavaThread &quot;Hashed wheel timer #1&quot; [_thread_blocked, id=25603, stack(0x000070000f6e8000,0x000070000f7e8000)] 0x00007fae56016800 JavaThread &quot;DubboClientReconnectTimer-thread-1&quot; daemon [_thread_blocked, id=25091, stack(0x000070000f5e5000,0x000070000f6e5000)] 0x00007fae54a33800 JavaThread &quot;New I/O boss #6&quot; daemon [_thread_in_native, id=38659, stack(0x000070000f4e2000,0x000070000f5e2000)] 0x00007fae54c3e000 JavaThread &quot;New I/O worker #5&quot; daemon [_thread_blocked, id=24579, stack(0x000070000f3df000,0x000070000f4df000)] 0x00007fae561d4800 JavaThread &quot;New I/O worker #4&quot; daemon [_thread_in_native, id=39427, stack(0x000070000f2dc000,0x000070000f3dc000)] 0x00007fae561c7800 JavaThread &quot;New I/O worker #3&quot; daemon [_thread_in_native, id=39683, stack(0x000070000f1d9000,0x000070000f2d9000)] 0x00007fae561c6800 JavaThread &quot;New I/O worker #2&quot; daemon [_thread_in_native, id=24067, stack(0x000070000f0d6000,0x000070000f1d6000)] 0x00007fae561cb800 JavaThread &quot;New I/O worker #1&quot; daemon [_thread_blocked, id=23811, stack(0x000070000efd3000,0x000070000f0d3000)] 0x00007fae55c61000 JavaThread &quot;DubboSaveRegistryCache-thread-1&quot; daemon [_thread_blocked, id=40459, stack(0x000070000eed0000,0x000070000efd0000)] 0x00007fae561c6000 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=40963, stack(0x000070000edcd000,0x000070000eecd000)] 0x00007fae56502000 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_in_native, id=41475, stack(0x000070000ecca000,0x000070000edca000)] 0x00007fae56501000 JavaThread &quot;ZkClient-EventThread-50-192.168.0.156:2181&quot; daemon [_thread_blocked, id=23307, stack(0x000070000ebc7000,0x000070000ecc7000)] 0x00007fae564fc000 JavaThread &quot;DubboRegistryFailedRetryTimer-thread-1&quot; daemon [_thread_blocked, id=5703, stack(0x000070000eac4000,0x000070000ebc4000)] 0x00007fae55283800 JavaThread &quot;Curator-Framework-0&quot; daemon [_thread_blocked, id=42243, stack(0x000070000e9c1000,0x000070000eac1000)] 0x00007fae55282800 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=42499, stack(0x000070000e8be000,0x000070000e9be000)] 0x00007fae564f2800 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_blocked, id=22787, stack(0x000070000e7bb000,0x000070000e8bb000)] 0x00007fae5526d800 JavaThread &quot;Curator-ConnectionStateManager-0&quot; daemon [_thread_blocked, id=43047, stack(0x000070000e6b8000,0x000070000e7b8000)] 0x00007fae55aad000 JavaThread &quot;RMI TCP Connection(3)-192.168.0.123&quot; daemon [_thread_in_native, id=43267, stack(0x000070000e5b5000,0x000070000e6b5000)] 0x00007fae551e2000 JavaThread &quot;RMI Scheduler(0)&quot; daemon [_thread_blocked, id=21763, stack(0x000070000e4b2000,0x000070000e5b2000)] 0x00007fae5497b000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=15875, stack(0x000070000e2ac000,0x000070000e3ac000)] 0x00007fae55a09000 JavaThread &quot;RMI TCP Connection(1)-127.0.0.1&quot; daemon [_thread_in_native, id=15363, stack(0x000070000e1a9000,0x000070000e2a9000)] 0x00007fae55a16000 JavaThread &quot;RMI TCP Accept-52007&quot; daemon [_thread_in_native, id=16899, stack(0x000070000e0a6000,0x000070000e1a6000)] 0x00007fae5617f000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=17155, stack(0x000070000dfa3000,0x000070000e0a3000)] 0x00007fae54956800 JavaThread &quot;Service Thread&quot; daemon [_thread_blocked, id=17411, stack(0x000070000dea0000,0x000070000dfa0000)] 0x00007fae560f0000 JavaThread &quot;C1 CompilerThread2&quot; daemon [_thread_blocked, id=14083, stack(0x000070000dd9d000,0x000070000de9d000)] 0x00007fae5593f000 JavaThread &quot;C2 CompilerThread1&quot; daemon [_thread_blocked, id=13571, stack(0x000070000dc9a000,0x000070000dd9a000)] 0x00007fae560ef800 JavaThread &quot;C2 CompilerThread0&quot; daemon [_thread_blocked, id=17923, stack(0x000070000db97000,0x000070000dc97000)] 0x00007fae55034000 JavaThread &quot;Monitor Ctrl-Break&quot; daemon [_thread_in_native, id=18435, stack(0x000070000da94000,0x000070000db94000)] 0x00007fae5600f000 JavaThread &quot;Signal Dispatcher&quot; daemon [_thread_blocked, id=12811, stack(0x000070000d991000,0x000070000da91000)] 0x00007fae5482b000 JavaThread &quot;Finalizer&quot; daemon [_thread_blocked, id=11779, stack(0x000070000d88e000,0x000070000d98e000)] 0x00007fae55032800 JavaThread &quot;Reference Handler&quot; daemon [_thread_blocked, id=20995, stack(0x000070000d78b000,0x000070000d88b000)]Other Threads:=&gt;0x00007fae5502f800 VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251] 0x00007fae5497b800 WatcherThread [stack: 0x000070000e3af000,0x000070000e4af000] [id=16131]VM state:at safepoint (normal execution)VM Mutex/Monitor currently owned by a thread: ([mutex/lock_event])[0x00007fae54601800] Threads_lock - owner thread: 0x00007fae5502f800[0x00007fae54601d00] Heap_lock - owner thread: 0x00007fae55a24000Heap: PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KCard table byte_map: [0x0000000102bc0000,0x0000000102fc1000] byte_map_base: 0x00000000ff1c0000Marking Bits: (ParMarkBitMap*) 0x000000010182d5d0 Begin Bits: [0x000000010326c000, 0x000000010526c000) End Bits: [0x000000010526c000, 0x000000010726c000)Polling page: 0x0000000101f24000CodeCache: size=245760Kb used=13228Kb max_used=13248Kb free=232531Kb bounds [0x000000010d78b000, 0x000000010e48b000, 0x000000011c78b000] total_blobs=6800 nmethods=6274 adapters=438 compilation: enabledCompilation events (10 events):Event: 72.788 Thread 0x00007fae560f0000 nmethod 6375 0x000000010dd32b10 code [0x000000010dd32c80, 0x000000010dd32da8]Event: 72.790 Thread 0x00007fae560f0000 6376 1 com.sun.jmx.mbeanserver.MBeanSupport::invoke (19 bytes)Event: 72.790 Thread 0x00007fae560f0000 nmethod 6376 0x000000010dd50590 code [0x000000010dd50700, 0x000000010dd50898]Event: 72.792 Thread 0x00007fae560f0000 6377 1 javax.management.remote.rmi.RMIConnectionImpl::nullIsEmpty (12 bytes)Event: 72.793 Thread 0x00007fae560f0000 nmethod 6377 0x000000010dd502d0 code [0x000000010dd50420, 0x000000010dd50530]Event: 72.793 Thread 0x00007fae560f0000 6378 1 com.sun.jmx.mbeanserver.PerInterface::invoke (269 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6378 0x000000010dd3e510 code [0x000000010dd3e820, 0x000000010dd3f4a8]Event: 72.797 Thread 0x00007fae560f0000 6379 1 javax.management.remote.rmi.RMIConnectionImpl$6::run (17 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6379 0x000000010dd3e190 code [0x000000010dd3e300, 0x000000010dd3e448]Event: 72.797 Thread 0x00007fae560f0000 6380 ! 1 javax.management.remote.rmi.RMIConnectionImpl::unwrap (301 bytes)GC Heap History (10 events):Event: 54.010 GC heap afterHeap after GC invocations=24 (full 3): PSYoungGen total 611840K, used 34359K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40321K, capacity 41992K, committed 42112K, reserved 1085440K class space used 4923K, capacity 5182K, committed 5248K, reserved 1048576K&#125;Event: 55.308 GC heap before&#123;Heap before GC invocations=25 (full 3): PSYoungGen total 611840K, used 568887K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 100% used [0x0000000795580000,0x00000007b5f80000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576KEvent: 55.332 GC heap afterHeap after GC invocations=25 (full 3): PSYoungGen total 617472K, used 47568K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576K&#125;Event: 56.843 GC heap before&#123;Heap before GC invocations=26 (full 3): PSYoungGen total 617472K, used 589776K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576KEvent: 56.881 GC heap afterHeap after GC invocations=26 (full 3): PSYoungGen total 586752K, used 44259K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576K&#125;Event: 71.208 GC heap before&#123;Heap before GC invocations=27 (full 3): PSYoungGen total 586752K, used 586467K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576KEvent: 71.246 GC heap afterHeap after GC invocations=27 (full 3): PSYoungGen total 623616K, used 33938K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576K&#125;Event: 72.798 GC heap before&#123;Heap before GC invocations=28 (full 3): PSYoungGen total 623616K, used 66204K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 5% used [0x0000000795580000,0x0000000797502a20,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KEvent: 72.833 GC heap afterHeap after GC invocations=28 (full 3): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576K&#125;Event: 72.833 GC heap before&#123;Heap before GC invocations=29 (full 4): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KDeoptimization events (0 events):No eventsInternal exceptions (10 events):Event: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeBeanInfo&gt; (0x0000000795895208) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictionaEvent: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeCustomizer&gt; (0x00000007958b3560) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictioEvent: 71.290 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795901e88) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanBeanInfo&gt; (0x00000007959c81d8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanCustomizer&gt; (0x00000007959ea158) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/syEvent: 71.309 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795a1a220) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.327 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b18538) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2dd00) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2ead8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b34770) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Events (10 events):Event: 72.768 Thread 0x00007fae560f0000 flushing nmethod 0x000000010df51bd0Event: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparatorEvent: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparator doneEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContextEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContext doneEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContextEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContext doneEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$SegmentEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$Segment doneEvent: 72.798 Executing VM operation: CollectForMetadataAllocationDynamic libraries:0x000000001832f000 /System/Library/Frameworks/Cocoa.framework/Versions/A/Cocoa0x000000001832f000 /System/Library/Frameworks/Security.framework/Versions/A/Security0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices0x000000001832f000 /usr/lib/libz.1.dylib0x000000001832f000 /usr/lib/libSystem.B.dylib0x000000001832f000 /usr/lib/libobjc.A.dylib0x000000001832f000 /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation0x000000001832f000 /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation0x000000001832f000 /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit0x000000001832f000 /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData0x000000001832f000 /System/Library/PrivateFrameworks/RemoteViewServices.framework/Versions/A/RemoteViewServices0x000000001832f000 /System/Library/PrivateFrameworks/UIFoundation.framework/Versions/A/UIFoundation0x000000001832f000 /System/Library/PrivateFrameworks/DFRFoundation.framework/Versions/A/DFRFoundation0x000000001832f000 /System/Library/Frameworks/Metal.framework/Versions/A/Metal0x000000001832f000 /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv0x000000001832f000 /usr/lib/libenergytrace.dylib0x000000001832f000 /System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight0x000000001832f000 /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics0x000000001832f000 /usr/lib/libScreenReader.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate0x000000001832f000 /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface0x000000001832f000 /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox0x000000001832f000 /System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit0x000000001832f000 /System/Library/PrivateFrameworks/DataDetectorsCore.framework/Versions/A/DataDetectorsCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox0x000000001832f000 /usr/lib/libicucore.A.dylib0x000000001832f000 /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition0x000000001832f000 /usr/lib/libauto.dylib0x000000001832f000 /usr/lib/libxml2.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI0x000000001832f000 /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio0x000000001832f000 /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration0x000000001832f000 /usr/lib/liblangid.dylib0x000000001832f000 /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport0x000000001832f000 /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit0x000000001832f000 /usr/lib/libDiagnosticMessagesClient.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices0x000000001832f000 /System/Library/PrivateFrameworks/PerformanceAnalysis.framework/Versions/A/PerformanceAnalysis0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL0x000000001832f000 /System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync0x000000001832f000 /System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage0x000000001832f000 /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO0x000000001832f000 /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup0x000000001832f000 /usr/lib/libarchive.2.dylib0x000000001832f000 /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork0x000000001832f000 /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration0x000000001832f000 /usr/lib/libCRFSuite.dylib0x000000001832f000 /usr/lib/libc++.1.dylib0x000000001832f000 /usr/lib/libc++abi.dylib0x000000001832f000 /usr/lib/system/libcache.dylib0x000000001832f000 /usr/lib/system/libcommonCrypto.dylib0x000000001832f000 /usr/lib/system/libcompiler_rt.dylib0x000000001832f000 /usr/lib/system/libcopyfile.dylib0x000000001832f000 /usr/lib/system/libcorecrypto.dylib0x000000001832f000 /usr/lib/system/libdispatch.dylib0x000000001832f000 /usr/lib/system/libdyld.dylib0x000000001832f000 /usr/lib/system/libkeymgr.dylib0x000000001832f000 /usr/lib/system/liblaunch.dylib0x000000001832f000 /usr/lib/system/libmacho.dylib0x000000001832f000 /usr/lib/system/libquarantine.dylib0x000000001832f000 /usr/lib/system/libremovefile.dylib0x000000001832f000 /usr/lib/system/libsystem_asl.dylib0x000000001832f000 /usr/lib/system/libsystem_blocks.dylib0x000000001832f000 /usr/lib/system/libsystem_c.dylib0x000000001832f000 /usr/lib/system/libsystem_configuration.dylib0x000000001832f000 /usr/lib/system/libsystem_coreservices.dylib0x000000001832f000 /usr/lib/system/libsystem_darwin.dylib0x000000001832f000 /usr/lib/system/libsystem_dnssd.dylib0x000000001832f000 /usr/lib/system/libsystem_info.dylib0x000000001832f000 /usr/lib/system/libsystem_m.dylib0x000000001832f000 /usr/lib/system/libsystem_malloc.dylib0x000000001832f000 /usr/lib/system/libsystem_network.dylib0x000000001832f000 /usr/lib/system/libsystem_networkextension.dylib0x000000001832f000 /usr/lib/system/libsystem_notify.dylib0x000000001832f000 /usr/lib/system/libsystem_sandbox.dylib0x000000001832f000 /usr/lib/system/libsystem_secinit.dylib0x000000001832f000 /usr/lib/system/libsystem_kernel.dylib0x000000001832f000 /usr/lib/system/libsystem_platform.dylib0x000000001832f000 /usr/lib/system/libsystem_pthread.dylib0x000000001832f000 /usr/lib/system/libsystem_symptoms.dylib0x000000001832f000 /usr/lib/system/libsystem_trace.dylib0x000000001832f000 /usr/lib/system/libunwind.dylib0x000000001832f000 /usr/lib/system/libxpc.dylib0x000000001832f000 /usr/lib/closure/libclosured.dylib0x000000001832f000 /usr/lib/libbsm.0.dylib0x000000001832f000 /usr/lib/system/libkxld.dylib0x000000001832f000 /usr/lib/libOpenScriptingUtil.dylib0x000000001832f000 /usr/lib/libcoretls.dylib0x000000001832f000 /usr/lib/libcoretls_cfhelpers.dylib0x000000001832f000 /usr/lib/libpam.2.dylib0x000000001832f000 /usr/lib/libsqlite3.dylib0x000000001832f000 /usr/lib/libxar.1.dylib0x000000001832f000 /usr/lib/libbz2.1.0.dylib0x000000001832f000 /usr/lib/liblzma.5.dylib0x000000001832f000 /usr/lib/libnetwork.dylib0x000000001832f000 /usr/lib/libapple_nghttp2.dylib0x000000001832f000 /usr/lib/libpcap.A.dylib0x000000001832f000 /usr/lib/libboringssl.dylib0x000000001832f000 /usr/lib/libusrtcp.dylib0x000000001832f000 /usr/lib/libapple_crypto.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList0x000000001832f000 /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS0x000000001832f000 /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth0x000000001832f000 /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport0x000000001832f000 /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC0x000000001832f000 /usr/lib/libmecabra.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis0x000000001832f000 /System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib0x000000001832f000 /System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator0x000000001832f000 /System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment0x000000001832f000 /System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib0x000000001832f000 /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo0x000000001832f000 /System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders0x000000001832f000 /usr/lib/libFosl_dynamic.dylib0x000000001832f000 /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore0x000000001832f000 /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL0x000000001832f000 /usr/lib/libcompression.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG0x000000001832f000 /System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib0x000000001832f000 /usr/lib/libcups.2.dylib0x000000001832f000 /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos0x000000001832f000 /System/Library/Frameworks/GSS.framework/Versions/A/GSS0x000000001832f000 /usr/lib/libresolv.9.dylib0x000000001832f000 /usr/lib/libiconv.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal0x000000001832f000 /usr/lib/libheimdal-asn1.dylib0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory0x000000001832f000 /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory0x000000001832f000 /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation0x000000001832f000 /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS0x000000001832f000 /usr/lib/libutil.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce0x000000001832f000 /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData0x000000001832f000 /usr/lib/libmarisa.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon0x000000001832f000 /usr/lib/libChineseTokenizer.dylib0x000000001832f000 /usr/lib/libcmph.dylib0x000000001832f000 /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling0x000000001832f000 /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji0x000000001832f000 /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement0x000000001832f000 /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement0x000000001832f000 /usr/lib/libxslt.1.dylib0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink0x000000001832f000 /System/Library/PrivateFrameworks/TextureIO.framework/Versions/A/TextureIO0x000000001832f000 /usr/lib/libate.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport0x000000001832f000 /System/Library/PrivateFrameworks/Sharing.framework/Versions/A/Sharing0x000000001832f000 /System/Library/PrivateFrameworks/IconServices.framework/Versions/A/IconServices0x000000001832f000 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/Versions/A/ProtocolBuffer0x000000001832f000 /System/Library/PrivateFrameworks/Apple80211.framework/Versions/A/Apple802110x000000001832f000 /System/Library/Frameworks/CoreWLAN.framework/Versions/A/CoreWLAN0x000000001832f000 /System/Library/PrivateFrameworks/CoreUtils.framework/Versions/A/CoreUtils0x000000001832f000 /System/Library/Frameworks/IOBluetooth.framework/Versions/A/IOBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/CoreWiFi.framework/Versions/A/CoreWiFi0x000000001832f000 /System/Library/Frameworks/CoreBluetooth.framework/Versions/A/CoreBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/SignpostNotification.framework/Versions/A/SignpostNotification0x000000001832f000 /System/Library/PrivateFrameworks/DebugSymbols.framework/Versions/A/DebugSymbols0x000000001832f000 /System/Library/PrivateFrameworks/CoreSymbolication.framework/Versions/A/CoreSymbolication0x000000001832f000 /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication0x000000001832f000 /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression0x000000001832f000 /System/Library/PrivateFrameworks/SpeechRecognitionCore.framework/Versions/A/SpeechRecognitionCore0x000000001832f000 /System/Library/CoreServices/Encodings/libSimplifiedChineseConverter.dylib0x0000000100f3a000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib0x000000001832f000 /usr/lib/libstdc++.6.0.9.dylib0x0000000101ee1000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libverify.dylib0x0000000101eef000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libjava.dylib0x0000000101f25000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libinstrument.dylib0x0000000101fc3000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libzip.dylib0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaRuntimeSupport.framework/Versions/A/JavaRuntimeSupport0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaNativeFoundation.framework/Versions/A/JavaNativeFoundation0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/JavaVM0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon0x000000001832f000 /System/Library/PrivateFrameworks/JavaLaunching.framework/Versions/A/JavaLaunching0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI0x000000010ae78000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnet.dylib0x000000010aed7000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libmanagement.dylib0x000000010aee5000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnio.dylibVM Arguments:jvm_args: -XX:TieredStopAtLevel=1 -Xverify:none -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=52007 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=52008:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8 java_command: com.ejlerp.saleorder.SaleOrderProviderApplicationjava_class_path (initial): /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomeLauncher Type: SUN_STANDARDEnvironment Variables:JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomePATH=/Users/victor/jar/byteman-download-3.0.10/bin:/Users/victor/jar/btrace-bin-1.3.10/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbinSHELL=/bin/bashSignal Handlers:SIGSEGV: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_ONSTACK|SA_RESTART|SA_SIGINFOSIGBUS: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGFPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGPIPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGXFSZ: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGILL: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGUSR1: SIG_DFL, sa_mask[0]=00000000000000000000000000000000, sa_flags=noneSIGUSR2: [libjvm.dylib+0x488ce2], sa_mask[0]=00100000000000000000000000000000, sa_flags=SA_RESTART|SA_SIGINFOSIGHUP: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGINT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGTERM: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGQUIT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFO--------------- S Y S T E M ---------------OS:Bsduname:Darwin 17.3.0 Darwin Kernel Version 17.3.0: Thu Nov 9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64rlimit: STACK 8192k, CORE 0k, NPROC 709, NOFILE 10240, AS infinityload average:5.50 4.41 3.51CPU:total 4 (initial active 4) (2 cores per cpu, 2 threads per core) family 6 model 61 stepping 4, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, avx, avx2, aes, clmul, erms, 3dnowpref, lzcnt, ht, tsc, tscinvbit, bmi1, bmi2, adxMemory: 4k page, physical 8388608k(184936k free)/proc/meminfo:vm_info: Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for bsd-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:37:08 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)time: Thu Dec 28 15:17:01 2017elapsed time: 72 seconds (0d 0h 1m 12s)]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-web-zookeeper]]></title>
    <url>%2F2017%2F12%2F28%2Fegenie_bugfix%2Ferror-web-zookeeper%2F</url>
    <content type="text"><![CDATA[123452017-12-26 19:42:40.907 WARN [localhost-startStop-1-SendThread(10.26.235.193:2181)][ClientCnxn.java:1162] - Session 0x15e05c1c95a0370 for server 10.26.235.193/10.26.235.193:2181, unexpected error, closing socket connection and attempting reconnectjava.lang.NoClassDefFoundError: org/apache/zookeeper/proto/SetWatches at org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:926) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.8.jar:3.4.8--1] 问题 问题1:一直包上面的错误 问题2:26号把25号的日志给覆盖了,同时15号的错误日志也写到了9号的文件中]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2F%E7%88%B1%E5%A5%BD%2Fstudy-snowboard%2F</url>
    <content type="text"><![CDATA[goski视频教学走刃练习 前刃,后刃(不间断的跳,掌握重心重心和支撑的感觉) 向刃上加压力 直线加速,然后骤停 用刃向上跳。(前后刃) 换刃转身练习 双手抓裤子 防止搓雪太多 回山动作 如果能上去 代表 中心 不止是在前脚 两种转弯技巧 刻滑和扫雪 央视视频教学连续小回转 如羚羊一般自如 换刃平稳性检测双手背上放学块,不掉下来,说明稳定性高 滑雪助手视频教学换刃 重心前脚。身体站起。 直滑降 重心中心。下蹲。 走刃 换刃的开始 是靠膝盖的下降 YouTuBe Snowboard Addiction 前后刃刹车,一定要蹲下去,不能直腿,否则会chachacha 板头平衡/板尾平衡/后刃横向两侧平衡/后刃横向两侧平衡 Eurocarve 可以贴在地上 练习反脚 重心靠前,巧记后脚板子3下 连续转4个360度(慢慢的做) 其他视频 搓雪转弯:后刃减速,因为能看到前面,前刃比较自然 换刃: 用后面的板子的刃,向两边搓雪减速, 更快的转弯,(利用膝盖),陡坡管用 后刃,后手往前伸 前刃,后手往后伸,可以保持身体直立 走刃: 前刃时,弯曲膝盖;身体要直,不能太前倾,否则卡不住雪;重心在中间 后刃时,坐的越深;身体越要向前倾斜,否则卡不住雪;重心在中间 滑雪笔记历史视频 https://v.qq.com/x/page/y0374rcpz1y.html https://v.qq.com/x/page/p0374j04u5p.html https://v.qq.com/x/page/e0374vazd55.html 2017年11月30日-怀北-2017年冬天第一次滑单板 正脚：身体跟随刃一起动,可以保持不搓雪，压刃，重心中心;总体感觉较好,有时候后任会chachacha,应该是立刃不足,或者身体太直 反脚: 总体不是很流畅, https://v.qq.com/x/page/p0527pxet7b.html]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[双板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2F%E7%88%B1%E5%A5%BD%2Fstudy-ski%2F</url>
    <content type="text"><![CDATA[犁式直降动作成v字 犁式转弯练习方案 平举双手,转弯时,双手放到山下腿,其中山下退要承受重量,让身体靠近山下腿 重心的转移很重要 山上腿,打开(解锁)膝盖,很自然的并板子 动作要流畅,s形,而不是z形 平行式 之前是入弯后们转为平行 打开膝盖,提早并腿 转换重心时,同时换刃 转弯一个弯,再下一个(控制好速度,再转下一个) 转弯时拧板,会出现型 两个阶段: 准备入弯 控制速度 避免过早结束转弯 立刃,类似于单板的推坡(垂直方向) 练习:立刃,放平,来回切换 练习”直线,立刃,转弯,停]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mac安装kubernetes]]></title>
    <url>%2F2017%2F12%2F21%2Fdocker%2Fstudy-ubernetes-install%2F</url>
    <content type="text"><![CDATA[https://github.com/jolestar/kubernetes-complete-course 容器的特性 让不标准的物品标准化（杂物，水，应用） 给上层工具提供标准化的操作方式，屏蔽细节 包装，运输 add/remove/iterator（复用算法） 应用管理和调度 Docker (Moby) 如何实现应用标准化 问题 现状 Docker 的方案 安装包 war/jar，rpm/deb, src, bin Image/Image Layer 运行环境 jvm，php, ruby, python Image/Image Layer 进程启动方式 web container, cmd, script Image ENTRYPOINT/CMD 进程资源隔离限制 Namespace/CGroup 进程文件路径冲突 Chroot 端口冲突 修改配置 Network（IP per Container） 日志输出 文件 stderr/stdout 安装包的仓库 nexus, rpm rep，ftp Docker Registry Kubernetes 为何而生 - 云发展到一个新阶段IaaS 云解决了哪些问题按需购买接管硬件资源的运维提供可编程接口来管理资源提供 SDN，SDS 模拟硬件网络以及存储 特点对应用无侵入面向资源 用户从关注资源的运维转向关注应用的开发运维成本 Kubernetes 为何而生 - 容器的成熟奠定了基础容器（Docker/Moby） 解决了哪些问题应用安装包的标准化（Image）应用进程的标准化（Container） 特点单进程标准化 容器编排系统应运而生我们需要一种 面向应用（Application Oriented） 的系统来降低服务端应用的开发部署和运维成本 We wanted people to be able to program for the data center just like they program for their laptop –Ben Hindman 我们再引申一下，从开发延伸到部署运维 We wanted people to be able to manager app for the data center just like they manager app on their laptop 官网地址http://kubernetes.kansea.com/docs/whatisk8s/ mac本地安装kubernetes(minikube)http://kubernetes.kansea.com/docs/getting-started-guides/minikube/ virtualBox安装 minikube安装 kubectl安装 需要ss的的代理,否则google的镜像无法下载123456789minikube deleteminikube start --docker-env HTTP_PROXY=http://192.168.99.1:1087 --docker-env HTTPS_PROXY=http://192.168.99.1:1087 --docker-env NO_PROXY=192.168.99.0/24kubectl get pods --all-namespaces等待readykubectl get nodes 12345678910111213141516171819202122232425victordeMacBook-Pro:~ victor$ kubectl run nginx --image=nginx --port=80deployment &quot;nginx&quot; createdvictordeMacBook-Pro:~ victor$ kubectl expose deployment nginx --port=80 --type=NodePort --name=nginx-httpservice &quot;nginx-http&quot; exposedvictordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 0/1 ContainerCreating 0 17svictordeMacBook-Pro:~ victor$ kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20mnginx-http NodePort 10.99.7.195 &lt;none&gt; 80:32562/TCP 12svictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlWaiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...^CvictordeMacBook-Pro:~ victor$ kubectl get nodesNAME STATUS ROLES AGE VERSIONminikube Ready &lt;none&gt; 22m v1.8.0victordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 1/1 Running 0 2mvictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlhttp://192.168.99.100:32562 tips: 本地的ss需要设置http代理,其中监听的地址从127.0.0.1改为0.0.0.0,这样虚拟机就可以访问到了,在这步卡了很久 docker安装https://yeasy.gitbooks.io/docker_practice/content/kubernetes/quickstart.html 这些服务大概分为三类：主节点服务、工作节点服务和其它服务。 主节点服务apiserver 是整个系统的对外接口，提供 RESTful 方式供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 工作节点服务kubelet 是工作节点执行操作的 agent，负责具体的容器生命周期管理，根据从数据库中获取的信息来管理容器，并上报 pod 运行状态等； proxy 为 pod 上的服务提供访问的代理。 其它服务Etcd 是所有状态的存储数据库； gcr.io/google_containers/pause:0.8.0 是 Kubernetes 启动后自动 pull 下来的测试镜像。 https://yeasy.gitbooks.io/docker_practice/content/kubernetes/concepts.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-service-mesh(服务网格)]]></title>
    <url>%2F2017%2F12%2F20%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fstudy-service-mesh%2F</url>
    <content type="text"><![CDATA[service-mesh概念首先服务网格是一个基础设施层，功能在于处理服务间通信，职责是负责实现请求的可靠传递。在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明。 设计图 概念学习https://zhuanlan.zhihu.com/p/28794062https://zhuanlan.zhihu.com/p/30292372 Kubernetes和Spring Cloud哪个部署微服务更好？https://www.kubernetes.org.cn/1057.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>service-mesh</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opitimize_git_clone]]></title>
    <url>%2F2017%2F12%2F20%2Ftools%2Fopitimize-git-clone%2F</url>
    <content type="text"><![CDATA[找到自己代理的端口 命令:git config –global http.https://github.com.proxy https://127.0.0.1:1087git config –global https.https://github.com.proxy https://127.0.0.1:1087 查看git设置git config –list #BTW此种加速对http和https协议有效 对ssh协议无效,如:git clone git@github.com:xxxxxx/xxxxxx.git]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课1]]></title>
    <url>%2F2017%2F12%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study1%2F</url>
    <content type="text"><![CDATA[最优化方法百度https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95 知乎抽象概念1234567 在一定的约束条件下，求一个函数的最大（小）值。 要理解的其实只有两个概念，函数和约束条件。甚至函数这个概念已经包含了对约束条件的考虑。所谓函数，简单理解的话，可以当做一个机器，你给它一个输入，它就给你一个输出，它是一个对应。你通过调节输入，达到最好的输出。它是现实状况的数学语言表达。例如我们要最小化总费用，我们知道单价，我们可以决定数量，于是我们得到的数学表达：总费用=单价乘以数量。我们通过调整数量来最小的总费用。至于约束条件，它有很多种，例如等式的约束，不等式的约束，微分方程的约束，概率的约束，等等等等。他们也是对我们现实状况中的约束的数学表达。不同的约束配上不同的目标函数就会得到一个不同的问题。例如目标函数和约束都是线性的，这个最优化问题就叫线性规划，如果约束是个常微分方程，就叫最优控制。等等等等。作者：滴水链接：https://www.zhihu.com/question/26341871/answer/41242951来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 蛮形象的解释https://www.zhihu.com/question/263418711234567之所以要使用计算机，是因为数据量太大，远远超过人脑的处理能力。比如我们需要从一堆人脸图片里给每个人标上正确的名字，一幅32像素见方的人脸图像有1024颗像素点，你能想象出一百万张这样的照片和1万个人名字之间的关系是什么样吗。再比如给你1万个患者的DNA序列，每个患者的序列由百万级的碱基对构成，你能找到这些天文数字量级的序列和是否患某种疾病之间的联系吗？答案是不能！所以研究者退而求其次，建立很多学习模型，这些模型输入是一个样本的数据（头像图片、一个人的DNA序列），输出是样本的标签（人名、是否患病）。模型里有大量可以调整的参数，这些参数通过训练，能够学习到数据和标签之间人类无法直接理解的、复杂的关系。科学家期望当模型训练完成后，再拿来一个样本，喂给这个训练好的机器，它能够吐出一个标签，这个标签恰好就是样本对应的那个正确的标签。目前人们已经研究出一大堆学习模型：神经网络、支持向量机、AdaBoost、随机森林、隐马尔科夫链、卷积神经网络等等。它们的结构差异很大，但是共同点都是拥有一大堆参数，就等着你喂给它数据供它学习。这些模型的学习也需要一个目标函数：让模型的分类错误率尽量小。为了达到目的，模型的训练往往首先给参数赋上随机初值，然后用各种下降法来寻找能让分类错误率更小的参数设置，梯度下降、牛顿法、共轭梯度法和Levenberg—Marquard法都是常见的方法。 随着研究的深入，问题也越来越多，比如下降法往往只能保证找到目标函数的局部最小值，找不到全局最小值，怎么办呢？答案是不一味下降、也适当爬爬山，说不定能跳出小水沟（局部极小值）找到真正的深井（全局极小值），这种算法叫模拟退火。也可以增大搜索范围，让一群蚂蚁（蚁群算法）或者鸟儿（粒子群算法）一齐搜索，或者让参数巧妙地随机改变（遗传算法）。 那么多模型，到底该选哪个？研究者又发现了一个定理“天下没有免费的午餐”定理，意思是没有一个模型能一直比其他模型好，对于不同类型的数据，必须要通过实验才能发现哪种学习模型更适合。机器学习领域也就成了学界灌水严重的领域之一——换模型、调参数就能发文章哎。 下面说到了调参数，问题又来了，到底是参数多了好还是少了好？参数少了模型太笨学不到数据内的复杂关系，参数多了模型太精明又可能会把数据中的随机噪声当作某种关系进行认真学习（过拟合）。最后大家一致认为，确定模型的复杂度时，要保证模型能力足够强，能够学会数据之间的关系，能力又不能太强，以至于耍小聪明乱学习。这种选择模型的思想被称为奥卡姆剃刀：选择有能力的模型中最简单的那个。此外，训练模型的目标并不是为了使训练样本能够被尽量正确分类，更需要对未知新样本有好的分类效果，这样模型才有实用价值，这种能力被称为泛化能力。除了奥卡姆剃刀原理外，训练时引入随机性的模型比确定的模型（比如BP神经网络）具有更好的泛化能力。 模型的更新也是问题。如果引入了新数据，全部模型都需要重新训练是一笔很大的开销，在线学习模型采用来一个样本学一点的模式，能够不断自我更新；半监督学习利用少量带标签的样本训练一个原始模型，然后利用大量无标签数据再学习。 举例1比如想从广州去杭州，怎样最快又最经济（目标函数）？你有很多种方法，可以坐火车，飞机，汽车(很多种解，而且可以对这些解进行组合)，但总是有个组合最让你满意（最优解），最符合你的期望。怎么去求解这个最优解，由此产生的一系列方法。 博客http://www.cnblogs.com/maybe2030/p/4751804.html]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-AI技术内参1-经典搜索核心算法]]></title>
    <url>%2F2017%2F12%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-study1%2F</url>
    <content type="text"><![CDATA[TF-IDF及其变种 信息检索,文本挖掘,自然语言处理领域 把查询关键字(Query)和文档(Document)都转为向量 ‘向量空间模型’Vector Spcece Model就是希望吧查询关键字和文档都表达成变量,然后利用向量之间的运算来进行进一步表达向量之间的关系 相似性:余弦相似性,或者是点积 V个词汇,V维度,查询关键字和每个文档的向量都有V个维度 TF和IDF的乘机 TF单词频率Term Frequency,计算一个查询关键字中某一个单子在目标文档中出现的次数 如查询’car insurance’,那么计算car出现了多少次,insurance出现了多少次 表示相关度 IDF,逆文档频率Inerse Document Frequency,需要去惩罚哪些出现在太多文档中的单词 多少文档包含了这个单词,越大越不重要 其他学习资料http://www.ruanyifeng.com/blog/2013/03/tf-idf.html123让我们从一个实例开始讲起。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。所以，排在最前面的几个词，就是这篇文章的关键词。除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如，信息检索时，对于每个文档，都可以分别计算一组搜索词（&quot;中国&quot;、&quot;蜜蜂&quot;、&quot;养殖&quot;）的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以&quot;词频&quot;衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。） BM25及其变种 BM是’最佳匹配’Best Match的简称 用来计算某一目标文档(Document)相对于一个查询关键字(Query)的”相关性”(Relevance)的流程, 非监督学习排序算法中的一个典型代表 定义: 单词和目标文档的相关性 词频 TF-IDF里面的TF部分,but词频需要”标准化”,某一个单词对最后的分数的贡献不会随着词频的增加而无限增加 两个超参数:当前文档的长度,整个数据集所有文档的平均长度 单词和查询关键词的相关性 同样需要标准化过程 单词的权重部分 某种变形的来对单词加权,例如某种变形的IDF来对单词甲醛 罗伯逊-斯巴克-琼斯权重,需要一个监督信息 在很多情况下,利用IDF来直接对单词权重的版本更加普遍,如果再有监督信息的情况下,RSJ值也不失为一个很好的选择 这个三个部分的乘积组成某一个单词的分数,然后,整个文档相对于某个查询关键字的分数,就是所有查询关键字里所有单词分数的总和 bm25是对某一概率相关模型的逼近 bm25算法变种:bm25f, 域的概念(文档包括标题,摘要和正文) 把BM25和其他文档信息(非文字)结合起来 BM25和PageRank的线性结果来确定网页的相关性 语言模型及其变种 详解:用概率模型(Probabilistic Model)来描述查询关键字和目标文档之间的关系 最简单的:查询关键字似然检索模型 一个语言模型就是一个针对词汇表的概率分布 词汇表1w个单词,1w个单词上的离散概率分布 查询关键字是从一个语言模型中”抽样”得到一个样本 对一个查询关键字打分=这组词出现的联合概率,因为联合概率可能会很小,因此很多时候都通过一个对数变化,来把概率的乘积变成概率对数加和 语言模型的参数:”类别分布”(Categorical Distiribution),也就是多项式分布,去除排列组合信息 参数股计算法:最大似然估计 每个单词出现的可能性,正好等于这个单词在目标文档中出现的次数,除以所有单词在文档中出现的次数. 每个文档都对应一个类别分布,有多少文档,就有多少个类别分布 如果没有在训练数据中出现过,最优解就是0 平滑(Smoohting)http://52opencourse.com/111/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88language-modeling%EF%BC%89]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[api网关学习]]></title>
    <url>%2F2017%2F12%2F18%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fstudy-api-gateway%2F</url>
    <content type="text"><![CDATA[什么是api网关123王延炯：API Gateway（API GW / API 网关），顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界。在微服务概念的流行之前，API GW的实体就已经诞生了，这时的主要应用场景是OpenAPI，也就是开放平台，面向的是企业外部合作伙伴，对于这个应用场景，相信接触的人会比较多。当在微服务概念流行起来之后，API网关似乎成了在上层应用层集成的标配组件。 为什么需要api网关 负载均衡 减少客户端与服务端的直接调用 容错 服务发现与注册 统一认证 选型spring cloud zuulhttps://github.com/Netflix/zuul nginx konghttps://github.com/Kong/kong 阿里云apigatewayhttps://www.aliyun.com/product/apigateway API 生命周期管理 支持包括 API 发布、API 测试、API 下线等生命周期管理功能。 支持 API 日常管理、API 版本管理、API 快速回滚等维护功能。 全面的安全防护 支持多种认证方式，支持 HMAC (SHA-1，SHA-256) 算法签名。 支持 HTTPS 协议，支持 SSL 加密。 防攻击、防注入、请求防重放、请求防篡改。 灵活的权限控制 用户以 APP 作为请求 API 的身份，网关支持针对 APP 的权限控制。 只有已经获得授权的 APP 才能请求相应的 API。 API 提供者可以主动授权某个 APP 调用某个 API 的权限。 API 若上架到 API 市场，则购买者可以将已购买的 API 授权给自己的 APP。 精准的流量控制 流量控制可以用于管控 API的被访问频率、APP的请求频率、用户的请求频率。 流量控制的时间单位可以是分钟、小时、天。 同时支持流控例外，允许设置特殊的 APP 或者用户。 请求校验 支持参数类型、参数值（范围、枚举、正则、Json Schema）校验，无效校验直接会被 API 网关拒绝，减少无效请求对后端造成的资源浪费，大大降低后端服务的处理成本。 数据转换 通过配置映射规则，实现前、后端数据翻译。 支持前端请求的数据转换。 支持返回结果的数据转换。 监控报警 提供可视化的API实时监控，包括：调用量、流量大小、响应时间、错误率，在陆续增加维度。 支持历史情况查询，以便统筹分析。 可配置预警方式（短信、Email），订阅预警信息，以便实时掌握API运行情况。 自动工具 自动生成 API 文档，可供在线查看。 API 网关提供多种语言 SDK 的示例。降低 API 的运维成本。 提供可视化的界面调试工具，快速测试，快速上线。 API 市场 可将 API 上架到 API 市场，供更多开发者采购和使用。 参考资料http://www.infoq.com/cn/news/2016/07/API-background-architecture-floohttp://www.infoq.com/cn/articles/construct-micro-service-using-api-gateway]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[禁止使用@Reference的注解]]></title>
    <url>%2F2017%2F12%2F14%2Fegenie_bugfix%2Foptimize-dubbuo-reference%2F</url>
    <content type="text"><![CDATA[dubbo服务引用默认情况下可以通过@Reference和xml注解来引入例如1234567891011@Reference(version = "0.1", timeout = 8000) private TenantService tenantService; @Reference(version = "0.1", timeout = 8000) private ProductService productService; @Reference(version = "0.1", timeout = 8000) private DictService dictService; @Reference(version = "0.1", timeout = 8000) private CategoryService categoryService; 或者123456&lt;dubbo:reference id="remoteBaseCustomPropsService" interface="com.ejlerp.baseinfo.api.BaseCustomPropsService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuStepPriceService" interface="com.ejlerp.baseinfo.api.SkuStepPriceService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuUnitService" interface="com.ejlerp.baseinfo.api.SkuUnitService" version="0.1" timeout="60000"/&gt; 出现的问题生产环境上调用微服务超时,结果发现即使通过123service: @Reference(version = "0.1", timeout = 8000) private ProductService productService; 的方式设置了超时时间,但生产环境的错误,还是设置的1000ms的超时时间, 问题原因在其他的service中同样是引用了这个注解123其他service: @Reference(version = "0.1") private ProductService productService; Reference注解 包含了初始化和注入dubbo的bean,两种功能其实是声明了一个bean,但是到底是用哪个timeout,是有spring初始化bean的顺序所决定的,很可能出现设置了timeout但是仍然没有效果的情况 解决办法 在2017-12-12后的,所有微服务,禁止使用Reference注解,通过autowirdj进行钟乳 统一使用xml的方式,进行声明dubbo的bean 优点 统一Reference方式对其他微服务的引用,放置不一致的配置出现 xml的方式,方便设置方法级别的参数 1234&lt;dubbo:reference id="remoteArrivalStockOutReportService" interface="com.ejlerp.pms.api.StockOutReportService" version="0.1" timeout="60000"&gt; &lt;dubbo:method name="refreshAction" timeout="9000000" retry="0"/&gt;&lt;/dubbo:reference&gt; 修改步骤如下 去除掉DubboConf.java中大部分代码 添加spring-dubbo,xml 删除旧的@Reference,同时添加@Autowird 替换默认的@Reference无超时时间的,基本为dao中id 和 sn generater 将web中最全的dubbo.conf复制到为服务中 本项目为pms,删除掉所有pms相关的xml注入 逐行全文搜索,删掉没用的service 再次遍历dubb.conf的所有service,修改成项目中原来的超时时间,并去掉个性化设置的@Reference 编译,解决编译问题,补充一些@Autowird的包 尝试启动,补充一些egenie-web中没有声明,但是微服务中用到的service 例如:com.ejlerp.messages.api.QueueService,com.ejlerp.cache.api.SortedSetCacher,com.ejlerp.cache.api.IDGenerator,com.ejlerp.cache.api.IDGenerator等 启动成功 具体改动,见git: http://git.ejlerp.com/egenie/ejlerp-pms/commit/4d431233af740e0f1c85c8733afcaadfb0638a18 BTW http://dubbo.io/books/dubbo-user-book/demos/fault-tolerent-strategy.html 在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。 Failover Cluster 失败自动切换，当出现失败，重试其它服务器 1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 2。通常用于通知所有提供者更新缓存或日志等本地资源信息。 开发人员可以根据自己的实际业务,设置失败时的处理方式]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>reference</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm崩溃]]></title>
    <url>%2F2017%2F12%2F14%2Fjava_jvm%2Foperation-jvm%2F</url>
    <content type="text"><![CDATA[日常日志及错误1232017-12-13 18:26:00.001 [pool-27-thread-1] INFO com.ejlerp.pms.provider.mqCrond.MqPmsTradeOrderCrond.sendMsgToInter - == 处理采购推送交易库定时任务 start ==2017-12-13 18:26:05.711 [pool-27-thread-1] ERROR org.springframework.scheduling.support.TaskUtils$LoggingErrorHandler.handleError - Unexpected error occurred in scheduled task.java.lang.OutOfMemoryError: Java heap space 同时jvm由于重启过,gc日志也刷新了 每个jvm不仅用自己个性化的参数调优,还应该有共同参数,例如:打印gc日志,dump内存等参数TODO 待总结]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上redis崩溃记录]]></title>
    <url>%2F2017%2F12%2F14%2Fredis%2Foperation-redis%2F</url>
    <content type="text"><![CDATA[错误日志grep com.alibaba.dubbo.rpc.filter.ExceptionFilter.error123456789101112131415161718199:02org.springframework.data.redis.RedisConnectionFailureException: Unexpected end of stream.; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream.好多条org.springframework.dao.InvalidDataAccessApiUsageException: LOADING Redis is loading the dataset in memory; nested exception is redis.clients.jedis.exceptions.JedisDataException: LOADING Redis is loading the dataset in memory 好多条org.springframework.data.redis.RedisConnectionFailureException: java.net.SocketTimeoutException: Read timed out; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed outorg.springframework.data.redis.RedisConnectionFailureException: java.net.SocketException: Connection reset; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketException: Connection resetorg.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool很多9:21开始org.springframework.dao.InvalidDataAccessApiUsageException: ERR READONLY You can&apos;t write against a read only instance; nested exception is redis.clients.jedis.exceptions.JedisDataException: ERR READONLY You can&apos;t write against a read only instance很多 期间代码回滚到了上一版本,过了一段时间系统正常最后发现是 业务层面循环调用了redis操作,一次请求会有1k次的redis,导致redis崩掉,而且我们使用的阿里云的主从版云redis 几次循环调用,inFlow的变化 具体得失hset方法的调用 反思 对于监控系统,应该有各个节点的平时统计数据,包括,调用次数+相应时长 通过环比和同比数据的对比,可以快速的发现问题,解决问题,而不是当系统垮掉时,才有所反应 BTWnest exception学习http://www.iteye.com/problems/87876 即调用顺序是 action—&gt;service—&gt;dao—-&gt;hibernate—&gt;jdbc 抛出异常顺序是 jdbc—-&gt;hibernate—-&gt;dao–抛出–&gt;service–继续抛出–&gt;action 异常其实是栈调用的快照 1、最下层的异常是出错的原因，上边的异常是对下边的封装，目的是一致性 和 更可读；（即下边异常是引起上边异常的原因，每一个Exception都有一个cause，如hibernate异常的cause就是jdbc的异常） 2、对于每一段异常，方法调用顺序是从下往上 3、想知道是由于前面创建的错误导致后边的异常，还是后边的异常导致前面的创建错误，后边导致前面，，，前面对后面的进行了封装，，目的是提供一致的异常（并且把原始错误显示出来 就是 nested exception 后边部分） NestedRuntimeException 例子我们最熟悉的就是 DataAccessException12345678910111213package org.springframework.dao;import org.springframework.core.NestedRuntimeException;public abstract class DataAccessException extends NestedRuntimeException &#123; public DataAccessException(String msg) &#123; super(msg); &#125; public DataAccessException(String msg, Throwable cause) &#123; super(msg, cause); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>breakdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix总结-12.13]]></title>
    <url>%2F2017%2F12%2F14%2Fegenie_bugfix%2Fbugfix-2-1213%2F</url>
    <content type="text"><![CDATA[bugfix1-redis相关 快速定位问题 12345678910111213141516171819202017-12-13 18:33:39.688 DEBUG [http-bio-6000-exec-17][JdbcTemplate.java:875] - SQL update affected 1 rows2017-12-13 18:33:40.590 ERROR [http-bio-6000-exec-17][UniExceptionHandler.java:57] - 捕捉到技术异常: URI: /shop/insert 最大内存: 1012m 已分配内存: 1012m 已分配内存中的剩余空间: 532m 最大可用内存: 532mjava.lang.RuntimeException: org.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerExceptionorg.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerException at org.springframework.data.redis.FallbackExceptionTranslationStrategy.getFallback(FallbackExceptionTranslationStrategy.java:48) at org.springframework.data.redis.FallbackExceptionTranslationStrategy.translate(FallbackExceptionTranslationStrategy.java:38) at org.springframework.data.redis.connection.jedis.JedisConnection.convertJedisAccessException(JedisConnection.java:242) at org.springframework.data.redis.connection.jedis.JedisConnection.set(JedisConnection.java:1236) at org.springframework.data.redis.connection.DefaultStringRedisConnection.set(DefaultStringRedisConnection.java:744) at org.springframework.data.redis.core.DefaultValueOperations$10.inRedis(DefaultValueOperations.java:172) at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:57) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:207) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:91) at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169) at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34) at com.alibaba.dubbo.common.bytecode.Wrapper7.invokeMethod(Wrapper7.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) 首先这个是一个没有见过的异常 解决途径: 搜索自己公司包开头的代码,找到调用地方 下载源码,底层依赖可能有真的有 在本次bugfix中,由于是微服务调用,真正看出问题是在,controller层才看出的问题12345678910@ApiOperation(value = &quot;新增&quot;)@RequestMapping(value = &quot;/insert&quot;, method = RequestMethod.POST)public JsonResult insert(@RequestBody String body) &#123; Long id = IdGenerator.generate(getEntityName(), fetchTenantId()).getIdValue(); CommonVo vo = CommonVo.of(getEntityName(), WebHelper.parseJsonBody(body, false, false)); vo.put(&quot;shop_id&quot;, id); getService().insert(fetchTenantId(), fetchUserId(), vo); kvCacher.set(&quot;logistic_node_&quot; + id.toString(), vo.get(&quot;logistic_node&quot;)); return new JsonResult(JsonResult.SUCCESSFUL, null);&#125; vo可能别没有获取到 反思:at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34),这个一句其实只有两个参数,一个是传入的key,一个是value,一定是其中一个入参发生了问题,才会导致底层出现问题的 当然,也不排除是redis服务可能出现了问题,但是当时已经重启了reids,错误依旧存在 最后,bug定位到了是前端一个select标签,由于数据库中的dict没有初始化,导致这个select标签的初始值没有初始化完成,当然表单提交时,便不会提交这个字段, 小结 controller层的vo依然不要使用map,否则排查起来很费劲 bugfix2 分组问题 这个bugfix,其实是这样的,条件写反导致的 1234 Map&lt;Long, VSaleOrder&gt; orderMap = omsAgentService.findByIds(callerInfo, arriveMap.keySet());- Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::isNull).filter(v -&gt; &#123;+ Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::nonNull).filter(v -&gt; &#123; Integer courierPrintMarkState = v.getCourierPrintMarkState(); 问题是,历史数据的修复,其实应该在线上发现问题时,作为一套完整的方案,进行提交的,而不是部署到生产环境后,又发现历史数据有问题,在半夜升级后改数据,风险真是很大 对于一些合并操作,虽然业务上提出了操作,其实从逻辑上讲,应该出现拆分的反响逻辑预支对应 问题3 jvm参数设置]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix对接baidu语音合成]]></title>
    <url>%2F2017%2F12%2F13%2Fegenie_bugfix%2Fbugfix-voice-generate%2F</url>
    <content type="text"><![CDATA[背景项目中使用了baidu的语音合成,原本的设计是,批量获取设置到redis中,用户每次使用时从redis中获取 空指针异常12345678910112017-12-13 16:34:30.076 ERROR [http-bio-6000-exec-45][DownloadVoiceFromBaiduYY.java:36] - DownloadVoiceFromBaiduYY error &#123;&#125;java.lang.NullPointerException at com.baidu.aip.speech.AipSpeech.synthesis(AipSpeech.java:133) ~[java-sdk-3.2.0.jar:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoice(DownloadVoiceFromBaiduYY.java:33) [classes/:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoiceB64(DownloadVoiceFromBaiduYY.java:45) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getB64(VoiceController.java:233) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getVoiceData(VoiceController.java:149) [classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92] 下载源码后debug返现返回的response Content-Type是大写,与sdk中get的string不一致,于是查找github的源文件 发现了,这个bug已经fix了,https://github.com/Baidu-AIP/java-sdk/commit/c338bc71690f84351def0d64b311986c586763d2 其他遇到的问题 判断字符串写反 1234- if (StringUtils.isEmpty(value)) &#123;+ if (!StringUtils.isEmpty(value)) &#123; redisMap.put(key, value); &#125; APPkey修改错了配置文件 反思 在与外部api进行接口对接时,一定要判断各种异常情况的发生,不能只考虑正常情况 1234567try &#123; TtsResponse res = client.synthesis(voice, &quot;zh&quot;, 1, options); JSONObject result = res.getResult(); if (result != null) &#123; LOGGER.warn(&quot;downloadVoice:&#123;&#125;&quot;, result); &#125; download = res.getData(); 删除掉无用的代码,放置误导自己和别人 本地充分测试后,再提交测试部署,否则害人害己,耽误时间 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 不能依靠测试发现程序问题,即使是别人的代码,也要认真研读,滤清思路,不能头疼医头,脚痛医脚 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署 待提高 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 测试用例编写 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署]]></content>
      <categories>
        <category>bugfix</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化2:定位io高的原因mysql]]></title>
    <url>%2F2017%2F12%2F13%2Fegenie_bugfix%2Foptime-156%2F</url>
    <content type="text"><![CDATA[#重新定位问题-%wa指CPU等待磁盘写入完成的时间 首先看下%wa的解释：Percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. #iostat #pidstat 2 10 -d发现mysql的读写量非常高]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>io高</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化1:清理zookeeper过多的历史文件]]></title>
    <url>%2F2017%2F12%2F12%2Fegenie_bugfix%2Foptimize-zookeeper%2F</url>
    <content type="text"><![CDATA[背景156机器是本地开发环境上的机器跑了如下服务:mysqlzookeeperdubbokeeper 现象从ssh登陆服务器就比较卡top命令后,负载一直很高 排查iotop命令看到zookeeper的io比较高http://pic.victor123.cn/17-12-12/59575921.jpg 操作步骤 https://www.cnblogs.com/jxwch/p/6526271.html 打开这两个参数 autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个； autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。 清空历史数据 效果 相关知识http://www.linuxidc.com/Linux/2016-03/129509.htmdataDir用于存储Log（事务日志）与Snapshot（快照）数据 http://blog.51cto.com/nileader/932156 1在后续的观察中发现,156的io高并不全是zookeeper的问题,so本次只是清除了历史文件,对于156的io高问题目前定位是mysql问题,待续]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>io高</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习pandas api时发现了一个奇怪的现象]]></title>
    <url>%2F2017%2F12%2F10%2Fegenie_bugfix%2Ferror-pandas-date-range%2F</url>
    <content type="text"><![CDATA[学习pandas api时发现了一个奇怪的现象 通过代码 dates = pd.date_range(‘20130101’, periods=6) 定义了函数, 下一行无法打印出来, 可是下面仍然能够使用这个datas的变脸,很是神奇,百思不得其解 结论 怀疑是应该是jupyter notebook的问题, 直接打印出pd.date_range(‘20130101’, periods=6)的结果都是正确的]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>机器学习</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas中read_csv方法的学习]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fpython-pandas-read-csv%2F</url>
    <content type="text"><![CDATA[#read_csv内容过大的处理方式:123451.train = pd.read_csv(&quot;/Users/victor/code/kaggle/Expedia/input/train.csv&quot;,nrows=3000)2.chunksize=100 总apihttp://pandas.pydata.org/pandas-docs/version/0.15]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kaggle-expedia-hotel-recommendations学习笔记]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fkaggle%2Fkaggle-expedia-hotel-recommendations%2F</url>
    <content type="text"><![CDATA[题目地址https://www.kaggle.com/c/expedia-hotel-recommendations#description 学习地址https://www.dataquest.io/blog/kaggle-tutorial/ 目标 初步了解机器学习流程 通过实际代码,了解python代码的语法 学习心得 数据探索 1234567import pandas as pddestinations = pd.read_csv("destinations.csv")test = pd.read_csv("test.csv")train = pd.read_csv("train.csv")#train文件有4个g大,读了半天都不出来 数据量 数据分布 目标变量 目标变量是什么 探索目标变量 探索用户id 采样统计 添加时间和日期 挑选1000名用户 区分测试集和验证集 移除无关数据(click 事件) 一个简单的算法 生成预测 1234567891011predictions = [most_common_clusters for i in range(t2.shape[0])]# 不是很理解 [] 和 shape[0]的含义# shape()方法返回 行数 和 维度数 .其中:0:行数 1:维度数# pyhton中的遍历:for iterating_var in sequence: statements(s)# 但是 for前面的most_common_clusters 是什么意思?# 通过测试了解到是复制一个变量n遍的意思aa=[&quot;abc&quot; for i in range(10)]print(aa)输出了10个 abc 评估效果 123456789import ml_metrics as metricstarget = [[l] for l in t2[&quot;hotel_cluster&quot;]]metrics.mapk(target, predictions, k=5)# 不是很理解 [l]代表什么# 把t2[&quot;hotel_cluster&quot;]列表中的变量l,外面 前一层 列表 []xx=[1,2,3,4]target = [[l] for l in xx]print(target)[[1], [2], [3], [4]] 查找相关因素 更近一步 生成特征 从destinations生成特征 123456789from sklearn.decomposition import PCApca = PCA(n_components=3)dest_small = pca.fit_transform(destinations[[&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)]])dest_small = pd.DataFrame(dest_small)dest_small[&quot;srch_destination_id&quot;] = destinations[&quot;srch_destination_id&quot;]# 解释 取d1-d149字段print([&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)])[&apos;d1&apos;, &apos;d2&apos;, &apos;d3&apos;, &apos;d4&apos;, &apos;d5&apos;, &apos;d6&apos;, &apos;d7&apos;, &apos;d8&apos;, &apos;d9&apos;, &apos;d10&apos;, &apos;d11&apos;, &apos;d12&apos;, &apos;d13&apos;, &apos;d14&apos;, &apos;d15&apos;, &apos;d16&apos;, &apos;d17&apos;, &apos;d18&apos;, &apos;d19&apos;, &apos;d20&apos;, &apos;d21&apos;, &apos;d22&apos;, &apos;d23&apos;, &apos;d24&apos;, &apos;d25&apos;, &apos;d26&apos;, &apos;d27&apos;, &apos;d28&apos;, &apos;d29&apos;, &apos;d30&apos;, &apos;d31&apos;, &apos;d32&apos;, &apos;d33&apos;, &apos;d34&apos;, &apos;d35&apos;, &apos;d36&apos;, &apos;d37&apos;, &apos;d38&apos;, &apos;d39&apos;, &apos;d40&apos;, &apos;d41&apos;, &apos;d42&apos;, &apos;d43&apos;, &apos;d44&apos;, &apos;d45&apos;, &apos;d46&apos;, &apos;d47&apos;, &apos;d48&apos;, &apos;d49&apos;, &apos;d50&apos;, &apos;d51&apos;, &apos;d52&apos;, &apos;d53&apos;, &apos;d54&apos;, &apos;d55&apos;, &apos;d56&apos;, &apos;d57&apos;, &apos;d58&apos;, &apos;d59&apos;, &apos;d60&apos;, &apos;d61&apos;, &apos;d62&apos;, &apos;d63&apos;, &apos;d64&apos;, &apos;d65&apos;, &apos;d66&apos;, &apos;d67&apos;, &apos;d68&apos;, &apos;d69&apos;, &apos;d70&apos;, &apos;d71&apos;, &apos;d72&apos;, &apos;d73&apos;, &apos;d74&apos;, &apos;d75&apos;, &apos;d76&apos;, &apos;d77&apos;, &apos;d78&apos;, &apos;d79&apos;, &apos;d80&apos;, &apos;d81&apos;, &apos;d82&apos;, &apos;d83&apos;, &apos;d84&apos;, &apos;d85&apos;, &apos;d86&apos;, &apos;d87&apos;, &apos;d88&apos;, &apos;d89&apos;, &apos;d90&apos;, &apos;d91&apos;, &apos;d92&apos;, &apos;d93&apos;, &apos;d94&apos;, &apos;d95&apos;, &apos;d96&apos;, &apos;d97&apos;, &apos;d98&apos;, &apos;d99&apos;, &apos;d100&apos;, &apos;d101&apos;, &apos;d102&apos;, &apos;d103&apos;, &apos;d104&apos;, &apos;d105&apos;, &apos;d106&apos;, &apos;d107&apos;, &apos;d108&apos;, &apos;d109&apos;, &apos;d110&apos;, &apos;d111&apos;, &apos;d112&apos;, &apos;d113&apos;, &apos;d114&apos;, &apos;d115&apos;, &apos;d116&apos;, &apos;d117&apos;, &apos;d118&apos;, &apos;d119&apos;, &apos;d120&apos;, &apos;d121&apos;, &apos;d122&apos;, &apos;d123&apos;, &apos;d124&apos;, &apos;d125&apos;, &apos;d126&apos;, &apos;d127&apos;, &apos;d128&apos;, &apos;d129&apos;, &apos;d130&apos;, &apos;d131&apos;, &apos;d132&apos;, &apos;d133&apos;, &apos;d134&apos;, &apos;d135&apos;, &apos;d136&apos;, &apos;d137&apos;, &apos;d138&apos;, &apos;d139&apos;, &apos;d140&apos;, &apos;d141&apos;, &apos;d142&apos;, &apos;d143&apos;, &apos;d144&apos;, &apos;d145&apos;, &apos;d146&apos;, &apos;d147&apos;, &apos;d148&apos;, &apos;d149&apos;] 生成其他特征 12345678910111213141516171819202122232425262728def calc_fast_features(df): df[&quot;date_time&quot;] = pd.to_datetime(df[&quot;date_time&quot;]) df[&quot;srch_ci&quot;] = pd.to_datetime(df[&quot;srch_ci&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) # 参数errors=&quot;coerce&quot; 遇到错误可以赋值为空。 df[&quot;srch_co&quot;] = pd.to_datetime(df[&quot;srch_co&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) props = &#123;&#125; for prop in [&quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;minute&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;]: props[prop] = getattr(df[&quot;date_time&quot;].dt, prop) carryover = [p for p in df.columns if p not in [&quot;date_time&quot;, &quot;srch_ci&quot;, &quot;srch_co&quot;]] for prop in carryover: props[prop] = df[prop] date_props = [&quot;month&quot;, &quot;day&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;] for prop in date_props: props[&quot;ci_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_ci&quot;].dt, prop) props[&quot;co_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_co&quot;].dt, prop) props[&quot;stay_span&quot;] = (df[&quot;srch_co&quot;] - df[&quot;srch_ci&quot;]).astype(&apos;timedelta64[h]&apos;) ret = pd.DataFrame(props) ret = ret.join(dest_small, on=&quot;srch_destination_id&quot;, how=&apos;left&apos;, rsuffix=&quot;dest&quot;) ret = ret.drop(&quot;srch_destination_iddest&quot;, axis=1) return retdf = calc_fast_features(t1)df.fillna(-1, inplace=True) 123456789101112131415161718192021新的列:[ &apos;channel&apos;, &apos;ci_day&apos;, &apos;ci_dayofweek&apos;, &apos;ci_month&apos;, &apos;ci_quarter&apos;, &apos;cnt&apos;, &apos;co_day&apos;, &apos;co_dayofweek&apos;, &apos;co_month&apos;, &apos;co_quarter&apos;, &apos;day&apos;, &apos;dayofweek&apos;, &apos;hotel_cluster&apos;, &apos;hotel_continent&apos;, &apos;hotel_country&apos;, &apos;hotel_market&apos;, &apos;hour&apos;, &apos;is_booking&apos;, &apos;is_mobile&apos;, &apos;is_package&apos;, &apos;minute&apos;, &apos;month&apos;, &apos;orig_destination_distance&apos;, &apos;posa_continent&apos;, &apos;quarter&apos;, &apos;site_name&apos;, &apos;srch_adults_cnt&apos;, &apos;srch_children_cnt&apos;, &apos;srch_destination_id&apos;, &apos;srch_destination_type_id&apos;, &apos;srch_rm_cnt&apos;, &apos;stay_span&apos;, &apos;user_id&apos;, &apos;user_location_city&apos;, &apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;year&apos;, 0, 1, 2] + 机器学习 * 随机森林 1234567predictors = [c for c in df.columns if c not in [&quot;hotel_cluster&quot;]]from sklearn import cross_validationfrom sklearn.ensemble import RandomForestClassifierclf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)scores = cross_validation.cross_val_score(clf, df[predictors], df[&apos;hotel_cluster&apos;], cv=3)scores * 二分分类 123456789101112131415161718192021222324252627282930313233from sklearn.ensemble import RandomForestClassifierfrom sklearn.cross_validation import KFoldfrom itertools import chainall_probs = []unique_clusters = df[&quot;hotel_cluster&quot;].unique()for cluster in unique_clusters: df[&quot;target&quot;] = 1 df[&quot;target&quot;][df[&quot;hotel_cluster&quot;] != cluster] = 0 predictors = [col for col in df if col not in [&apos;hotel_cluster&apos;, &quot;target&quot;]] probs = [] cv = KFold(len(df[&quot;target&quot;]), n_folds=2) # 交叉验证(CrossValidation) # 方法思想是为了在不动用测试集之前，就评估一下模型是否过于复杂而引起过度拟合 clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1) for i, (tr, te) in enumerate(cv): # 不是很理解 上面一句 clf.fit(df[predictors].iloc[tr], df[&quot;target&quot;].iloc[tr]) preds = clf.predict_proba(df[predictors].iloc[te]) probs.append([p[1] for p in preds]) full_probs = chain.from_iterable(probs) all_probs.append(list(full_probs))prediction_frame = pd.DataFrame(all_probs).Tprediction_frame.columns = unique_clustersdef find_top_5(row): return list(row.nlargest(5).index)preds = []for index, row in prediction_frame.iterrows(): preds.append(find_top_5(row))metrics.mapk([[l] for l in t2.iloc[&quot;hotel_cluster&quot;]], preds, k=5) 在目的地下的最受欢迎的酒店选择 123456789101112131415161718192021222324252627def make_key(items): return &quot;_&quot;.join([str(i) for i in items])match_cols = [&quot;srch_destination_id&quot;]cluster_cols = match_cols + [&apos;hotel_cluster&apos;]groups = t1.groupby(cluster_cols)top_clusters = &#123;&#125;for name, group in groups: clicks = len(group.is_booking[group.is_booking == False]) bookings = len(group.is_booking[group.is_booking == True]) score = bookings + .15 * clicks clus_name = make_key(name[:len(match_cols)]) if clus_name not in top_clusters: top_clusters[clus_name] = &#123;&#125; top_clusters[clus_name][name[-1]] = scoreimport operatorcluster_dict = &#123;&#125;for n in top_clusters: tc = top_clusters[n] top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]] cluster_dict[n] = top 给予目的地,进行预测 1234567preds = []for index, row in t2.iterrows(): key = make_key([row[m] for m in match_cols]) if key in cluster_dict: preds.append(cluster_dict[key]) else: preds.append([]) 评估错误 1metrics.mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], preds, k=5) 更好的结果 根据用户 12345678910111213141516match_cols = [&apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;user_location_city&apos;, &apos;hotel_market&apos;, &apos;orig_destination_distance&apos;]groups = t1.groupby(match_cols) def generate_exact_matches(row, match_cols): index = tuple([row[t] for t in match_cols]) try: group = groups.get_group(index) except Exception: return [] clus = list(set(group.hotel_cluster)) return clusexact_matches = []for i in range(t2.shape[0]): exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols)) 合并预测 1234567891011121314def f5(seq, idfun=None): if idfun is None: def idfun(x): return x seen = &#123;&#125; result = [] for item in seq: marker = idfun(item) if marker in seen: continue seen[marker] = 1 result.append(item) return result full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], full_preds, k=5) 生成提交文件 12345write_p = [&quot; &quot;.join([str(l) for l in p]) for p in full_preds]write_frame = [&quot;&#123;0&#125;,&#123;1&#125;&quot;.format(t2[&quot;id&quot;][i], write_p[i]) for i in range(len(full_preds))]write_frame = [&quot;id,hotel_clusters&quot;] + write_framewith open(&quot;predictions.csv&quot;, &quot;w+&quot;) as f: f.write(&quot;\n&quot;.join(write_frame)) 总结 下一步]]></content>
      <categories>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>kaggle</tag>
        <tag>随机森林</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac_Chrome浏览器下载csv.gz后缀时遇到的问题]]></title>
    <url>%2F2017%2F12%2F04%2Fegenie_bugfix%2Ferror-download-gz%2F</url>
    <content type="text"><![CDATA[问题描述: 下载一个应该为csv.gz后缀名的问题,不知道为什么没有了后缀名,一开始以为是字符集问题 下载的是kaggle的data数据https://www.kaggle.com/c/expedia-hotel-recommendations/data 报错错误 问了小伙伴,解压后的文件应该有几个g,不应该几百兆,因此推断是后缀名问题 解决http://pic.victor123.cn/17-12-4/7396408.jpg 知识小结123456789101112131415.tar 解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）———————————————.gz解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName.tar.gz 和 .tgz解压：tar zxvf FileName.tar.gz压缩：tar zcvf FileName.tar.gz DirName———————————————]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化idea插件安装]]></title>
    <url>%2F2017%2F12%2F01%2Ftools%2Fidea-plugins-install%2F</url>
    <content type="text"><![CDATA[常常遇到从idea程序中搜索插件，下载超时的情况,解决方式如下1.直接在官网下载并进行安装,然后Install from diskhttps://plugins.jetbrains.com/search?correctionAllowed=true&amp;pr=idea&amp;orderBy=&amp;search= 2.使用ss作代理，直接下载]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>代理</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next主题保存]]></title>
    <url>%2F2017%2F11%2F30%2Fegenie_bugfix%2Ferror-next-submodule%2F</url>
    <content type="text"><![CDATA[通过git的submodule功能对博客内容和主题分别进行版本控制方案https://stackoverflow.com/questions/12898278/issue-with-adding-common-code-as-git-submodule-already-exists-in-the-index 12345678git ls-files --stagegit rm --cached themes/nextgit submodule add git@github.com:victorsheng/hexo-theme-next.git themes/nextgit add .gitmodules .gitmodulesn内容如下：[submodule “themes/next”] path = themes/next url = git@github.com:victorsheng/hexo-theme-next.git]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>git</tag>
        <tag>submodule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac安装seaborn遇到的问题]]></title>
    <url>%2F2017%2F11%2F30%2Fegenie_business%2Ferror-pip-install-seaborn%2F</url>
    <content type="text"><![CDATA[异常信息12345678910111213141516171819202122232425262728293031323334353637pip install numpyMacBook-Pro:~ victor$ pip install seabornCollecting seaborn Downloading seaborn-0.8.1.tar.gz (178kB) 100% |████████████████████████████████| 184kB 666kB/sCollecting pandas (from seaborn) Using cached pandas-0.21.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Collecting numpy&gt;=1.9.0 (from pandas-&gt;seaborn) Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: pytz&gt;=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Installing collected packages: numpy, pandas, seaborn Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-gOIIvZ-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos; 发现卸载这个numpy都不行1234567891011121314151617181920212223242526sudo -H pip uninstall numpyDEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.Uninstalling numpy-1.8.0rc1: /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-infoProceed (y/n)? yException:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/uninstall.py&quot;, line 76, in run requirement_set.uninstall(auto_confirm=options.yes) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 346, in uninstall req.uninstall(auto_confirm=auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/tmp/pip-Ez2DTF-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info 解决方案https://blog.wizchen.com/2016/06/17/Mac%E4%B8%8B%E6%9B%B4%E6%96%B0python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93numpy/ 说是System Integrity Protection的问题，解决的办法是关闭SIP: 重启电脑，电脑启动的时候安住 command + R 等画面上出现 apple logo 的，你会看到 OS X 工具程式的窗口，选择终端，等待终端打开，直接输入csrutil disable，回车后重启即可 重启完毕后，再次在终端输入 最后成功1234567891011121314151617181920212223242526272829303132333435363738pip install -U numpyCollecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-rfPgIG-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos;shengsiyudeMacBook-Pro:~ victor$ sudo -H pip install -U numpyPassword:Collecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1: Successfully uninstalled numpy-1.8.0rc1Successfully installed numpy-1.13.3]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mac</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术搜索技巧]]></title>
    <url>%2F2017%2F11%2F28%2Fcommon_tools%2Fcode-blog-website%2F</url>
    <content type="text"><![CDATA[结合搜索引擎语法 site:功能,可以高效的搜索出常见的技术类问题的解决方案常见的网址如下: 国内 博客园 cnblogs.com CSDN csdn.net 开源中国 oschina.net 简书 jianshu.com SegmentFault segmentfault.com 掘金 juejin.im 国外 stackoverflow Github GithubPage 知识分享 知乎 quora 而对于相对专业的技能 api文档 和官方文档]]></content>
      <categories>
        <category>搜索技巧</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据展现技术选型]]></title>
    <url>%2F2017%2F11%2F28%2Fdata_warehouse%2FBI-show-tool%2F</url>
    <content type="text"><![CDATA[数据展现技术选型 阿里云Quick Bi(试用过30天)Quick BI 是一个基于云计算的灵活的轻量级的自助 BI 工具服务平台。 Quick BI 支持众多种类的数据源，既可以连接 MaxCompute（ODPS）、RDS、Analytic DB、HybridDB（Greenplum）等云数据源，也支持连接 ECS 上您自有的 MySQL 数据库，还支持上传本地文件到 Quick BI 内置的探索空间进行分析。 Tableauhttps://www.tableau.com/ From GitHubSuperset Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名Panoramix、Caravel），该工具在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。 https://github.com/apache/incubator-superset Saiku https://github.com/OSBI/saiku 另外一些是没有实际调研过的一些工具 QlikviewFineBIBDP商业数据平台永洪]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>数据展示</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习分型]]></title>
    <url>%2F2017%2F11%2F27%2Fdocker%2Fshare-docker%2F</url>
    <content type="text"><![CDATA[简介 Docker 是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大提高了应用的运行效率，降低了云计算资源供应的成本！使用 Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松！ 无论是应用开发者、运维人员、还是其他信息技术从业人员，都有必要认识和掌握 Docker，节约有限的时间。 docker的由来 Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎，由 Go 语言编写的，源代码托管在 github 而且居然只有 1W 行就完成了这些功能。 Docker自2013年以来非常火热，无论是从 github 上的代码活跃度，还是Redhat在RHEL6.5中集成对Docker的支持, 就连 Google 的 Compute Engine 也支持 docker 在其之上运行。 Docker设想是交付运行环境如同海运，OS如同一个货轮，每一个在OS基础上的软件都如同一个集装箱，用户可以通过标准化手段自由组装运行环境，同时集装箱的内容可以由用户自定义，也可以由专业人员制造。这样，交付一个软件，就是一系列标准化组件的集合的交付，如同乐高积木，用户只需要选择合适的积木组合，并且在最顶端署上自己的名字(最后个标准化组件是用户的app)。这也就是基于docker的PaaS产品的原型。 为什么要使用 Docker？ 更高效的利用系统资源 更快速的启动时间 一致的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 镜像（Image） Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container） 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 仓库（Repository） 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 基本命令 docker run busybox echo “hello world” docker ps 官方仓库https://store.docker.com/ mac版本图形化客户端:kitematicKitematic 完全自动化了 Docker 安装和设置过程，并提供了一个直观的图形用户接口（GUI）来在 Mac 上运行 Docker。Kitematic 集成了 Docker Machine 来在 Mac 上分发一个虚拟机并安装 Docker 引擎。 一旦安装成功，Kitematic GUI 便会启动，紧接着你可以立刻运行控制台中的镜像。你仅仅只需要在 Kitematic 搜索框键入镜像名就可以搜索任何在 Docker Hub 上存在的镜像。通过 GUI 你可以非常容易的创建、运行和管理你的容器，不需要使用命令行或者是在 Docker CLI 和 GUI之间来回切换。 Kitematic 也让Docker的一些高级特性使用更加方便，比如管理端口和配置 volumes。你可以方便的修改环境变量、查看日志，单机终端就可以进入容器，这些特性GUI都支持。dockerfileDockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。例如:https://hub.docker.com/r/haocen/docker-hexo-with-hexo-admin/ 进阶数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性: 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 网络管理Docker启动时，会自动在主机上创建一个docker0虚拟网桥，实际上是Linux的一个bridge,可以理解为一个软件交换机，它会而挂载到它的网口之间进行转发 当创建一个Docker容器的时候，同理会创建一对veth pair接口(当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包)，这对接口一端在容器内，即eth0;另一端在本地并被挂载到docker0网桥，名称以veth开头。 容器安全 内核命名空间 控制组控制组是 Linux 容器机制的另外一个关键组件，负责实现资源的审计和限制。它提供了很多有用的特性；以及确保各个容器可以公平地分享主机的内存、CPU、磁盘 IO 等资源；当然，更重要的是，控制组确保了当容器内的资源使用产生压力时不会连累主机系统。 内核能力机制12345678910大部分情况下，容器并不需要“真正的” root 权限，容器只需要少数的能力即可。为了加强安全，容器可以禁用一些没必要的权限。 完全禁止任何 mount 操作； 禁止直接访问本地主机的套接字； 禁止访问一些文件系统的操作，比如创建新的设备、修改文件属性等； 禁止模块加载。这样，就算攻击者在容器中取得了 root 权限，也不能获得本地主机的较高权限，能进行的破坏也有限。默认情况下，Docker采用白名单机制，禁用必需功能之外的其它权限。 当然，用户也可以根据自身需求来为 Docker 容器启用额外的权限。 容器编排编排是一个新的词汇，指的是容器的集群化和调度。另一类含义指的是容器管理，负责管理容器化应用和组件任务。 &lt;img src=&quot;http://pic.victor123.cn/17-11-29/58239834.jpg&quot;&gt; Docker Swarm、Kubernetes、Marathon和Nomad 快速安装docker12345678910useradd appusrpasswd appusrgroupadd dockerusermod -aG docker appusryum install epel-release –yyum install docker-io –ysystemctl start dockersystemctl enable docker 使用案例本地的nginx12345678910111213141516171819202122232425262728293031323334353637383940docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -v $PWD/logs:/etc/nginx/logs -d nginxnginx配置文件:server &#123; listen 80 default_server; location /api/iac &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.222:9060; &#125; location /api/bi &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.106:9991; &#125; location = / &#123; proxy_connect_timeout 1800; proxy_read_timeout 1800; proxy_send_timeout 1800; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location / &#123; proxy_pass http://192.168.0.106:8099; &#125; location /page &#123; proxy_pass http://192.168.0.106:8888; &#125; location /static &#123; proxy_pass http://192.168.0.106:8888; &#125; location /main &#123; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location /login&#123; proxy_pass http://192.168.0.106:8888/page/login/index.html; &#125;&#125; 用docker安装mysql数据库准备工作123456789101112yum install gitmkdir /dockerchown -R appusr /dockersudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://cz3my8je.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 启动12345678910要复制conf到制定目录下docker run -p 3306:3306 --name mymysql -v /docker/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /docker/mysql/logs:/logs -v /docker/mysql/data:/mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6docker ps -adocker run -it --link mymysql:mysql --rm mysql sh -c &apos;exec mysql -h 172.18.0.1 -P 3306 -u root -p123456&apos;CREATE USER &apos;pig&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;GRANT ALL ON *.* TO &apos;pig&apos;@&apos;%&apos;; 附录10张图带你深入理解Docker容器和镜像http://dockone.io/article/783 菜鸟网 http://www.runoob.com/docker/docker-hello-world.html Docker 安装 Nginx Docker 安装 PHP Docker 安装 MySQL Docker 安装 Tomcat Docker 安装 Python Docker 安装 Redis Docker 安装 MongoDB Docker 安装 Apache 学习资料 https://joshhu.gitbooks.io/docker_theory_install/content/ https://docs.docker.com/ https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能采购实现逻辑梳理]]></title>
    <url>%2F2017%2F11%2F27%2Fegenie_business%2Fcode-samrtPurchase%2F</url>
    <content type="text"><![CDATA[智能采购实现逻辑梳理销量部分计算(一天执行一次) 刷新1天,7天,30天,自定义天销量方法 排除掉不采购仓库的销量 排除掉备货仓的销量 分批进行持久化 触发一次采购部分计算 采购部分计算(定时半个小时执行一次) 获取界面上手动覆盖的参数 如果有批量修改勾选的ids则至处理这部分智能采购记录,否则查询全部智能采购记录 如果修改了上限和下限库存,则县持久化 填充库存 本仓库库存+本仓库的备货仓的库粗查询 计算存货天数 取采购周期,供货商 1234567* 根据excel公式,计算备货的字段* 日均销量=7天销量/7* 最低库存=日均销量*备货天数* 上限库存=日均销量*(备货天数+采购周期)* 存货预警库存=在途库存-最低库存 P.S.小于0的需要采购* 建议采购数量=上限采购数量-在途库存*/ 查询参数 强制覆盖采购周期和存货天数 计算上限和下限库存 Double minStock = avgSaleVolume * inventoryDays; Double maxStock = avgSaleVolume * (inventoryDays + procurementCycle); 强制覆盖上限和下限库存 如果开启智能计算跳过此步骤 查询SaleStockSetting表中记录的上限和线下库存,别设置isManual=true 计算预警库存和建议采购量 Integer saleStock = v.getSaleStock(); Integer onWayStock = v.getOnWayStock(); int stock = saleStock + onWayStock; double warningStock = stock - minStock; 如果预警库存&lt;0,double originAdviceNum = maxStock - stock,并向上取整 如果预警库存&gt;=0,不进行建议 强制覆盖最总结果 对verifyNum进行赋值 强制覆盖verifyNum 持久化更新]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数学习]]></title>
    <url>%2F2017%2F11%2F24%2Fmath%2Fmath-linear-algebra%2F</url>
    <content type="text"><![CDATA[推荐一(博客)http://www.hahack.com/wiki/math-linear-algebra.html 矩阵 基本运算 加 减 乘 求逆 矩阵的转职 应用举例 求解方程组 求向量组合 向量 基本运算 加 减 乘 标量乘向量 向量点积 向量外积 矩阵向量积 向量的转置 线性无关 张成空间 线性相关和线性无关 判断是否线性相关 张量 线性代数进阶 阶梯形矩阵 阶梯形矩阵 行简化阶梯形矩阵 行最简形矩阵 将矩阵化简成行最简阶梯形 线性子空间 零空间 列空间 行空间 左零空间 子空间的正交补 最小二乘逼近 实例1：求解方程 实例2：线性回归 特征向量 求解特征值 求解特征向量 推荐二 http://space.bilibili.com/88461692#!/ 线性代数的本质 http://space.bilibili.com/88461692#!/channel/detail?cid=9450 一天就看了好几集,让我对数学又重新产生了兴趣, 对此,本篇的目的旨在记录这两天所学到的内容: 线性代数的本质01向量究竟是什么 向量是函数 向量是一条记录(多个观察值) 向量是物理运动 02线性组合、张成的空间03矩阵与线性变换 矩阵向量乘法是一种线性变化,第一列是i帽移动的,第二列是j帽移动的位置 其中,2X2矩阵就是二维线性变换 04矩阵乘法与线性变换复合 矩阵的乘法就是两个线性变化的相继结果 从右往左读 先是e,g向量,线性变化,chengwei ae+bg,ce+dg,如图 矩阵的乘法没有交换律,有结合律 04三维空间中的线性05行列式(线性变化的行列式) 行列式= 二位线性变化所对应的面积缩放比例,三维实体积 行列式结果=1,代表面积没有变化 行列式结果=6,代表面积乘以6 行列式结果=0,代表在降维了 行列式结果为负数,代表空间反面了 结算公式:ad-bc det(矩阵)=行列式 06逆矩阵、列空间与零空 求解线性方程组 行列式不为0时:线性变化*逆向线性变化=什么都不做(1) 行列式为0时:无法求逆 秩:变化后的空间维数 3*3矩阵的最大秩:为3,否则就意味着被压缩了 矩阵的列空间:所有可能的输出向量构成的集合(列张成的空间=列空间) 整个线被压缩:降1维(零空间) 整个平面被压缩:降2维(零空间) 06补充说明:非方阵07点积与对偶性 向量的点成:一个向量*另一个向量在该向量上的投影 矩阵和向量之间的联系 转换*向量 矩阵向量乘积 类似 向量的点积 08第一部分:叉积的标准介绍08第二部分:以线性变化的眼光看叉积09基变换10特征向量与特征值11抽象向量空间]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺货销售订单生成采购单逻辑梳理]]></title>
    <url>%2F2017%2F11%2F21%2Fegenie_business%2Fcode-saleGeneratePurchaseOrder%2F</url>
    <content type="text"><![CDATA[缺货销售订单生成采购单逻辑梳理入口: 采购单界面,一键生成采购单 订单处理界面 勾选制定订单,生成采购单 按照查询条件,生成采购单 实现逻辑: 查询基档案warehouse 是否需要采购,以及换货仓 查询之前的组号映射关系 未关闭的采购单 到货状态的唯一码 更新之前组的到货数量 查询总的缺货销售订单数 分页生成采购单,默认5000单一组 分页查询缺货销售订单 根据系统参数 过滤掉申请退款的明细 复制订单和订单明细,到新的数据结构(VSaleOrder,VSaleOrderDetail)–&gt;(PmsDailyPurchase,PmsDailyPurchaseDetail) 过滤采购完成 过滤无需采购 绝对唯一码规则.一条明细生成多个唯一码 根据三级明细分配采购单号 将未分拣墙上的设置到制定A组中 单件不进分组 相同订单的,使用上次的组号,同一订单组号继续使用 大单量分组 普通分组,并且分组下的订单数没有超过计划的订单数量 使用已有的分组(按A-Z的优先顺序) 创建新的分组 合并最后一个分组信息 回写新增的组至totalGroupMap(内存级别) 批量填充唯一码 生成36进制的唯一码 唯一码规则:租户内唯一 唯一码规则:9位唯一码 sku的唯一码,以1开头 (前绑定)根据采购单数,绑定订单和唯一码 (后绑定)先尝试使用为分拣墙上的sku,此部分无需采购,更新updateNum为-1 持久化PmsPurchaseOrder 汇总三级明细,生成二级明细 次品仓业务(原采购单有相同sku的,用次品仓的货物换;没有的,增加采购数量) 根据skuIds,查询换货仓的库存 原采购数量&lt;换货仓库存,新采购数量=换货仓数量 原采购数量&gt;=换货仓数量,新采购数量=原采购数量 自动生成次品仓盘点单 填充供货信息VendorSupply 根据skuIds查询默认供应商 设置采购周期和到货时间 设置最小采购数量 设置采购供应商 设置采购价格 优先价格体系 设置采购人(PDA推送的依据) 查询不到的取sku得采购信息,取sku得采购信息 设置采购周期和到货时间 设置最小采购数量 设置采购价格 反写采购单明细的信息到拿货明细 二级明细业务处理: update 和 insert的 持久化二级明细 回写二级明细id到二点五级明细和三级明细 移除掉不需要采购的采购单明细,和拿货订单明细,二级和三级需要同时移除 规则一:供应商无需采购(之所以再次移除,是因为此处采购供应商) 规则二:几天后到货的(目前已废弃) 如果所有明细都移除了,则无需持久化采购单主表 持久化(update 和 insert)订单主表 持久化PmsDailyPurchase,PmsDailyPurchaseDetail 返回生成采购单报告]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的武器库]]></title>
    <url>%2F2017%2F11%2F21%2F%E5%85%B6%E4%BB%96%2F%E6%88%91%E7%9A%84%E6%AD%A6%E5%99%A8%E5%BA%93%2F</url>
    <content type="text"><![CDATA[搜索引擎我掌握的语言 java sql python 技术框架持续使用的githubmac常用软件 Sublime DateGrip IntliJ IDEA WebStorm SourceTree Jprofiler MAT Beyound Compare PlantUML ShadowSocks_NG Postman 命令常用软件 brew docker 文本处理器 vim Pandoc markdown]]></content>
      <categories>
        <category>技术栈</category>
      </categories>
      <tags>
        <tag>我的</tag>
      </tags>
  </entry>
</search>
