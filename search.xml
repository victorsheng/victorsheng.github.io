<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ali-message]]></title>
    <url>%2F2018%2F03%2F25%2Fmessages%2F2018-03-25-ali-message%2F</url>
    <content type="text"><![CDATA[顺序消息全局顺序对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景： 性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景。 举例说明： 【例一】证券处理中，以人民币兑换美元为 Topic，在价格相同的情况下，先出价者优先处理，则可以通过全局顺序的方式按照 FIFO 的方式进行发布和订阅。 分区顺序对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景： 性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。 举例说明： 【例一】用户注册需要发送发验证码，以用户 ID 作为 sharding key， 那么同一个用户发送的消息都会按照先后顺序来发布和订阅。 【例二】电商的订单创建，以订单 ID 作为 sharding key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照先后顺序来发布和订阅。 阿里巴巴集团内部电商系统均使用此种分区顺序消息，既保证业务的顺序，同时又能保证业务的高性能。 全局顺序与分区顺序对比在控制台创建顺序消息使用的 Topic，各种类型 Topic 对比如下。 消息类型对比 Topic 类型 支持事务消息 支持定时消息 性能 无序消息 是 是 最高 分区顺序 否 否 高 全局顺序 否 否 一般 发送方式对比 消息类型 支持可靠同步发送 支持可靠异步发送 支持 Oneway 发送 无序消息 是 是 是 分区顺序 是 否 否 全局顺序 是 否 否]]></content>
  </entry>
  <entry>
    <title><![CDATA[atom设置本地代理]]></title>
    <url>%2F2018%2F03%2F24%2Ftools%2F2018-03-24-atom-proxy-set%2F</url>
    <content type="text"><![CDATA[atom设置proxy12apm config set strict-ssl falseapm config set https-proxy http://localhost:1087]]></content>
  </entry>
  <entry>
    <title><![CDATA[optimizie-sql-order-by]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Foptimizie-sql-order-by%2F</url>
    <content type="text"><![CDATA[mysql排序方式:常规排序 a 从表t1中获取满足WHERE条件的记录 b 对于每条记录，将记录的主键+排序键(id,col2)取出放入sort buffer c 如果sort buffer可以存放所有满足条件的(id,col2)对，则进行排序；否则sort buffer满后，进行排序并固化到临时文件中。(排序算法采用的是快速排序算法) d 若排序中产生了临时文件，需要利用归并排序算法，保证临时文件中记录是有序的 e 循环执行上述过程，直到所有满足条件的记录全部参与排序 f 扫描排好序的(id,col2)对，并利用id去捞取SELECT需要返回的列(col1,col2,col3) g 将获取的结果集返回给用户。 从上述流程来看，是否使用文件排序主要看sort buffer是否能容下需要排序的(id,col2)对，这个buffer的大小由sort_buffer_size参数控制。此外一次排序需要两次IO，一次是捞(id,col2),第二次是捞(col1,col2,col3)，由于返回的结果集是按col2排序，因此id是乱序的，通过乱序的id去捞(col1,col2,col3)时会产生大量的随机IO。对于第二次MySQL本身一个优化，即在捞之前首先将id排序，并放入缓冲区，这个缓存区大小由参数read_rnd_buffer_size控制，然后有序去捞记录，将随机IO转为顺序IO。 优化排序常规排序方式除了排序本身，还需要额外两次IO。优化的排序方式相对于常规排序，减少了第二次IO。主要区别在于，放入sort buffer不是(id,col2),而是(col1,col2,col3)。由于sort buffer中包含了查询需要的所有字段，因此排序完成后可以直接返回，无需二次捞数据。这种方式的代价在于，同样大小的sort buffer，能存放的(col1,col2,col3)数目要小于(id,col2)，如果sort buffer不够大，可能导致需要写临时文件，造成额外的IO。当然MySQL提供了参数max_length_for_sort_data，只有当排序元组小于max_length_for_sort_data时，才能利用优化排序方式，否则只能用常规排序方式。 优先队列排序为了得到最终的排序结果，无论怎样，我们都需要将所有满足条件的记录进行排序才能返回。那么相对于优化排序方式，是否还有优化空间呢？5.6版本针对Order by limit M，N语句，在空间层面做了优化，加入了一种新的排序方式:优先队列，这种方式采用堆排序实现。堆排序算法特征正好可以解limit M，N 这类排序的问题，虽然仍然需要所有元素参与排序，但是只需要M+N个元组的sort buffer空间即可，对于M，N很小的场景，基本不会因为sort buffer不够而导致需要临时文件进行归并排序的问题。对于升序，采用大顶堆，最终堆中的元素组成了最小的N个元素，对于降序，采用小顶堆，最终堆中的元素组成了最大的N的元素。 对比页数比较大的情况低效率: 高效率: 针对limit 优化有很多种方式1 前端加缓存、搜索，减少落到库的查询操作。比如海量商品可以放到搜索里面，使用瀑布流的方式展现数据，很多电商网站采用了这种方式。2 优化SQL 访问数据的方式，直接快速定位到要访问的数据行。3 使用书签方式 ，记录上次查询最新/大的id值，向后追溯 M行记录。 快速定位对于第二种方式 我们推荐使用”延迟关联”的方法来优化排序操作，何谓”延迟关联” ：通过使用覆盖索引查询返回需要的主键,再根据主键关联原表获得需要的数据。3.1 延迟关联123root@xxx 12:33:48&gt;explain SELECT id, cu_id, name, info, biz_type, gmt_create, gmt_modified,start_time, end_time, market_type, back_leaf_category,item_status,picuture_url FROM relation where biz_type =&apos;0&apos; AND end_time &gt;=&apos;2014-05-29&apos; ORDER BY id asc LIMIT 149420 ,20;explain SELECT a.* FROM relation a, (select id from relation where biz_type =&apos;0&apos; AND end_time &gt;=&apos;2014-05-29&apos; ORDER BY id asc LIMIT 149420 ,20 ) b where a.id=b.id; 书签方式首先要获取复合条件的记录的最大 id和最小id(默认id是主键)1select max(id) as maxid ,min(id) as minid from t where kid=2333 and type=1; 其次 根据id 大于最小值或者小于最大值 进行遍历。 123select xx,xx from t where kid=2333 and type=1 and id &gt;=min_id order by id asc limit 100;select xx,xx from t where kid=2333 and type=1 and id &lt;=max_id order by id desc limit 100; 使用延迟关联查询数据510ms ，使用基于书签模式的解决方法减少到10ms以内 绝对是一个质的飞跃。]]></content>
  </entry>
  <entry>
    <title><![CDATA[sql-killer]]></title>
    <url>%2F2018%2F03%2F24%2Fmysql%2Fsql-killer%2F</url>
    <content type="text"><![CDATA[每个oltp数据库实例上设置一个sql-killer进程用于kill掉执行时间超过一定阈值测sql,并发邮件报警]]></content>
  </entry>
  <entry>
    <title><![CDATA[软删除唯一索引解决]]></title>
    <url>%2F2018%2F03%2F24%2Fegenie_bugfix%2Floft-delete-unquie-key%2F</url>
    <content type="text"><![CDATA[软件中使用软删除is_usable=1改为0来代表删除，但是遇到唯一索引时，例如：username+is_usable的唯一索引第二次删除则会失败，解决办法，将is_usable 改为其他不重复的数字及可]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-cap]]></title>
    <url>%2F2018%2F03%2F23%2F%E5%88%86%E5%B8%83%E5%BC%8F%2Fstudy-cap%2F</url>
    <content type="text"><![CDATA[CAP（Consistency一致性、Availability可用性、Partition-tolerance分区可容忍性）理论普遍被看成是大数据技术的理论基础。同时，凭据该理论，业界有一种极度流行、极度“专业”的认识，那就是：关系型数据库设计选择了C（一致性）与A（可用性），NoSQL数据库设计则差别。其中，HBase选择了C（一致性）与P（分区可容忍性），Cassandra选择了A（可用性）与P（分区可容忍性）。 Consistency一致性：你的客户再次来电时总能查到他们刚来电更新的信息，不论相隔多短 Availability可用性：不论你和你妻子谁来工作，记忆公司总能接听来电，处理客户请求 Partition-tolerance分区可容忍性：即便你和你妻子失联，记忆公司依然能正常运转 Feature Consul zookeeper etcd euerka 服务健康检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 可配支持 多数据中心 支持 — — — kv存储服务 支持 支持 支持 — 一致性 raft paxos raft — cap ca cp cp ap 使用接口(多语言能力) 支持http和dns 客户端 http/grpc http（sidecar） watch支持 全量/支持long polling 支持 支持 long polling 支持 long polling/大部分增量 自身监控 metrics — metrics metrics 安全 acl /https acl https支持（弱） — spring cloud集成 已支持 已支持 已支持 已支持 特性 HBase Cassandra 语言 Java Java 出发点 BigTable BigTable and Dynamo License Apache Apache Protocol HTTP/REST (also Thrift) Custom, binary (Thrift) 数据分布 表划分为多个region存在不同region server上 改进的一致性哈希（虚拟节点） 存储目标 大文件 小文件 一致性 强一致性 最终一致性，Quorum NRW策略 架构 master/slave p2p 高可用性 NameNode是HDFS的单点故障点 P2P和去中心化设计，不会出现单点故障 伸缩性 Region Server扩容，通过将自身发布到Master，Master均匀分布Region 扩容需在Hash Ring上多个节点间调整数据分布 读写性能 数据读写定位可能要通过最多6次的网络RPC，性能较低。 数据读写定位非常快 数据冲突处理 乐观并发控制（optimistic concurrency control） 向量时钟 临时故障处理 Region Server宕机，重做HLog 数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。 永久故障恢复 Region Server恢复，master重新给其分配region Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性 成员通信及错误检测 Zookeeper 基于Gossip CAP 1，强一致性，0数据丢失。2，可用性低。3，扩容方便。 1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。 cap 有这样两种情况：一种情况是要求节点A、B、C的三份数据完全一致后返回。也就是说，这时从任何一个网络节点读取的数据都是一样的，这就是所谓的强一致性读。很明显，这时数据读取的Latency要高一些（由于要等数据在网络中的复制），同时A、B、C三个节点中任何一个宕机，都会导致数据不行用。也就是说，要保证强一致性，网络中的副本越多，数据的可用性就越差； 另一种情况是，允许读操作立刻返回，容忍B节点的读取与A节点的读取不一致的情况发生。这样一来，可用性显然获得了提高，网络中的副本也可以多一些，唯一得不到保证的是数据一致性。当然，对写操作同样也有多个节点一致性的情况，在此不再赘述。 cap 分布式系统分区容忍肯定是要保证的，因为总会有网络延迟，网络波动导致每个节点互相有短暂或长时间的通讯不通。所以我们在这个基础上，如果我们解决了一致性问题，也就是我们在网络波动和延迟的时候也让每个节点的数据是一样的，保证同时从任意节点取到的数据是一样的。 那么我们就得舍弃可用性，也就是说我们在网络波动或者延迟的时候让整个分布式系统不可用，等到数据都同步完了，每个节点的数据都一样了，这时候我们在让分布式系统可用。这就是舍弃了可用性。 那什么是舍弃一致性呢？就是在有网络延迟的时候，我整个的分布式系统还对外提供服务，这时就有可能短暂的出现获取的数据不是一致的。这就是舍弃了一致性。所以一般来说我们都是保证可用性，虽然有短暂的数据不一致，但我们只要最终保证了一致性在有些时候也是可以满足需要的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[data-warehouse-build]]></title>
    <url>%2F2018%2F03%2F21%2Fdata_warehouse%2Fdata-warehouse-build%2F</url>
    <content type="text"><![CDATA[https://tech.meituan.com/tag/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93 https://tech.meituan.com/mtdp_travel_yydp_present.html 架构图 领域内常见的建模方法① 3NF模型 3NF模型（又叫“范式模型”）是数据仓库之父Inmon提出的，它用实体加关系的数据模型描述业务架构，在范式理论上符合3NF，是站在全局角度面向主题的抽象。它更多的是面向数据的一致性治理。 3NF模型最基本的要素是实体、属性和关系： 实体：相同特征和性质的属性抽象，用抽象的实体名和属性名集合共同刻画的逻辑实体；关系：实体之间的关系；属性：实体的某种特性，一般实体具有多个属性。② 维度模型 维度模型是Kimball提出的。维度模型多为分析和决策提供服务，因此它重点解决快速完成分析，同时提供大规模复杂查询的响应性能（预聚合），更直接地面向业务。例如熟知的星形模型，以及特殊场景的雪花模型。 维度建模最基本的要素是事实和维度： 事实表：一般由两部分组成，纬度和指标，通常理解为“某人在某时间某地点通过某手段做了什么事情”的事实记录，它体现了业务流程的核心内容；维度表：看待事实的角度，用以描述和还原事实发生的场景，比如通过地址、时间等维度还原业务场景。③ DV模型（DataVault） DataVault是Dan Linstedt发起的，是一种介于3NF和维度建模之间的建模方法。它的设计主要是满足灵活性、可扩展性、一致性和对需求的适应性。它强调建立一个可审计的基础数据层，主要包括Hub（核心实体）、Link（关系）、Satellite（实体属性）三个要素。 ④ Anchor模型 Anchor模型由Lars. Rönnbäck提出，是DataVault模型的进一步范式化处理，核心思想是只添加、不修改的可扩展模型，Anchor模型构建的表极窄，类似于K-V结构化模型。它主要包括Anchors（实体且只有主键），Atributes（属性），Ties（关系），Knots（公用枚举属性)）。Anchor是应用中比较少的建模方法，只有传统企业和少数几家互联网公司有应用，例如：蚂蜂窝等。 运营专题数据如何构建随着促销系统不断发展，平台趋于稳定，再结合各活动类型，及对需求的整理和进一步产品化，选择了3NF+维度建模为基础的模型方法论，对数据进行合理划分和整合，构建了运营专题数据体系。 ① 数据规范制定 数据规范的制定也是指标字典和服务层规则引擎抽象的基础。首先同业务达成共识，制定数据一致性标准，统一口径。同时将核心指标和个性化指标进行抽象，抽取统一规范定义，例如：月初到月末的整体交易类GMV和补贴类GMV，其原子指标是GMV，其它要素都属于指标的修饰。 ② 数仓模型架构 将数据分为ODS层、BAS层、FACT层、TOPIC层。 ODS层主要功能 从分布式消息队列中消费Binlog和Click-log，并对埋点数据进行清洗和业务库数据还原，并根据需要增量或全量同步到Hive，同时积累历史数据并保存。 BAS层主要功能 采用3NF建模方法，对整体业务进行概念抽象及适当冗余，在保证数据一致的同时将同属性实体归纳整合到同一逻辑域。BAS层主要是为了减少数据的不一致，减少存储空间，响应业务系统的变化，避免更新异常。 FACT层主要功能 采用维度建模方法，根据活动特点及事实场景，对代金券、现金券、促销等的事件进一步整合。经过对维度的预处理，在使用信息的时候，不但减少时间成本、提高数据的提取效率，又为用户在Ad-Hoc平台查询提供很好的支撑，同时它成为了上层数据应用的关键出口。 TOPIC层主要功能 该层建设不是必须的，是针对业务中个性化诉求，根据需要建设专题数据。服务小范围业务群体和用户，用来支撑核心业务指标外的某一块个性化指标和应用。 如图所示，数仓模型整体架构图。通过构建运营专题的底层数据，针对数据一致性等问题，在数仓层面上得到了很好的解决，同时在数据提取效率上有很大的提升。数仓建设为接下来的业务支撑打好了充分的基础。 多维预计算层预计算层是连接数据和应用之间的管道，是应用层垂直模块的专项支持。它是在Fact层数据之上的预聚合，强依赖于数仓模型中事实和维度的构建以及预关联。预计算采用Kylin引擎构建Cube聚合组，来解决取数门槛和数据处理耗时等问题，同是提供多维分析的能力，不但提供了新的Ad-Hoc(Query Engine)平台，在提高查询响应的同时，又能为产品带来更流畅的交互，增强用户体验。例如：创建一个交易数据cube，它包含日期（datakey）、用户（userid）、付款方式（paytype）、购买城市（city）。为满足不同消费方式在不同城市的应用情况和查看用户在不同城市的消费行为，建立以下两个聚合组，包含的维度和方式如图所示： 中台服务层数据预计算之后，需要分别对PC和移动端提供计算和装载，并且要针对不同端的特定模块做特定的开发，为了应对多变的业务逻辑，以及未来的可扩展能力，需要提供可插拔的、统一的服务层，该层主要可以解决如下问题： 服务与预计算数据同步，数据模型的修改只影响到预计算层，同时服务层还可以完全感知预计算数据的变化，不需要对服务做开发调整，实现数据变更的同步响应； 服务与端解耦，针对不同端产品提供统一数据服务，避免重复开发，同时产品的迭代升级与服务层隔离，应对多变的业务发展和增长； 服务扩展能力增强，支持服务的横向扩展，不影响正常业务的同时提高服务能力，同时在该层实现可抽象通用操作以及规范管理。 总体 整个服务由独立的Web应用端发起请求，通过权限验证后对中台发起调用，然后读取配置中心的配置，由计算引擎对数据进行并行计算，同时规则引擎按业务线和指标修饰词等生产衍生指标，然后将引擎完成的数据按周期进行快照，存入备忘录，同时关联指标字典将数据与文案返回前台，最后按功能再对数据做可视化处理。下面分别对服务中交互的几个模块做简单的介绍。]]></content>
  </entry>
  <entry>
    <title><![CDATA[data-warehouse-layering]]></title>
    <url>%2F2018%2F03%2F21%2Fdata_warehouse%2Fdata-warehouse-layering%2F</url>
    <content type="text"><![CDATA[传统分层 阿里数据分层https://oss-cn-hangzhou.aliyuncs.com/yqfiles/ceea30ef3e4db4ec980c5a3fb8dee73d.pdf?spm=a2c4e.11153959.blogcont69316.176.367f2caePvjO9h&amp;file=ceea30ef3e4db4ec980c5a3fb8dee73d.pdf 基础层 数据中间层 数据集市层 流式数据集 美团分层https://tech.meituan.com/traffic_data_product.html A层（也称ODS层），包含美团App的大搜日志、页面流量日志、模块事件日志以及描述埋点内容的信息日志。公共维度，其中重要的流量入口维度、页面维度都是从具有统一规则的埋点标记日志中，抽象形成的维度。B3层（酒旅基础明细层），通过对A层的抽取转换，初步形成只含酒旅业务所需的基础流量日志。B2层（酒旅多维模型层），对已有的基础层数据和公共维度的轻加工，扩展出业务常用的维度信息，例如页面类型、商家门店、产品、城市，以及平台等。B1层（主题宽表层），主题宽表层主要是对多维模型层的聚合计算，包括多个复杂业务口径的输出、少数维度的深加工，以及来源入口的增加，保证数据的一致性。App层，该层是针对各自的流量应用（流量罗盘）设计的，满足该产品应用所需且具有一定扩展容量的聚合模型结构。视图层，作为App层与Kylin cube的缓冲层，依靠其本身视图的特性，能够很好地解决顶层扩展、查询延时、资源分配，以及表意理解等多个问题。cube层，每个Kylin cube是由单个视图与多个维度的雪花组合，输出计算数据给罗盘后台服务。后台服务层，包含查询引擎和配置模块两部分的内容。处理前端的查询请求。权限层，对各个业务线分平台和终端控制权限。前端展示层，与用户交互并提交用户的查询请求。 数据仓库分层的原因1通过数据预处理提高效率，因为预处理，所以会存在冗余数据 2如果不分层而业务系统的业务规则发生变化，就会影响整个数据清洗过程，工作量巨大 3通过分层管理来实现分步完成工作，这样每一层的处理逻辑就简单了 标准的数据仓库分层： ods（临时存储层） pdw（数据仓库层） mid（数据集市层） 轻度汇总(宽表几百个字段) app（应用层）OLAP/OLAM/app 1234567中间层是数据仓库最重要的一层。直接决定了数据仓库的性能。一般的做法是：1）数据汇总。将底层数据按维度进行小颗粒度汇总2）信息聚合。将多张表的信息聚合在一个表中。这样的好处，是避免使用表关联，提高查询性能。 ods：历史存储层，它和源系统数据是同构的，而且这一层数据粒度是最细的，这层的表分为两种，一种是存储当前需要加载的数据，一种是用于存储处理完后的数据。 pdw：数据仓库层，它的数据是干净的数据，是一致的准确的，也就是清洗后的数据，它的数据一般都遵循数据库第三范式，数据粒度和ods的粒度相同，它会保存bi系统中所有历史数据 mid：数据集市层，它是面向主题组织数据的，通常是星状和雪花状数据，从数据粒度将，它是轻度汇总级别的数据，已经不存在明细的数据了，从广度来说，它包含了所有业务数量。从分析角度讲，大概就是近几年 app：应用层，数据粒度高度汇总，倒不一定涵盖所有业务数据，只是mid层数据的一个子集。 数据仓库的目的是构建面向分析的集成化数据环境，为企业提供决策支持。数据仓库的context也可以理解为：数据源，数据仓库，数据应用 数据仓库可以理解为中间集成化数据管理的一个平台 etl（抽取extra，转化transfer，装载load）是数据仓库的流水线，也可以认为是数据仓库的血液。 数据仓库的存储并不需要存储所有原始数据，因为比如你存储冗长的文本数据完全没必要，但需要存储细节数据，因为需求是多变的，而且数据仓库是导入数据必须经过整理和转换使它面向主题，因为前台数据库的数据是基于oltp操作组织优化的，这些可能不适合做分析，面向主题的组织形式才有利于分析。 多维数据模型就是说可以多维度交叉查询和细分，应用一般都是基于联机分析处理（online analytical process OLAP），面向特定需求群体的数据集市会基于多位数据模型构建 而报表展示就是将聚合数据和多维分析数据展示到报表，提供简单和直观的数据。 元数据，也叫解释性数据，或者数据字典，会记录数据仓库中模型的定义，各层级之间的映射关系，监控数据仓库的数据状态和etl的任务运行状态。一般通过元数据资料库来统一存储和管理元数据。 概念数据来源层日志或者关系型数据库，并通过Flume、Sqoop、Kettle等etl工具导入到HDFS，并映射到HIVE的数据仓库表中。 事实表是数据仓库结构中的中央表，它包含联系事实与维度表的数字度量值和键。事实数据表包含描述业务（例如产品销售）内特定事件的数据。 维度表是维度属性的集合。是分析问题的一个窗口。是人们观察数据的特定角度，是考虑问题时的一类属性，属性的集合构成一个维。数据库结构中的星型结构，该结构在位于结构中心的单个事实数据表中维护数据，其它维度数据存储在维度表中。每个维度表与事实数据表直接相关，且通常通过一个键联接到事实数据表中。星型架构是数据仓库比较流向的一种架构 主题表：主题（Subject）是在较高层次上将企业信息系统中的数据进行综合、归类和分析利用的一个抽象概念，每一个主题基本对应一个宏观的分析领域。在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。例如“销售分析”就是一个分析领域，因此这个数据仓库应用的主题就是“销售分析”。 面向主题的数据组织方式，就是在较高层次上对分析对象数据的一个完整并且一致的描述，能刻画各个分析对象所涉及的企业各项数据，以及数据之间的联系。所谓较高层次是相对面向应用的数据组织方式而言的，是指按照主题进行数据组织的方式具有更高的数据抽象级别。与传统数据库面向应用进行数据组织的特点相对应，数据仓库中的数据是面向主题进行组织的。例如，一个生产企业的数据仓库所组织的主题可能有产品订货分析和货物发运分析等。而按应用来组织则可能为财务子系统、销售子系统、供应子系统、人力资源子系统和生产调度子系统。 汇总数据层(周报、月报、季报、年报)聚合原子粒度事实表及维度表，为满足固定分析需求，以提高查询性能为目的，形成的高粒度表，如周报、月报、季报、年报等。 应用层：为应用层，这层数据是完全为了满足具体的分析需求而构建的数据，也是星形结构的数据。应用层为前端应用的展现提现数据，可以为关系型数据库组成。]]></content>
  </entry>
  <entry>
    <title><![CDATA[keymap-idea]]></title>
    <url>%2F2018%2F03%2F21%2Fjava_tools%2Fkeymap-idea%2F</url>
    <content type="text"><![CDATA[代码包围1alt+comand+t]]></content>
  </entry>
  <entry>
    <title><![CDATA[catch异常但是仍然回滚]]></title>
    <url>%2F2018%2F03%2F21%2Fegenie_bugfix%2Fbugfix-exception-try-catch%2F</url>
    <content type="text"><![CDATA[上代码方式1:1234567891011public void insert() &#123; long insuranceId = IdGenerator.generateId(&quot;insurance&quot;); String sql = String.format(&quot;insert into a (id) values(%s)&quot;, insuranceId); int update = jdbcTemplate.update(sql); try &#123; hrow new RuntimeException(); &#125; catch (RuntimeException e) &#123; e.printStackTrace(); &#125;&#125; 方式2:1234567891011@Service@Transactional(readOnly = false)public class ExService2 &#123; @Autowired JdbcTemplate jdbcTemplate; public void ex() &#123; throw new RuntimeException(); &#125;&#125; 1234567891011public void insert() &#123; long insuranceId = IdGenerator.generateId(&quot;insurance&quot;); String sql = String.format(&quot;insert into a (id) values(%s)&quot;, insuranceId); int update = jdbcTemplate.update(sql);try &#123; exService2.ex();// throw new RuntimeException(); &#125; catch (RuntimeException e) &#123; e.printStackTrace(); &#125;&#125; 测试结果看似同样的逻辑,但是对于事务的回滚影响却截然不同 方式1:未回滚+一个异常日志方式2:回滚:两个异常日志+Transaction rolled back because it has been marked as rollback-only 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505120861 [http-nio-9991-exec-1] ERROR o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only] with root causeorg.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:724) at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:485) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:291) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) at cn.egenie.admin.domain.controller.ExService$$EnhancerBySpringCGLIB$$c69282d3.insert(&lt;generated&gt;) at cn.egenie.admin.domain.controller.ExceptionController.info(ExceptionController.java:25) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:832) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:743) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:961) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:895) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:967) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:858) at javax.servlet.http.HttpServlet.service(HttpServlet.java:622) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:843) at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:292) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:240) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:207) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:522) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1095) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:672) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1502) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1458) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-sharding-mysql]]></title>
    <url>%2F2018%2F03%2F21%2Fmysql%2Fstudy-sharding-mysql%2F</url>
    <content type="text"><![CDATA[参考https://tech.meituan.com/dianping_order_db_sharding.htmlhttps://help.aliyun.com/knowledge_list/52171.html?spm=a2c4g.11186623.6.702.CJt75Chttp://shardingjdbc.io/docs_cn/02-guide/sharding/https://github.com/MyCATApache/Mycat-doc/blob/master/%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/mycat%E5%88%86%E7%89%87%E8%A7%84%E5%88%99%20.docx 水平切分切分策略查询切分将ID和库的Mapping关系记录在一个单独的库中。优点：ID和库的Mapping算法可以随意更改。缺点：引入额外的单点。 范围切分比如按照时间区间或ID区间来切分。优点：单表大小可控，天然水平扩展。缺点：无法解决集中写入瓶颈的问题。 3. Hash切分 按照订单号来做hash分散订单数据 均匀分散 如果要查询某用户的所有订单呢？由于是根据订单号来分散数据的。他的订单分散在了多个库、多个表中。总不能去所有的库，所有的表扫描吧。这样效率很低。 取模切分(较多) 要扩容的时候，为了减少迁移的数据量，一般扩容是以倍数的形式增加。比如原来是8个库，扩容的时候，就要增加到16个库，再次扩容，就增加到32个库。这样迁移的数据量，就小很多了。这个问题不算很大问题，毕竟一次扩容，可以保证比较长的时间，而且使用倍数增加的方式，已经减少了数据迁移量。 为了保持性能，每张表的数据量要控制。单表可以维持在一千万-5千万行的数据。1024*一千万。哇，可以表示很多数据了。 一般采用Mod来切分，下面着重讲一下Mod的策略。 数据水平切分后我们希望是一劳永逸或者是易于水平扩展的，所以推荐采用mod 2^n这种一致性Hash。 以统一订单库为例，我们分库分表的方案是32*32的，即通过UserId后四位mod 32分到32个库中，同时再将UserId后四位整除32后 Mod 32将每个库分为32个表，共计分为1024张表。线上部署情况为8个集群(主从)，每个集群4个库。 为什么说这种方式是易于水平扩展的呢？我们分析如下两个场景。 场景一：数据库性能达到瓶颈方法一按照现有规则不变，可以直接扩展到32个数据库集群。 方法二如果32个集群也无法满足需求，那么将分库分表规则调整为(322^n)(32/2^n)，可以达到最多1024个集群。 查询需求的考虑 思路：既然是根据订单号分散订单数据，如果需要知道某个用户所有的订单。只要我能知道了a用户的所有的订单号，那么就可以根据订单号定位到表名称了。 思路：既然是根据用户id来分散订单数据的。那么只要知道了这个订单号是谁的(得到了用户id)，就能知道去哪个库、哪个表查询数据了。 那怎么知道是谁的呢？建立一个索引关系表，暂且叫做订单用户关系索引表order_user_idx。咱们命名为了保持维护性，还是一看能够知道是干嘛用的。 存储的数据包括两项：订单号、用户编号。 这样输入订单号，可以去查询索引关系表，获取到用户编号。 得到了用户编号，问题解决了。订单信息是根据用户编号分库分表的，可以直接定位到x库x表了。 当创建订单的时候，就要把关系插入到表里面去了。保存关系记录时，为了减低用户等待时间，不需要实时，做成异步。加入到消息队列中去操作。 唯一ID方案其他方案 事务支持：我们是将整个订单领域聚合体切分，维度一致，所以对聚合体的事务是支持的。 复杂查询：垂直切分后，就跟join说拜拜了；水平切分后，查询的条件一定要在切分的维度内，比如查询具体某个用户下的各位订单等；禁止不带切分的维度的查询，即使中间件可以支持这种查询，可以在内存中组装，但是这种需求往往不应该在在线库查询，或者可以通过其他方法转换到切分的维度来实现。 场景二：单表容量达到瓶颈（或者1024已经无法满足你） 方法： 假如单表都已突破200G，2001024=200T（按照现有的订单模型算了算，大概一万千亿订单，相信这一天，嗯，指日可待！），没关系，32(32*2^n)，这时分库规则不变，单库里的表再进行裂变，当然，在目前订单这种规则下（用userId后四位 mod）还是有极限的，因为只有四位，所以最多拆8192个表，至于为什么只取后四位，后面会有篇幅讲到。 另外一个维度是通过ShopID进行切分，规则8*8和UserID比较类似，就不再赘述，需要注意的是Shop库我们仅存储了订单主表，用来满足Shop维度的查询。 数据迁移（从单表–切换到分表的过程）数据库拆分一般是业务发展到一定规模后的优化和重构，为了支持业务快速上线，很难一开始就分库分表，垂直拆分还好办，改改数据源就搞定了，一旦开始水平拆分，数据清洗就是个大问题，为此，我们经历了以下几个阶段。 第一阶段数据库双写（事务成功以老模型为准），查询走老模型。每日job数据对账（通过DW），并将差异补平。通过job导历史数据。 第二阶段历史数据导入完毕并且数据对账无误。依然是数据库双写，但是事务成功与否以新模型为准，在线查询切新模型。每日job数据对账，将差异补平。 第三阶段其他场景思考一、b2b平台的订单分卖家和买家的时候，选择什么字段来分库分表呢？上面讨论的情况是，b2c平台。订单的卖家就一个，就是平台自己。b2b平台，上面支持开店，买家和卖家都要能够登陆看到自己的订单。先来看看，分表使用买家id分库分表和根据卖家id分库分表，两种办法出现的问题如果按买家id来分库分表。有卖家的商品，会有n个用户购买，他所有的订单，会分散到多个库多个表中去了，卖家查询自己的所有订单，跨库、跨表扫描，性能低下。 如果按卖家id分库分表。买家会在n个店铺下单。订单就会分散在多个库、多个表中。买家查询自己所有订单，同样要去所有的库、所有的表搜索，性能低下。 所以，无论是按照买家id切分订单表，还是按照卖家id切分订单表。两边都不讨好。 淘宝的做法是拆分买家库和卖家库，也就是两个库：买家库、卖家库。 买家库，按照用户的id来分库分表。卖家库，按照卖家的id来分库分表。 实际上是通过数据冗余解决的：一个订单，在买家库里面有，在卖家库里面也存储了一份。下订单的时候，要写两份数据。先把订单写入买家库里面去，然后通过消息中间件来同步订单数据到卖家库里面去。 买家库的订单a修改了后，要发异步消息，通知到卖家库去，更改状态。 思考二：那可以按订单号来分库分表吗?这样分库分表的话，用户有10个订单，订单不见得都在一个库、一个表里面。查询a用户的所有订单，就会变得麻烦了。尤其是要进行分页展示，分散在不同的表，甚至不同的数据库服务器，也比较耗费性能。 那么订单号里面，最好是要有分库分表信息。淘宝的是在订单号里面添加了卖家id末2位、买家id末2位。这样的好处是干嘛呢？直接定位到具体的库、具体的表去了？ 怎么根据这个呢。因为分库、分表的规则，买家库是按照卖家id末尾2位数分，卖家库是按照卖家id末尾两位分。 所以，只要从订单号里面拿到了这些数字信息，就知道在哪个库，哪个表了。 这种办法，与微信的红包订单号是类似的，末尾三位数包含了库信息、表信息。 按照这样，其实就没必要使用订单号来计算了？ 如果是按照用户id的后4位数取模分散订单数据。那么订单号的生成，可以在后面加上用户id的后4位数。 那么，虽然是按照用户id来对订单表分库分表的。其实可以直接根据订单号，知道这个订单在哪个库哪个表了。 如果是b2b系统，涉及到卖家和买家。那么可以把卖家和买家的id后面4位都加进去。不过是不是订单号太长了？ 思考三、按照订单的时间来分表如何?一月一张表。一年一张表。用户的所有订单，会分散在不同的库、不同的表中。 按照时间分，在切分订单数据的时候，业界用得比较少。 出现如下两个问题： 1、如果需要分页查询某个用户的所有订单数据，就会出现跨库、跨表查询。效率低。 可以做折中：限制只能查一个范围内的订单，比如一次只能查询，一年以内或者一个月以内的订单。 2、某个时间集中写入数据，出现瓶颈。如一个月一张表。这个月的订单量暴涨呢。那么写入新的订单数据都会操作这张表。造成性能低下。影响整个业务系统交易。 真正好的分表方案，尽量将写数据分散到多个表去，达到分流效果，系统的并发能力就提高了。 分库分表需要解决的问题事务问题方案一：使用分布式事务优点：交由数据库管理，简单有效缺点：性能代价高，特别是shard越来越多时方案二：由应用程序和数据库共同控制原理：将一个跨多个数据库的分布式事务分拆成多个仅处 于单个数据库上面的小事务，并通过应用程序来总控 各个小事务。优点：性能上有优势缺点：需要应用程序在事务控制上做灵活设计。如果使用 了spring的事务管理，改动起来会面临一定的困难。 跨节点Join的问题只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 跨节点的count,order by,group by以及聚合函数问题这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 数据迁移，容量规划，扩容等问题来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 事务ID问题跨分片的排序分页分库策略分库数量路由透明使用框架还是自主研发如何选择分片数DRDS 中的水平拆分有两个层次：分库和分表。每个 RDS 实例上默认会创建8个物理分库，每个物理分库上可以创建一个或多个物理分表。分表数通常也被称为分片数。 一般情况下，建议单个物理分表的容量不超过500万行数据。通常可以预估1到2年的数据增长量，用估算出的总数据量除以总的物理分库数，再除以建议的最大数据量500万，即可得出每个物理分库上需要创建的物理分表数： 物理分库上的物理分表数 = 向上取整(估算的总数据量 / (RDS 实例数 * 8) / 5,000,000) 如何选择拆分键拆分键即分库/分表字段，是在水平拆分过程中用于生成拆分规则的数据表字段。DRDS 根据拆分键的值将数据表水平拆分到每个 RDS 实例上的物理分库中。 数据表拆分的首要原则，就是要尽可能找到数据表中的数据在业务逻辑上的主体，并确定大部分（或核心的）数据库操作都是围绕这个主体的数据进行，然后可使用该主体对应的字段作为拆分键，进行分库分表。 业务逻辑上的主体，通常与业务的应用场景相关，下面的一些典型应用场景都有明确的业务逻辑主体，可用于拆分键： 面向用户的互联网应用，都是围绕用户维度来做各种操作，那么业务逻辑主体就是用户，可使用用户对应的字段作为拆分键； 侧重于卖家的电商应用，都是围绕卖家维度来进行各种操作，那么业务逻辑主体就是卖家，可使用卖家对应的字段作为拆分键； 游戏类的应用，是围绕玩家维度来做各种操作，那么业务逻辑主体就是玩家，可使用玩家对应的字段作为拆分键； 车联网方面的应用，则是基于车辆信息进行操作，那么业务逻辑主体就是车辆，可使用车辆对应的字段作为拆分键； 税务类的应用，主要是基于纳税人的信息来开展前台业务，那么业务逻辑主体就是纳税人，可使用纳税人对应的字段作为拆分键。以此类推，其它类型的应用场景，大多也能找到合适的业务逻辑主体作为拆分键的选择。 如果确实找不到合适的业务逻辑主体作为拆分键，那么可以考虑下面的方法来选择拆分键： 根据数据分布和访问的均衡度来考虑拆分键，尽量将数据表中的数据相对均匀地分布在不同的物理分库/分表中，适用于大量分析型查询的应用场景（查询并发度大部分能维持为1）； 按照数字（字符串）类型与时间类型字段相结合作为拆分键，进行分库和分表，适用于日志检索类的应用场景。 http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/pic/29659/cn_zh/1497859380824/DRDS_overview.png]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-nginx-statistics]]></title>
    <url>%2F2018%2F03%2F20%2F%E8%BF%90%E7%BB%B4%2Fstudy-nginx-statistics%2F</url>
    <content type="text"><![CDATA[根据nginx日志,查询访问最频繁的IP 1.根据访问IP统计UV1awk &apos;&#123;print $1&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |wc -l 2.统计访问URL统计PV1awk &apos;&#123;print $7&#125;&apos; /var/log/nginx/access.log|wc -l 3.查询访问最频繁的URL1awk &apos;&#123;print $7&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |sort -n -k 1 -r|more 4.查询访问最频繁的IP1awk &apos;&#123;print $1&#125;&apos; /var/log/nginx/access.log|sort | uniq -c |sort -n -k 1 -r|more]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-spring-concurrent]]></title>
    <url>%2F2018%2F03%2F19%2Fjava_spring%2Fstudy-spring-concurrent%2F</url>
    <content type="text"><![CDATA[Spring并发访问的线程安全性问题 只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。那么对于有状态的bean呢？Spring对一些（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态的bean采用ThreadLocal进行处理，让它们也成为线程安全的状态，因此有状态的Bean就可以在多线程中共享了。 如果用有状态的bean，也可以使用用prototype模式，每次在注入的时候就重新创建一个bean，在多线程中互不影响。 RequestContextHolder我们可以知道HttpServletRequest是在执行doService方法之前，也就是具体的业务逻辑前进行设置的，然后在执行完业务逻辑或者抛出异常时重置RequestContextHolder移除当前的HttpServletRequest。]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix-duplicate-key]]></title>
    <url>%2F2018%2F03%2F19%2Fegenie_bugfix%2Fbugfix-duplicate-key%2F</url>
    <content type="text"><![CDATA[一次bugfix的经历过 步骤异常信息1234567891011121314java.lang.IllegalStateException: Duplicate key at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133) ~[?:1.8.0_92] at java.util.HashMap.merge(HashMap.java:1253) ~[?:1.8.0_92] at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320) ~[?:1.8.0_92] at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169) ~[?:1.8.0_92] at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[?:1.8.0_92] at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ~[?:1.8.0_92] at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_92] at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ~[?:1.8.0_92] at 报错代码1Map&lt;Long, PmsDailyPurchase&gt; result = all.stream().collect(Collectors.toMap(PmsDailyPurchase::getSaleOrderId, Function.identity())); 对于ToMap方法没有做兼容,优点是方便问题的排查逻辑上讲应该是不会出现Duplicate key 的 主要逻辑先查询,如果不存在就插入 问题总结 dubbo默认容错机制:dubbo默认的2次重复调用(加起来3次) provider提供的接口没有幂等性 注解配置问题:项目中AvoidRepeatInvoke注解会对重复的调用进行处理 未调用过:真正执行,保存调用结果 调用过:直接返回调用结果 调用的凭证是60s超时的,对于响应大于60s的会自动过期,但实际上还在执行,导致问题的发生 大事务:最近上线读写分离,在整个大方的外部添加了事务注解,导致无法自动提交,当并发时,可能查不到其他事务,已经insert但是没有提交的内容(此处也有幻读的风险,但是使用阿里rds测试后,没有发生) 反思 修改项目级别的默认容错机制, retries=0 超时时间设定 统计监控微服务的方法级别超时时间,修改方法级别 批量接口,限制最大数量,否则调用时间会太长 事务的范围,需要仔细考虑,不能有过大的事务]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix类转换异常]]></title>
    <url>%2F2018%2F03%2F13%2Fegenie_bugfix%2Fbugfix-class-cast-exception%2F</url>
    <content type="text"><![CDATA[异常信息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181192018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204):eateNum=null,planCreateDate=null,version=null,cumulativeDefectNum=0,creator=null,createdAt=null,lastUpdater=null,lastUpdated=null,tenantId=null,isUsable=null]]2018-03-13 15:36:51.395 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 新建并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.399 [DubboServerHandler-10.47.124.90:20888-thread-100] WARN com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 存在重复锁[msi_fp_pms-1035108456]2018-03-13 15:36:51.401 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.404 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms1289336139]2018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor270.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70):eateNum=null,planCreateDate=null,version=null,cumulativeDefectNum=0,creator=null,createdAt=null,lastUpdater=null,lastUpdated=null,tenantId=null,isUsable=null]]2018-03-13 15:36:51.395 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 新建并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.399 [DubboServerHandler-10.47.124.90:20888-thread-100] WARN com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 存在重复锁[msi_fp_pms-1035108456]2018-03-13 15:36:51.401 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms-1035108456]2018-03-13 15:36:51.404 [DubboServerHandler-10.47.124.90:20888-thread-100] DEBUG com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice - 释放并发锁[msi_lock_pms1289336139]2018-03-13 15:36:51.409 [DubboServerHandler-10.47.124.90:20888-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.OutOfStockOrderService, method: generateOOSPurchaseOrder, exception: java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.ClassCastException: com.alibaba.fastjson.JSONObject cannot be cast to com.ejlerp.pms.domain.PmsPurchaseOrderDetail at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.writeBackDetailInfoToDailyDetails(DailyPurchaseServiceImpl.java:502) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl.generatePurchaseOrderAndDetails(DailyPurchaseServiceImpl.java:121) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$FastClassBySpringCGLIB$$3b1a314.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor270.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.DailyPurchaseServiceImpl$$EnhancerBySpringCGLIB$$41b3ba70.generatePurchaseOrderAndDetails(&lt;generated&gt;) at sun.reflect.GeneratedMethodAccessor283.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:333) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) at com.sun.proxy.$Proxy77.generatePurchaseOrderAndDetails(Unknown Source) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$ToPurchaseOrder.invoke(OutOfStockOrderServiceImpl.java:931) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.getToPurchaseOrderResult(OutOfStockOrderServiceImpl.java:250) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.generateOOSPurchaseOrder(OutOfStockOrderServiceImpl.java:215) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl.generateOOSPurchaseOrder(OutOfStockOrderServiceImpl.java:125) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$$FastClassBySpringCGLIB$$5a5ccc6a.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.oms.OutOfStockOrderServiceImpl$$EnhancerBySpringCGLIB$$c7b6bc32.generateOOSPurchaseOrder(&lt;generated&gt;) at com.alibaba.dubbo.common.bytecode.Wrapper56.invokeMethod(Wrapper56.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:70) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:132) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:113) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 排查步骤 1.排查最近的代码改动,没有相关的修改 2.在代码中加入debug信息,逐行查找变化 3.排查发现可能是aop的代码导致 1@AvoidRepeatInvoke(prefix = &quot;pms&quot;) 4.原先的逻辑 1234if (kvCacher.exist(footprint)) &#123; //判断redis是否存在调用过的足迹,如有,直接返回上一次的结果 LOGGER.warn(&quot;存在重复锁[&#123;&#125;]&quot;, footprint); return JSON.parseObject(kvCacher.get(fpVal), retClass); 5.fastjson中对于带泛型的反持久化应该用type的方式https://github.com/alibaba/fastjson/wiki/TypeReference 6.试验 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Reflect &#123; public List&lt;A&gt; hello() &#123; return null; &#125; public static void main(String[] args) throws NoSuchMethodException, NoSuchFieldException, IllegalAccessException &#123; Class&lt;Reflect&gt; reflectClass = Reflect.class; Method hello = reflectClass.getMethod(&quot;hello&quot;, null); Type genericReturnType = hello.getGenericReturnType(); System.out.println(genericReturnType); ArrayList&lt;A&gt; list = new ArrayList&lt;&gt;(); list.add(new A(&quot;AA1&quot;)); list.add(new A(&quot;AA2&quot;)); list.add(new A(&quot;AA3&quot;)); list.add(new A(&quot;AA4&quot;)); String json = JSON.toJSONString(list); //传统方式// List&lt;A&gt; as = JSON.parseObject(json, new TypeReference&lt;List&lt;A&gt;&gt;() &#123;&#125;.getType()); //反射方式 List&lt;A&gt; as = JSON.parseObject(json, new TypeReference4Reflect(genericReturnType).getType()); System.out.println(as); &#125; public static class A implements Serializable &#123; String name; public A(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; final StringBuffer sb = new StringBuffer(&quot;A&#123;&quot;); sb.append(&quot;name=&apos;&quot;).append(name).append(&apos;\&apos;&apos;); sb.append(&apos;&#125;&apos;); return sb.toString(); &#125; &#125; static public class TypeReference4Reflect&lt;T&gt; extends TypeReference&lt;T&gt; &#123; public TypeReference4Reflect(T t) throws IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException &#123; Class&lt;?&gt; cla = TypeReference.class; Field field = cla.getDeclaredField(&quot;type&quot;); field.setAccessible(true); field.set(this, t); &#125; &#125;&#125; 7.改造 参考:http://www.iteye.com/problems/80586 1234567891011 return JSON.parseObject(cacheResult, new TypeReference4Reflect(genericReturnType).getType());static public class TypeReference4Reflect&lt;T&gt; extends TypeReference&lt;T&gt; &#123; public TypeReference4Reflect(T t) throws IllegalArgumentException, IllegalAccessException, SecurityException, NoSuchFieldException &#123; Class&lt;?&gt; cla = TypeReference.class; Field field = cla.getDeclaredField(&quot;type&quot;); field.setAccessible(true); field.set(this, t); &#125;&#125; 反思 日志中可能会有细节,要注意观察 排查步骤,要全面,逐步深入,debug信息表示调用行数]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql锁超时处理]]></title>
    <url>%2F2018%2F03%2F10%2Fegenie_bugfix%2Fbugfix-mysql-lock-timeout%2F</url>
    <content type="text"><![CDATA[问题生成采购单逻辑,一直报错,锁等待超时手动删除这个记录也是报错,应该是锁了pms_daily_group的id为101958的记录 解决123select l.* from ( select &apos;Blocker&apos; role, p.id, p.user, left(p.host, locate(&apos;:&apos;, p.host) - 1) host, tx.trx_id, tx.trx_state, tx.trx_started, timestampdiff(second, tx.trx_started, now()) duration, lo.lock_mode, lo.lock_type, lo.lock_table, lo.lock_index, tx.trx_query, lw.requesting_thd_id Blockee_id, lw.requesting_trx_id Blockee_trx from information_schema.innodb_trx tx, information_schema.innodb_lock_waits lw, information_schema.innodb_locks lo, information_schema.processlist p where lw.blocking_trx_id = tx.trx_id and p.id = tx.trx_mysql_thread_id and lo.lock_id = lw.blocking_lock_id union select &apos;Blockee&apos; role, p.id, p.user, left(p.host, locate(&apos;:&apos;, p.host) - 1) host, tx.trx_id, tx.trx_state, tx.trx_started, timestampdiff(second, tx.trx_started, now()) duration, lo.lock_mode, lo.lock_type, lo.lock_table, lo.lock_index, tx.trx_query, null, null from information_schema.innodb_trx tx, information_schema.innodb_lock_waits lw, information_schema.innodb_locks lo, information_schema.processlist p where lw.requesting_trx_id = tx.trx_id and p.id = tx.trx_mysql_thread_id and lo.lock_id = lw.requested_lock_id) l order by role desc, trx_state desc;kill 184631781 发现了未提交的事务 roleiduserhosttrx_idtrx_statetrx_starteddurationlock_modelock_typelock_tablelock_indextrx_queryBlockee_idBlockee_trxBlocker184631781egeniekn10.26.109.1404994407160RUNNING2018-03-10 10:39:224996XRECORDegenie_kn.pms_daily_groupPRIMARYNULL1846004244996523486Blockee184600424egeniekn10.25.241.2034996523486LOCK WAIT2018-03-10 12:02:326XRECORDegenie_kn.pms_daily_groupPRIMARY/ ApplicationName=DataGrip 2017.3 / UPDATE egenie_kn.pms_daily_group t SET t.is_usable = 0 WHERE t.pms_daily_group_id = 101958NULLNULL]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-binary-heap]]></title>
    <url>%2F2018%2F03%2F05%2Fjava_data_structure%2Fstudy-binary-heap%2F</url>
    <content type="text"><![CDATA[什么是二叉堆简介 二叉堆故名思议是一种特殊的堆，二叉堆具有堆的性质（父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值），二叉堆又具有二叉树的性质（二叉堆是完全二叉树或者是近似完全二叉树）。当父节点的键值大于或等于（小于或等于）它的每一个子节点的键值时我们称它为最大堆（最小堆）。 二叉堆多数是以数组作为它们底层元素的存储，根节点在数组中的索引是1，存储在第n个位置的父节点它的子节点在数组中的存储位置为2n与2n+1。可以借用网上的一幅图来标示这种存储结构。其中数字表明节点在数组中的存储位置。 1234567 1 / \ 2 3 / \ / \ 4 5 6 7 / \ / \ 8 9 10 11 二叉堆支持的操作二叉堆通常支持以下操作：删除，插入节点,创建二叉堆。这些操作复杂对都是O(log2n) 二叉堆也可以支持这些操作：查找。O(n)复杂度。 二叉堆的特点二叉堆是专门为取出最大或最小节点而设计点数据结构，这种数据结构在查找一般元素方面性能和一般数组是没有多大区别的。二叉堆在取出最大或最最小值的性能表现是O(1)，取出操作完成之后，二叉堆需要一次整形操作，以便得到下一个最值，这个操作复杂度O(log2n)。这是一个相当理想的操作时间。但是二叉堆也有一个缺点，就是二叉堆对存储在内存中的数据操作太过分散，这导致了二叉堆在cpu高速缓存的利用与内存击中率上面表现不是很好，这也是一个二叉堆理想操作时间所需要付出的代价。 二叉堆的实现二叉堆的应用]]></content>
  </entry>
  <entry>
    <title><![CDATA[draft-blockchain]]></title>
    <url>%2F2018%2F03%2F04%2Fblockchain%2Fdraft-blockchain%2F</url>
    <content type="text"><![CDATA[区块链的本质分布式数据库 首先，区块链的主要作用是储存信息。任何需要保存的信息，都可以写入区块链，也可以从里面读取，所以它是数据库。 其次，任何人都可以架设服务器，加入区块链网络，成为一个节点。区块链的世界里面，没有中心节点，每个节点都是平等的，都保存着整个数据库。你可以向任何一个节点，写入/读取数据，因为所有节点最后都会同步，保证区块链一致。 区块链的最大特点分布式数据库并非新发明，市场上早有此类产品。但是，区块链有一个革命性特点。 区块链没有管理员，它是彻底无中心的。其他的数据库都有管理员，但是区块链没有。如果有人想对区块链添加审核，也实现不了，因为它的设计目标就是防止出现居于中心地位的管理当局。 正是因为无法管理，区块链才能做到无法被控制。否则一旦大公司大集团控制了管理权，他们就会控制整个平台，其他使用者就都必须听命于他们了。 但是，没有了管理员，人人都可以往里面写入数据，怎么才能保证数据是可信的呢？被坏人改了怎么办？请接着往下读，这就是区块链奇妙的地方。 区块区块链由一个个区块（block）组成。区块很像数据库的记录，每次写入数据，就是创建一个区块。 每个区块包含两个部分。 12区块头（Head）：记录当前区块的特征值区块体（Body）：实际数据 区块头包含了当前区块的多项特征值。 1234生成时间实际数据（即区块体）的哈希上一个区块的哈希... 这里，你需要理解什么叫哈希（hash），这是理解区块链必需的。 所谓”哈希”就是计算机可以对任意内容，计算出一个长度相同的特征值。区块链的 哈希长度是256位，这就是说，不管原始内容是什么，最后都会计算出一个256位的二进制数字。而且可以保证，只要原始内容不同，对应的哈希一定是不同的。 举例来说，字符串123的哈希是a8fdc205a9f19cc1c7507a60c4f01b13d11d7fd0（十六进制），转成二进制就是256位，而且只有123能得到这个哈希。（理论上，其他字符串也有可能得到这个哈希，但是概率极低，可以近似认为不可能发生。） 因此，就有两个重要的推论。 12推论1：每个区块的哈希都是不一样的，可以通过哈希标识区块。推论2：如果区块的内容变了，它的哈希一定会改变。]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-java-ReetrantLock]]></title>
    <url>%2F2018%2F02%2F28%2Fjava_lock%2Fstudy-java-ReetrantLock%2F</url>
    <content type="text"><![CDATA[Lock接口1234567Lock lock = new ReentrantLock();lock.lock();try&#123; //临界区......&#125;finally&#123; lock.unlock();&#125; 正如代码所显示(ReentrantLock是Lock的实现类，稍后分析)，当前线程使用lock()方法与unlock()对临界区进行包围，其他线程由于无法持有锁将无法进入临界区直到当前线程释放锁，注意unlock()操作必须在finally代码块中，这样可以确保即使临界区执行抛出异常，线程最终也能正常释放锁，Lock接口还提供了锁以下相关方法 1234567891011121314151617181920ublic interface Lock &#123; //加锁 void lock(); //解锁 void unlock(); //可中断获取锁，与lock()不同之处在于可响应中断操作，即在获 //取锁的过程中可中断，注意synchronized在获取锁时是不可中断的 void lockInterruptibly() throws InterruptedException; //尝试非阻塞获取锁，调用该方法后立即返回结果，如果能够获取则返回true，否则返回false boolean tryLock(); //根据传入的时间段获取锁，在指定时间内没有获取锁则返回false，如果在指定时间内当前线程未被中并断获取到锁则返回true boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //获取等待通知组件，该组件与当前锁绑定，当前线程只有获得了锁 //才能调用该组件的wait()方法，而调用后，当前线程将释放锁。 Condition newCondition(); 可见Lock对象锁还提供了synchronized所不具备的其他同步特性，如可中断锁的获取(synchronized在等待获取锁时是不可中的)，超时中断锁的获取，等待唤醒机制的多条件变量Condition等，这也使得Lock锁在使用上具有更大的灵活性。下面进一步分析Lock的实现类重入锁ReetrantLock。 重入锁ReetrantLock重入锁ReetrantLock，JDK 1.5新增的类，实现了Lock接口，作用与synchronized关键字相当，但比synchronized更加灵活。ReetrantLock本身也是一种支持重进入的锁，即该锁可以支持一个线程对资源重复加锁，同时也支持公平锁与非公平锁。所谓的公平与非公平指的是在请求先后顺序上，先对锁进行请求的就一定先获取到锁，那么这就是公平锁，反之，如果对于锁的获取并没有时间上的先后顺序，如后请求的线程可能先获取到锁，这就是非公平锁，一般而言非，非公平锁机制的效率往往会胜过公平锁的机制，但在某些场景下，可能更注重时间先后顺序，那么公平锁自然是很好的选择。需要注意的是ReetrantLock支持对同一线程重加锁，但是加锁多少次，就必须解锁多少次，这样才可以成功释放锁。下面看看ReetrantLock的简单使用案例： 123456789101112131415161718192021222324252627282930import java.util.concurrent.locks.ReentrantLock;public class ReenterLock implements Runnable&#123; public static ReentrantLock lock=new ReentrantLock(); public static int i=0; @Override public void run() &#123; for(int j=0;j&lt;10000000;j++)&#123; lock.lock(); //支持重入锁 lock.lock(); try&#123; i++; &#125;finally&#123; //执行两次解锁 lock.unlock(); lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ReenterLock tl=new ReenterLock(); Thread t1=new Thread(tl); Thread t2=new Thread(tl); t1.start();t2.start(); t1.join();t2.join(); //输出结果：20000000 System.out.println(i); &#125;&#125; 代码非常简单，我们使用两个线程同时操作临界资源i，执行自增操作，使用ReenterLock进行加锁，解决线程安全问题，这里进行了两次重复加锁，由于ReenterLock支持重入，因此这样是没有问题的，需要注意的是在finally代码块中，需执行两次解锁操作才能真正成功地让当前执行线程释放锁，从这里看ReenterLock的用法还是非常简单的，除了实现Lock接口的方法，ReenterLock其他方法说明如下 1234567891011121314151617181920212223242526272829303132333435//查询当前线程保持此锁的次数。int getHoldCount() //返回目前拥有此锁的线程，如果此锁不被任何线程拥有，则返回 null。 protected Thread getOwner(); //返回一个 collection，它包含可能正等待获取此锁的线程，其内部维持一个队列，这点稍后会分析。 protected Collection&lt;Thread&gt; getQueuedThreads(); //返回正等待获取此锁的线程估计数。 int getQueueLength();// 返回一个 collection，它包含可能正在等待与此锁相关给定条件的那些线程。protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition); //返回等待与此锁相关的给定条件的线程估计数。 int getWaitQueueLength(Condition condition);// 查询给定线程是否正在等待获取此锁。 boolean hasQueuedThread(Thread thread); //查询是否有些线程正在等待获取此锁。 boolean hasQueuedThreads();//查询是否有些线程正在等待与此锁有关的给定条件。 boolean hasWaiters(Condition condition); //如果此锁的公平设置为 true，则返回 true。 boolean isFair() //查询当前线程是否保持此锁。 boolean isHeldByCurrentThread() //查询此锁是否由任意线程保持。 boolean isLocked() 并发基础组件AQS与ReetrantLockAQS工作原理概要AbstractQueuedSynchronizer又称为队列同步器(后面简称AQS)，它是用来构建锁或其他同步组件的基础框架，内部通过一个int类型的成员变量state来控制同步状态,当state=0时，则说明没有任何线程占有共享资源的锁，当state=1时，则说明有线程目前正在使用共享变量，其他线程必须加入同步队列进行等待，AQS内部通过内部类Node构成FIFO的同步队列来完成线程获取锁的排队工作，同时利用内部类ConditionObject构建等待队列，当Condition调用wait()方法后，线程将会加入等待队列中，而当Condition调用signal()方法后，线程将从等待队列转移动同步队列中进行锁竞争。注意这里涉及到两种队列，一种的同步队列，当线程请求锁而等待的后将加入同步队列等待，而另一种则是等待队列(可有多个)，通过Condition调用await()方法释放锁后，将加入等待队列。关于Condition的等待队列我们后面再分析，这里我们先来看看AQS中的同步队列模型，如下 同步队列(竞争锁) 等待队列(await方法) 12345678910111213141516/** * AQS抽象类 */public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer&#123;//指向同步队列队头private transient volatile Node head;//指向同步的队尾private transient volatile Node tail;//同步状态，0代表锁未被占用，1代表锁已被占用private volatile int state;//省略其他代码......&#125; head和tail分别是AQS中的变量，其中head指向同步队列的头部，注意head为空结点，不存储信息。而tail则是同步队列的队尾，同步队列采用的是双向链表的结构这样可方便队列进行结点增删操作。state变量则是代表同步状态，执行当线程调用lock方法进行加锁后，如果此时state的值为0，则说明当前线程可以获取到锁(在本篇文章中，锁和同步状态代表同一个意思)，同时将state设置为1，表示获取成功。如果state已为1，也就是当前锁已被其他线程持有，那么当前执行线程将被封装为Node结点加入同步队列等待。其中Node结点是对每一个访问同步代码的线程的封装，从图中的Node的数据结构也可看出，其包含了需要同步的线程本身以及线程的状态，如是否被阻塞，是否等待唤醒，是否已经被取消等。每个Node结点内部关联其前继结点prev和后继结点next，这样可以方便线程释放锁后快速唤醒下一个在等待的线程，Node是AQS的内部类，其数据结构如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static final class Node &#123; //共享模式 static final Node SHARED = new Node(); //独占模式 static final Node EXCLUSIVE = null; //标识线程已处于结束状态 static final int CANCELLED = 1; //等待被唤醒状态 static final int SIGNAL = -1; //条件状态， static final int CONDITION = -2; //在共享模式中使用表示获得的同步状态会被传播 static final int PROPAGATE = -3; //等待状态,存在CANCELLED、SIGNAL、CONDITION、PROPAGATE 4种 volatile int waitStatus; //同步队列中前驱结点 volatile Node prev; //同步队列中后继结点 volatile Node next; //请求锁的线程 volatile Thread thread; //等待队列中的后继结点，这个与Condition有关，稍后会分析 Node nextWaiter; //判断是否为共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; //获取前驱结点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; //.....&#125; 其中SHARED和EXCLUSIVE常量分别代表共享模式和独占模式，所谓共享模式是一个锁允许多条线程同时操作，如信号量Semaphore采用的就是基于AQS的共享模式实现的，而独占模式则是同一个时间段只能有一个线程对共享资源进行操作，多余的请求线程需要排队等待，如ReentranLock。变量waitStatus则表示当前被封装成Node结点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE。 CANCELLED：值为1，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。 SIGNAL：值为-1，被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消，将会通知该后继结点的线程执行。说白了，就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。 CONDITION：值为-2，与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 0状态：值为0，代表初始化状态。 pre和next，分别指向当前Node结点的前驱结点和后继结点，thread变量存储的请求锁的线程。nextWaiter，与Condition相关，代表等待队列中的后继结点，关于这点这里暂不深入，后续会有更详细的分析，嗯，到此我们对Node结点的数据结构也就比较清晰了。总之呢，AQS作为基础组件，对于锁的实现存在两种不同的模式，即共享模式(如Semaphore)和独占模式(如ReetrantLock)，无论是共享模式还是独占模式的实现类，其内部都是基于AQS实现的，也都维持着一个虚拟的同步队列，当请求锁的线程超过现有模式的限制时，会将线程包装成Node结点并将线程当前必要的信息存储到node结点中，然后加入同步队列等会获取锁，而这系列操作都有AQS协助我们完成，这也是作为基础组件的原因，无论是Semaphore还是ReetrantLock，其内部绝大多数方法都是间接调用AQS完成的，下面是AQS整体类图结构 这里以ReentrantLock为例，简单讲解ReentrantLock与AQS的关系 AbstractOwnableSynchronizer：抽象类，定义了存储独占当前锁的线程和获取的方法 AbstractQueuedSynchronizer：抽象类，AQS框架核心类，其内部以虚拟队列的方式管理线程的锁获取与锁释放，其中获取锁(tryAcquire方法)和释放锁(tryRelease方法)并没有提供默认实现，需要子类重写这两个方法实现具体逻辑，目的是使开发人员可以自由定义获取锁以及释放锁的方式。 Node：AbstractQueuedSynchronizer 的内部类，用于构建虚拟队列(链表双向链表)，管理需要获取锁的线程。 Sync：抽象类，是ReentrantLock的内部类，继承自AbstractQueuedSynchronizer，实现了释放锁的操作(tryRelease()方法)，并提供了lock抽象方法，由其子类实现。 NonfairSync：是ReentrantLock的内部类，继承自Sync，非公平锁的实现类。 FairSync：是ReentrantLock的内部类，继承自Sync，公平锁的实现类。 ReentrantLock：实现了Lock接口的，其内部类有Sync、NonfairSync、FairSync，在创建时可以根据fair参数决定创建NonfairSync(默认非公平锁)还是FairSync。 ReentrantLock内部存在3个实现类，分别是Sync、NonfairSync、FairSync，其中Sync继承自AQS实现了解锁tryRelease()方法，而NonfairSync(非公平锁)、 FairSync(公平锁)则继承自Sync，实现了获取锁的tryAcquire()方法，ReentrantLock的所有方法调用都通过间接调用AQS和Sync类及其子类来完成的。从上述类图可以看出AQS是一个抽象类，但请注意其源码中并没一个抽象的方法，这是因为AQS只是作为一个基础组件，并不希望直接作为直接操作类对外输出，而更倾向于作为基础组件，为真正的实现类提供基础设施，如构建同步队列，控制同步状态等，事实上，从设计模式角度来看，AQS采用的模板模式的方式构建的，其内部除了提供并发操作核心方法以及同步队列操作外，还提供了一些模板方法让子类自己实现，如加锁操作以及解锁操作，为什么这么做？这是因为AQS作为基础组件，封装的是核心并发操作，但是实现上分为两种模式，即共享模式与独占模式，而这两种模式的加锁与解锁实现方式是不一样的，但AQS只关注内部公共方法实现并不关心外部不同模式的实现，所以提供了模板方法给子类使用，也就是说实现独占锁，如ReentrantLock需要自己实现tryAcquire()方法和tryRelease()方法，而实现共享模式的Semaphore，则需要实现tryAcquireShared()方法和tryReleaseShared()方法，这样做的好处是显而易见的，无论是共享模式还是独占模式，其基础的实现都是同一套组件(AQS)，只不过是加锁解锁的逻辑不同罢了，更重要的是如果我们需要自定义锁的话，也变得非常简单，只需要选择不同的模式实现不同的加锁和解锁的模板方法即可，AQS提供给独占模式和共享模式的模板方法如下 1234567891011121314151617181920212223242526272829//AQS中提供的主要模板方法，由子类实现。public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer&#123; //独占模式下获取锁的方法 protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125; //独占模式下解锁的方法 protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125; //共享模式下获取锁的方法 protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; //共享模式下解锁的方法 protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException(); &#125; //判断是否为持有独占锁 protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException(); &#125;&#125; 基于ReetrantLock分析AQS独占模式实现过程ReetrantLock中非公平锁AQS同步器的实现依赖于内部的同步队列(FIFO的双向链表对列)完成对同步状态(state)的管理，当前线程获取锁(同步状态)失败时，AQS会将该线程以及相关等待信息包装成一个节点(Node)并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会将头结点head中的线程唤醒，让其尝试获取同步状态。关于同步队列和Node结点，前面我们已进行了较为详细的分析，这里重点分析一下获取同步状态和释放同步状态以及如何加入队列的具体操作，这里从ReetrantLock入手分析AQS的具体实现，我们先以非公平锁为例进行分析。 12345678910111213//默认构造，创建非公平锁NonfairSyncpublic ReentrantLock() &#123; sync = new NonfairSync();&#125;//根据传入参数创建锁类型public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125;//加锁操作public void lock() &#123; sync.lock();&#125; 123456789101112131415/** * 非公平锁实现 */static final class NonfairSync extends Sync &#123; //加锁 final void lock() &#123; //执行CAS操作，获取同步状态 if (compareAndSetState(0, 1)) //成功则将独占锁线程设置为当前线程 setExclusiveOwnerThread(Thread.currentThread()); else //否则再次请求同步状态 acquire(1); &#125;&#125; 这里获取锁时，首先对同步状态执行CAS操作，尝试把state的状态从0设置为1，如果返回true则代表获取同步状态成功，也就是当前线程获取锁成，可操作临界资源，如果返回false，则表示已有线程持有该同步状态(其值为1)，获取锁失败，注意这里存在并发的情景，也就是可能同时存在多个线程设置state变量，因此是CAS操作保证了state变量操作的原子性。返回false后，执行 acquire(1)方法，该方法是AQS中的方法，它对中断不敏感，即使线程获取同步状态失败，进入同步队列，后续对该线程执行中断操作也不会从同步队列中移出，方法如下 123456public final void acquire(int arg) &#123; //再次尝试获取同步状态 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这里传入参数arg表示要获取同步状态后设置的值(即要设置state的值)，因为要获取锁，而status为0时是释放锁，1则是获取锁，所以这里一般传递参数为1，进入方法后首先会执行tryAcquire(arg)方法，在前面分析过该方法在AQS中并没有具体实现，而是交由子类实现，因此该方法是由ReetrantLock类内部实现的 12345678910111213141516171819202122232425262728293031323334353637//NonfairSync类static final class NonfairSync extends Sync &#123; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125;//Sync类abstract static class Sync extends AbstractQueuedSynchronizer &#123; //nonfairTryAcquire方法 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //判断同步状态是否为0，并尝试再次获取同步状态 if (c == 0) &#123; //执行CAS操作 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程已获取锁，属于重入锁，再次获取锁后将status值加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); //设置当前同步状态，当前只有一个线程持有锁，因为不会发生线程安全问题，可以直接执行 setState(nextc); setState(nextc); return true; &#125; return false; &#125; //省略其他代码&#125; 从代码执行流程可以看出，这里做了两件事，一是尝试再次获取同步状态，如果获取成功则将当前线程设置为OwnerThread，否则失败，二是判断当前线程current是否为OwnerThread，如果是则属于重入锁，state自增1，并获取锁成功，返回true，反之失败，返回false，也就是tryAcquire(arg)执行失败，返回false。需要注意的是nonfairTryAcquire(int acquires)内部使用的是CAS原子性操作设置state值，可以保证state的更改是线程安全的，因此只要任意一个线程调用nonfairTryAcquire(int acquires)方法并设置成功即可获取锁，不管该线程是新到来的还是已在同步队列的线程，毕竟这是非公平锁，并不保证同步队列中的线程一定比新到来线程请求(可能是head结点刚释放同步状态然后新到来的线程恰好获取到同步状态)先获取到锁，这点跟后面还会讲到的公平锁不同。ok~，接着看之前的方法acquire(int arg) 123456public final void acquire(int arg) &#123; //再次尝试获取同步状态 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 如果tryAcquire(arg)返回true，acquireQueued自然不会执行，这是最理想的，因为毕竟当前线程已获取到锁，如果tryAcquire(arg)返回false，则会执行addWaiter(Node.EXCLUSIVE)进行入队操作,由于ReentrantLock属于独占锁，因此结点类型为Node.EXCLUSIVE，下面看看addWaiter方法具体实现 12345678910111213141516171819private Node addWaiter(Node mode) &#123; //将请求同步状态失败的线程封装成结点 Node node = new Node(Thread.currentThread(), mode); Node pred = tail; //如果是第一个结点加入肯定为空，跳过。 //如果非第一个结点则直接执行CAS入队操作，尝试在尾部快速添加 if (pred != null) &#123; node.prev = pred; //使用CAS执行尾部结点替换，尝试在尾部快速添加 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //如果第一次加入或者CAS操作没有成功执行enq入队操作 enq(node); return node;&#125; 创建了一个Node.EXCLUSIVE类型Node结点用于封装线程及其相关信息，其中tail是AQS的成员变量，指向队尾(这点前面的我们分析过AQS维持的是一个双向的链表结构同步队列)，如果是第一个结点，则为tail肯定为空，那么将执行enq(node)操作，如果非第一个结点即tail指向不为null，直接尝试执行CAS操作加入队尾，如果CAS操作失败还是会执行enq(node)，继续看enq(node)： 123456789101112131415161718private Node enq(final Node node) &#123; //死循环 for (;;) &#123; Node t = tail; //如果队列为null，即没有头结点 if (t == null) &#123; // Must initialize //创建并使用CAS设置头结点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123;//队尾添加新结点 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 这个方法使用一个死循环进行CAS操作，可以解决多线程并发问题。这里做了两件事，一是如果还没有初始同步队列则创建新结点并使用compareAndSetHead设置头结点，tail也指向head，二是队列已存在，则将新结点node添加到队尾。注意这两个步骤都存在同一时间多个线程操作的可能，如果有一个线程修改head和tail成功，那么其他线程将继续循环，直到修改成功，这里使用CAS原子操作进行头结点设置和尾结点tail替换可以保证线程安全，从这里也可以看出head结点本身不存在任何数据，它只是作为一个牵头结点，而tail永远指向尾部结点(前提是队列不为null)。 添加到同步队列后，结点就会进入一个自旋过程，即每个结点都在观察时机待条件满足获取同步状态，然后从同步队列退出并结束自旋，回到之前的acquire()方法，自旋过程是在acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法中执行的，代码如下 12345678910111213141516171819202122232425262728final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; //自旋，死循环 for (;;) &#123; //获取前驱结点 final Node p = node.predecessor(); 当且仅当p为头结点才尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //将node设置为头结点 setHead(node); //清空原来头结点的引用便于GC p.next = null; // help GC failed = false; return interrupted; &#125; //如果前驱结点不是head，判断是否挂起线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) //最终都没能获取同步状态，结束该线程的请求 cancelAcquire(node); &#125;&#125; 当前线程在自旋(死循环)中获取同步状态，当且仅当前驱结点为头结点才尝试获取同步状态，这符合FIFO的规则，即先进先出，其次head是当前获取同步状态的线程结点，只有当head释放同步状态唤醒后继结点，后继结点才有可能获取到同步状态，因此后继结点在其前继结点为head时，才进行尝试获取同步状态，其他时刻将被挂起。进入if语句后调用setHead(node)方法，将当前线程结点设置为head 1234567//设置为头结点private void setHead(Node node) &#123; head = node; //清空结点数据 node.thread = null; node.prev = null;&#125; 设置为node结点被设置为head后，其thread信息和前驱结点将被清空，因为该线程已获取到同步状态(锁)，正在执行了，也就没有必要存储相关信息了，head只有保存指向后继结点的指针即可，便于head结点释放同步状态后唤醒后继结点，执行结果如下图 从图可知更新head结点的指向，将后继结点的线程唤醒并获取同步状态，调用setHead(node)将其替换为head结点，清除相关无用数据。当然如果前驱结点不是head，那么执行如下 12345678910111213141516171819202122232425262728293031323334//如果前驱结点不是head，判断是否挂起线程if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt()) interrupted = true;&#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取当前结点的等待状态 int ws = pred.waitStatus; //如果为等待唤醒（SIGNAL）状态则返回true if (ws == Node.SIGNAL) return true; //如果ws&gt;0 则说明是结束状态， //遍历前驱结点直到找到没有结束状态的结点 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果ws小于0又不是SIGNAL状态， //则将其设置为SIGNAL状态，代表该结点的线程正在等待唤醒。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;private final boolean parkAndCheckInterrupt() &#123; //将当前线程挂起 LockSupport.park(this); //获取线程中断状态,interrupted()是判断当前中断状态， //并非中断线程，因此可能true也可能false,并返回 return Thread.interrupted();&#125; shouldParkAfterFailedAcquire()方法的作用是判断当前结点的前驱结点是否为SIGNAL状态(即等待唤醒状态)，如果是则返回true。如果结点的ws为CANCELLED状态(值为1&gt;0),即结束状态，则说明该前驱结点已没有用应该从同步队列移除，执行while循环，直到寻找到非CANCELLED状态的结点。倘若前驱结点的ws值不为CANCELLED，也不为SIGNAL(当从Condition的条件等待队列转移到同步队列时，结点状态为CONDITION因此需要转换为SIGNAL)，那么将其转换为SIGNAL状态，等待被唤醒。若shouldParkAfterFailedAcquire()方法返回true，即前驱结点为SIGNAL状态同时又不是head结点，那么使用parkAndCheckInterrupt()方法挂起当前线程，称为WAITING状态，需要等待一个unpark()操作来唤醒它，到此ReetrantLock内部间接通过AQS的FIFO的同步队列就完成了lock()操作，这里我们总结成逻辑流程图 关于获取锁的操作，这里看看另外一种可中断的获取方式，即调用ReentrantLock类的lockInterruptibly()或者tryLock()方法，最终它们都间接调用到doAcquireInterruptibly() 1234567891011121314151617181920212223private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //直接抛异常，中断线程的同步状态请求 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 最大的不同是1234if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) //直接抛异常，中断线程的同步状态请求 throw new InterruptedException(); 检测到线程的中断操作后，直接抛出异常，从而中断线程的同步状态请求，移除同步队列，ok~,加锁流程到此。下面接着看unlock()操作 123456789101112131415161718192021222324252627282930313233343536//ReentrantLock类的unlockpublic void unlock() &#123; sync.release(1);&#125;//AQS类的release()方法public final boolean release(int arg) &#123; //尝试释放锁 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒后继结点的线程 unparkSuccessor(h); return true; &#125; return false;&#125;//ReentrantLock类中的内部类Sync实现的tryRelease(int releases) protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //判断状态是否为0，如果是则说明已释放同步状态 if (c == 0) &#123; free = true; //设置Owner为null setExclusiveOwnerThread(null); &#125; //设置更新同步状态 setState(c); return free; &#125; 释放同步状态的操作相对简单些，tryRelease(int releases)方法是ReentrantLock类中内部类自己实现的，因为AQS对于释放锁并没有提供具体实现，必须由子类自己实现。释放同步状态后会使用unparkSuccessor(h)唤醒后继结点的线程，这里看看unparkSuccessor(h) 12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒&#125; 从代码执行操作来看，这里主要作用是用unpark()唤醒同步队列中最前边未放弃线程(也就是状态为CANCELLED的线程结点s)。此时，回忆前面分析进入自旋的函数acquireQueued()，s结点的线程被唤醒后，会进入acquireQueued()函数的if (p == head &amp;&amp; tryAcquire(arg))的判断，如果p!=head也不会有影响，因为它会执行shouldParkAfterFailedAcquire()，由于s通过unparkSuccessor()操作后已是同步队列中最前边未放弃的线程结点，那么通过shouldParkAfterFailedAcquire()内部对结点状态的调整，s也必然会成为head的next结点，因此再次自旋时p==head就成立了，然后s把自己设置成head结点，表示自己已经获取到资源了，最终acquire()也返回了，这就是独占锁释放的过程。ok~，关于独占模式的加锁和释放锁的过程到这就分析完，总之呢，在AQS同步器中维护着一个同步队列，当线程获取同步状态失败后，将会被封装成Node结点，加入到同步队列中并进行自旋操作，当当前线程结点的前驱结点为head时，将尝试获取同步状态，获取成功将自己设置为head结点。在释放同步状态时，则通过调用子类(ReetrantLock中的Sync内部类)的tryRelease(int releases)方法释放同步状态，释放成功则唤醒后继结点的线程。 ReetrantLock中公平锁了解完ReetrantLock中非公平锁的实现后，我们再来看看公平锁。与非公平锁不同的是，在获取锁的时，公平锁的获取顺序是完全遵循时间上的FIFO规则，也就是说先请求的线程一定会先获取锁，后来的线程肯定需要排队，这点与前面我们分析非公平锁的nonfairTryAcquire(int acquires)方法实现有锁不同，下面是公平锁中tryAcquire()方法的实现 123456789101112131415161718192021//公平锁FairSync类中的实现protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //注意！！这里先判断同步队列是否存在结点 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 该方法与nonfairTryAcquire(int acquires)方法唯一的不同是在使用CAS设置尝试设置state值前，调用了hasQueuedPredecessors()判断同步队列是否存在结点，如果存在必须先执行完同步队列中结点的线程，当前线程进入等待状态。这就是非公平锁与公平锁最大的区别，即公平锁在线程请求到来时先会判断同步队列是否存在结点，如果存在先执行同步队列中的结点线程，当前线程将封装成node加入同步队列等待。而非公平锁呢，当线程请求到来时，不管同步队列是否存在线程结点，直接尝试获取同步状态，获取成功直接访问共享资源，但请注意在绝大多数情况下，非公平锁才是我们理想的选择，毕竟从效率上来说非公平锁总是胜于公平锁。 以上便是ReentrantLock的内部实现原理，这里我们简单进行小结，重入锁ReentrantLock，是一个基于AQS并发框架的并发控制类，其内部实现了3个类，分别是Sync、NoFairSync以及FairSync类，其中Sync继承自AQS，实现了释放锁的模板方法tryRelease(int)，而NoFairSync和FairSync都继承自Sync，实现各种获取锁的方法tryAcquire(int)。ReentrantLock的所有方法实现几乎都间接调用了这3个类，因此当我们在使用ReentrantLock时，大部分使用都是在间接调用AQS同步器中的方法，这就是ReentrantLock的内部实现原理,最后给出张类图结构 关于synchronized 与ReentrantLock在JDK 1.6之后，虚拟机对于synchronized关键字进行整体优化后，在性能上synchronized与ReentrantLock已没有明显差距，因此在使用选择上，需要根据场景而定，大部分情况下我们依然建议是synchronized关键字，原因之一是使用方便语义清晰，二是性能上虚拟机已为我们自动优化。而ReentrantLock提供了多样化的同步特性，如超时获取锁、可以被中断获取锁（synchronized的同步是不能中断的）、等待唤醒机制的多个条件变量(Condition)等，因此当我们确实需要使用到这些功能是，可以选择ReentrantLock 神奇的Condition关于Condition接口在并发编程中，每个Java对象都存在一组监视器方法，如wait()、notify()以及notifyAll()方法，通过这些方法，我们可以实现线程间通信与协作（也称为等待唤醒机制），如生产者-消费者模式，而且这些方法必须配合着synchronized关键字使用，关于这点，如果想有更深入的理解，可观看博主另外一篇博文【 深入理解Java并发之synchronized实现原理】，与synchronized的等待唤醒机制相比Condition具有更多的灵活性以及精确性，这是因为notify()在唤醒线程时是随机(同一个锁)，而Condition则可通过多个Condition实例对象建立更加精细的线程控制，也就带来了更多灵活性了，我们可以简单理解为以下两点 通过Condition能够精细的控制多线程的休眠与唤醒。 对于一个锁，我们可以为多个线程间建立不同的Condition。 Condition是一个接口类，其主要方法如下： 1234567891011121314151617181920212223242526272829303132public interface Condition &#123; /** * 使当前线程进入等待状态直到被通知(signal)或中断 * 当其他线程调用singal()或singalAll()方法时，该线程将被唤醒 * 当其他线程调用interrupt()方法中断当前线程 * await()相当于synchronized等待唤醒机制中的wait()方法 */ void await() throws InterruptedException; //当前线程进入等待状态，直到被唤醒，该方法不响应中断要求 void awaitUninterruptibly(); //调用该方法，当前线程进入等待状态，直到被唤醒或被中断或超时 //其中nanosTimeout指的等待超时时间，单位纳秒 long awaitNanos(long nanosTimeout) throws InterruptedException; //同awaitNanos，但可以指明时间单位 boolean await(long time, TimeUnit unit) throws InterruptedException; //调用该方法当前线程进入等待状态，直到被唤醒、中断或到达某个时 //间期限(deadline),如果没到指定时间就被唤醒，返回true，其他情况返回false boolean awaitUntil(Date deadline) throws InterruptedException; //唤醒一个等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notify()相同 void signal(); //唤醒所有等待在Condition上的线程，该线程从等待方法返回前必须 //获取与Condition相关联的锁，功能与notifyAll()相同 void signalAll();&#125; 关于Condition的实现类是AQS的内部类ConditionObject，关于这点我们稍后分析，这里先来看一个Condition的使用案例，即经典消费者生产者模式 Condition的使用案例-生产者消费者模式conditon使唤醒的更加精细,更目标化 这里我们通过一个卖烤鸭的案例来演示多生产多消费者的案例，该场景中存在两条生产线程t1和t2，用于生产烤鸭，也存在两条消费线程t3，t4用于消费烤鸭，4条线程同时执行，需要保证只有在生产线程产生烤鸭后，消费线程才能消费，否则只能等待，直到生产线程产生烤鸭后唤醒消费线程，注意烤鸭不能重复消费。ResourceByCondition类中定义product()和consume()两个方法，分别用于生产烤鸭和消费烤鸭，并且定义ReentrantLock锁，用于控制product()和consume()的并发，由于必须在烤鸭生成完成后消费线程才能消费烤鸭，否则只能等待，因此这里定义两组Condition对象，分别是producer_con和consumer_con，前者拥有控制生产线程，后者拥有控制消费线程，这里我们使用一个标志flag来控制是否有烤鸭，当flag为true时，代表烤鸭生成完毕，生产线程必须进入等待状态同时唤醒消费线程进行消费，消费线程消费完毕后将flag设置为false，代表烤鸭消费完成，进入等待状态，同时唤醒生产线程生产烤鸭，具体代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.zejian.concurrencys;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by zejian on 2017/7/22. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class ResourceByCondition &#123; private String name; private int count = 1; private boolean flag = false; //创建一个锁对象。 Lock lock = new ReentrantLock(); //通过已有的锁获取两组监视器，一组监视生产者，一组监视消费者。 Condition producer_con = lock.newCondition(); Condition consumer_con = lock.newCondition(); /** * 生产 * @param name */ public void product(String name) &#123; lock.lock(); try &#123; while(flag)&#123; try&#123;producer_con.await();&#125;catch(InterruptedException e)&#123;&#125; &#125; this.name = name + count; count++; System.out.println(Thread.currentThread().getName()+&quot;...生产者5.0...&quot;+this.name); flag = true; consumer_con.signal();//直接唤醒消费线程 &#125; finally &#123; lock.unlock(); &#125; &#125; /** * 消费 */ public void consume() &#123; lock.lock(); try &#123; while(!flag)&#123; try&#123;consumer_con.await();&#125;catch(InterruptedException e)&#123;&#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;...消费者.5.0.......&quot;+this.name);//消费烤鸭1 flag = false; producer_con.signal();//直接唤醒生产线程 &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;执行代码package com.zejian.concurrencys;/** * Created by zejian on 2017/7/22. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class Mutil_Producer_ConsumerByCondition &#123; public static void main(String[] args) &#123; ResourceByCondition r = new ResourceByCondition(); Mutil_Producer pro = new Mutil_Producer(r); Mutil_Consumer con = new Mutil_Consumer(r); //生产者线程 Thread t0 = new Thread(pro); Thread t1 = new Thread(pro); //消费者线程 Thread t2 = new Thread(con); Thread t3 = new Thread(con); //启动线程 t0.start(); t1.start(); t2.start(); t3.start(); &#125;&#125;/** * @decrition 生产者线程 */class Mutil_Producer implements Runnable &#123; private ResourceByCondition r; Mutil_Producer(ResourceByCondition r) &#123; this.r = r; &#125; public void run() &#123; while (true) &#123; r.product(&quot;北京烤鸭&quot;); &#125; &#125;&#125;/** * @decrition 消费者线程 */class Mutil_Consumer implements Runnable &#123; private ResourceByCondition r; Mutil_Consumer(ResourceByCondition r) &#123; this.r = r; &#125; public void run() &#123; while (true) &#123; r.consume(); &#125; &#125;&#125; 正如代码所示，我们通过两者Condition对象单独控制消费线程与生产消费，这样可以避免消费线程在唤醒线程时唤醒的还是消费线程，如果是通过synchronized的等待唤醒机制实现的话，就可能无法避免这种情况，毕竟同一个锁，对于synchronized关键字来说只能有一组等待唤醒队列，而不能像Condition一样，同一个锁拥有多个等待队列。synchronized的实现方案如下， 123456789101112131415161718192021222324252627282930313233343536public class KaoYaResource &#123; private String name; private int count = 1;//烤鸭的初始数量 private boolean flag = false;//判断是否有需要线程等待的标志 /** * 生产烤鸭 */ public synchronized void product(String name)&#123; while(flag)&#123; //此时有烤鸭，等待 try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; this.name=name+count;//设置烤鸭的名称 count++; System.out.println(Thread.currentThread().getName()+&quot;...生产者...&quot;+this.name); flag=true;//有烤鸭后改变标志 notifyAll();//通知消费线程可以消费了 &#125; /** * 消费烤鸭 */ public synchronized void consume()&#123; while(!flag)&#123;//如果没有烤鸭就等待 try&#123;this.wait();&#125;catch(InterruptedException e)&#123;&#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;...消费者........&quot;+this.name);//消费烤鸭1 flag = false; notifyAll();//通知生产者生产烤鸭 &#125;&#125; 如上代码，在调用notify()或者 notifyAll()方法时，由于等待队列中同时存在生产者线程和消费者线程，所以我们并不能保证被唤醒的到底是消费者线程还是生产者线程，而Codition则可以避免这种情况。嗯，了解完Condition的使用方式后，下面我们将进一步探讨Condition背后的实现机制 Condition的实现原理Condition的具体实现类是AQS的内部类ConditionObject，前面我们分析过AQS中存在两种队列，一种是同步队列，一种是等待队列，而等待队列就相对于Condition而言的。注意在使用Condition前必须获得锁，同时在Condition的等待队列上的结点与前面同步队列的结点是同一个类即Node，其结点的waitStatus的值为CONDITION。在实现类ConditionObject中有两个结点分别是firstWaiter和lastWaiter，firstWaiter代表等待队列第一个等待结点，lastWaiter代表等待队列最后一个等待结点，如下 1234567 public class ConditionObject implements Condition, java.io.Serializable &#123; //等待队列第一个等待结点 private transient Node firstWaiter; //等待队列最后一个等待结点 private transient Node lastWaiter; //省略其他代码.......&#125; 每个Condition都对应着一个等待队列，也就是说如果一个锁上创建了多个Condition对象，那么也就存在多个等待队列。等待队列是一个FIFO的队列，在队列中每一个节点都包含了一个线程的引用，而该线程就是Condition对象上等待的线程。当一个线程调用了await()相关的方法，那么该线程将会释放锁，并构建一个Node节点封装当前线程的相关信息加入到等待队列中进行等待，直到被唤醒、中断、超时才从队列中移出。Condition中的等待队列模型如下 正如图所示，Node节点的数据结构，在等待队列中使用的变量与同步队列是不同的，Condtion中等待队列的结点只有直接指向的后继结点并没有指明前驱结点，而且使用的变量是nextWaiter而不是next，这点我们在前面分析结点Node的数据结构时讲过。firstWaiter指向等待队列的头结点，lastWaiter指向等待队列的尾结点，等待队列中结点的状态只有两种即CANCELLED和CONDITION，前者表示线程已结束需要从等待队列中移除，后者表示条件结点等待被唤醒。再次强调每个Codition对象对于一个等待队列，也就是说AQS中只能存在一个同步队列，但可拥有多个等待队列。下面从代码层面看看被调用await()方法(其他await()实现原理类似)的线程是如何加入等待队列的，而又是如何从等待队列中被唤醒的 123456789101112131415161718192021222324252627public final void await() throws InterruptedException &#123; //判断线程是否被中断 if (Thread.interrupted()) throw new InterruptedException(); //创建新结点加入等待队列并返回 Node node = addConditionWaiter(); //释放当前线程锁即释放同步状态 int savedState = fullyRelease(node); int interruptMode = 0; //判断结点是否同步队列(SyncQueue)中,即是否被唤醒 while (!isOnSyncQueue(node)) &#123; //挂起线程 LockSupport.park(this); //判断是否被中断唤醒，如果是退出循环。 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //被唤醒后执行自旋操作争取获得锁，同时判断线程是否被中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // clean up if cancelled if (node.nextWaiter != null) //清理等待队列中不为CONDITION状态的结点 unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; 执行addConditionWaiter()添加到等待队列。 1234567891011121314151617private Node addConditionWaiter() &#123; Node t = lastWaiter; // 判断是否为结束状态的结点并移除 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //创建新结点状态为CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); //加入等待队列 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; await()方法主要做了3件事，一是调用addConditionWaiter()方法将当前线程封装成node结点加入等待队列，二是调用fullyRelease(node)方法释放同步状态并唤醒后继结点的线程。三是调用isOnSyncQueue(node)方法判断结点是否在同步队列中，注意是个while循环，如果同步队列中没有该结点就直接挂起该线程，需要明白的是如果线程被唤醒后就调用acquireQueued(node, savedState)执行自旋操作争取锁，即当前线程结点从等待队列转移到同步队列并开始努力获取锁。 接着看看唤醒操作singal()方法 123456789public final void signal() &#123; //判断是否持有独占锁，如果不是抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; //唤醒等待队列第一个结点的线程 if (first != null) doSignal(first);&#125; 这里signal()方法做了两件事，一是判断当前线程是否持有独占锁，没有就抛出异常，从这点也可以看出只有独占模式先采用等待队列，而共享模式下是没有等待队列的，也就没法使用Condition。二是唤醒等待队列的第一个结点，即执行doSignal(first) 123456789101112131415161718192021222324252627282930313233private void doSignal(Node first) &#123; do &#123; //移除条件等待队列中的第一个结点， //如果后继结点为null，那么说没有其他结点将尾结点也设置为null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; //如果被通知节点没有进入到同步队列并且条件等待队列还有不为空的节点，则继续循环通知后续结点 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125;//transferForSignal方法final boolean transferForSignal(Node node) &#123; //尝试设置唤醒结点的waitStatus为0，即初始化状态 //如果设置失败，说明当期结点node的waitStatus已不为 //CONDITION状态，那么只能是结束状态了，因此返回false //返回doSignal()方法中继续唤醒其他结点的线程，注意这里并 //不涉及并发问题，所以CAS操作失败只可能是预期值不为CONDITION， //而不是多线程设置导致预期值变化，毕竟操作该方法的线程是持有锁的。 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //加入同步队列并返回前驱结点p Node p = enq(node); int ws = p.waitStatus; //判断前驱结点是否为结束结点(CANCELLED=1)或者在设置 //前驱节点状态为Node.SIGNAL状态失败时，唤醒被通知节点代表的线程 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) //唤醒node结点的线程 LockSupport.unpark(node.thread); return true; &#125; 注释说得很明白了，这里我们简单整体说明一下，doSignal(first)方法中做了两件事，从条件等待队列移除被唤醒的节点，然后重新维护条件等待队列的firstWaiter和lastWaiter的指向。二是将从等待队列移除的结点加入同步队列(在transferForSignal()方法中完成的)，如果进入到同步队列失败并且条件等待队列还有不为空的节点，则继续循环唤醒后续其他结点的线程。到此整个signal()的唤醒过程就很清晰了，即signal()被调用后，先判断当前线程是否持有独占锁，如果有，那么唤醒当前Condition对象中等待队列的第一个结点的线程，并从等待队列中移除该结点，移动到同步队列中，如果加入同步队列失败，那么继续循环唤醒等待队列中的其他结点的线程，如果成功加入同步队列，那么如果其前驱结点是否已结束或者设置前驱节点状态为Node.SIGNAL状态失败，则通过LockSupport.unpark()唤醒被通知节点代表的线程，到此signal()任务完成，注意被唤醒后的线程，将从前面的await()方法中的while循环中退出，因为此时该线程的结点已在同步队列中，那么while (!isOnSyncQueue(node))将不在符合循环条件，进而调用AQS的acquireQueued()方法加入获取同步状态的竞争中，这就是等待唤醒机制的整个流程实现原理，流程如下图所示（注意无论是同步队列还是等待队列使用的Node数据结构都是同一个，不过是使用的内部变量不同罢了） 参考http://blog.csdn.net/javazejian/article/details/75043422]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-java-unsafe]]></title>
    <url>%2F2018%2F02%2F28%2Fjava_lock%2Fstudy-java-unsafe%2F</url>
    <content type="text"><![CDATA[无锁的概念在谈论无锁概念时，总会关联起乐观派与悲观派，对于乐观派而言，他们认为事情总会往好的方向发展，总是认为坏的情况发生的概率特别小，可以无所顾忌地做事，但对于悲观派而已，他们总会认为发展事态如果不及时控制，以后就无法挽回了，即使无法挽回的局面几乎不可能发生。这两种派系映射到并发编程中就如同加锁与无锁的策略，即加锁是一种悲观策略，无锁是一种乐观策略，因为对于加锁的并发程序来说，它们总是认为每次访问共享资源时总会发生冲突，因此必须对每一次数据操作实施加锁策略。而无锁则总是假设对共享资源的访问没有冲突，线程可以不停执行，无需加锁，无需等待，一旦发现冲突，无锁策略则采用一种称为CAS的技术来保证线程执行的安全性，这项CAS技术就是无锁策略实现的关键，下面我们进一步了解CAS技术的奇妙之处。 无锁的执行者-CASCASCAS的全称是Compare And Swap 即比较交换，其算法核心思想如下1执行函数：CAS(V,E,N) 如果V值等于E值，则将V的值设为N。若V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是CAS操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行CAS操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作 由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。同时从这点也可以看出，由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁。 CPU指令对CAS的支持或许我们可能会有这样的疑问，假设存在多个线程执行CAS操作并且CAS的步骤很多，有没有可能在判断V和E相同后，正要赋值时，切换了线程，更改了值。造成了数据不一致呢？答案是否定的，因为CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 鲜为人知的指针: Unsafe类Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，单从名称看来就可以知道该类是非安全的，毕竟Unsafe拥有着类似于C的指针操作，因此总是不应该首先使用Unsafe类，Java官方也不建议直接使用的Unsafe类，据说Oracle正在计划从Java 9中去掉Unsafe类，但我们还是很有必要了解该类，因为Java中CAS操作的执行依赖于Unsafe类的方法，注意Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的方法都直接调用操作系统底层资源执行相应任务，关于Unsafe类的主要功能点如下： 内存管理Unsafe类中存在直接操作内存的方法 123456789101112131415161718192021222324//分配内存指定大小的内存public native long allocateMemory(long bytes);//根据给定的内存地址address设置重新分配指定大小的内存public native long reallocateMemory(long address, long bytes);//用于释放allocateMemory和reallocateMemory申请的内存public native void freeMemory(long address);//将指定对象的给定offset偏移量内存块中的所有字节设置为固定值public native void setMemory(Object o, long offset, long bytes, byte value);//设置给定内存地址的值public native void putAddress(long address, long x);//获取指定内存地址的值public native long getAddress(long address);//设置给定内存地址的long值public native void putLong(long address, long x);//获取指定内存地址的long值public native long getLong(long address);//设置或获取指定内存的byte值public native byte getByte(long address);public native void putByte(long address, byte x);//其他基本数据类型(long,char,float,double,short等)的操作与putByte及getByte相同//操作系统的内存页大小public native int pageSize(); 提供实例对象新途径12//传入一个对象的class并创建该实例对象，但不会调用构造方法public native Object allocateInstance(Class cls) throws InstantiationException; 类和实例对象以及变量的操作1234567891011121314151617181920212223242526272829/获取字段f在实例对象中的偏移量public native long objectFieldOffset(Field f);//静态属性的偏移量，用于在对应的Class对象中读写静态属性public native long staticFieldOffset(Field f);//返回值就是f.getDeclaringClass()public native Object staticFieldBase(Field f);//获得给定对象偏移量上的int值，所谓的偏移量可以简单理解为指针指向该变量的内存地址，//通过偏移量便可得到该对象的变量，进行各种操作public native int getInt(Object o, long offset);//设置给定对象上偏移量的int值public native void putInt(Object o, long offset, int x);//获得给定对象偏移量上的引用类型的值public native Object getObject(Object o, long offset);//设置给定对象偏移量上的引用类型的值public native void putObject(Object o, long offset, Object x);//其他基本数据类型(long,char,byte,float,double)的操作与getInthe及putInt相同//设置给定对象的int值，使用volatile语义，即设置后立马更新到内存对其他线程可见public native void putIntVolatile(Object o, long offset, int x);//获得给定对象的指定偏移量offset的int值，使用volatile语义，总能获取到最新的int值。public native int getIntVolatile(Object o, long offset);//其他基本数据类型(long,char,byte,float,double)的操作与putIntVolatile及getIntVolatile相同，引用类型putObjectVolatile也一样。//与putIntVolatile一样，但要求被操作字段必须有volatile修饰public native void putOrderedInt(Object o,long offset,int x); 下面通过一个简单的Demo来演示上述的一些方法以便加深对Unsafe类的理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class UnSafeDemo &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException &#123; // 通过反射得到theUnsafe对应的Field对象 Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;); // 设置该Field为可访问 field.setAccessible(true); // 通过Field得到该Field对应的具体对象，传入null是因为该Field为static的 Unsafe unsafe = (Unsafe) field.get(null); System.out.println(unsafe); //通过allocateInstance直接创建对象 User user = (User) unsafe.allocateInstance(User.class); Class userClass = user.getClass(); Field name = userClass.getDeclaredField(&quot;name&quot;); Field age = userClass.getDeclaredField(&quot;age&quot;); Field id = userClass.getDeclaredField(&quot;id&quot;); //获取实例变量name和age在对象内存中的偏移量并设置值 unsafe.putInt(user,unsafe.objectFieldOffset(age),18); unsafe.putObject(user,unsafe.objectFieldOffset(name),&quot;android TV&quot;); // 这里返回 User.class， Object staticBase = unsafe.staticFieldBase(id); System.out.println(&quot;staticBase:&quot;+staticBase); //获取静态变量id的偏移量staticOffset long staticOffset = unsafe.staticFieldOffset(userClass.getDeclaredField(&quot;id&quot;)); //获取静态变量的值 System.out.println(&quot;设置前的ID:&quot;+unsafe.getObject(staticBase,staticOffset)); //设置值 unsafe.putObject(staticBase,staticOffset,&quot;SSSSSSSS&quot;); //获取静态变量的值 System.out.println(&quot;设置前的ID:&quot;+unsafe.getObject(staticBase,staticOffset)); //输出USER System.out.println(&quot;输出USER:&quot;+user.toString()); long data = 1000; byte size = 1;//单位字节 //调用allocateMemory分配内存,并获取内存地址memoryAddress long memoryAddress = unsafe.allocateMemory(size); //直接往内存写入数据 unsafe.putAddress(memoryAddress, data); //获取指定内存地址的数据 long addrData=unsafe.getAddress(memoryAddress); System.out.println(&quot;addrData:&quot;+addrData); /** * 输出结果: sun.misc.Unsafe@6f94fa3e staticBase:class geym.conc.ch4.atomic.User 设置前的ID:USER_ID 设置前的ID:SSSSSSSS 输出USER:User&#123;name=&apos;android TV&apos;, age=18&apos;, id=SSSSSSSS&apos;&#125; addrData:1000 */ &#125;&#125;class User&#123; public User()&#123; System.out.println(&quot;user 构造方法被调用&quot;); &#125; private String name; private int age; private static String id=&quot;USER_ID&quot;; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, age=&quot; + age +&apos;\&apos;&apos; + &quot;, id=&quot; + id +&apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125;public static Unsafe getUnsafe() &#123; Class cc = sun.reflect.Reflection.getCallerClass(2); if (cc.getClassLoader() != null) throw new SecurityException(&quot;Unsafe&quot;); return theUnsafe; &#125; 虽然在Unsafe类中存在getUnsafe()方法，但该方法只提供给高级的Bootstrap类加载器使用，普通用户调用将抛出异常，所以我们在Demo中使用了反射技术获取了Unsafe实例对象并进行相关操作。 数组操作1234//获取数组第一个元素的偏移地址public native int arrayBaseOffset(Class arrayClass);//数组中一个元素占据的内存空间,arrayBaseOffset与arrayIndexScale配合使用，可定位数组中每个元素在内存中的位置public native int arrayIndexScale(Class arrayClass); CAS 操作相关CAS是一些CPU直接支持的指令，也就是我们前面分析的无锁操作，在Java中无锁操作CAS基于以下3个方法实现，在稍后讲解Atomic系列内部方法是基于下述方法的实现的。1234567//第一个参数o为给定对象，offset为对象内存的偏移量，通过这个偏移量迅速定位字段并设置或获取该字段的值，//expected表示期望值，x表示要设置的值，下面3个方法都通过CAS原子指令执行操作。public final native boolean compareAndSwapObject(Object o, long offset,Object expected, Object x); public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x);public final native boolean compareAndSwapLong(Object o, long offset,long expected,long x); 这里还需介绍Unsafe类中JDK 1.8新增的几个方法，它们的实现是基于上述的CAS方法，如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//1.8新增，给定对象o，根据获取内存偏移量指向的字段，将其增加delta， //这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值 public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; //获取内存中最新值 v = getIntVolatile(o, offset); //通过CAS操作 &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &#125;//1.8新增，方法作用同上，只不过这里操作的long类型数据 public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v; &#125; //1.8新增，给定对象o，根据获取内存偏移量对于字段，将其 设置为新值newValue， //这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值 public final int getAndSetInt(Object o, long offset, int newValue) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, newValue)); return v; &#125;// 1.8新增，同上，操作的是long类型 public final long getAndSetLong(Object o, long offset, long newValue) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, newValue)); return v; &#125; //1.8新增，同上，操作的是引用类型数据 public final Object getAndSetObject(Object o, long offset, Object newValue) &#123; Object v; do &#123; v = getObjectVolatile(o, offset); &#125; while (!compareAndSwapObject(o, offset, v, newValue)); return v; &#125; 挂起与恢复将一个线程进行挂起是通过park方法实现的，调用 park后，线程将一直阻塞直到超时或者中断等条件出现。unpark可以终止一个挂起的线程，使其恢复正常。Java对线程的挂起操作被封装在 LockSupport类中，LockSupport类中有各种版本pack方法，其底层实现最终还是使用Unsafe.park()方法和Unsafe.unpark()方法 12345//线程调用该方法，线程将一直阻塞直到超时，或者是中断条件出现。 public native void park(boolean isAbsolute, long time); //终止挂起的线程，恢复正常.java.util.concurrent包中挂起操作都是在LockSupport类实现的，其底层正是使用这两个方法， public native void unpark(Object thread); 内存屏障这里主要包括了loadFence、storeFence、fullFence等方法，这些方法是在Java 8新引入的，用于定义内存屏障，避免代码重排序 123456//在该方法之前的所有读操作，一定在load屏障之前执行完成public native void loadFence();//在该方法之前的所有写操作，一定在store屏障之前执行完成public native void storeFence();//在该方法之前的所有读写操作，一定在full屏障之前执行完成，这个内存屏障相当于上面两个的合体功能public native void fullFence(); 其他操作12345678910111213141516171819202122//获取持有锁，已不建议使用@Deprecatedpublic native void monitorEnter(Object var1);//释放锁，已不建议使用@Deprecatedpublic native void monitorExit(Object var1);//尝试获取锁，已不建议使用@Deprecatedpublic native boolean tryMonitorEnter(Object var1);//获取本机内存的页数，这个值永远都是2的幂次方 public native int pageSize(); //告诉虚拟机定义了一个没有安全检查的类，默认情况下这个类加载器和保护域来着调用者类 public native Class defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain); //加载一个匿名类public native Class defineAnonymousClass(Class hostClass, byte[] data, Object[] cpPatches);//判断是否需要加载一个类public native boolean shouldBeInitialized(Class&lt;?&gt; c);//确保类一定被加载 public native void ensureClassInitialized(Class&lt;?&gt; c) 并发包中的原子操作类(Atomic系列)通过前面的分析我们已基本理解了无锁CAS的原理并对Java中的指针类Unsafe类有了比较全面的认识，下面进一步分析CAS在Java中的应用，即并发包中的原子操作类(Atomic系列)，从JDK 1.5开始提供了java.util.concurrent.atomic包，在该包中提供了许多基于CAS实现的原子操作类，用法方便，性能高效，主要分以下4种类型。 原子更新基本类型原子更新基本类型主要包括3个类： AtomicBoolean：原子更新布尔类型AtomicInteger：原子更新整型AtomicLong：原子更新长整型这3个类的实现原理和使用方式几乎是一样的，这里我们以AtomicInteger为例进行分析，AtomicInteger主要是针对int类型的数据执行原子操作，它提供了原子自增方法、原子自减方法以及原子赋值方法等，鉴于AtomicInteger的源码不多，我们直接看源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // 获取指针类Unsafe private static final Unsafe unsafe = Unsafe.getUnsafe(); //下述变量value在AtomicInteger实例对象内的内存偏移量 private static final long valueOffset; static &#123; try &#123; //通过unsafe类的objectFieldOffset()方法，获取value变量在对象内存中的偏移 //通过该偏移量valueOffset，unsafe类的内部方法可以获取到变量value对其进行取值或赋值操作 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; //当前AtomicInteger封装的int变量value private volatile int value; public AtomicInteger(int initialValue) &#123; value = initialValue; &#125; public AtomicInteger() &#123; &#125; //获取当前最新值， public final int get() &#123; return value; &#125; //设置当前值，具备volatile效果，方法用final修饰是为了更进一步的保证线程安全。 public final void set(int newValue) &#123; value = newValue; &#125; //最终会设置成newValue，使用该方法后可能导致其他线程在之后的一小段时间内可以获取到旧值，有点类似于延迟加载 public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; //设置新值并获取旧值，底层调用的是CAS操作即unsafe.compareAndSwapInt()方法 public final int getAndSet(int newValue) &#123; return unsafe.getAndSetInt(this, valueOffset, newValue); &#125; //如果当前值为expect，则设置为update(当前值指的是value变量) public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; //当前值加1返回旧值，底层CAS操作 public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125; //当前值减1，返回旧值，底层CAS操作 public final int getAndDecrement() &#123; return unsafe.getAndAddInt(this, valueOffset, -1); &#125; //当前值增加delta，返回旧值，底层CAS操作 public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta); &#125; //当前值加1，返回新值，底层CAS操作 public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; //当前值减1，返回新值，底层CAS操作 public final int decrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, -1) - 1; &#125; //当前值增加delta，返回新值，底层CAS操作 public final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta; &#125; //省略一些不常用的方法....&#125; 通过上述的分析，可以发现AtomicInteger原子类的内部几乎是基于前面分析过Unsafe类中的CAS相关操作的方法实现的，这也同时证明AtomicInteger是基于无锁实现的，这里重点分析自增操作实现过程，其他方法自增实现原理一样。 1234//当前值加1，返回新值，底层CAS操作public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125; 我们发现AtomicInteger类中所有自增或自减的方法都间接调用Unsafe类中的getAndAddInt()方法实现了CAS操作，从而保证了线程安全，关于getAndAddInt其实前面已分析过，它是Unsafe类中1.8新增的方法，源码如下 12345678//Unsafe类中的getAndAddInt方法public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &#125; 可看出getAndAddInt通过一个while循环不断的重试更新要设置的值，直到成功为止，调用的是Unsafe类中的compareAndSwapInt方法，是一个CAS操作方法。这里需要注意的是，上述源码分析是基于JDK1.8的，如果是1.8之前的方法，AtomicInteger源码实现有所不同，是基于for死循环的，如下 12345678910//JDK 1.7的源码，由for的死循环实现，并且直接在AtomicInteger实现该方法，//JDK1.8后，该方法实现已移动到Unsafe类中，直接调用getAndAddInt方法即可public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125;&#125; 原子更新引用原子更新引用类型可以同时更新引用类型，这里主要分析一下AtomicReference原子类，即原子更新引用类型。先看看其使用方式，如下 1234567891011121314151617181920212223242526272829303132333435public class AtomicReferenceDemo2 &#123; public static AtomicReference&lt;User&gt; atomicUserRef = new AtomicReference&lt;User&gt;(); public static void main(String[] args) &#123; User user = new User(&quot;zejian&quot;, 18); atomicUserRef.set(user); User updateUser = new User(&quot;Shine&quot;, 25); atomicUserRef.compareAndSet(user, updateUser); //执行结果:User&#123;name=&apos;Shine&apos;, age=25&#125; System.out.println(atomicUserRef.get().toString()); &#125; static class User &#123; public String name; private int age; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, age=&quot; + age + &apos;&#125;&apos;; &#125; &#125;&#125; 那么AtomicReference原子类内部是如何实现CAS操作的呢？ 12345678910111213141516171819202122232425262728293031323334public class AtomicReference&lt;V&gt; implements java.io.Serializable &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; //内部变量value，Unsafe类通过valueOffset内存偏移量即可获取该变量 private volatile V value;//CAS方法，间接调用unsafe.compareAndSwapObject(),它是一个//实现了CAS操作的native方法public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update);&#125;//设置并获取旧值public final V getAndSet(V newValue) &#123; return (V)unsafe.getAndSetObject(this, valueOffset, newValue); &#125; //省略其他代码......&#125;//Unsafe类中的getAndSetObject方法，实际调用还是CAS操作public final Object getAndSetObject(Object o, long offset, Object newValue) &#123; Object v; do &#123; v = getObjectVolatile(o, offset); &#125; while (!compareAndSwapObject(o, offset, v, newValue)); return v; &#125; 原子更新数组原子更新数组指的是通过原子的方式更新数组里的某个元素，主要有以下3个类 AtomicIntegerArray：原子更新整数数组里的元素AtomicLongArray：原子更新长整数数组里的元素AtomicReferenceArray：原子更新引用类型数组里的元素这里以AtomicIntegerArray为例进行分析，其余两个使用方式和实现原理基本一样，简单案例如下， 12345678910111213141516171819202122232425public class AtomicIntegerArrayDemo &#123; static AtomicIntegerArray arr = new AtomicIntegerArray(10); public static class AddThread implements Runnable&#123; public void run()&#123; for(int k=0;k&lt;10000;k++) //执行数组中元素自增操作,参数为index,即数组下标 arr.getAndIncrement(k%arr.length()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread[] ts=new Thread[10]; //创建10条线程 for(int k=0;k&lt;10;k++)&#123; ts[k]=new Thread(new AddThread()); &#125; //启动10条线程 for(int k=0;k&lt;10;k++)&#123;ts[k].start();&#125; for(int k=0;k&lt;10;k++)&#123;ts[k].join();&#125; //执行结果 //[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000] System.out.println(arr); &#125;&#125; 启动10条线程对数组中的元素进行自增操作，执行结果符合预期。使用方式比较简单，接着看看AtomicIntegerArray内部是如何实现，先看看部分源码 1234567891011121314151617181920212223242526272829303132public class AtomicIntegerArray implements java.io.Serializable &#123; //获取unsafe类的实例对象 private static final Unsafe unsafe = Unsafe.getUnsafe(); //获取数组的第一个元素内存起始地址 private static final int base = unsafe.arrayBaseOffset(int[].class); private static final int shift; //内部数组 private final int[] array; static &#123; //获取数组中一个元素占据的内存空间 int scale = unsafe.arrayIndexScale(int[].class); //判断是否为2的次幂，一般为2的次幂否则抛异常 if ((scale &amp; (scale - 1)) != 0) throw new Error(&quot;data type scale not a power of two&quot;); // shift = 31 - Integer.numberOfLeadingZeros(scale); &#125; private long checkedByteOffset(int i) &#123; if (i &lt; 0 || i &gt;= array.length) throw new IndexOutOfBoundsException(&quot;index &quot; + i); return byteOffset(i); &#125; //计算数组中每个元素的的内存地址 private static long byteOffset(int i) &#123; return ((long) i &lt;&lt; shift) + base; &#125; //省略其他代码......&#125; 通过前面对Unsafe类的分析，我们知道arrayBaseOffset方法可以获取数组的第一个元素起始地址，而arrayIndexScale方法可以获取每个数组元素占用的内存空间，由于这里是Int类型，而Java中一个int类型占用4个字节，也就是scale的值为4，那么如何根据数组下标值计算每个元素的内存地址呢？显然应该是每个数组元素的内存地址=起始地址+元素下标 * 每个元素所占用的内存空间 原子更新属性如果我们只需要某个类里的某个字段，也就是说让普通的变量也享受原子操作，可以使用原子更新字段类，如在某些时候由于项目前期考虑不周全，项目需求又发生变化，使得某个类中的变量需要执行多线程操作，由于该变量多处使用，改动起来比较麻烦，而且原来使用的地方无需使用线程安全，只要求新场景需要使用时，可以借助原子更新器处理这种场景，Atomic并发包提供了以下三个类： AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。AtomicLongFieldUpdater：原子更新长整型字段的更新器。AtomicReferenceFieldUpdater：原子更新引用类型里的字段。请注意原子更新器的使用存在比较苛刻的条件如下 操作的字段不能是static类型。 操作的字段不能是final类型的，因为final根本没法修改。 字段必须是volatile修饰的，也就是数据本身是读一致的。 属性必须对当前的Updater所在的区域是可见的，如果不是当前类内部进行原子更新器操作不能使用private，protected子类操作父类时修饰符必须是protect权限及以上，如果在同一个package下则必须是default权限及以上，也就是说无论何时都应该保证操作类与被操作类间的可见性。 下面看看AtomicIntegerFieldUpdater和AtomicReferenceFieldUpdater的简单使用方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class AtomicIntegerFieldUpdaterDemo &#123; public static class Candidate&#123; int id; volatile int score; &#125; public static class Game&#123; int id; volatile String name; public Game(int id, String name) &#123; this.id = id; this.name = name; &#125; @Override public String toString() &#123; return &quot;Game&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125; &#125; static AtomicIntegerFieldUpdater&lt;Candidate&gt; atIntegerUpdater = AtomicIntegerFieldUpdater.newUpdater(Candidate.class, &quot;score&quot;); static AtomicReferenceFieldUpdater&lt;Game,String&gt; atRefUpdate = AtomicReferenceFieldUpdater.newUpdater(Game.class,String.class,&quot;name&quot;); //用于验证分数是否正确 public static AtomicInteger allScore=new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &#123; final Candidate stu=new Candidate(); Thread[] t=new Thread[10000]; //开启10000个线程 for(int i = 0 ; i &lt; 10000 ; i++) &#123; t[i]=new Thread() &#123; public void run() &#123; if(Math.random()&gt;0.4)&#123; atIntegerUpdater.incrementAndGet(stu); allScore.incrementAndGet(); &#125; &#125; &#125;; t[i].start(); &#125; for(int i = 0 ; i &lt; 10000 ; i++) &#123; t[i].join();&#125; System.out.println(&quot;最终分数score=&quot;+stu.score); System.out.println(&quot;校验分数allScore=&quot;+allScore); //AtomicReferenceFieldUpdater 简单的使用 Game game = new Game(2,&quot;zh&quot;); atRefUpdate.compareAndSet(game,game.name,&quot;JAVA-HHH&quot;); System.out.println(game.toString()); /** * 输出结果: * 最终分数score=5976 校验分数allScore=5976 Game&#123;id=2, name=&apos;JAVA-HHH&apos;&#125; */ &#125;&#125; 我们使用AtomicIntegerFieldUpdater更新候选人(Candidate)的分数score，开启了10000条线程投票，当随机值大于0.4时算一票，分数自增一次，其中allScore用于验证分数是否正确(其实用于验证AtomicIntegerFieldUpdater更新的字段是否线程安全)，当allScore与score相同时，则说明投票结果无误，也代表AtomicIntegerFieldUpdater能正确更新字段score的值，是线程安全的。对于AtomicReferenceFieldUpdater，我们在代码中简单演示了其使用方式，注意在AtomicReferenceFieldUpdater注明泛型时需要两个泛型参数，一个是修改的类类型，一个修改字段的类型。至于AtomicLongFieldUpdater则与AtomicIntegerFieldUpdater类似，不再介绍。接着简单了解一下AtomicIntegerFieldUpdater的实现原理，实际就是反射和Unsafe类结合，AtomicIntegerFieldUpdater是个抽象类，实际实现类为AtomicIntegerFieldUpdaterImpl 123456789public abstract class AtomicIntegerFieldUpdater&lt;T&gt; &#123; public static &lt;U&gt; AtomicIntegerFieldUpdater&lt;U&gt; newUpdater(Class&lt;U&gt; tclass, String fieldName) &#123; //实际实现类AtomicIntegerFieldUpdaterImpl return new AtomicIntegerFieldUpdaterImpl&lt;U&gt; (tclass, fieldName, Reflection.getCallerClass()); &#125; &#125; 看看AtomicIntegerFieldUpdaterImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private static class AtomicIntegerFieldUpdaterImpl&lt;T&gt; extends AtomicIntegerFieldUpdater&lt;T&gt; &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private final long offset;//内存偏移量 private final Class&lt;T&gt; tclass; private final Class&lt;?&gt; cclass; AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) &#123; final Field field;//要修改的字段 final int modifiers;//字段修饰符 try &#123; field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() &#123; public Field run() throws NoSuchFieldException &#123; return tclass.getDeclaredField(fieldName);//反射获取字段对象 &#125; &#125;); //获取字段修饰符 modifiers = field.getModifiers(); //对字段的访问权限进行检查,不在访问范围内抛异常 sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) &#123; sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); &#125; &#125; catch (PrivilegedActionException pae) &#123; throw new RuntimeException(pae.getException()); &#125; catch (Exception ex) &#123; throw new RuntimeException(ex); &#125; Class&lt;?&gt; fieldt = field.getType(); //判断是否为int类型 if (fieldt != int.class) throw new IllegalArgumentException(&quot;Must be integer type&quot;); //判断是否被volatile修饰 if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException(&quot;Must be volatile type&quot;); this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; caller != tclass) ? caller : null; this.tclass = tclass; //获取该字段的在对象内存的偏移量，通过内存偏移量可以获取或者修改该字段的值 offset = unsafe.objectFieldOffset(field); &#125; &#125; 从AtomicIntegerFieldUpdaterImpl的构造器也可以看出更新器为什么会有这么多限制条件了，当然最终其CAS操作肯定是通过unsafe完成的，简单看一个方法123456789101112131415public int incrementAndGet(T obj) &#123; int prev, next; do &#123; prev = get(obj); next = prev + 1; //CAS操作 &#125; while (!compareAndSet(obj, prev, next)); return next;&#125;//最终调用的还是unsafe.compareAndSwapInt()方法public boolean compareAndSet(T obj, int expect, int update) &#123; if (obj == null || obj.getClass() != tclass || cclass != null) fullCheck(obj); return unsafe.compareAndSwapInt(obj, offset, expect, update); &#125; CAS的ABA问题及其解决方案假设这样一种场景，当第一个线程执行CAS(V,E,U)操作，在获取到当前变量V，准备修改为新值U前，另外两个线程已连续修改了两次变量V的值，使得该值又恢复为旧值，这样的话，我们就无法正确判断这个变量是否已被修改过，如下图 这就是典型的CAS的ABA问题，一般情况这种情况发现的概率比较小，可能发生了也不会造成什么问题，比如说我们对某个做加减法，不关心数字的过程，那么发生ABA问题也没啥关系。但是在某些情况下还是需要防止的，那么该如何解决呢？在Java中解决ABA问题，我们可以使用以下两个原子类 AtomicStampedReference AtomicStampedReference原子类是一个带有时间戳的对象引用，在每次修改后，AtomicStampedReference不仅会设置新值而且还会记录更改的时间。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功，这也就解决了反复读写时，无法预知值是否已被修改的窘境，测试demo如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Created by zejian on 2017/7/2. * Blog : http://blog.csdn.net/javazejian [原文地址,请尊重原创] */public class ABADemo &#123; static AtomicInteger atIn = new AtomicInteger(100); //初始化时需要传入一个初始值和初始时间 static AtomicStampedReference&lt;Integer&gt; atomicStampedR = new AtomicStampedReference&lt;Integer&gt;(200,0); static Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; //更新为200 atIn.compareAndSet(100, 200); //更新为100 atIn.compareAndSet(200, 100); &#125; &#125;); static Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atIn.compareAndSet(100,500); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atIn); &#125; &#125;); static Thread t3 = new Thread(new Runnable() &#123; @Override public void run() &#123; int time=atomicStampedR.getStamp(); //更新为200 atomicStampedR.compareAndSet(100, 200,time,time+1); //更新为100 int time2=atomicStampedR.getStamp(); atomicStampedR.compareAndSet(200, 100,time2,time2+1); &#125; &#125;); static Thread t4 = new Thread(new Runnable() &#123; @Override public void run() &#123; int time = atomicStampedR.getStamp(); System.out.println(&quot;sleep 前 t4 time:&quot;+time); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atomicStampedR.compareAndSet(100,500,time,time+1); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atomicStampedR.getReference()); &#125; &#125;); public static void main(String[] args) throws InterruptedException &#123; t1.start(); t2.start(); t1.join(); t2.join(); t3.start(); t4.start(); /** * 输出结果: flag:true,newValue:500 sleep 前 t4 time:0 flag:false,newValue:200 */ &#125;&#125; 对比输出结果可知，AtomicStampedReference类确实解决了ABA的问题，下面我们简单看看其内部实现原理 123456789101112131415161718192021public class AtomicStampedReference&lt;V&gt; &#123; //通过Pair内部类存储数据和时间戳 private static class Pair&lt;T&gt; &#123; final T reference; final int stamp; private Pair(T reference, int stamp) &#123; this.reference = reference; this.stamp = stamp; &#125; static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) &#123; return new Pair&lt;T&gt;(reference, stamp); &#125; &#125; //存储数值和时间的内部类 private volatile Pair&lt;V&gt; pair; //构造器，创建时需传入初始值和时间初始值 public AtomicStampedReference(V initialRef, int initialStamp) &#123; pair = Pair.of(initialRef, initialStamp); &#125;&#125; 接着看看其compareAndSet方法的实现： 123456789101112public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) &#123; Pair&lt;V&gt; current = pair; return expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); &#125; 同时对当前数据和当前时间进行比较，只有两者都相等是才会执行casPair()方法，单从该方法的名称就可知是一个CAS方法，最终调用的还是Unsafe类中的compareAndSwapObject方法123private boolean casPair(Pair&lt;V&gt; cmp, Pair&lt;V&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val); &#125; 到这我们就很清晰AtomicStampedReference的内部实现思想了，通过一个键值对Pair存储数据和时间戳，在更新时对数据和时间戳进行比较，只有两者都符合预期才会调用Unsafe的compareAndSwapObject方法执行数值和时间戳替换，也就避免了ABA的问题。 AtomicMarkableReference类 AtomicMarkableReference与AtomicStampedReference不同的是，AtomicMarkableReference维护的是一个boolean值的标识，也就是说至于true和false两种切换状态，经过博主测试，这种方式并不能完全防止ABA问题的发生，只能减少ABA问题发生的概率。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ABADemo &#123; static AtomicMarkableReference&lt;Integer&gt; atMarkRef = new AtomicMarkableReference&lt;Integer&gt;(100,false); static Thread t5 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark=atMarkRef.isMarked(); System.out.println(&quot;mark:&quot;+mark); //更新为200 System.out.println(&quot;t5 result:&quot;+atMarkRef.compareAndSet(atMarkRef.getReference(), 200,mark,!mark)); &#125; &#125;); static Thread t6 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark2=atMarkRef.isMarked(); System.out.println(&quot;mark2:&quot;+mark2); System.out.println(&quot;t6 result:&quot;+atMarkRef.compareAndSet(atMarkRef.getReference(), 100,mark2,!mark2)); &#125; &#125;); static Thread t7 = new Thread(new Runnable() &#123; @Override public void run() &#123; boolean mark=atMarkRef.isMarked(); System.out.println(&quot;sleep 前 t7 mark:&quot;+mark); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean flag=atMarkRef.compareAndSet(100,500,mark,!mark); System.out.println(&quot;flag:&quot;+flag+&quot;,newValue:&quot;+atMarkRef.getReference()); &#125; &#125;); public static void main(String[] args) throws InterruptedException &#123; t5.start();t5.join(); t6.start();t6.join(); t7.start(); /** * 输出结果: mark:false t5 result:true mark2:true t6 result:true sleep 前 t5 mark:false flag:true,newValue:500 ----&gt;成功了.....说明还是发生ABA问题 */ &#125;&#125; 再谈自旋锁自旋锁是一种假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这种方式确实也是可以提升效率的。但问题是当线程越来越多竞争很激烈时，占用CPU的时间变长会导致性能急剧下降，因此Java虚拟机内部一般对于自旋锁有一定的次数限制，可能是50或者100次循环后就放弃，直接挂起线程，让出CPU资源。如下通过AtomicReference可实现简单的自旋锁。 1234567891011121314public class SpinLock &#123; private AtomicReference&lt;Thread&gt; sign =new AtomicReference&lt;&gt;(); public void lock()&#123; Thread current = Thread.currentThread(); while(!sign .compareAndSet(null, current))&#123; &#125; &#125; public void unlock ()&#123; Thread current = Thread.currentThread(); sign .compareAndSet(current, null); &#125;&#125; 使用CAS原子操作作为底层实现，lock()方法将要更新的值设置为当前线程，并将预期值设置为null。unlock()函数将要更新的值设置为null，并预期值设置为当前线程。然后我们通过lock()和unlock来控制自旋锁的开启与关闭，注意这是一种非公平锁。事实上AtomicInteger(或者AtomicLong)原子类内部的CAS操作也是通过不断的自循环(while循环)实现，不过这种循环的结束条件是线程成功更新对于的值，但也是自旋锁的一种。 参考资料http://blog.csdn.net/javazejian/article/details/72772470]]></content>
  </entry>
  <entry>
    <title><![CDATA[手工合并采购单分组的sql]]></title>
    <url>%2F2018%2F02%2F26%2Fegenie_business%2Fmanual-sql-separate-purchase-group%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980-- 查询出问题的采购单SELECT *FROM pms_purchase_orderWHERE pms_purchase_order_no IN (&apos;CG2018-02100061021&apos;, &apos;CG2018-02100061023&apos;);-- 订单为主表,先将要处理的订单,抽出到一个表中CREATE TABLE `tmp_0226_mlj` AS SELECT DISTINCT sale_order_id, &quot;XXXX&quot; AS group_no FROM pms_daily_purchase_detail WHERE pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 由于create table的语法限制,如果 group_no 为null,无法进行update,so 先放一个长的字符串XXXX进去DESC tmp_0226_mlj;-- 手动更新组号UPDATE tmp_0226_mljSET group_no = &apos;C&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;D&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;E&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;F&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;G&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;H&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;M&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;UPDATE tmp_0226_mljSET group_no = &apos;N&apos;WHERE group_no = &quot;XXXX&quot;LIMIT 200;-- 预览手动分配的组号SELECT count(1), group_noFROM tmp_0226_mljGROUP BY group_no;SELECT * from pms_daily_purchase_detail WHERE pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 更新采购单明细UPDATE pms_daily_purchase_detail, tmp_0226_mljSET pms_daily_purchase_detail.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = pms_daily_purchase_detail.sale_order_id AND pms_purchase_order_id IN (216606, 216608) AND single = 0;-- 更新订单UPDATE sale_order, tmp_0226_mljSET sale_order.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = sale_order.sale_order_id;-- 更新发货单UPDATE wms_order, tmp_0226_mljSET wms_order.group_no = tmp_0226_mlj.group_noWHERE tmp_0226_mlj.sale_order_id = wms_order.sale_order_id;]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm垃圾回收策略]]></title>
    <url>%2F2018%2F02%2F18%2Fjava_jvm%2Fjvm-gc%2F</url>
    <content type="text"><![CDATA[简介GC（Garbage Collection）的发生时机:总体来说是内存使用紧张的时候会进行GC，即新对象所需内存比剩下的内存大时发生。 Stop the worldVM thread在进行GC前，必须要让所有的Java线程阻塞，从而stop the world，开始标记，不管什么算法的收集器，都需要有这个标记的过程，只是时间长短的问题。这一步是非常关键的一步，关于这个部分的内容的介绍也比较少。 How Stop the world安全点（safe point）在准备Stop the World时，其实就是相当于设置了一个中断标志位，而安全点其实就是一些指令，在JIT执行方式下，JIT编译的时候直接把safepoint的检查代码加入了生成的本地代码，不同线程运行到这条指令时会主动去检查这个标志位是否被设置，如果设置了就将线程停顿，否则就继续运行。 安全区域（safe region）而一些Sleep或者被blocked的线程不能主动运行到safepoint。这些线程也需要在GC的时候被标记检查，JVM引入了safe region的概念。safe region是指一块区域，这块区域中的引用都不会被修改，比如线程被阻塞了，那么它的线程堆栈中的引用是不会被修改的，JVM可以安全地进行标记。线程进入到safe region的时候先标识自己进入了safe region，等它被唤醒准备离开safe region的时候，先检查能否离开，如果GC已经完成，那么可以离开，否则就在safe region呆在。 找出活的对象标记的第一步就是得先获得GC roots，也就是根节点法，引用计数法因为循环引用的问题无法解决这里就不提了。所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。GC roots是下面这些数据的集合： JVM栈的栈帧中的局部变量表里的有效的局部变量（局部变量有作用域）所引用的对象 方法区里面的类元素对象的static、常量所引用的对象 运行时方法区里面的类元素对象的运行时常量所引用的对象 本地方法栈里的引用所引用的对象 Tracing GC的根本思路就是：给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可到达的）对象就被判定为存活，其余对象（也就是没有被遍历到的）就自然被判定为死亡。 而Jvm运行时的对象很多，如果一个个去遍历必然会花费大量的时间，获取GC roots最主要的部分在解决如何快速找到JVM栈的栈帧的局部变量表中的局部变量所引用的对象。 在HotSpot里实现的方式从外部记录下类型信息，存成映射表。HotSpot把这样的数据结构叫做OopMap。要实现这种功能，需要虚拟机里的解释器和JIT编译器都有相应的支持，由它们来生成足够的元数据提供给GC。 清理的过程新生代垃圾回收SUN/Oracle 的HotSpot JVM 又把新生代进一步划分为3个区域：一个相对大点的区域，称为”伊甸园区(Eden)”；两个相对小点的区域称为”From 幸存区(survivor)”和”To 幸存区(survivor)”。按照规定,新对象会首先分配在 Eden 中(如果新对象过大，会直接分配在老年代中)。在GC中，Eden 中的对象会被移动到survivor中，直至对象满足一定的年纪(定义为熬过GC的次数),会被移动到老年代。 基于大多数新生对象都会在GC中被收回的假设。新生代的GC 使用复制算法。在GC前To 幸存区(survivor)保持清空,对象保存在 Eden 和 From 幸存区(survivor)中，GC运行时,Eden中的幸存对象被复制到 To 幸存区(survivor)。针对 From 幸存区(survivor)中的幸存对象，会考虑对象年龄,如果年龄没达到阀值(tenuring threshold)，对象会被复制到To 幸存区(survivor)。如果达到阀值对象被复制到老年代。复制阶段完成后，Eden 和From 幸存区中只保存死对象，可以视为清空。如果在复制过程中To 幸存区被填满了，剩余的对象会被复制到老年代中。最后 From 幸存区和 To幸存区会调换下名字，在下次GC时，To 幸存区会成为From 幸存区。 上图演示GC过程，黄色表示死对象，绿色表示剩余空间，红色表示幸存对象 参数设置-XX:NewSize and -XX:MaxNewSize就像可以通过参数(-Xms and -Xmx) 指定堆大小一样，可以通过参数指定新生代大小。设置 XX:MaxNewSize 参数时，应该考虑到新生代只是整个堆的一部分，新生代设置的越大，老年代区域就会减少。一般不允许新生代比老年代还大，因为要考虑GC时最坏情况，所有对象都晋升到老年代。(译者:会发生OOM错误) -XX:MaxNewSize 最大可以设置为-Xmx/2 . 考虑性能，一般会通过参数 -XX:NewSize 设置新生代初始大小。如果知道新生代初始分配的对象大小(经过监控) ，这样设置会有帮助，可以节省新生代自动扩展的消耗。 -XX:NewRatio可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=3 指定老年代/新生代为3/1. 老年代占堆大小的 3/4 ，新生代占 1/4 . 如果针对新生代,同时定义绝对值和相对值,绝对值将起作用。下面例子：$ java -XX:NewSize=32m -XX:MaxNewSize=512m -XX:NewRatio=3 MyApp 以上设置, JVM 会尝试为新生代分配四分之一的堆大小，但不会小于32MB或大于521MB 在设置新生代大小问题上，使用绝对值还是相对值，不存在通用准则 。如果了解应用的内存使用情况,设置固定大小的堆和新生代更有利，当然也可以设置相对值。如果对应用的内存使用一无所知,正确的做法是不要设置任何参数，如果应用运行良好。很好，我们不用做任何额外动作.如果遇到性能或OutOfMemoryErrors, 在调优之前，首先需要进行一系列有目的的监控测试，缩小问题的根源。 -XX:SurvivorRatio参数 -XX:SurvivorRatio 与 -XX:NewRatio 类似，作用于新生代内部区域。-XX:SurvivorRatio 指定伊甸园区(Eden)与幸存区大小比例. 例如, -XX:SurvivorRatio=10 表示伊甸园区(Eden)是 幸存区To 大小的10倍(也是幸存区From的10倍).所以,伊甸园区(Eden)占新生代大小的10/12, 幸存区From和幸存区To 每个占新生代的1/12 .注意,两个幸存区永远是一样大的.. 设定幸存区大小有什么作用? 假设幸存区相对伊甸园区(Eden)太小, 相应新生对象的伊甸园区(Eden)永远很大空间, 我们当然希望,如果这些对象在GC时全部被回收,伊甸园区(Eden)被清空,一切正常.然而,如果有一部分对象在GC中幸存下来, 幸存区只有很少空间容纳这些对象.结果大部分幸存对象在一次GC后，就会被转移到老年代 ,这并不是我们希望的.考虑相反情况, 假设幸存区相对伊甸园区(Eden)太大,当然有足够的空间，容纳GC后的幸存对象. 但是过小的伊甸园区(Eden),意味着空间将越快耗尽，增加新生代GC次数，这是不可接受的。 总之,我们希望最小化短命对象晋升到老年代的数量，同时也希望最小化新生代GC 的次数和持续时间.我们需要找到针对当前应用的折中方案, 寻找适合方案的起点是 了解当前应用中对象的年龄分布情况。 -XX:+PrintTenuringDistribution参数 -XX:+PrintTenuringDistribution 指定JVM 在每次新生代GC时，输出幸存区中对象的年龄分布。例如:Desired survivor size 75497472 bytes, new threshold 15 (max 15) age 1: 19321624 bytes, 19321624 total age 2: 79376 bytes, 19401000 total age 3: 2904256 bytes, 22305256 total 第一行说明幸存区To大小为 75 MB. 也有关于老年代阀值(tenuring threshold)的信息, 老年代阀值，意思是对象从新生代移动到老年代之前，经过几次GC(即, 对象晋升前的最大年龄). 上例中,老年代阀值为15,最大也是15. 之后行表示，对于小于老年代阀值的每一个对象年龄,本年龄中对象所占字节 (如果当前年龄没有对象,这一行会忽略). 上例中,一次 GC 后幸存对象大约 19 MB, 两次GC 后幸存对象大约79 KB , 三次GC 后幸存对象大约 3 MB .每行结尾，显示直到本年龄全部对象大小.所以,最后一行的 total 表示幸存区To 总共被占用22 MB . 幸存区To 总大小为 75 MB ,当前老年代阀值为15，可以断定在本次GC中，没有对象会移动到老年代。现在假设下一次GC 输出为： Desired survivor size 75497472 bytes, new threshold 2 (max 15) age 1: 68407384 bytes, 68407384 total age 2: 12494576 bytes, 80901960 total age 3: 79376 bytes, 80981336 total age 4: 2904256 bytes, 83885592 total 对比前一次老年代分布。明显的,年龄2和年龄3 的对象还保持在幸存区中，因为我们看到年龄3和4的对象大小与前一次年龄2和3的相同。同时发现幸存区中,有一部分对象已经被回收,因为本次年龄2的对象大小为 12MB ，而前一次年龄1的对象大小为 19 MB。最后可以看到最近的GC中，有68 MB 新对象，从伊甸园区移动到幸存区。 注意,本次GC 幸存区占用总大小 84 MB -大于75 MB. 结果,JVM 把老年代阀值从15降低到2，在下次GC时，一部分对象会强制离开幸存区，这些对象可能会被回收(如果他们刚好死亡)或移动到老年代。 -XX:InitialTenuringThreshold, -XX:MaxTenuringThreshold and -XX:TargetSurvivorRatio参数 -XX:+PrintTenuringDistribution 输出中的部分值可以通过其它参数控制。通过 -XX:InitialTenuringThreshold 和 -XX:MaxTenuringThreshold 可以设定老年代阀值的初始值和最大值。另外,可以通过参数 -XX:TargetSurvivorRatio 设定幸存区的目标使用率.例如 , -XX:MaxTenuringThreshold=10 -XX:TargetSurvivorRatio=90 设定老年代阀值的上限为10,幸存区空间目标使用率为90%。 有多种方式,设置新生代行为，没有通用准则。我们必须清楚以下2中情况：1 如果从年龄分布中发现，有很多对象的年龄持续增长，在到达老年代阀值之前。这表示 -XX:MaxTenuringThreshold 设置过大2 如果 -XX:MaxTenuringThreshold 的值大于1，但是很多对象年龄从未大于1.应该看下幸存区的目标使用率。如果幸存区使用率从未到达，这表示对象都被GC回收，这正是我们想要的。 如果幸存区使用率经常达到，有些年龄超过1的对象被移动到老年代中。这种情况，可以尝试调整幸存区大小或目标使用率。 -XX:+NeverTenure and -XX:+AlwaysTenure最后,我们介绍2个颇为少见的参数,对应2种极端的新生代GC情况.设置参数 -XX:+NeverTenure , 对象永远不会晋升到老年代.当我们确定不需要老年代时，可以这样设置。这样设置风险很大,并且会浪费至少一半的堆内存。相反设置参数 -XX:+AlwaysTenure, 表示没有幸存区,所有对象在第一次GC时，会晋升到老年代。没有合理的场景使用这个参数。可以在测试环境中，看下这样设置会发生什么有趣的事.但是并不推荐使用这些参数. 垃圾回收在实践中我们发现对于大多数的应用领域，评估一个垃圾收集(GC)算法如何根据如下两个标准： 吞吐量越高算法越好 暂停时间越短算法越好 高吞吐量最好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。 直觉上，吞吐量越高程序运行越快。 低暂停时间最好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。 这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。 因此，具有低的最大暂停时间是非常重要的，特别是对于一个交互式应用程序。 面向吞吐量-的垃圾收集算法-XX:+UseSerialGC(单核)我们使用该标志来激活串行垃圾收集器，例如单线程面向吞吐量垃圾收集器。 无论年轻代还是年老代都将只有一个线程执行垃圾收集。 该标志被推荐用于只有单个可用处理器核心的JVM。 在这种情况下，使用多个垃圾收集线程甚至会适得其反，因为这些线程将争用CPU资源，造成同步开销，却从未真正并行运行。 -XX:+UseParallelGC(并行执行年轻代垃圾收集)有了这个标志，我们告诉JVM使用多线程并行执行年轻代垃圾收集。 在我看来，Java 6中不应该使用该标志因为-XX:+UseParallelOldGC显然更合适。 需要注意的是Java 7中该情况改变了一点(详见本概述)，就是-XX:+UseParallelGC能达到-XX:+UseParallelOldGC一样的效果。 -XX:+UseParallelOldGC(并行执行老年代垃圾收集)该标志的命名有点不巧，因为”老”听起来像”过时”。 然而，”老”实际上是指年老代，这也解释了为什么-XX:+UseParallelOldGC要优于-XX:+UseParallelGC：除了激活年轻代并行垃圾收集，也激活了年老代并行垃圾收集。 当期望高吞吐量，并且JVM有两个或更多可用处理器核心时，我建议使用该标志。 作为旁注，HotSpot的并行面向吞吐量垃圾收集算法通常称为”吞吐量收集器”，因为它们旨在通过并行执行来提高吞吐量。 -XX:ParallelGCThreads通过-XX:ParallelGCThreads=我们可以指定并行垃圾收集的线程数量。 例如，-XX:ParallelGCThreads=6表示每次并行垃圾收集将有6个线程执行。 如果不明确设置该标志，虚拟机将使用基于可用(虚拟)处理器数量计算的默认值。 决定因素是由Java Runtime。availableProcessors()方法的返回值N，如果N&lt;=8，并行垃圾收集器将使用N个垃圾收集线程，如果N&gt;8个可用处理器，垃圾收集线程数量应为3+5N/8。当JVM独占地使用系统和处理器时使用默认设置更有意义。 但是，如果有多个JVM(或其他耗CPU的系统)在同一台机器上运行，我们应该使用-XX:ParallelGCThreads来减少垃圾收集线程数到一个适当的值。 例如，如果4个以服务器方式运行的JVM同时跑在在一个具有16核处理器的机器上，设置-XX:ParallelGCThreads=4是明智的，它能使不同JVM的垃圾收集器不会相互干扰。 -XX:-UseAdaptiveSizePolicy吞吐量垃圾收集器提供了一个有趣的(但常见，至少在现代JVM上)机制以提高垃圾收集配置的用户友好性。 这种机制被看做是HotSpot在Java 5中引入的”人体工程学”概念的一部分。 通过人体工程学，垃圾收集器能将堆大小动态变动像GC设置一样应用到不同的堆区域，只要有证据表明这些变动将能提高GC性能。 “提高GC性能”的确切含义可以由用户通过-XX:GCTimeRatio和-XX:MaxGCPauseMillis(见下文)标记来指定。重要的是要知道人体工程学是默认激活的。 这很好，因为自适应行为是JVM最大优势之一。 不过，有时我们需要非常清楚对于特定应用什么样的设置是最合适的，在这些情况下，我们可能不希望JVM混乱我们的设置。 每当我们发现处于这种情况时，我们可以考虑通过-XX:-UseAdaptiveSizePolicy停用一些人体工程学。 -XX:GCTimeRatio通过-XX:GCTimeRatio=我们告诉JVM吞吐量要达到的目标值。 更准确地说，-XX:GCTimeRatio=N指定目标应用程序线程的执行时间(与总的程序执行时间)达到N/(N+1)的目标比值。 例如，通过-XX:GCTimeRatio=9我们要求应用程序线程在整个执行时间中至少9/10是活动的(因此，GC线程占用其余1/10)。 基于运行时的测量，JVM将会尝试修改堆和GC设置以期达到目标吞吐量。 -XX:GCTimeRatio的默认值是99，也就是说，应用程序线程应该运行至少99%的总执行时间。 -XX:MaxGCPauseMillis通过-XX:GCTimeRatio=告诉JVM最大暂停时间的目标值(以毫秒为单位)。 在运行时，吞吐量收集器计算在暂停期间观察到的统计数据(加权平均和标准偏差)。 如果统计表明正在经历的暂停其时间存在超过目标值的风险时，JVM会修改堆和GC设置以降低它们。 需要注意的是，年轻代和年老代垃圾收集的统计数据是分开计算的，还要注意，默认情况下，最大暂停时间没有被设置。如果最大暂停时间和最小吞吐量同时设置了目标值，实现最大暂停时间目标具有更高的优先级。 当然，无法保证JVM将一定能达到任一目标，即使它会努力去做。 最后，一切都取决于手头应用程序的行为。当设置最大暂停时间目标时，我们应注意不要选择太小的值。 正如我们现在所知道的，为了保持低暂停时间，JVM需要增加GC次数，那样可能会严重影响可达到的吞吐量。 这就是为什么对于要求低暂停时间作为主要目标的应用程序(大多数是Web应用程序)，我会建议不要使用吞吐量收集器，而是选择CMS收集器。 CMS收集器是本系列下一部分的主题。 CMS收集器 处理阶段CMS收集器的GC周期由6个阶段组成。其中4个阶段(名字以Concurrent开始的)与实际的应用程序是并发执行的，而其他2个阶段需要暂停应用程序线程。 初始标记(STW initial mark) 并发标记(Concurrent marking) 并发预清理(Concurrent precleaning) 重新标记(STW remark) 并发清理(Concurrent sweeping) 并发重置(Concurrent reset) 初始标记 ：在这个阶段，需要虚拟机停顿正在执行的任务，官方的叫法STW(Stop The Word)。这个过程从垃圾回收的”根对象”开始，只扫描到能够和”根对象”直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记 ：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 并发预清理 ：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段”重新标记”的工作，因为下一个阶段会Stop The World。 重新标记 ：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从”跟对象”开始向下追溯，并处理对象关联。 并发清理 ：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。 并发重置 ：这个阶段，重置CMS收集器的数据结构，等待下一次垃圾回收。 初始标记、重新标记这两个步骤仍然需要“stop the world”，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生表动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。 尽管CMS收集器为老年代垃圾回收提供了几乎完全并发的解决方案，然而年轻代仍然通过“stop-the-world”方法来进行收集。对于交互式应用，停顿也是可接受的，背后的原理是年轻带的垃圾回收时间通常是相当短的。 gc日志分析39.910: [GC 39.910: [ParNew: 261760K-&gt;0K(261952K), 0.2314667 secs] 262017K-&gt;26386K(1048384K), 0.2318679 secs]新生代使用 (ParNew 并行)回收器。新生代容量为261952K，GC回收后占用从261760K降到0,耗时0.2314667秒。(译注：262017K-&gt;26386K(1048384K), 0.2318679 secs 表示整个堆占用从262017K 降至26386K,费时0.2318679) 40.146: [GC [1 CMS-initial-mark: 26386K(786432K)] 26404K(1048384K), 0.0074495 secs]开始使用CMS回收器进行老年代回收。初始标记(CMS-initial-mark)阶段,这个阶段标记由根可以直接到达的对象，标记期间整个应用线程会暂停。老年代容量为786432K,CMS 回收器在空间占用达到 26386K 时被触发 40.154: [CMS-concurrent-mark-start]开始并发标记(concurrent-mark-start) 阶段，在第一个阶段被暂停的线程重新开始运行，由前阶段标记过的对象出发，所有可到达的对象都在本阶段中标记。 40.683: [CMS-concurrent-mark: 0.521/0.529 secs]并发标记阶段结束，占用 0.521秒CPU时间, 0.529秒墙钟时间(也包含线程让出CPU给其他线程执行的时间) 40.683: [CMS-concurrent-preclean-start]开始预清理阶段预清理也是一个并发执行的阶段。在本阶段，会查找前一阶段执行过程中,从新生代晋升或新分配或被更新的对象。通过并发地重新扫描这些对象，预清理阶段可以减少下一个stop-the-world 重新标记阶段的工作量。 40.701: [CMS-concurrent-preclean: 0.017/0.018 secs]预清理阶段费时 0.017秒CPU时间，0.018秒墙钟时间。 40.704: [GC40.704: [Rescan (parallel) , 0.1790103 secs]40.883: [weak refs processing, 0.0100966 secs] [1 CMS-remark: 26386K(786432K)] 52644K(1048384K), 0.1897792 secs]Stop-the-world 阶段,从根及被其引用对象开始，重新扫描 CMS 堆中残留的更新过的对象。这里重新扫描费时0.1790103秒，处理弱引用对象费时0.0100966秒，本阶段费时0.1897792 秒。 40.894: [CMS-concurrent-sweep-start]开始并发清理阶段，在清理阶段，应用线程还在运行。 41.020: [CMS-concurrent-sweep: 0.126/0.126 secs]并发清理阶段费时0.126秒 41.020: [CMS-concurrent-reset-start]开始并发重置 41.147: [CMS-concurrent-reset: 0.127/0.127 secs]在本阶段，重新初始化CMS内部数据结构，以备下一轮 GC 使用。本阶段费时0.127秒 这是CMS正常运行周期打印的日志，现在让我们一起看一下其他的CMS日志记录： 197.976: [GC 197.976: [ParNew: 260872K-&gt;260872K(261952K), 0.0000688 secs]197.976: [CMS197.981: [CMS-concurrent-sweep: 0.516/0.531 secs](concurrent mode failure): 402978K-&gt;248977K(786432K), 2.3728734 secs] 663850K-&gt;248977K(1048384K), 2.3733725 secs]这段信息显示ParNew 收集器被请求进行新生代的回收，但收集器并没有尝试回收，因为 它 预计在最糟糕的情况下， CMS 老年代中没有足够的空间容纳新生代的幸存对象。我们把这个失败称之为”完全晋升担保失败”。 因为这样，并发模式的 CMS 被中断同并且在 197.981秒时，Full GC被启动。这次Full GC，采用标记-清除-整理算法，会发生stop-the-world，费时2.3733725秒。CMS 老年代占用从 402978K 降到248977K。 避免并发模式失败, 通过增加老年代空间大小或者设置参数 CMSInitiatingOccupancyFraction 同时设置UseCMSInitiatingOccupancyOnly为true。参数 CMSInitiatingOccupancyFraction 的值必须谨慎选择，设置过低会造成频繁发生 CMS 回收。 优缺点CMS是一款优秀的收集器，主要优点：并发收集、低停顿。 缺点： CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。 CMS是一款“标记–清除”算法实现的收集器，容易出现大量空间碎片。当空间碎片过多，将会给大对象分配带来很大的麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。 CMS收集器无法处理浮动垃圾。如果获取对象实例的频率高于收集器清除堆里死对象的频率，并发算法将再次失败。从某种程度上说，老年代将没有足够的可用空间来容纳一个从年轻代提升过来的对象。这种情况被称为“并发模式失败”，并且JVM会执行堆碎片整理：触发Full GC。当这些情形之一出现在实践中时(经常会出现在生产系统中)，经常被证实是老年代有大量不必要的对象。一个可行的办法就是增加年轻代的堆大小，以防止年轻代短生命的对象提前进入老年代。另一个办法就似乎利用分析器，快照运行系统的堆转储，并且分析过度的对象分配，找出这些对象，最终减少这些对象的申请。 CMS收集器调优相关的JVM标志参数-XX：+UseConcMarkSweepGC该标志首先是激活CMS收集器。默认HotSpot JVM使用的是并行收集器。 -XX：UseParNewGC当使用CMS收集器时，该标志激活年轻代使用多线程并行执行垃圾回收。这令人很惊讶，我们不能简单在并行收集器中重用-XX：UserParNewGC标志，因为概念上年轻代用的算法是一样的。然而，对于CMS收集器，年轻代GC算法和老年代GC算法是不同的，因此年轻代GC有两种不同的实现，并且是两个不同的标志。 注意最新的JVM版本，当使用-XX：+UseConcMarkSweepGC时，-XX：UseParNewGC会自动开启。因此，如果年轻代的并行GC不想开启，可以通过设置-XX：-UseParNewGC来关掉。 -XX：+CMSConcurrentMTEnabled当该标志被启用时，并发的CMS阶段将以多线程执行(因此，多个GC线程会与所有的应用程序线程并行工作)。该标志已经默认开启，如果顺序执行更好，这取决于所使用的硬件，多线程执行可以通过-XX：-CMSConcurremntMTEnabled禁用。 -XX：ConcGCThreads标志-XX：ConcGCThreads=(早期JVM版本也叫-XX:ParallelCMSThreads)定义并发CMS过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加CMS线程数是否真的能够带来性能的提升。 如果还标志未设置，JVM会根据并行收集器中的-XX：ParallelGCThreads参数的值来计算出默认的并行CMS线程数。该公式是ConcGCThreads = (ParallelGCThreads + 3)/4。因此，对于CMS收集器， -XX:ParallelGCThreads标志不仅影响“stop-the-world”垃圾收集阶段，还影响并发阶段。 总之，有不少方法可以配置CMS收集器的多线程执行。正是由于这个原因,建议第一次运行CMS收集器时使用其默认设置, 然后如果需要调优再进行测试。只有在生产系统中测量(或类生产测试系统)发现应用程序的暂停时间的目标没有达到 , 就可以通过这些标志应该进行GC调优。 -XX:CMSInitiatingOccupancyFraction当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对象。对于CMS收集器，长时间等待是不可取的，因为在并发垃圾收集期间应用持续在运行(并且分配对象)。因此，为了在应用程序使用完内存之前完成垃圾收集周期，CMS收集器要比并行收集器更先启动。 因为不同的应用会有不同对象分配模式，JVM会收集实际的对象分配(和释放)的运行时数据，并且分析这些数据，来决定什么时候启动一次CMS垃圾收集周期。为了引导这一过程， JVM会在一开始执行CMS周期前作一些线索查找。该线索由 -XX:CMSInitiatingOccupancyFraction=来设置，该值代表老年代堆空间的使用率。比如，value=75意味着第一次CMS垃圾收集会在老年代被占用75%时被触发。通常CMSInitiatingOccupancyFraction的默认值为68(之前很长时间的经历来决定的)。 -XX：+UseCMSInitiatingOccupancyOnly我们用-XX+UseCMSInitiatingOccupancyOnly标志来命令JVM不基于运行时收集的数据来启动CMS垃圾收集周期。而是，当该标志被开启时，JVM通过CMSInitiatingOccupancyFraction的值进行每一次CMS收集，而不仅仅是第一次。然而，请记住大多数情况下，JVM比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。 -XX:+CMSClassUnloadingEnabled相对于并行收集器，CMS收集器默认不会对永久代进行垃圾回收。如果希望对永久代进行垃圾回收，可用设置标志-XX:+CMSClassUnloadingEnabled。在早期JVM版本中，要求设置额外的标志-XX:+CMSPermGenSweepingEnabled。注意，即使没有设置这个标志，一旦永久代耗尽空间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC。 -XX:+CMSIncrementalMode该标志将开启CMS收集器的增量模式。增量模式经常暂停CMS过程，以便对应用程序线程作出完全的让步。因此，收集器将花更长的时间完成整个收集周期。因此，只有通过测试后发现正常CMS周期对应用程序线程干扰太大时，才应该使用增量模式。由于现代服务器有足够的处理器来适应并发的垃圾收集，所以这种情况发生得很少。 -XX:+ExplicitGCInvokesConcurrent and -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses如今,被广泛接受的最佳实践是避免显式地调用GC(所谓的“系统GC”)，即在应用程序中调用system.gc()。然而，这个建议是不管使用的GC算法的，值得一提的是，当使用CMS收集器时，系统GC将是一件很不幸的事，因为它默认会触发一次Full GC。幸运的是，有一种方式可以改变默认设置。标志-XX:+ExplicitGCInvokesConcurrent命令JVM无论什么时候调用系统GC，都执行CMS GC，而不是Full GC。第二个标志-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses保证当有系统GC调用时，永久代也被包括进CMS垃圾回收的范围内。因此，通过使用这些标志，我们可以防止出现意料之外的”stop-the-world”的系统GC。 -XX:+DisableExplicitGC然而在这个问题上…这是一个很好提到- XX:+ DisableExplicitGC标志的机会，该标志将告诉JVM完全忽略系统的GC调用(不管使用的收集器是什么类型)。对于我而言，该标志属于默认的标志集合中，可以安全地定义在每个JVM上运行，而不需要进一步思考。 G1收集器不同于其他的分代回收算法、G1将堆空间划分成了互相独立的区块。每块区域既有可能属于O区、也有可能是Y区，且每类区域空间可以是不连续的（对比CMS的O区和Y区都必须是连续的）。这种将O区划分成多块的理念源于：当并发后台线程寻找可回收的对象时、有些区块包含可回收的对象要比其他区块多很多。虽然在清理这些区块时G1仍然需要暂停应用线程、但可以用相对较少的时间优先回收包含垃圾最多区块。这也是为什么G1命名为Garbage First的原因： 第一时间处理垃圾最多的区块。 堆内存结构以往的垃圾回收算法，如CMS，使用的堆内存结构如下： 在G1算法中，采用了另外一种完全不同的方式组织堆内存，堆内存被划分为多个大小相等的内存块（Region），每个Region是逻辑连续的一段内存，结构如下： 每一个分配的Region，都可以分成两个部分，已分配的和未被分配的。它们之间的界限被称为top。总体上来说，把一个对象分配到Region内，只需要简单增加top的值。这个做法实际上就是bump-the-pointer。过程如下 G1具备如下特点： G1在压缩空间方面有优势 G1通过将内存空间分成区域（Region）的方式避免内存碎片问题 Eden, Survivor, Old区不再固定、在内存使用效率上来说更灵活 G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间避免应用雪崩现象 G1在回收内存后会马上同时做合并空闲内存的工作、而CMS默认是在STW（stop the world）的时候做 G1会在Young GC中使用、而CMS只能在O区使用 以下场景下G1更适合服务端多核CPU、JVM内存占用较大的应用（至少大于4G）应用在运行过程中会产生大量内存碎片、需要经常压缩空间想要更可控、可预期的GC停顿周期；防止高并发下应用雪崩现象 GC模式： young gc mix gc G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。 由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。 上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。 Young GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm-new-object]]></title>
    <url>%2F2018%2F02%2F10%2Fjava_jvm%2Fjvm-new-object%2F</url>
    <content type="text"><![CDATA[类的初始化类加载机制概述我们知道，一个.java文件在编译后会形成相应的一个或多个Class文件（若一个类中含有内部类，则编译后会产生多个Class文件），但这些Class文件中描述的各种信息，最终都需要加载到虚拟机中之后才能被运行和使用。事实上，虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型的过程就是虚拟机的 类加载机制。 与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载和连接都是在程序运行期间完成，这样会在类加载时稍微增加一些性能开销，但是却能为Java应用程序提供高度的灵活性，Java中天生可以动态扩展的语言特性多态就是依赖运行期动态加载和动态链接这个特点实现的。例如，如果编写一个使用接口的应用程序，可以等到运行时再指定其实际的实现。这种组装应用程序的方式广泛应用于Java程序之中。 类的生命周期Java类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using) 和 卸载(Unloading)七个阶段。其中准备、验证、解析3个部分统称为连接（Linking），如图所示： 加载：把二进制形式的Java类型读入Java虚拟机中。 连接：把装载的二进制形式的类型数据合并到虚拟机的运行时状态中去。 验证：确保Java类型数据格式正确并且适合于Java虚拟机使用。 准备：负责为该类型分配它所需内存。 解析：把常量池中的符号引用转换为直接引用。(可推迟到运行中的程序真正使用某个符号引用时再解析) 初始化：为类变量赋适当的初始值 加载（Loading） 在加载阶段（可以参考java.lang.ClassLoader的loadClass()方法），虚拟机需要完成以下三件事情： (1). 通过一个类的全限定名来获取定义此类的二进制字节流（并没有指明要从一个Class文件中获取，可以从其他渠道，譬如：网络、动态生成、数据库等）； (2). 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； (3). 在内存中(对于HotSpot虚拟就而言就是方法区)生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； Java虚拟机在识别Java class文件，产生了类型的二进制数据后，Java虚拟机必须把这些二进制数据解析为与实现相关的内部数据结构。装载的最终产品就是Class实例，它称为Java程序与内部数据结构之间的接口。要访问关于该类型的信息(存储在内部数据结构中)，程序就要调用该类型对应的Class实例的方法。这样一个过程，就是把一个类型的二进制数据解析为方法区中的内部数据结构，并在堆上建立一个Class对象的过程，这被称为”创建”类型。 加载阶段和连接阶段（Linking）的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 验证（Verification）验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范(例如，是否以魔术0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型) 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求(例如：这个类是否有父类，除了java.lang.Object之外)； 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的; 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响。如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备(Preparation)准备阶段是正式为类变量(static 成员变量)分配内存并设置类变量初始值（零值）的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： public static int value = 123; 那么，变量value在准备阶段过后的值为0而不是123。因为这时候尚未开始执行任何java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器方法()之中，所以把value赋值为123的动作将在初始化阶段才会执行。至于“特殊情况”是指：当类字段的字段属性是ConstantValue时，会在准备阶段初始化为指定的值，所以标注为final之后，value的值在准备阶段初始化为123而非0。 public static final int value = 123; 解析(Resolution)解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 初始化(Initialization)类初始化阶段是类加载过程的最后一步。在前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的java程序代码(字节码)。 在准备阶段，变量已经赋过一次系统要求的初始值(零值)；而在初始化阶段，则根据程序猿通过程序制定的主观计划去初始化类变量和其他资源，或者更直接地说：初始化阶段是执行类构造器()方法的过程。()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块static{}中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。 结束生命周期在如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载的时机那么，什么情况下虚拟机需要开始初始化一个类呢？这在虚拟机规范中是有严格规定的，虚拟机规范指明 有且只有 种情况必须立即对类进行初始化（而这一过程自然发生在加载、验证、准备之后）： 遇到new、getstatic、putstatic或invokestatic这四条字节码指令（注意，newarray指令触发的只是数组类型本身的初始化，而不会导致其相关类型的初始化，比如，new String[]只会直接触发String[]类的初始化，也就是触发对类Ljava.lang.String的初始化，而直接不会触发String类的初始化）时，如果类没有进行过初始化，则需要先对其进行初始化。生成这四条指令的最常见的Java代码场景是： 使用new关键字实例化对象的时候； 读取或设置一个类的静态字段（被final修饰，已在编译器把结果放入常量池的静态字段除外）的时候； 调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用jdk1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getstatic,REF_putstatic,REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 注意，对于这五种会触发类进行初始化的场景，虚拟机规范中使用了一个很强烈的限定语：“有且只有”，这五种场景中的行为称为对一个类进行 主动引用。除此之外，所有引用类的方式，都不会触发初始化，称为 被动引用。被动引用的几种经典场景 通过子类引用父类的静态字段，不会导致子类初始化 通过数组定义来引用类，不会触发此类的初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 类加载器寻找类加载器，先来一个小例子 123456789package com.neo.classloader;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125; 运行后，输出结果： 123sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 这几种类加载器的层次关系如下图所示： 站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其它的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 JVM三种预定义类型类加载器启动（Bootstrap）类加载器：引导类加载器是用 本地代码实现的类加载器，它负责将 /lib下面的核心类库 或 -Xbootclasspath选项指定的jar包等 虚拟机识别的类库 加载到内存中。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以 不允许直接通过引用进行操作。 扩展（Extension）类加载器：扩展类加载器是由Sun的ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的，它负责将 /lib/ext或者由系统变量-Djava.ext.dir指定位置中的类库 加载到内存中。开发者可以直接使用标准扩展类加载器。 系统（System）类加载器：系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的，它负责将 用户类路径(java -classpath或-Djava.class.path变量所指的目录，即当前类所在路径及其引用的第三方类库的路径，如第四节中的问题6所述)下的类库 加载到内存中。开发者可以直接使用系统类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 1、在执行非置信代码之前，自动验证数字签名。2、动态地创建符合用户特定需要的定制化构建类。3、从特定的场所取得java class，例如数据库中和网络中。 JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 类的加载 1、命令行启动应用时候由JVM初始化加载 2、通过Class.forName()方法动态加载 3、通过ClassLoader.loadClass()方法动态加载 Class.forName()和ClassLoader.loadClass()区别 Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 类加载双亲委派机制介绍和分析 1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 123456789101112131415161718192021222324252627public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 双亲委派模型意义： 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行 自定义类加载器通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自ClassLoader类，从上面对loadClass方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.neo.classloader;import java.io.*;public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace(&apos;.&apos;, File.separatorChar) + &quot;.class&quot;; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(&quot;E:\\temp&quot;); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(&quot;com.neo.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。这里有几点需要注意： 1、这里传递的文件名需要是类的全限定性名称，即com.paddx.test.classloading.Test格式的，因为 defineClass 方法是按这种格式进行处理的。 2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3、这类Test 类本身可以被 AppClassLoader类加载，因此我们不能把com/paddx/test/classloading/Test.class放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由AppClassLoader加载，而不会通过我们自定义类加载器来加载。 类的实例化对象创建时机 使用new关键字创建对象 使用Class类的newInstance方法(反射机制) 使用Constructor类的newInstance方法(反射机制) 使用Clone方法创建对象 使用(反)序列化机制创建对象 从Java虚拟机层面看，除了使用new关键字创建对象的方式外，其他方式全部都是通过转变为invokevirtual指令直接创建对象的。 创建过程实例变量初始化我们在定义（声明）实例变量的同时，还可以直接对实例变量进行赋值或者使用实例代码块对其进行赋值。如果我们以这两种方式为实例变量进行初始化，那么它们将在构造函数执行之前完成这些初始化操作。实际上，如果我们对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后(还记得吗？Java要求构造函数的第一条语句必须是超类构造函数的调用语句)，构造函数本身的代码之前。 实例代码块初始化构造函数初始化Java要求在实例化类之前，必须先实例化其超类，以保证所创建实例的完整性。 对象初始化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Parent &#123; /* 静态变量 */ public static String p_StaticField = &quot;父类--静态变量&quot;; /* 变量 */ public String p_Field = &quot;父类--变量&quot;; protected int i = 9; protected int j = 0; /* 静态初始化块 */ static &#123; System.out.println( p_StaticField ); System.out.println( &quot;父类--静态初始化块&quot; ); &#125; /* 初始化块 */ &#123; System.out.println( p_Field ); System.out.println( &quot;父类--初始化块&quot; ); &#125; /* 构造器 */ public Parent() &#123; System.out.println( &quot;父类--构造器&quot; ); System.out.println( &quot;i=&quot; + i + &quot;, j=&quot; + j ); j = 20; &#125;&#125;public class SubClass extends Parent &#123; /* 静态变量 */ public static String s_StaticField = &quot;子类--静态变量&quot;; /* 变量 */ public String s_Field = &quot;子类--变量&quot;; /* 静态初始化块 */ static &#123; System.out.println( s_StaticField ); System.out.println( &quot;子类--静态初始化块&quot; ); &#125; /* 初始化块 */ &#123; System.out.println( s_Field ); System.out.println( &quot;子类--初始化块&quot; ); &#125; /* 构造器 */ public SubClass() &#123; System.out.println( &quot;子类--构造器&quot; ); System.out.println( &quot;i=&quot; + i + &quot;,j=&quot; + j ); &#125; /* 程序入口 */ public static void main( String[] args ) &#123; System.out.println( &quot;子类main方法&quot; ); new SubClass(); &#125;&#125; 结果: 12345678910111213父类--静态变量父类--静态初始化块子类--静态变量子类--静态初始化块子类main方法父类--变量父类--初始化块父类--构造器i=9, j=0子类--变量子类--初始化块子类--构造器i=9,j=20]]></content>
  </entry>
  <entry>
    <title><![CDATA[jvm-memory-model]]></title>
    <url>%2F2018%2F02%2F07%2Fjava_jvm%2Fjvm-memory-model%2F</url>
    <content type="text"><![CDATA[程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 虚拟机栈线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。 动画是由一帧一帧图片连续切换结果的结果而产生的，其实虚拟机的运行和动画也类似，每个在虚拟机中运行的程序也是由许多的帧的切换产生的结果，只是这些帧里面存放的是方法的局部变量，操作数栈，动态链接，方法返回地址和一些额外的附加信息组成。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 局部变量表用于存放方法参数和方法内部定义的局部变量 虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 操作栈动态链接返回地址异常本地方法栈堆 是Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 但是随着JIT 编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆” 如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代； 新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及SurvivorSpace的大小。 老年代：用于存放经过多次新生代GC仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：1、大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。2、大的数组对象，且数组中无引用外部对象。 方法区也称”永久代” 、“非堆”， 它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。 类信息常量静态变量即时编译后的代码class文件常量池运行时常量池之所以说运行时常量池关键，是因为它相对于Class文件常量池的另外一个重要特性是具备动态性，java语言并不要求常量一定只有编译器才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，比如String类的intern方法就为此类操作。运行时常量池为我们提供了一种能够在运行时动态操作常量池的方法。 方法区主要有以下几个特点：1、方法区是线程安全的。由于所有的线程都共享方法区，所以，方法区里的数据访问必须被设计成线程安全的。例如，假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待 2、方法区的大小不必是固定的，JVM可根据应用需要动态调整。同时，方法区也不一定是连续的，方法区可以在一个堆(甚至是JVM自己的堆)中自由分配。 3、方法区也可被垃圾收集，当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的的一部分。但这部分内存在项目中也会被频繁的使用，而且也可能导致OOM异常，所以我们一起进行归类。 在JDK1.4中新加入了NIO类，引入了一种基于通道与缓冲区的I/O方法，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的对象堆这块内存进行操作。 各区域参数设置 控制参数: -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。老年代空间大小=堆空间大小-年轻代大空间大小 资料http://www.ityouknow.com/jvm.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[bugfix-dubbo-channel-close]]></title>
    <url>%2F2018%2F02%2F06%2Fegenie_bugfix%2Fbugfix-dubbo-channel-close%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method findByIds in the service com.ejlerp.baseinfo.api.SkuService. Tried 3 times of the providers [10.27.215.53:20880, 10.26.109.140:20881] (2/3) from the registry 10.25.242.182:2181 on the consumer 118.178.19.115 using the dubbo version 2.8.4. Last error is: Failed to invoke remote method: findByIds, provider: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.SkuService?application=ejlerp-pms-provider&amp;check=false&amp;dubbo=2.8.4&amp;generic=false&amp;interface=com.ejlerp.baseinfo.api.SkuService&amp;methods=generateSkuNo,findSimpleSkuLikeSkuNo,batchFindByBarcode,findAll,saveAvoidDuplicate,translateSku,calculateWeight,queryAndTranslateSku,findByBarcode,updateColumn,queryByNo,findSimpleSkuLikeSellerOuterNoIsEnabled,getSkuSpec,findSkuLikeProductNo,updateNotEmptyById,findSimpleSkuLikeProductName,findSkuLikeProductName,isCombinedSku,findSimpleSkuByCategoryNo,findSimpleSKUBySKUNo,findSimpleSKULikeShortCutKey,findAllSimpleSku,findAllSimpleSkuIsEnabled,batchUpdateNotEmptyById,findSimpleSkuLikeSizeType,updateSku,batchInsert,save,findAllSkus,batchReplace,findSimpleSkuLikeSellerOuterNo,batchDelete,findSkubyColorType,findById,findCombinedSku,findPage,findSkuIdByCondition,deleteSkus,findSimpleSkuLikeProductNoIsEnabled,findSimpleSkuByProductIdAndColor,batchInsertAvoidDuplicate,getSkuInfoByCondition,updateOneColumnById,replace,addSku,findPageV2,findSkubySizeType,findSimpleSkuByIds,findSkuInfoForMatch,isHugeSku,findByProductIds,findSimpleSkuLikeProductShortcutKeyIsEnabled,queryByBarcode,findSimpleSkuLikeSpec,batchGenerateSkus,findSimpleSkuByProductIds,findByIds,findSkuLikeProductShortcutKey,findLikeSkuNo,findSimpleSkuLikeProductNameIsEnabled,findBySellerOuterNo,setCombinedSku,checkUniqueColumn,findByNo,hardDelete,findSimpleSkuLikeNoOrBarcode,getAllProduct,findSkuIdsByProductIds,batchUpdate,findOne,findByNos,findSimpleSkuLikeProductShortcutKey,findSkuNotInIds,update,batchHardDelete,delete,findByCondition,findDetailsBySkuId,findSkuByNoOrBarCode,findSimpleSkuByProductIdAndSize,setNeedSpec,findByProductId,findTranslateByIds,findSimpleSkuLikeSkuNoIsEnabled,findSimpleSKUByBarCode,updateSKUsCostPrice,queryLikeNo,deleteSku,findSimpleSkuLikeColorType,findSimpleSkuLikeProductNo,queryById&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=60000&amp;timestamp=1517844500677&amp;version=0.1, cause: message can not send, because channel is closed . url:dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1 at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:108) at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:227) at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:72) at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:52) at com.alibaba.dubbo.common.bytecode.proxy6.findByIds(proxy6.java) at com.ejlerp.pms.provider.service.agent.baseinfo.BaseInfoAgentService.findSkuByIds(BaseInfoAgentService.java:92) at com.ejlerp.pms.provider.service.StockOutReportServiceImpl.pageExecute(StockOutReportServiceImpl.java:114) at com.ejlerp.pms.provider.service.StockOutReportServiceImpl.refreshAction(StockOutReportServiceImpl.java:99) at com.alibaba.dubbo.common.bytecode.Wrapper51.invokeMethod(Wrapper51.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:70) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:132) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:113) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: com.alibaba.dubbo.remoting.RemotingException: message can not send, because channel is closed . url:dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1 at com.alibaba.dubbo.remoting.transport.AbstractClient.send(AbstractClient.java:268) at com.alibaba.dubbo.remoting.transport.AbstractPeer.send(AbstractPeer.java:51) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeChannel.request(HeaderExchangeChannel.java:112) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeClient.request(HeaderExchangeClient.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.ReferenceCountExchangeClient.request(ReferenceCountExchangeClient.java:81) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:96) at com.alibaba.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:144) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:53) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:48) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) at com.alibaba.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:74) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:77) ... 35 common frames omitted dubbo提供了自动重连的机制 12345678910111213141516171819202122232425262728293031323334/** * init reconnect thread */ private synchronized void initConnectStatusCheckCommand() &#123; //reconnect=false to close reconnect int reconnect = getReconnectParam(getUrl()); if (reconnect &gt; 0 &amp;&amp; (reconnectExecutorFuture == null || reconnectExecutorFuture.isCancelled())) &#123; Runnable connectStatusCheckCommand = new Runnable() &#123; public void run() &#123; try &#123; if (!isConnected()) &#123; connect(); &#125; else &#123; lastConnectedTime = System.currentTimeMillis(); &#125; &#125; catch (Throwable t) &#123; String errorMsg = &quot;client reconnect to &quot; + getUrl().getAddress() + &quot; find error . url: &quot; + getUrl(); // wait registry sync provider list if (System.currentTimeMillis() - lastConnectedTime &gt; shutdown_timeout) &#123; if (!reconnect_error_log_flag.get()) &#123; reconnect_error_log_flag.set(true); logger.error(errorMsg, t); return; &#125; &#125; if (reconnect_count.getAndIncrement() % reconnect_warning_period == 0) &#123; logger.warn(errorMsg, t); &#125; &#125; &#125; &#125;; reconnectExecutorFuture = reconnectExecutorService.scheduleWithFixedDelay(connectStatusCheckCommand, reconnect, reconnect, TimeUnit.MILLISECONDS); &#125; &#125; 日志 12345678910111213141516171819202122232018-02-06 08:10:57.798 [DubboClientReconnectTimer-thread-1] ERROR com.alibaba.dubbo.remoting.transport.AbstractClient.error - [DUBBO] client reconnect to 10.27.215.53:20880 find error . url: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1, dubbo version: 2.8.4, current host:118.178.19.115com.alibaba.dubbo.remoting.RemotingException: client(url: dubbo://10.27.215.53:20880/com.ejlerp.baseinfo.api.DictService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.DictService&amp;methods=findCustomerDicts,findDictsByType,findCustomerDictsByType,deleteCustomerDict,updateDict,findCustomerDict,findCustomerDictByKey,findAllDicts,findMaxCodeByCustomerType,addCustomerDict,findCustomerDictMapByTypes,findDictByKey,findCustomerDictsMapByType,findDicts,deleteDict,updateCustomerDict,findDictsByTypes,findCustomerDictsByTypeAndKeys,findMaxCodeByType,findCustomerDictByType,findCustomerDictByKeys,findDict,findDictsMapByType,addDict,findDictMapByTypes,findCustomerDictByValue,findDictByValue,findCustomerDictLikeValue&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844501227&amp;version=0.1) failed to connect to server /10.27.215.53:20880 client-side timeout 3000ms (elapsed: 3001ms) from netty client 118.178.19.115 using dubbo version 2.8.4 at com.alibaba.dubbo.remoting.transport.netty.NettyClient.doConnect(NettyClient.java:147) at com.alibaba.dubbo.remoting.transport.AbstractClient.connect(AbstractClient.java:280) at com.alibaba.dubbo.remoting.transport.AbstractClient$1.run(AbstractClient.java:145) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 1234567891011121314151617181920212223242018-02-06 02:34:26.962 [DubboClientReconnectTimer-thread-1] WARN com.alibaba.dubbo.remoting.transport.AbstractClient.warn - [DUBBO] client reconnect to 10.25.242.182:20885 find error . url: dubbo://10.25.242.182:20885/com.ejlerp.baseinfo.api.VendorService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.VendorService&amp;methods=findLikeVendorNo,findByVendorTenantId,updateOneColumnById,replace,findLikeVendorShortcutKey,findPageV2,findAll,saveAvoidDuplicate,findAndSaveByVendorName,findVendorIdAndNameMap,findMyVendorOL,enableVendor,findVendorNoAndIdMap,addVendor,updateColumn,findByIds,relateVendorOL,deleteVendor,checkUniqueColumn,findByNo,findByVendorName,updateNotEmptyById,hardDelete,batchUpdateNotEmptyById,batchUpdate,batchInsert,findOne,save,batchHardDelete,update,findByPuchaserId,batchReplace,delete,updateVendor,batchDelete,vendorOLSync,findById,findTmpByVendorTenantIds,findByMobile,findPage,findLikeVendorName,disableVendor,batchInsertAvoidDuplicate,findByCategoryNo,findByVendorNames&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844500217&amp;version=0.1, dubbo version: 2.8.4, current host: 118.178.19.115com.alibaba.dubbo.remoting.RemotingException: client(url: dubbo://10.25.242.182:20885/com.ejlerp.baseinfo.api.VendorService?application=ejlerp-pms-provider&amp;check=false&amp;codec=dubbo&amp;dubbo=2.8.4&amp;generic=false&amp;heartbeat=60000&amp;interface=com.ejlerp.baseinfo.api.VendorService&amp;methods=findLikeVendorNo,findByVendorTenantId,updateOneColumnById,replace,findLikeVendorShortcutKey,findPageV2,findAll,saveAvoidDuplicate,findAndSaveByVendorName,findVendorIdAndNameMap,findMyVendorOL,enableVendor,findVendorNoAndIdMap,addVendor,updateColumn,findByIds,relateVendorOL,deleteVendor,checkUniqueColumn,findByNo,findByVendorName,updateNotEmptyById,hardDelete,batchUpdateNotEmptyById,batchUpdate,batchInsert,findOne,save,batchHardDelete,update,findByPuchaserId,batchReplace,delete,updateVendor,batchDelete,vendorOLSync,findById,findTmpByVendorTenantIds,findByMobile,findPage,findLikeVendorName,disableVendor,batchInsertAvoidDuplicate,findByCategoryNo,findByVendorNames&amp;organization=ejlerp&amp;owner=victor&amp;pid=3801&amp;revision=0.1&amp;side=consumer&amp;timeout=8000&amp;timestamp=1517844500217&amp;version=0.1) failed to connect to server /10.25.242.182:20885 client-side timeout 3000ms (elapsed: 3000ms) from netty client 118.178.19.115 using dubbo version 2.8.4 at com.alibaba.dubbo.remoting.transport.netty.NettyClient.doConnect(NettyClient.java:147) at com.alibaba.dubbo.remoting.transport.AbstractClient.connect(AbstractClient.java:280) at com.alibaba.dubbo.remoting.transport.AbstractClient$1.run(AbstractClient.java:145) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 1java -Xmx150M -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintHeapAtGC -Xloggc:./pms-gc.log -jar ejlerp-pms-provider-0.2-SNAPSHOT.jar --spring.profiles.active=prod --regCenter.serverList=10.25.242.182:2181 --server.port=9087 --druid.url=jdbc:mysql://rm-bp1ov5155kw37fa31i.mysql.rds.aliyuncs.com:3306/egenie_kn --druid.username=egeniekn --druid.password=ejl@2302 --spring.datasource.url=jdbc:mysql://rm-bp1ov5155kw37fa31i.mysql.rds.aliyuncs.com:3306/job_hz1 --dubbo.registry.address=zookeeper://10.25.242.182:2181 --dubbo.protocol.host=10.25.242.182 --dubbo.monitor=false --provider.appKey=pmsP-hz1-s1 --goods.rest.host=http://www.runscm.com --pmsTradeIsOpen=0 &gt; /dev/null 2&gt;&amp;1 &amp;]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-id-generater]]></title>
    <url>%2F2018%2F02%2F06%2Fdesign%2Fstudy-id-generater%2F</url>
    <content type="text"><![CDATA[分布式的Unique ID的用途如此广泛，从业务对象Id到服务化体系里分布式调用链的TraceId http://ericliang.info/2015/01/18/what-kind-of-id-generator-we-need-in-business-systems.html http://calvin1978.blogcn.com/articles/uuid.html http://www.cnblogs.com/relucent/p/4955340.html https://tech.meituan.com/MT_Leaf.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[线上服务无法打印异常]]></title>
    <url>%2F2018%2F02%2F05%2Fegenie_bugfix%2Fbugfix-log-erro%2F</url>
    <content type="text"><![CDATA[线上异常无堆栈信息12342018-02-04 15:27:54.153 [DubboServerHandler-10.26.235.193:20884-thread-100] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.26.235.193. service: com.ejlerp.pms.api.ArrivalRecordService, method: purchaseConfirm, exception: java.lang.NullPointerException: null, dubbo version: 2.8.4, current host: 10.26.235.193java.lang.NullPointerException: null 无任何其他异常信息 查看dubbo源码:ExceptionFilter 123logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + exception.getClass().getName() + &quot;: &quot; + exception.getMessage(), exception); 问题排查 对比每天的日志:发现升级后就出现了问题 对比其他机器是否有该问题:都有 对比生产/测试环境是否有该问题:发现hz6有问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566672018-02-02 14:12:51.230 [DubboServerHandler-10.47.124.90:20886-thread-86] ERROR com.alibaba.dubbo.rpc.filter.ExceptionFilter.error - [DUBBO] Got unchecked and undeclared exception which called by 10.47.124.90. service: com.ejlerp.pms.api.ArrivalRecordService, method: purchaseConfirm, exception: java.lang.NullPointerException: null, dubbo version: 2.8.4, current host: 10.47.124.90java.lang.NullPointerException: null at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl.batchUpdate(BaseDaoImpl.java:766) at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl$$FastClassBySpringCGLIB$$26be7043.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.dao.jdbc.PurchaseOrderDetailDaoImpl$$EnhancerBySpringCGLIB$$4f4f9329.batchUpdate(&lt;generated&gt;) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl.batchUpdate(PurchaseOrderDetailServiceImpl.java:963) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl$$FastClassBySpringCGLIB$$e0903e90.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.PurchaseOrderDetailServiceImpl$$EnhancerBySpringCGLIB$$a4c2c1fc.batchUpdate(&lt;generated&gt;) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl.handleUniqueCodeArrive(DailyPurchaseDetailServiceImpl.java:830) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl.updatePurchaseState(DailyPurchaseDetailServiceImpl.java:773) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl$$FastClassBySpringCGLIB$$d0f852c3.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.DailyPurchaseDetailServiceImpl$$EnhancerBySpringCGLIB$$5a3b675.updatePurchaseState(&lt;generated&gt;) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl.purchaseConfirm(ArrivalRecordServiceImpl.java:166) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl$$FastClassBySpringCGLIB$$eab61da4.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:282) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.adapter.MethodBeforeAdviceInterceptor.invoke(MethodBeforeAdviceInterceptor.java:52) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:97) at com.ejlerp.dal.framework.service.advice.AvoidRepeatInvokeAdvice.aroundAdvice(AvoidRepeatInvokeAdvice.java:131) at sun.reflect.GeneratedMethodAccessor266.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:629) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:618) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:47) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:168) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.ejlerp.pms.provider.service.ArrivalRecordServiceImpl$$EnhancerBySpringCGLIB$$c67e6bb8.purchaseConfirm(&lt;generated&gt;) at com.alibaba.dubbo.common.bytecode.Wrapper64.invokeMethod(Wrapper64.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) 问题问题1(业务错误)java.lang.NullPointerException: null at com.ejlerp.dal.framework.dao.impl.BaseDaoImpl.batchUpdate(BaseDaoImpl.java:766) 问题2 jvm jit编译优化由于服务一直没有重启过,在导致过多次数的异常后,jvm对异常进行了优化 OmitStackTraceInFastThrow参数在生产环境JRE 运行在server 模式下， 从日志上看大量的NullPointException日志打印时，没有堆栈信息输出。查了一下，JIT编译会对某些异常如果大量的抛出时，会进行优化，删除堆栈信息。 这是HotSpot VM专门针对异常做的一个优化，称为fast throw，当一些异常在代码里某个特定位置被抛出很多次的话，HotSpot Server Compiler（C2）会用fast throw来优化这个抛出异常的地方，直接抛出一个事先分配好的、类型匹配的对象，这个对象的message和stack trace都被清空。 可以明确：抛出这个异常非常快，不用额外分配内存，也不用爬栈。 -XX:-OmitStackTraceInFastThrow 关闭异常堆栈优化 -Xint 以解释模式执行 加号则表示启用减号代表关闭 启动脚本里没有添加-server参数-server，在64位linux中，你想设成-client都不行的，所以写了也是白写。 在排查问题时,发现的另一个错误用法启动脚本错误: 1&gt;/dev/null 2&gt; 1 &amp; 正确 1&gt; /dev/null 2&gt;&amp;1 &amp; http://www.cnblogs.com/caolisong/archive/2007/04/25/726896.html]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
        <tag>jvm</tag>
        <tag>OmitStackTraceInFastThrow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-common]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-common%2F</url>
    <content type="text"><![CDATA[ExtensionLoader源码扩展点是Dubbo的核心，而扩展点的核心则是ExtensionLoader，这个类有点类似ClassLoader，但是ExtensionLoader是加载Dubbo的扩展点的。下面列出ExtensionLoader几个重要的属性结构。 123456789101112public class ExtensionLoader&lt;T&gt; &#123;private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;();private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; EXTENSION_INSTANCES = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;();private final Class&lt;?&gt; type;private final ExtensionFactory objectFactory;private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;Map&lt;String,Class&lt;?&gt;&gt;&gt;();private final Holder&lt;Object&gt; cachedAdaptiveInstance = new Holder&lt;Object&gt;();&#125; 可以看到EXTENSION_LOADERS属性是一个static final的，那么说明应该是一个常量，这个就是用来装载dubbo的所有扩展点的ExtensionLoader 在Dubbo中，每种类型的扩展点都会有一个与其对应的ExtensionLoader，类似jvm中每个Class都会有一个ClassLoader,每个ExtensionLoader会包含多个该扩展点的实现，类似一个ClassLoader可以加载多个具体的类，但是不同的ExtensionLoader之间是隔离的，这点也和ClassLoader类似。那么理解dubbo的ExtensionLoader可以拿ClassLoader来进行类比，这样会加快自己对它的理解。 另一个常量属性是EXTENSION_INSTANCES，他是一个具体扩展类的实体，用于缓存，防止由于扩展点比较重，导致会浪费没必要的资源，所以在实现扩展点的时候，一定要确保扩展点可单例化，否则可能会出现问题。 另一个重要的属性是type，这里的type一般是接口，用于制定扩展点的类型，因为dubbo的扩展点申明是SPI的方式，所以某一个类型扩展点，就需要申明一个扩展点接口。 1234private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 在ExtensionLoader.getExtensionLoader(ExtensionFactory.class)之后，不是直接返回某个扩展点，而是调用getAdaptiveExtension来获取一个扩展的适配器，这是为什么呢？因为一个扩展点有多个具体扩展的实现，那么直接通过ExtensionLoader直接返回一个扩展是不可靠的，需要一个适配器来根据实际情况返回具体的扩展实现。所以这里就有了cachedAdaptiveInstance属性的存在，dubbo里面的每个扩展的ExtensionLoader都有一个cachedAdaptiveInstance，这个属性的类型必须实现ExtensionLoader.type接口，这就是设计模式中的适配器模式。比如ExtensionFactory扩展点就有AdaptiveExtensionFactory适配器。扩展点的适配器可以是自己通过@Adaptive，也可以不提供实现，由dubbo通过动态生成Adaptive来提供一个适配器类。此处需要注意：Adaptive也是扩展点的某个实现，下面例举出ExtensionFactory扩展点的适配器 cachedClasses,这个就是存储当前ExtensionLoader有哪些扩展点实现，从而可以实例化出某个具体的扩展点实体，cachedClasses声明为Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt;类型，其实可以理解为是Map&lt;String, Class&lt;?&gt;&gt;类型，Map的key是在type.getName文件中的=之前的内容，value这是这个扩展点实现的类对象了。 小结 1、一个扩展点类型一定是一个接口 2、一个扩展点一定对应一个ExtensionLoader 3、一个ExtensionLoader一定有一个Adapter 4、一个扩展点可以有多个实现，并且都是用一个ExtensionLoader进行加载 5、一个ExtensionLoader（除去ExtensionFactory扩展）都要有一个ExtensionFactory]]></content>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-filter]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-filter%2F</url>
    <content type="text"><![CDATA[dubbo中提供的Filter实现1234567891011121314echo=com.alibaba.dubbo.rpc.filter.EchoFiltergeneric=com.alibaba.dubbo.rpc.filter.GenericFiltergenericimpl=com.alibaba.dubbo.rpc.filter.GenericImplFiltertoken=com.alibaba.dubbo.rpc.filter.TokenFilteraccesslog=com.alibaba.dubbo.rpc.filter.AccessLogFilteractivelimit=com.alibaba.dubbo.rpc.filter.ActiveLimitFilterclassloader=com.alibaba.dubbo.rpc.filter.ClassLoaderFiltercontext=com.alibaba.dubbo.rpc.filter.ContextFilterconsumercontext=com.alibaba.dubbo.rpc.filter.ConsumerContextFilterexception=com.alibaba.dubbo.rpc.filter.ExceptionFilterexecutelimit=com.alibaba.dubbo.rpc.filter.ExecuteLimitFilterdeprecated=com.alibaba.dubbo.rpc.filter.DeprecatedFiltercompatible=com.alibaba.dubbo.rpc.filter.CompatibleFiltertimeout=com.alibaba.dubbo.rpc.filter.TimeoutFilter 顺序服务提供方的过滤器被调用顺序：EchoFilter-&gt;ClassLoaderFilter-&gt;GenericFilter-&gt;ContextFilter-&gt;(这4个是在代码中指定的)ExceptionFilter-&gt; TimeoutFilter -&gt;MonitorFilter-&gt; TraceFilter服务消费方的过滤器顺序：ConsumerContextFilter-&gt;FutureFilter-&gt;MonitorFilter负责加载过滤器的类ProtocolFilterWrapper 构建Filter链1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//providerpublic &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); &#125;//consumerpublic &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER); &#125;private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; Invoker&lt;T&gt; last = invoker; List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; for (int i = filters.size() - 1; i &gt;= 0; i--) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last; &#125; ExceptionFilter某个系统调用dubbo请求，provider端（服务提供方）抛出了自定义的业务异常，但consumer端（服务消费方）拿到的并不是自定义的业务异常。这是为什么呢？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Activate(group = Constants.PROVIDER) public class ExceptionFilter implements Filter &#123; private final Logger logger; public ExceptionFilter() &#123; this(LoggerFactory.getLogger(ExceptionFilter.class)); &#125; public ExceptionFilter(Logger logger) &#123; this.logger = logger; &#125; public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; Result result = invoker.invoke(invocation); if (result.hasException() &amp;&amp; GenericService.class != invoker.getInterface()) &#123; try &#123; Throwable exception = result.getException(); // 如果是checked异常，直接抛出 if (! (exception instanceof RuntimeException) &amp;&amp; (exception instanceof Exception)) &#123; return result; &#125; // 在方法签名上有声明，直接抛出 try &#123; Method method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes()); Class&lt;?&gt;[] exceptionClassses = method.getExceptionTypes(); for (Class&lt;?&gt; exceptionClass : exceptionClassses) &#123; if (exception.getClass().equals(exceptionClass)) &#123; return result; &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; return result; &#125; // 未在方法签名上定义的异常，在服务器端打印ERROR日志 logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + exception.getClass().getName() + &quot;: &quot; + exception.getMessage(), exception); // 异常类和接口类在同一jar包里，直接抛出 String serviceFile = ReflectUtils.getCodeBase(invoker.getInterface()); String exceptionFile = ReflectUtils.getCodeBase(exception.getClass()); if (serviceFile == null || exceptionFile == null || serviceFile.equals(exceptionFile))&#123; return result; &#125; // 是JDK自带的异常，直接抛出 String className = exception.getClass().getName(); if (className.startsWith(&quot;java.&quot;) || className.startsWith(&quot;javax.&quot;)) &#123; return result; &#125; // 是Dubbo本身的异常，直接抛出 if (exception instanceof RpcException) &#123; return result; &#125; // 否则，包装成RuntimeException抛给客户端 return new RpcResult(new RuntimeException(StringUtils.toString(exception))); &#125; catch (Throwable e) &#123; logger.warn(&quot;Fail to ExceptionFilter when called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + e.getClass().getName() + &quot;: &quot; + e.getMessage(), e); return result; &#125; &#125; return result; &#125; catch (RuntimeException e) &#123; logger.error(&quot;Got unchecked and undeclared exception which called by &quot; + RpcContext.getContext().getRemoteHost() + &quot;. service: &quot; + invoker.getInterface().getName() + &quot;, method: &quot; + invocation.getMethodName() + &quot;, exception: &quot; + e.getClass().getName() + &quot;: &quot; + e.getMessage(), e); throw e; &#125; &#125; &#125; http://blog.csdn.net/mj158518/article/details/51228649]]></content>
  </entry>
  <entry>
    <title><![CDATA[source-dubbo-loadbalance]]></title>
    <url>%2F2018%2F02%2F03%2Fjava_dubbo%2Fsource-dubbo-loadbalance%2F</url>
    <content type="text"><![CDATA[负载均衡在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。 https://dubbo.gitbooks.io/dubbo-dev-book/content/impls/load-balance.html https://dubbo.gitbooks.io/dubbo-dev-book/content/impls/load-balance.html 负载均衡策略Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.arguments&quot; value=&quot;0,1&quot; /&gt; 缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=&quot;hash.nodes&quot; value=&quot;320&quot; /&gt; Random试验启动两个provider,consumer新建200个线程,结果如下,总体上是平衡的 consumer程序1234567891011121314151617181920212223242526272829303132public static void main(String[] args) throws InterruptedException &#123; //Prevent to get IPV6 address,this way only work in debug mode //But you can pass use -Djava.net.preferIPv4Stack=true,then it work well whether in debug mode or not System.setProperty(&quot;java.net.preferIPv4Stack&quot;, &quot;true&quot;); ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;&quot;META-INF/spring/dubbo-demo-consumer.xml&quot;&#125;); context.start(); DemoService demoService = (DemoService) context.getBean(&quot;demoService&quot;); // get remote service proxy ExecutorService executorService = Executors.newFixedThreadPool(200); MyTask myTask = new MyTask(demoService); for (int i = 0; i &lt; 1000; i++) &#123; Thread.sleep(1000); executorService.submit(myTask); &#125; &#125; public static class MyTask implements Runnable &#123; private DemoService demoService; public MyTask(DemoService demoService) &#123; this.demoService = demoService; &#125; @Override public void run() &#123; String hello = demoService.sayHello(&quot;world&quot;); // call remote method System.out.println(hello); // get result &#125; &#125; 结果1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20882Hello world, response form provider: 192.168.0.100:20881]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>loadbalance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm-jstack]]></title>
    <url>%2F2018%2F02%2F02%2Fjava_jvm%2Fjvm-jstack%2F</url>
    <content type="text"><![CDATA[jstackjstack命令的语法格式： jstack 。可以用jps查看java进程id。这里要注意的是： 不同的 JAVA虚机的线程 DUMP的创建方法和文件格式是不一样的，不同的 JVM版本， dump信息也有差别。 在实际运行中，往往一次 dump的信息，还不足以确认问题。建议产生三次 dump信息，如果每次 dump都指向同一个问题，我们才确定问题的典型性。 jstack Dump 日志文件中的线程状态dump 文件里，值得关注的线程状态有 死锁， Deadlock（重点关注） 执行中，Runnable 等待资源， Waiting on condition（重点关注） 等待获取监视器， Waiting on monitor entry（重点关注） 暂停，Suspended 对象等待中，Object.wait() 或 TIMED_WAITING 阻塞， Blocked（重点关注） 停止，Parked Dump文件中的线程状态含义及注意事项 Deadlock：死锁线程，一般指多个线程调用间，进入相互资源占用，导致一直等待无法释放的情况。 Runnable：一般指该线程正在执行状态中，该线程占用了资源，正在处理某个请求，有可能正在传递SQL到数据库执行，有可能在对某个文件操作，有可能进行数据类型等转换。 Waiting on condition：该状态出现在线程等待某个条件的发生。具体是什么原因，可以结合 stacktrace来分析。最常见的情况是线程在等待网络的读写，比如当网络数据没有准备好读时，线程处于这种等待状态，而一旦有数据准备好读之后，线程会重新激活，读取并处理数据。在 Java引入 NewIO之前，对于每个网络连接，都有一个对应的线程来处理网络的读写操作，即使没有可读写的数据，线程仍然阻塞在读写操作上，这样有可能造成资源浪费，而且给操作系统的线程调度也带来压力。在 NewIO里采用了新的机制，编写的服务器程序的性能和可扩展性都得到提高。 如果发现有大量的线程都在处在 Wait on condition，从线程 stack看， 正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。一种情况是网络非常忙，几 乎消耗了所有的带宽，仍然有大量数据等待网络读 写；另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。所以要结合系统的一些性能观察工具来综合分析，比如 netstat统计单位时间的发送包的数目，如果很明显超过了所在网络带宽的限制 ; 观察 cpu的利用率，如果系统态的 CPU时间，相对于用户态的 CPU时间比例较高；如果程序运行在 Solaris 10平台上，可以用 dtrace工具看系统调用的情况，如果观察到 read/write的系统调用的次数或者运行时间遥遥领先；这些都指向由于网络带宽所限导致的网络瓶颈。另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒。 locked：线程阻塞，是指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源超时的线程。 Waiting for monitor entry 和 in Object.wait()：Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。 参数使用案例案例11.使用jps命令，获取需要调优的进程id为46924.2.使用top -Hp 46924命令获得最耗费资源的线程号(pid), TIME列就是各个Java线程耗费的CPU时间,这里我们选58767线程作为例子.3.使用printf “%x\n”，获得十六进制值。4.使用jstack命令，它用来输出进程46924的堆栈信息，然后根据线程ID(58767)的十六进制值grep，如下：这里就知道了最耗费时间的类是com.mchange.v2.async.ThreadPoolAsynchronousRunner$PoolThread-#2，Tomcat的线程池，方法是Object.wait()。]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo线程池相关源码解析]]></title>
    <url>%2F2018%2F02%2F02%2Fjava_dubbo%2Fsource-dubbo-thread-pool%2F</url>
    <content type="text"><![CDATA[dubbo几种线程池选择http://dubbo.io/books/dubbo-user-book/demos/thread-model.htmlThreadPool fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省) cached 缓存线程池，空闲一分钟自动删除，需要时重建。 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。 读取几个参数: threads:服务线程池大小(固定大小) queues:线程池队列大小，当线程池满时，排队等待执行的队列大小，建议不要设置，当线程程池时应立即失败，重试其它服务提供机器，而不是排队，除非有特殊需求 1234567891011121314public class FixedThreadPool implements ThreadPool &#123; public Executor getExecutor(URL url) &#123; String name = url.getParameter(Constants.THREAD_NAME_KEY, Constants.DEFAULT_THREAD_NAME); int threads = url.getParameter(Constants.THREADS_KEY, Constants.DEFAULT_THREADS); int queues = url.getParameter(Constants.QUEUES_KEY, Constants.DEFAULT_QUEUES); return new ThreadPoolExecutor(threads, threads, 0, TimeUnit.MILLISECONDS, queues == 0 ? new SynchronousQueue&lt;Runnable&gt;() : (queues &lt; 0 ? new LinkedBlockingQueue&lt;Runnable&gt;() : new LinkedBlockingQueue&lt;Runnable&gt;(queues)), new NamedThreadFactory(name, true), new AbortPolicyWithReport(name, url)); &#125;&#125; iothreads:IO线程池，接收网络读写中断，以及序列化和反序列化，不处理业务，业务线程池参见threads配置，此线程池和CPU相关，不建议配置。dubbo 中使用该参数初始化nettypublic static final int DEFAULT_IO_THREADS = Math.min(Runtime.getRuntime().availableProcessors() + 1, 32); 123456789101112131415161718192021222324252627282930313233protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap = new ServerBootstrap(); bossGroup = new NioEventLoopGroup(1, new DefaultThreadFactory(&quot;NettyServerBoss&quot;, true)); workerGroup = new NioEventLoopGroup(getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS), new DefaultThreadFactory(&quot;NettyServerWorker&quot;, true)); final NettyServerHandler nettyServerHandler = new NettyServerHandler(getUrl(), this); channels = nettyServerHandler.getChannels(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childOption(ChannelOption.TCP_NODELAY, Boolean.TRUE) .childOption(ChannelOption.SO_REUSEADDR, Boolean.TRUE) .childOption(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyServer.this); ch.pipeline()//.addLast(&quot;logging&quot;,new LoggingHandler(LogLevel.INFO))//for debug .addLast(&quot;decoder&quot;, adapter.getDecoder()) .addLast(&quot;encoder&quot;, adapter.getEncoder()) .addLast(&quot;handler&quot;, nettyServerHandler); &#125; &#125;); // bind ChannelFuture channelFuture = bootstrap.bind(getBindAddress()); channelFuture.syncUninterruptibly(); channel = channelFuture.channel(); &#125; dubbo的线程池拒绝策略AbortPolicyWithReport: dump线程信息 打印error日志 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class AbortPolicyWithReport extends ThreadPoolExecutor.AbortPolicy &#123; protected static final Logger logger = LoggerFactory.getLogger(AbortPolicyWithReport.class); private final String threadName; private final URL url; private static volatile long lastPrintTime = 0; private static Semaphore guard = new Semaphore(1); public AbortPolicyWithReport(String threadName, URL url) &#123; this.threadName = threadName; this.url = url; &#125; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; String msg = String.format(&quot;Thread pool is EXHAUSTED!&quot; + &quot; Thread Name: %s, Pool Size: %d (active: %d, core: %d, max: %d, largest: %d), Task: %d (completed: %d),&quot; + &quot; Executor status:(isShutdown:%s, isTerminated:%s, isTerminating:%s), in %s://%s:%d!&quot;, threadName, e.getPoolSize(), e.getActiveCount(), e.getCorePoolSize(), e.getMaximumPoolSize(), e.getLargestPoolSize(), e.getTaskCount(), e.getCompletedTaskCount(), e.isShutdown(), e.isTerminated(), e.isTerminating(), url.getProtocol(), url.getIp(), url.getPort()); logger.warn(msg); dumpJStack(); throw new RejectedExecutionException(msg); &#125; private void dumpJStack() &#123; long now = System.currentTimeMillis(); //dump every 10 minutes if (now - lastPrintTime &lt; 10 * 60 * 1000) &#123; return; &#125; if (!guard.tryAcquire()) &#123; return; &#125; Executors.newSingleThreadExecutor().execute(new Runnable() &#123; @Override public void run() &#123; String dumpPath = url.getParameter(Constants.DUMP_DIRECTORY, System.getProperty(&quot;user.home&quot;)); SimpleDateFormat sdf; String OS = System.getProperty(&quot;os.name&quot;).toLowerCase(); // window system don&apos;t support &quot;:&quot; in file name if(OS.contains(&quot;win&quot;))&#123; sdf = new SimpleDateFormat(&quot;yyyy-MM-dd_HH-mm-ss&quot;); &#125;else &#123; sdf = new SimpleDateFormat(&quot;yyyy-MM-dd_HH:mm:ss&quot;); &#125; String dateStr = sdf.format(new Date()); FileOutputStream jstackStream = null; try &#123; jstackStream = new FileOutputStream(new File(dumpPath, &quot;Dubbo_JStack.log&quot; + &quot;.&quot; + dateStr)); JVMUtil.jstack(jstackStream); &#125; catch (Throwable t) &#123; logger.error(&quot;dump jstack error&quot;, t); &#125; finally &#123; guard.release(); if (jstackStream != null) &#123; try &#123; jstackStream.flush(); jstackStream.close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; lastPrintTime = System.currentTimeMillis(); &#125; &#125;); &#125;&#125; 模拟dubbo线程池满时的情景consumer程序:1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; //Prevent to get IPV6 address,this way only work in debug mode //But you can pass use -Djava.net.preferIPv4Stack=true,then it work well whether in debug mode or not System.setProperty("java.net.preferIPv4Stack", "true"); ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;"META-INF/spring/dubbo-demo-consumer.xml"&#125;); context.start(); DemoService demoService = (DemoService) context.getBean("demoService"); // get remote service proxy ExecutorService executorService = Executors.newFixedThreadPool(1000); MyTask myTask = new MyTask(demoService); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit(myTask); &#125; &#125; public static class MyTask implements Runnable &#123; private DemoService demoService; public MyTask(DemoService demoService) &#123; this.demoService = demoService; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); String hello = demoService.sayHello("world"); // call remote method System.out.println(hello); // get result &#125; &#125; provider程序:12345678910111213141516public class DemoServiceImpl implements DemoService &#123; private static final Logger logger = LoggerFactory.getLogger(DemoService.class); public String sayHello(String name) &#123; try &#123; System.out.println(Thread.currentThread().getName()); Thread.sleep(10000000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("[" + new SimpleDateFormat("HH:mm:ss").format(new Date()) + "] Hello " + name + ", request from consumer: " + RpcContext.getContext().getRemoteAddress()); return "Hello " + name + ", response form provider: " + RpcContext.getContext().getLocalAddress(); &#125;&#125; consumer日志:1234[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-39 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1562, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-30 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1561, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-59 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1560, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100[03/02/18 01:41:43:043 CST] DubboClientHandler-192.168.0.100:20881-thread-57 WARN support.DefaultFuture: [DUBBO] The timeout response finally returned at 2018-02-03 13:41:43.668, response Response [id=1559, version=null, status=100, event=false, error=Server side(192.168.0.100,20881) threadpool is exhausted ,detail msg:Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20881, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20881!, result=null], channel: /192.168.0.100:62100 -&gt; /192.168.0.100:20881, dubbo version: 2.0.0, current host: 192.168.0.100 provider日志:1234567891011DubboServerHandler-192.168.0.100:20880-thread-197DubboServerHandler-192.168.0.100:20880-thread-198DubboServerHandler-192.168.0.100:20880-thread-199DubboServerHandler-192.168.0.100:20880-thread-200DubboServerHandler-192.168.0.100:20880-thread-1[02/02/18 10:53:44:044 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[02/02/18 10:53:45:045 CST] New I/O worker #1 WARN support.AbortPolicyWithReport: [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-192.168.0.100:20880, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 201 (completed: 1), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://192.168.0.100:20880!, dubbo version: 2.0.0, current host: 192.168.0.100[0 dump的文件1-rw-r--r-- 1 victor staff 599770 2 2 13:41 Dubbo_JStack.log.2018-02-02_13:41:34 其他结论1:奇怪的现象provider启动一次,两次启动consumer,发现第二次consumer不会报错线程池满的异常 其他结论2:只有超时时间到后,才会报线程池满的异常]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>线程池</tag>
        <tag>AbortPolicy</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-java-lock]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_lock%2Fstudy-java-lock%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728锁的实现在关于锁的面试过程中，一般主要问Synchronized和ReentrantLock的实现原理，更有甚者会问一些读写锁。场景对话：面试官：都了解Java中的什么锁？我：比如Synchronized和ReentrantLock...读写锁用的不多，就没研究了面试官：那好，你先说说Synchronized的实现原理吧我：嗯，Synchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中...&amp;&amp;@@#，（嗯，说了一大堆，面试官也没打断我）面试官：哦，嗯，理解的还挺透彻，那你说说ReentrantLock的实现吧...我：ReentrantLock是基于AQS实现的面试官：什么是AQS？我：在AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒&amp;&amp;&amp;$$（又说了一堆）面试官：能说说CAS的实现原理么？我：CAS是通过unsafe类的compareAndSwap方法实现的（心里得意的一笑）面试官：哦，好的，那你知道这个方法的参数的含义的么？我：（这是在逼我啊...努力的回想，因为我真的看过啊）我想想啊，这个方法看的时间有点久远了，第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值....（说出来之后都有点佩服自己，这个都记得，不过面试官好像还是不肯放过我...）面试官：嗯，对的，那你知道操作系统级别是如何实现的么？我：（我去你大爷...）我只记得X86中有一个cmp开头的指令，具体的我忘记了...面试官：嗯，好，你知道CAS指令有什么缺点么我：哦，CAS的缺点是存在ABA问题面试官：怎么讲？我：就是一个变量V，如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。面试官：那怎么解决？我：（有完没完了啊...我的心里是崩溃的）针对这种情况，java并发包中提供了一个带有标记的原子引用类&quot;AtomicStampedReference&quot;，它可以通过控制变量值的版本来保证CAS的正确性。本来转载自公众号 占小狼的博客作者占小狼 来自 美团点评 基础架构组 Java 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现 ACC_SYNCHRONIZED 虚拟机位数 头对象结构 说明 32/64bit Mark Word 存储对象的hashCode、锁信息或分代年龄或GC标志等信息 32/64bit Class Metadata Address 类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的实例。]]></content>
  </entry>
  <entry>
    <title><![CDATA[study-Synchronized-lock]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_jvm%2Fstudy-Synchronized-lock%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728锁的实现在关于锁的面试过程中，一般主要问Synchronized和ReentrantLock的实现原理，更有甚者会问一些读写锁。场景对话：面试官：都了解Java中的什么锁？我：比如Synchronized和ReentrantLock...读写锁用的不多，就没研究了面试官：那好，你先说说Synchronized的实现原理吧我：嗯，Synchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中...&amp;&amp;@@#，（嗯，说了一大堆，面试官也没打断我）面试官：哦，嗯，理解的还挺透彻，那你说说ReentrantLock的实现吧...我：ReentrantLock是基于AQS实现的面试官：什么是AQS？我：在AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒&amp;&amp;&amp;$$（又说了一堆）面试官：能说说CAS的实现原理么？我：CAS是通过unsafe类的compareAndSwap方法实现的（心里得意的一笑）面试官：哦，好的，那你知道这个方法的参数的含义的么？我：（这是在逼我啊...努力的回想，因为我真的看过啊）我想想啊，这个方法看的时间有点久远了，第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值....（说出来之后都有点佩服自己，这个都记得，不过面试官好像还是不肯放过我...）面试官：嗯，对的，那你知道操作系统级别是如何实现的么？我：（我去你大爷...）我只记得X86中有一个cmp开头的指令，具体的我忘记了...面试官：嗯，好，你知道CAS指令有什么缺点么我：哦，CAS的缺点是存在ABA问题面试官：怎么讲？我：就是一个变量V，如果变量V初次读取的时候是A，并且在准备赋值的时候检查到它仍然是A，那能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了B，然后又改回A，那CAS操作就会误认为它从来没有被修改过。面试官：那怎么解决？我：（有完没完了啊...我的心里是崩溃的）针对这种情况，java并发包中提供了一个带有标记的原子引用类&quot;AtomicStampedReference&quot;，它可以通过控制变量值的版本来保证CAS的正确性。本来转载自公众号 占小狼的博客作者占小狼 来自 美团点评 基础架构组 理解Java对象头与MonitorJava 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现 ACC_SYNCHRONIZED synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class Metadata Address 组成，其结构说明如下表： 其中Mark Word在默认情况下存储着对象的HashCode、分代年龄、锁标记位等以下是32位JVM的Mark Word默认存储结构 由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间，如32位JVM下，除了上述列出的Mark Word默认存储结构外，还有如下可能变化的结构： 其中轻量级锁和偏向锁是Java 6 对 synchronized 锁进行优化后新增加的，稍后我们会简要分析。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示 由此看来，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因(关于这点稍后还会进行分析)，ok~，有了上述知识基础后，下面我们将进一步分析synchronized在字节码层面的具体语义实现。 1234563: monitorenter //进入同步方法//..........省略其他 15: monitorexit //退出同步方法16: goto 24//省略其他.......21: monitorexit //退出同步方法 --抛异常时退出同步方法 从字节码中可知同步语句块的实现使用的是monitorenter 和 monitorexit 指令，其中monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 synchronized代码块底层原理方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构(method_info Structure) 中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。下面我们看看字节码层面如何实现： 1234567891011121314151617181920212223242526272829 Last modified 2017-6-2; size 308 bytes MD5 checksum f34075a8c059ea65e4cc2fa610e0cd94 Compiled from &quot;SyncMethod.java&quot;public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10&#125;SourceFile: &quot;SyncMethod.java&quot; 从字节码中可以看出，synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。同时我们还必须注意到的是在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。 Java虚拟机对synchronized的优化锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，关于重量级锁，前面我们已详细分析过，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段，这里并不打算深入到每个锁的实现和转换过程更多地是阐述Java虚拟机所提供的每个锁的核心优化思想，毕竟涉及到具体过程比较繁琐，如需了解详细过程可以查阅《深入理解Java虚拟机原理》。 偏向锁(单线程)偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。 轻量级锁(线程交替执行同步块的场合)倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁(针对线程持有锁的时间都不会太长)轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 锁消除(针对局部变量)消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 关于synchronized 可能需要了解的关键点synchronized的可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。每次重入，monitor中的计数器仍会加1。 线程中断与synchronized线程中断当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态) 除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的.应该使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。综合所述，可以简单总结一下中断两种情况，一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写： 12345678910public void run()&#123; try &#123; //判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位 while (!Thread.interrupted()) &#123; TimeUnit.SECONDS.sleep(2); &#125; &#125; catch (InterruptedException e) &#123; &#125;&#125; 中断与synchronized事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。 等待唤醒机制与synchronized所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。 需要特别理解的一点是，与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。 参考http://blog.csdn.net/javazejian/article/details/72828483]]></content>
  </entry>
  <entry>
    <title><![CDATA[dubbo-概述]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_dubbo%2Fsource-dubbo-total%2F</url>
    <content type="text"><![CDATA[各层说明 config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类 proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService protocol 远程调用层：封将 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool 接口verion1 接口verion2 基类模板方法–&gt;链式过滤器1234567891011121314151617public abstract AbstractInvoker implements Invoker &#123; public Result invoke(Invocation inv) throws RpcException &#123; // 伪代码 active ++; if (active &gt; max) wait(); doInvoke(inv); active --; notify(); &#125; protected abstract Result doInvoke(Invocation inv) throws RpcException &#125; 123456789101112131415public abstract LimitFilter implements Filter &#123; public Result invoke(Invoker chain, Invocation inv) throws RpcException &#123; // 伪代码 active ++; if (active &gt; max) wait(); chain.invoke(inv); active --; notify(); &#125; &#125; Invoker, Exporter, InvocationHandler, FilterChain 其实都是 invoke 行为的不同阶段，完全可以抽象掉，统一为 Invoker，减少概念。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source_dubbo_invoke]]></title>
    <url>%2F2018%2F02%2F01%2Fjava_dubbo%2Fsource-dubbo-invoke%2F</url>
    <content type="text"><![CDATA[消费方:123456789101112131415161718&quot;main@1&quot; prio=5 tid=0x1 nid=NA runnable java.lang.Thread.State: RUNNABLE at com.alibaba.dubbo.rpc.protocol.dubbo.DubboInvoker.doInvoke(DubboInvoker.java:69) at com.alibaba.dubbo.rpc.protocol.AbstractInvoker.invoke(AbstractInvoker.java:142) at com.alibaba.dubbo.rpc.listener.ListenerInvokerWrapper.invoke(ListenerInvokerWrapper.java:73) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:74) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.FutureFilter.invoke(FutureFilter.java:53) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ConsumerContextFilter.invoke(ConsumerContextFilter.java:47) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:52) at com.alibaba.dubbo.rpc.cluster.support.FailoverClusterInvoker.doInvoke(FailoverClusterInvoker.java:77) at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:232) at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:70) at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:51) at com.alibaba.dubbo.common.bytecode.proxy0.sayHello(proxy0.java:-1) at com.alibaba.dubbo.demo.consumer.Consumer.main(Consumer.java:35) 入口:InvokerInvocationHandlerDubboInvoker1234567891011121314151617181920212223242526272829303132333435protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); &#125; else if (isAsync) &#123; ResponseFuture future = currentClient.request(inv, timeout); RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); return new RpcResult(); &#125; else &#123; RpcContext.getContext().setFuture(null); return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123; throw new RpcException(RpcException.TIMEOUT_EXCEPTION, &quot;Invoke remote method timeout. method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125; catch (RemotingException e) &#123; throw new RpcException(RpcException.NETWORK_EXCEPTION, &quot;Failed to invoke remote method: &quot; + invocation.getMethodName() + &quot;, provider: &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125; &#125; 提供方1234567891011121314151617181920212223242526272829303132&quot;DubboServerHandler-192.168.1.4:20880-thread-10@3010&quot; daemon prio=5 tid=0x26 nid=NA runnable java.lang.Thread.State: RUNNABLE at com.alibaba.dubbo.demo.provider.DemoServiceImpl.sayHello(DemoServiceImpl.java:28) at com.alibaba.dubbo.common.bytecode.Wrapper1.invokeMethod(Wrapper1.java:-1) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:45) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:71) at com.alibaba.dubbo.config.invoker.DelegateProviderMetaDataInvoker.invoke(DelegateProviderMetaDataInvoker.java:48) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:52) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:61) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:74) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:41) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:77) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:71) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:131) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:99) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:168) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:50) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:79) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ChannelEventRunnable]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_map_reduce]]></title>
    <url>%2F2018%2F01%2F31%2Fdata_warehouse%2Fstudy-map-reduce%2F</url>
    <content type="text"><![CDATA[处理流程 在正式执行 Map 前，需要将输入数据进行 分片。所谓分片，就是将输入数据切分为大小相等的数据块，每一块作为单个 Map Worker 的输入被处理，以便于多个 Map Worker 同时工作。&lt; !– more –&gt; 分片完毕后，多个 Map Worker 便可同时工作。每个 Map Worker 在读入各自的数据后，进行计算处理，最终输出给 Reduce。Map Worker 在输出数据时，需要为每一条输出数据指定一个 Key，这个 Key 值决定了这条数据将会被发送给哪一个 Reduce Worker。Key 值和 Reduce Worker 是多对一的关系，具有相同 Key 的数据会被发送给同一个 Reduce Worker，单个 Reduce Worker 有可能会接收到多个 Key 值的数据。 在进入 Reduce 阶段之前，MapReduce 框架会对数据按照 Key 值排序，使得具有相同 Key 的数据彼此相邻。如果您指定了 合并操作（Combiner），框架会调用 Combiner，将具有相同 Key 的数据进行聚合。Combiner 的逻辑可以由您自定义实现。与经典的 MapReduce 框架协议不同，在 MaxCompute 中，Combiner 的输入、输出的参数必须与 Reduce 保持一致，这部分的处理通常也叫做 洗牌（Shuffle）。 接下来进入 Reduce 阶段。相同 Key 的数据会到达同一个 Reduce Worker。同一个 Reduce Worker 会接收来自多个 Map Worker 的数据。每个 Reduce Worker 会对 Key 相同的多个数据进行 Reduce 操作。最后，一个 Key 的多条数据经过 Reduce 的作用后，将变成一个值。 WordCount 操作步骤： 输入数据：对文本进行分片，将每片内的数据作为单个 Map Worker 的输入。 Map 阶段：Map 处理输入，每获取一个数字，将数字的 Count 设置为 1，并将此对输出，此时以 Word 作为输出数据的 Key。 Shuffle &gt; 合并排序：在 Shuffle 阶段前期，首先对每个 Map Worker 的输出，按照 Key 值（即 Word 值）进行排序。排序后进行 Combiner 操作，即将 Key 值（Word 值）相同的 Count 累加，构成一个新的对。此过程被称为合并排序。 Shuffle &gt; 分配 Reduce：在 Shuffle 阶段后期，数据被发送到 Reduce 端。Reduce Worker 收到数据后依赖 Key 值再次对数据排序。 Reduce 阶段：每个 Reduce Worker 对数据进行处理时，采用与 Combiner 相同的逻辑，将 Key 值（Word 值）相同的 Count 累加，得到输出结果。 输出结果数据。 学习资料https://help.aliyun.com/document_detail/27875.html]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[source_dubbo_cluster]]></title>
    <url>%2F2018%2F01%2F31%2Fjava_dubbo%2Fsource-dubbo-cluster%2F</url>
    <content type="text"><![CDATA[cluster层在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance 各节点关系： 这里的 Invoker 是 Provider 的一个可调用 Service 的抽象，Invoker 封装了 Provider 地址及 Service 接口信息 Directory 代表多个 Invoker，可以把它看成 List&lt;Invoker&gt; ，但与 List 不同的是，它的值可能是动态变化的，比如注册中心推送变更 Cluster 将 Directory 中的多个 Invoker 伪装成一个 Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个 Router 负责从多个 Invoker 中按路由规则选出子集，比如读写分离，应用隔离等 LoadBalance 负责从多个 Invoker 中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选 dubbo提供的实现Failover Cluster失败自动切换，当出现失败，重试其它服务器 [^1]。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。 重试次数配置如下： 1&lt;dubbo:service retries="2" /&gt; 或 1&lt;dubbo:reference retries="2" /&gt; 或 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; Failfast Cluster快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。 Broadcast Cluster广播调用所有提供者，逐个调用，任意一台报错则报错 [^2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。 源码解析AbstractClusterInvoker的invoke方法12345678910111213141516public Result invoke(final Invocation invocation) throws RpcException &#123; checkWheatherDestoried(); LoadBalance loadbalance; List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); return doInvoke(invocation, invokers, loadbalance);&#125; FailoverClusterInvoker失败自动切换，当出现失败，重试其它服务器 ^1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。 失败转移，当出现失败，重试其它服务器，通常用于读操作，但重试会带来更长延迟。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; checkInvokers(copyinvokers, invocation); int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; Result result = invoker.invoke(invocation); if (le != null &amp;&amp; logger.isWarnEnabled()) &#123; logger.warn(&quot;Although retry the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot; was successful by the provider &quot; + invoker.getUrl().getAddress() + &quot;, but there have been failed providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + le.getMessage(), le); &#125; return result; &#125; catch (RpcException e) &#123; if (e.isBiz()) &#123; // biz exception. throw e; &#125; le = e; &#125; catch (Throwable e) &#123; le = new RpcException(e.getMessage(), e); &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(le != null ? le.getCode() : 0, &quot;Failed to invoke the method &quot; + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName() + &quot;. Tried &quot; + len + &quot; times of the providers &quot; + providers + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size() + &quot;) from the registry &quot; + directory.getUrl().getAddress() + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot; + (le != null ? le.getMessage() : &quot;&quot;), le != null &amp;&amp; le.getCause() != null ? le.getCause() : le); &#125; FailbackClusterInvoker失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; try &#123; checkInvokers(invokers, invocation); Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null); return invoker.invoke(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failback to invoke method &quot; + invocation.getMethodName() + &quot;, wait for retry in background. Ignored exception: &quot; + e.getMessage() + &quot;, &quot;, e); addFailed(invocation, this); return new RpcResult(); // ignore &#125;&#125; //失败重试 private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) &#123; //单例初始化一个定时任务 if (retryFuture == null) &#123; synchronized (this) &#123; if (retryFuture == null) &#123; retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // 收集统计信息 try &#123; retryFailed(); &#125; catch (Throwable t) &#123; // 防御性容错 logger.error(&quot;Unexpected error occur at collect statistic&quot;, t); &#125; &#125; &#125;, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); &#125; &#125; &#125; //将失败的调用加入到Map中 failed.put(invocation, router);&#125;//重试的Futureprivate volatile ScheduledFuture&lt;?&gt; retryFuture;private final ConcurrentMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; failed = new ConcurrentHashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;(); //真实的进行重新调用 void retryFailed() &#123; //说明没有失败任务 if (failed.size() == 0) &#123; return; &#125; //遍历失败任务 for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;( failed).entrySet()) &#123; Invocation invocation = entry.getKey(); Invoker&lt;?&gt; invoker = entry.getValue(); try &#123; invoker.invoke(invocation); failed.remove(invocation); &#125; catch (Throwable e) &#123; logger.error(&quot;Failed retry to invoke method &quot; + invocation.getMethodName() + &quot;, waiting again.&quot;, e); &#125; &#125;&#125; ScheduledExecutorService核心方法 schedule 接收Runnable 接收Callable scheduleAtFixedRate 基于固定时间间隔进行任务调度 固定的频率来执行某项计划，它不受计划执行时间的影响。到时间，它就执行。 每次执行时间为 :initialDelay, initialDelay+period, initialDelay+2*period, … ScheduleWithFixedDelay 基于不固定时间间隔进行任务调度 是相对任务的。即无论某个任务执行多长时间，等执行完了，我再延迟指定的时间。也就是第二个方法，它受计划执行时间的影响。 每次执行时间为上一次任务结束起向后推一个时间间隔，即每次执行时间为：initialDelay, initialDelay+executeTime+delay ScheduledExecutorService的构造方法12345public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125; ForkingClusterInvoker并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。并行调用，只要一个成功即返回，通常用于实时性要求较高的操作，但需要浪费更多服务资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private final ExecutorService executor = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;forking-cluster-timer&quot;, true));public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; checkInvokers(invokers, invocation); final List&lt;Invoker&lt;T&gt;&gt; selected; final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); if (forks &lt;= 0 || forks &gt;= invokers.size()) &#123; selected = invokers; &#125; else &#123; selected = new ArrayList&lt;Invoker&lt;T&gt;&gt;(); for (int i = 0; i &lt; forks; i++) &#123; //在invoker列表(排除selected)后,如果没有选够,则存在重复循环问题.见select实现. Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected); if(!selected.contains(invoker))&#123;//防止重复添加invoker selected.add(invoker); &#125; &#125; &#125; RpcContext.getContext().setInvokers((List)selected); final AtomicInteger count = new AtomicInteger(); //核心代码:通过阻塞队列,来收集结果 final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;Object&gt;(); for (final Invoker&lt;T&gt; invoker : selected) &#123; executor.execute(new Runnable() &#123; public void run() &#123; try &#123; Result result = invoker.invoke(invocation); ref.offer(result); &#125; catch(Throwable e) &#123; int value = count.incrementAndGet(); if (value &gt;= selected.size()) &#123; ref.offer(e); &#125; &#125; &#125; &#125;); &#125; try &#123; //只要得到一个结果,就返回 Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); if (ret instanceof Throwable) &#123; Throwable e = (Throwable) ret; throw new RpcException(e instanceof RpcException ? ((RpcException)e).getCode() : 0, &quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e.getCause() != null ? e.getCause() : e); &#125; return (Result) ret; &#125; catch (InterruptedException e) &#123; throw new RpcException(&quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e); &#125; &#125;]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[review-java-thread-pool]]></title>
    <url>%2F2018%2F01%2F31%2Fjava_thread%2Freview-java-thread-pool%2F</url>
    <content type="text"><![CDATA[线程池背景 如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了， 频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 请求频繁，但是连接上以后读/写很少量的数据就断开连接。考虑到服务的并发问题，如果每个请求来到以后服务都为它启动一个线程，那么这对服务的资源可能会造成很大的浪费。 优点 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 第三：提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 核心接口ExecutorService,Executor 类 ExecutorService：真正的线程池接口。 ScheduledExecutorService:能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。 ThreadPoolExecutor:ExecutorService的默认实现。 ScheduledThreadPoolExecutor:继承ThreadPoolExecutor的- - ScheduledExecutorService接口实现，周期性任务调度的类实现。 Executors类里面提供了一些静态工厂，生成一些常用的线程池。 Executors 提供四种线程池 1）newCachedThreadPool 是一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute() 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。注意，可以使用 ThreadPoolExecutor 构造方法创建具有类似属性但细节不同（例如超时参数）的线程池。 2）newSingleThreadExecutor 创建是一个单线程池，也就是该线程池只有一个线程在工作，所有的任务是串行执行的，如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它，此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 3）newFixedThreadPool 创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小，线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 4）newScheduledThreadPool 创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求。 程池相关参数corePoolSize（线程池的基本大小）：当提交一个任务时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，直到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreTreads()方法，线程池就会提前创建并启动所有基本线程。 maximumPoolSize（线程最大数量）：线程池允许创建的最大线程数。如果队列已满，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。但如果使用了无界的任务队列，该参数没有效果。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。如果任务很多，且每个任务执行时间较短，可调大该值。 TimeUnit（线程活动保持时间的单位）：keepAliveTime的时间度量单位。可选天、小时、分钟、毫秒、微妙、纳秒。 BlockingQueue（任务队列）：用于保存等待执行的任务的阻塞嘟列，可以选择以下几个阻塞队列 ArrayBlockingQueue：基于数组结构的有界阻塞队列 LinkedBlockingQueue：基于链表机构的阻塞队列，吞吐量通常高于ArrayBlockingQueue，静态工厂方法Executors.newFixedThreadPool()使用该队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除，否则插入操作一直处于阻塞状态，吞吐量通常高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool()使用该队列。 PriorityBlockingQueue：具有优先级的无限阻塞队列。 ThreadFactory：创建线程的工厂。 RejectedExecutionHandler：饱和策略，即队列和线程池都满了，对于新提交的任务无法执行，这时采取的处理新来的任务的方法，有4种策略可选（也可以自定义策略—实现RejectedExecutionHandler接口，如记录日志或持久化不能处理的任务）： CallerRunsPolicy：使用调用者所在的线程来运行任务。 AbortPolicy：直接抛出RejectedExecutionException异常。（默认策略） DiscardPolicy：对新任务直接丢弃，不做任何事情 DiscardOldestPolicy：丢掉队列里最近（the oldest unhandled）的一个任务，并执行当前新任务。 线程池的关闭 ThreadPoolExecutor 提供了两个方法，用于线程池的关闭，分别是 shutdown() 和 shutdownNow()。 shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 核心流程 线程池规则线程池的线程执行规则跟任务队列有很大的关系。 下面都假设任务队列没有大小限制： 如果线程数量&lt;=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。 如果线程数量&gt;核心线程数，但&lt;=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。 如果线程数量&gt;核心线程数，并且&gt;最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。 任务队列大小有限时 当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。 SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。 使用方法123456789101112131415 void execute(Runnable task) Future&lt;?&gt; submit(Runnable task) &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; 全部执行,其中一个执行结束,或异常,则取消其他Callable的运行 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; 方法 invokeAll() 会调用存在于参数集合中的所有 Callable 对象，并且返回壹個包含 Future 对象的集合 future.isDone() //return true,false 无阻塞 future.get() // return 返回值，阻塞直到该线程运行结束 实际案例1(优化分页查询)1234567891011121314ExecutorService slaver = Executors.newSingleThreadExecutor();FutureTask&lt;List&lt;Map&lt;String, Object&gt;&gt;&gt; lastFuture = new FutureTask&lt;&gt;(countCallable);slaver.execute(lastFuture);slaver.shutdown();List&lt;Map&lt;String, Object&gt;&gt; stockFirst = jdbcTemplate.queryForList(contentSql);List&lt;Map&lt;String, Object&gt;&gt; stockLast = null;try &#123; stockLast = lastFuture.get();&#125; catch (Exception e) &#123; logger.error(&quot;错误&quot;, e);&#125; finally &#123; lastFuture.cancel(true);&#125; 实际案例2(dts抓单)123456789101112131415161718executor = new ThreadPoolExecutor(config.getMaxActive()/2+1, config.getMaxActive(), config.getTimeout4Borrow(), TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(config.getMaxActive()), this); @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; logger.error(&quot;wait too long to borrow worker: &quot; + taskOwner); try &#123; getMQService().push(getConfig().getAlertMq(), taskOwner); &#125; catch (Exception e) &#123; logger.error(&quot;mq service error: &quot;, e); &#125; logger.warn(&quot;worker &#123;&#125; need sleep &#123;&#125; millis to back to working &quot;, taskOwner, getConfig().getTimeout4Borrow()); try &#123; Thread.sleep(getConfig().getTimeout4Borrow() * 5); &#125; catch (Exception e) &#123; logger.error(&quot;thread error :&quot;, e); &#125; &#125; CompletionService接口 根据上面的介绍我们知道，现在在Java中使用多线程通常不会再使用Thread对象了。而是会用到java.util.concurrent包下的ExecutorService来初始化一个线程池供我们使用。使用ExecutorService类的时候，我们常维护一个list保存submit的callable task所返回的Future对象。然后在主线程中遍历这个list并调用Future的get()方法取到Task的返回值。 其实除了使用ExecutorService外，还可通过CompletionService包装ExecutorService，然后调用其take()方法去取Future对象。 CompletionService和ExecutorService的主要的区别在于submit的task不一定是按照加入自己维护的list顺序完成的。 ExecutorService中从list中遍历的每个Future对象并不一定处于完成状态，这时调用get()方法就会被阻塞住，如果系统是设计成每个线程完成后就能根据其结果继续做后面的事，这样对于处于list后面的但是先完成的线程就会增加了额外的等待时间。 而CompletionService的实现是维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。所以，先完成的必定先被取出。这样就减少了不必要的等待时间。 合理的配置线程池要想合理的配置线程池，就必须首先分析任务特性，可以从以下几个角度来进行分析： 任务的性质：CPU密集型任务，IO密集型任务和混合型任务。任务的优先级：高，中和低。任务的执行时间：长，中和短。任务的依赖性：是否依赖其他系统资源，如数据库连接。任务性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务配置尽可能小的线程，如配置Ncpu+1个线程的线程池。IO密集型任务则由于线程并不是一直在执行任务，则配置尽可能多的线程，如2*Ncpu。混合型的任务，如果可以拆分，则将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率，如果这两个任务执行时间相差太大，则没必要进行分解。我们可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。 优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 执行时间不同的任务可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，如果等待的时间越长CPU空闲时间就越长，那么线程数应该设置越大，这样才能更好的利用CPU。 建议使用有界队列，有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点，比如几千。有一次我们组使用的后台任务线程池的队列和线程池全满了，不断的抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞住，任务积压在线程池里。如果当时我们设置成无界队列，线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。当然我们的系统所有的任务是用的单独的服务器部署的，而我们使用不同规模的线程池跑不同类型的任务，但是出现这样问题时也会影响到其他任务。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 taskCount：线程池需要执行的任务数量。completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不+ getActiveCount：获取活动的线程数。通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如： SingleThreadExecutorCachedThreadPool①使用无容量队列SynchronousQueue，但maxmumPoolSize无界。如果提交任务的速度大于线程处理任务的速度，将会不断创建新线程，极端情况会因为创建过多线程而耗尽CPU资源。②keepAliveTime为60s，空闲线程超过该时间将会终止。③执行完任务的某线程会执行SynchronousQueue.poll()从队列中取任务，这个取的动作会持续60s，如果在60s内有新的任务，则执行新的任务，没有任务则终止线程。因此长时间保持空闲的CachedThreadPool不会占用任何资源。④当有任务提交时，a.如果当前线程池为空或者已创建的线程都正在处理任务，则CachedThreadPool会创建新线程来执行该任务。b.如果当前线程池有空闲的线程（正在执行阻塞方法SynchronousQueue.poll()），则将任务交给该等待任务的空闲线程来执行。 CachedThreadPool适用于执行很多的短期异步任务的小程序或者是负载较轻的服务器。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 排队策略直接提交工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 无界队列使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 有界队列当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 拒绝策略:RejectedExecutionHandler接口提供了对于拒绝任务的处理的自定方法的机会。在ThreadPoolExecutor中已经默认包含了4中策略 CallerRunsPolicy： 线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。 AbortPolicy： 处理程序遭到拒绝将抛出运行时 RejectedExecutionException 这种策略直接抛出异常，丢弃任务。 DiscardPolicy： 不能执行的任务将被删除 这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。 DiscardOldestPolicy： 如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。 设想:如果其他线程都还在运行，那么新来任务踢掉旧任务，缓存在queue中，再来一个任务又会踢掉queue中最老任务。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-study-BlockingQueue]]></title>
    <url>%2F2018%2F01%2F29%2Fjava_data_structure%2Fstudy-java-queue%2F</url>
    <content type="text"><![CDATA[BlockingQueue 阻塞队列 先进先出 有边界:当队列满时,插入的元素的线程会等待队列可有 等待队列为非空 生产者消费者&lt; !– more –&gt; 阻塞队列的主要功能并不是在于提升程序高并发时队列的性能，而是在于简化多线程间的数据共享（用于多线程间的数据传递）。 五种类ArrayBlockingQueue 有界。ArrayBlockingQueue是基于数组实现的有界阻塞队列；其能容纳的元素数量固定，一旦创建，就不能再增加其容量； FIFO。队列的获取操作作用于队列头部，添加操作作用于队列尾部，满足FIFO特性； 自动阻塞唤醒。试图向已满队列放入元素将导致操作阻塞，试图从空队列中获取元素同样将导致操作阻塞等待。 LinkedBlockingQueue 有界，也可认为是无界。LinkedBlockingQueue是基于链表实现的阻塞队列；如果在构造函数不指定容量，则默认为一个类似无限大小的容量，大小为Integer.MAX_VALUE，在此种情况下，如果生产者速度远远大于消费者速度，由于容量很大，那么系统内存有可能会被消耗殆尽；如果在构造函数指定了容量大小，则队列容纳的元素数量固定。 FIFO。队列的获取操作作用于队列头部，添加操作作用于队列尾部，满足FIFO特性 自动阻塞唤醒。put操作试图向已满队列放入元素将导致操作阻塞，直到其他线程从队列中获取元素，队列出现空闲后再唤醒操作；take操作试图从空队列中获取元素同样将导致操作阻塞等待，直到其他线程从队列中添加元素，队列中存在元素后再唤醒操作。 锁分离机制。对添加数据的操作与获取数据的操作分别采用了独立的、不同的锁来控制数据同步（ArrayBlockingQueue采用了同一把锁），即在高并发的情况下生产者和消费者可以并行的操作队列中的数据，进而提高整个队列的并发性能。 PriorityBlockingQueuePriorityBlockingQueue又称为优先级阻塞队列。其特性如下： 无界。由于容量不存在限制(最大为Integer.MAX_VALUE - 8，可基本认为是无限制)，队列就不会阻塞生产者，因为只要能生产数据，就可以把数据放入队列中；如果生产者速度远远大于消费者速度，由于容量无限，那么系统内存有可能会被消耗殆尽。 元素必须实现Comparable接口。在实现的CompareTo方法中，如果返回值为负数，则表明当前对象this的优先级越高；返回值为正数，则表明当前对象this的优先级越低。 实现了有序列表。优先级的判断通过构造函数传入的Compator对象实现队列元素的自定义排序；如果Compator为空，则按对象的比较方法进行排序。队列中元素的优先级依次降低，优先级最高的排在队首。默认情况下元素采取自然顺序排序，也可以通过比较器comparator来指定元素的排序规则。 仅阻塞消费者。当队列中无数据时，会阻塞消费者。 DelayQueueDelayQueue又称为延时队列。一个使用优先级队列（PriorityQueue）实现的无界阻塞队列。其特性如下： 队列容量无界；不能存放null元素。 元素必须同时实现Delayed接口与Comparable接口。元素所属类中必须实现public int compareTo(To)和long getDelay(TimeUnit unit)方法。其中，Delayed接口继承了Comparable接口，因此必须实现compareTo方法；在public int compareTo(To)方法中，如果当前对象的延迟值小于参数对象的值，将返回一个小于0的值；如果当前对象的延迟值大于参数对象的值，将返回一个大于0的值；如果两者的延迟值相等则返回0。该队列的头部是延迟期满后保存时间最长的 Delayed 元素（也就是保证先过期的元素排在头部）。如果延迟都还没有期满，则队列头部不会被返回，即队列的 poll 方法将返回null。 long getDelay(TimeUnit unit)方法中，是返回到激活日期的剩余时间；当返回值为0或者负数时，表面该元素已经可以被获取了；单位由单位参数指定。TimeUnit类是一个由下列常量组成的枚举类型：DAYS、HOURS、MICROSECONDS、MILLISECONDS、MINUTES、NANOSECONDS和SECONDES。 只有在延迟期满时才能从队列中提取元素；Delayed接口使得对象成为了延迟对象，它使得队列中的元素对象具有了延迟期。由于DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作永远不会被阻塞，而只有获取数据的操作才会被阻塞。适用场景： 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从队列中获取元素时候，表示缓存有效期到了。 定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间。一旦从队列中获取到任务就开始执行，比如TimerQueue就是用DelayQueue实现的。 SynchronousQueueSynchronousQueue又称为同步队列。一个不存储元素的阻塞队列。其特性如下： 是一个无缓冲的等待队列。队列本身不存储任何元素，每一个put操作必须等待一个take操作，否则不能继续添加元素。 支持公平与非公平两种操作模式。如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，体现了“先来先服务，后来则排队”的公平策略；如果采用非公平模式（SynchronousQueue默认选项），则配合一个LIFO队列来管理多余的生产者和消费者，体现了“无视当前排队，即来即抢占服务”的不公平策略，但是，在该种模式下，如果生产者和消费者的处理速度有差距，可能有某些生产者或者消费者永远都得不到处理（因为一直被抢占，一直被欺负）。 与其他阻塞队列不同，其他阻塞队列维护的是一组元素，SynchronousQueue则是维护了两组线程（一组生产者线程，一组消费者线程），实现两者之间的数据传递。举个列子，有A、B两位同事，A需要将一些资料交给B。如果是A把文件直接交到B手中，那么就是SynchronousQueue实现模式；如果A通过发邮件的形式把资料给B，那么就是其他阻塞队列的实现模式。 SyncchronousQueue吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。 适用场景：创建线程池。 LinkedTransferQueueLinkedTransferQueue又称为链表传输队列。一个由链表结构组成的无界阻塞队列。其特性如下： 一个无界队列。 具备FIFO特性。 特别的阻塞：LinkedTransferQueue实现了TransferQueue接口，TransferQueue又继承了BlockingQueue；这两个接口的区别在于：BlockingQueue：当生产者向满队列添加元素时则会被阻塞；当消费者从空队列中获取元素时则会被阻塞；TransferQueue：相比于BlockingQueue，生产者会一直阻塞直到所添加到队列的元素被某一个消费者所消费（不只是把元素添加到队列中），其接口中的transfer方法实现了该功能。顾名思义，就是发生在元素从一个线程transfer到另一个线程的过程中，它有效地实现了元素在线程之间的传递（以建立Java内存模型中的happens-before关系的方式）。 适用场景：生产者-消费者高并发的业务场景。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[data-Archiving-research]]></title>
    <url>%2F2018%2F01%2F25%2Fegenie_business%2Fdata-archiving-research%2F</url>
    <content type="text"><![CDATA[归档目的 主要处于性能考虑,减少查找的范围 归档需求 同时要求系统中可以查询到之前的数据,不能归档到非结构化系统中 要求条件需要多表进行关联,并添加自定义条件,保证业务 要求主子表归档具有一致性,主子表不能分离 已经归档过一次 稳定性 可追溯 数据一致性 定时自动执行 跨数据库,最好支持到不同的数据源 &lt; !–more–&gt; 归档流程梳理 复制指定条件的旧数据 删除旧数据(是否需要人工介入?)后续自动 读取归档数据 归档方案思路:1.建立归档表_archive这种方式是通过建立一个以_archive结尾的归档表来实施的。如果使用这种方式，那么一般需要在业务层进行查询的分离改造，比如基于我们的特定归档规则 ，对业务端核心代码改造或者使用proxy方案等来决定是使用主表还是归档表。同时我们还需要一个数据归档过程，当数据过时或者变成冷数据时，将该数据从主表迁移到归档表中。 在业务层查询时，我们可以通过时间字段来进行查询判断，例如将90天之前的数据在归档表中查询，否则就在主表查询。另一种方式可以通过增加status列去判断查询主表还是归档表，如果是inactive则查询归档表，否则就在主表查询。 mysql分区为了让优化器能将查询发送到正确的分区键，在创建分区表的时候，我们需要将分区键添加到主键里，并且理想情况下，该分区键能被包含在所有select/update/delete等语句的where条件里面，否则的话，你的查询将会按照顺序查找表对应的每个分区，这种情况下查询性能就没有那么好了。 根据日期进行分区这种方式是通过对表进行分区来实现，虽然这是一种不同的物理数据模型，但是确实有助于将表的数据进行拆分到不同的物理磁盘，并且不需要代码的任何改造。作为DBA，一般对表进行分区是比较常用的方式，我们可以通过日期字段很容易确定哪些是冷数据，并根据日期将不同日期的时间分配到不同的分区中，在查询的时候，我们可以通过日期来从分区中快速定位到对应的数据，同时建立分区表也比较利于DBA对大表进行管理操作。 我们根据数据行的创建时间，按年将数据放入到不同的分区，这里需要注意的是在2020年以后，我们还需要在表里添加新的年份，当然我们可以提前加更多的分区或者部署脚本来自动化创建新的分区。 通过状态进行分区我们也可以通过status状态列来进行分区，这种情况下，通常状态列会包含active/inactive两种状态，然后通过update进行状态列的更新（使用replace或者insert+delete也是可以的），将数据放入到正确的分区当中。请看下面的示例 通过ID进行分区具体方案复制表并且按照条件插入数据（此种方法除了主键索引不包括其他索引）–&gt;手动sqlhttp://blog.csdn.net/bluestarf/article/details/49641047 123CREATE TABLE lime_survey_549656_20151001 as select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; ALTER TABLE lime_survey_549656_20151001 change id id int primary key auto_increment; 创建一张空表，结构和索引和原表一样 –&gt;手动sql12create table lime_survey_549656_20151001 like lime_survey_549656; INSERT INTO lime_survey_549656_20151001 select * from lime_survey_549656 where submitdate &lt; &quot;2015-10-01 00:00:00&quot;; 存储过程来归档问题无法跨数据库备份 分区实现问题 表中有全文索引,无法分区 分区的话,需要修改业务sql,改动较大–&gt;待确定 pt-archvier(mysql percona工具集) 基础教程 https://yq.aliyun.com/articles/277145 是否可归档多表 https://www.percona.com/forums/questions-discussions/percona-toolkit/32449-pt-archiver-multiple-dependent-tables 可以多表条件,但是无法如果中途失败,无法继续归档 https://stackoverflow.com/questions/47203831/turn-mysql-query-into-percona-pt-archiver-string mysql_archiver (python实现+pt-archvier)https://github.com/dbarun/mysql_archiver MySQL_archiver基本上实现了数据归档的自动运转，统一的归档任务调度管理、自动监控和预警、自动生成报表。在一定程度上节约了生产力，提高了运维效率。 要知道每个归档任务成功与否、跑了多长时间、归档了多少数据JavaDataArchiver (java实现)https://github.com/Sunshow/JavaDataArchiver 问题下载源码后,发现未实现 阿里云maxcompute优点相对稳定,成本低,多数据源,可视化直接操作,无需开发,只需要配置 问题 多表之间的id无法直接传递,需要使用join 同时过滤主表和字表的条件,例如sale_order和sale_order_detail(严重) 0226 delete的条件传递 in (ids) delete的效率问题(性能) 0226 是否需要跨数据库备份 阿里云maxcompute+归档字段 先多表关联,将要归档的记录设置上需归档的状态 各表根据归档状态,单标归档 删除原表 问题数据量太大,可能update会锁表 阿里云maxcompute+归档记录 先多表关联,将要归档的记录设置上需归档的状态 各表根据归档状态,单标归档 删除原表 问题待试验 外部程序实现结论 使用: mysql_archiver !!!!!!后续开发读取归档数据,同时不能影响生产库的性能(最好先定下来,否则目标 会不是mysql) target 也需要分区 目标库选择 nogsql mysql my maxcompute 废弃分表策略,对于v_sale_order和v_sale_order_detail结论 采用阿里云数据集成,跑归档任务 在数据集成任务结束后的回调函数,可以配置删除归档数据的任务 暂时目标库,还是mysql,后续的查询采用ElasticSearch进行查询,(阿里云提供1个月的免费试用,待研究确认后执行)]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-java-thread-local]]></title>
    <url>%2F2018%2F01%2F24%2Fjava_thread%2Fstudy-java-thread-local%2F</url>
    <content type="text"><![CDATA[Thread Local的作用提供了一种将实例绑定到当前线程的机制，类似于隔离的效果. SoftReference、Weak Reference和PhantomRefrence强引用默认1234Object o=new Object(); Object o1=o; o=null; o1=null; 如果显式地设置o和o1为null，或超出范围，则gc认为该对象不存在引用，这时就可以收集它了。可以收集并不等于就一会被收集，什么时候收集这要取决于gc的算法，这要就带来很多不确定性。 其他12345String abc=new String(&quot;abc&quot;); //1 SoftReference&lt;String&gt; abcSoftRef=new SoftReference&lt;String&gt;(abc); //2 WeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(abc); //3 abc=null; //4 abcSoftRef.clear();//5 上面的代码中： 第一行在heap对中创建内容为“abc”的对象，并建立abc到该对象的强引用,该对象是强可及的。 第二行和第三行分别建立对heap中对象的软引用和弱引用，此时heap中的对象仍是强可及的。 第四行之后heap中对象不再是强可及的，变成软可及的。同样第五行执行之后变成弱可及的。 软引用被 Soft Reference 指到的对象，即使没有任何 Direct Reference，也不会被清除。一直要到 JVM 内存不足且 没有 Direct Reference 时才会清除 SoftReference 是用来设计 object-cache 之用的。如此一来 SoftReference 不但可以把对象 cache 起来，也不会造成内存不足的错误 （OutOfMemoryError）。我觉得 Soft Reference 也适合拿来实作 pooling 的技巧。 如果一个对象只具有软引用，那就类似于可有可物的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 软引用可以加速JVM对垃圾内存的回收速度 , 维护系统的运行安全 , 防止产生内存溢出的问题 弱引用可以用来观察是否被gc掉 gc收集弱可及对象的执行过程和软可及一样，只是gc不会根据内存情况来决定是不是收集该对象。 如果你希望能随时取得某对象的信息，但又不想影响此对象的垃圾收集，那么你应该用 Weak Reference 来记住此对象，而不是用一般的 reference。 如果一个对象只具有弱引用，那就类似于可有可物的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 12C c = new C(b);b = null; 当 b 被设置成null时，那么是否意味这一段时间后GC工作可以回收 b 所分配的内存空间呢？答案是否定的，因为即使 b 被设置成null，但 c 仍然持有对 b 的引用，而且还是强引用，所以GC不会回收 b 原先所分配的空间，既不能回收，又不能使用，这就造成了 内存泄露。可以通过c = null;，也可以使用弱引用WeakReference w = new WeakReference(b);。因为使用了弱引用WeakReference，GC是可以回收 b 原先所分配的空间的。如果是强引用,且thread依旧存活, Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 永远无法回收，造成内存泄漏。ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 虚引用 “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解 被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 方法123456789101112131415161718192021222324252627282930public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 内部结构存储在Thread中的 java.lang.ThreadLocal.ThreadLocalMap类型的内部成员变量其中 的Entry是弱引用: static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; ThreadLocal为什么使用WeakReference ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏（参考ThreadLocal 内存泄露的实例分析）。 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。 如果使用强引用则会,不remove,一直引用着key无法回收掉 第一步WeakReference弱引用,的使得ey可以被回收为null 在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value 但是如果不get(),set(),remove()就会出问题 so: 弱引用,解决了无其他引用时,有get(),set(),remove()调用的问题 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。 即使设计上最大程度上减少了内存泄漏发生的概率,但是仍然不能100%保证,还是得靠程序员来协调]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-debug]]></title>
    <url>%2F2018%2F01%2F24%2Fmysql%2Fmysql-debug%2F</url>
    <content type="text"><![CDATA[问题sql1234567 SELECT *FROM v_sale_orderWHERE 1 = 1 AND v_sale_order.is_usable = 1 AND v_sale_order.tenant_id = 100046 AND 1 = 1 AND archive_state IN (0, 1) AND# v_sale_order.buyer_nick LIKE '肆无忌惮演江山%' v_sale_order.buyer_nick LIKE 't_150175568%'ORDER BY v_sale_order.last_update_time DESC; 如果查询内容带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsosrefidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_idIDX_original_order_id6const,const837216Using where; Using filesort1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sos.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL1SIMPLEsorrefidx_sale_order_id,idx_buyer_nickidx_sale_order_id9egenie_kn.sos.sale_order_id1Using where1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sos.sale_order_id1NULL 如果查询内容不带下划线idselect_typetabletypepossible_keyskeykey_lenrefrowsExtra1SIMPLEsorrangeidx_sale_order_id,idx_buyer_nickidx_buyer_nick303NULL7Using index condition; Using where; Using temporary; Using filesort1SIMPLEsoseq_refidx_sale_order_id,IDX_ARCHIVE_SPLIT,oms_normal,oms_check,oms_suspend,oms_normal_v2,oms_check_v2,oms_suspend_v2,IX_SaleOrderStatus_SyncPlaystate,idx_pay_time,IDX_original_order_ididx_sale_order_id8egenie_kn.sor.sale_order_id1Using where1SIMPLEsocrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsowrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoeq_refPRIMARYPRIMARY8egenie_kn.sor.sale_order_id1NULL1SIMPLEsofrefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL1SIMPLEsoirefidx_sale_order_ididx_sale_order_id9egenie_kn.sor.sale_order_id1NULL 原因 %代表任意多个字符 _代表一个字符 如果想搜索 _ 就要用到转义符 “\” 解决1value = value.replaceAll("\\_", "\\\\_");]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>like</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_quick_sort]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_sort%2Fstudy-quick-sort%2F</url>
    <content type="text"><![CDATA[视频地址:https://visualgo.net/en/sorting 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class QuickSort &#123; public static void main(String[] args) throws Exception &#123; int[] ints = &#123;5, 3, 9, 1, 6, 7, 2, 4, 0, 8&#125;; int[] result = new QuickSort().sort(ints); System.out.println(Arrays.toString(result)); &#125; public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); return quickSort(arr, 0, arr.length - 1); &#125; private int[] quickSort(int[] arr, int left, int right) &#123; if (left &lt; right) &#123; int partitionIndex = partition(arr, left, right); System.out.println(partitionIndex); quickSort(arr, left, partitionIndex - 1); quickSort(arr, partitionIndex + 1, right); &#125; return arr; &#125; private int partition(int[] arr, int left, int right) &#123; // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) &#123; if (arr[i] &lt; arr[pivot]) &#123; swap(arr, i, index); index++; &#125; &#125; swap(arr, pivot, index - 1); return index - 1; &#125; private void swap(int[] arr, int i, int j) &#123; if (i == j) &#123; return; &#125; System.out.println(&quot;swap&quot; + i + &quot;----&quot; + j); int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(原理篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_spring%2Fstudy-springboot-springmvc%2F</url>
    <content type="text"><![CDATA[springboot如何配置DispatcherServlet?org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration中完成的 在springboot项目中,进行springmvc配置的新的方式12345678910111213141516171819202122232425@Configurationpublic class SpringMvcConfigure extends WebMvcConfigurerAdapter &#123; @Bean public InternalResourceViewResolver viewResolver() &#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(&quot;/WEB-INF/jsp/&quot;); viewResolver.setSuffix(&quot;.jsp&quot;); // viewResolver.setViewClass(JstlView.class); // 这个属性通常并不需要手动配置，高版本的Spring会自动检测 return viewResolver; &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new Interceptor1()).addPathPatterns(&quot;/**&quot;); registry.addInterceptor(new Interceptor2()).addPathPatterns(&quot;/users&quot;).addPathPatterns(&quot;/users/**&quot;); super.addInterceptors(registry); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; // addResourceHandler指的是访问路径，addResourceLocations指的是文件放置的目录 registry.addResourceHandler(&quot;/**&quot;).addResourceLocations(&quot;classpath:/res/&quot;); &#125;&#125; HTTP序列化/反序列化@RestController中有@ResponseBody，可以帮我们把User序列化到resp.body中。@RequestBody可以帮我们把req.body的内容转化为User对象。如果是开发Web应用，一般这两个注解对应的就是Json序列化和反序列化的操作。这里实际上已经体现了Http序列化/反序列化这个过程，只不过和普通的对象序列化有些不一样，Http序列化/反序列化的层次更高，属于一种Object2Object之间的转换。 有过Netty使用经验的对这个应该比较了解，Netty中的Decoder和Encoder就有两种基本层次，层次低的一种是Byte &lt;—&gt; Message，二进制与程序内部消息对象之间的转换，就是常见的序列化/反序列化；另外一种是 Message &lt;—&gt; Message，程序内部对象之间的转换，比较高层次的序列化/反序列化。 Http协议的处理过程，TCP字节流 &lt;—&gt; HttpRequest/HttpResponse &lt;—&gt; 内部对象，就涉及这两种序列化。在springmvc中第一步已经由Servlet容器（tomcat等等）帮我们处理了，第二步则主要由框架帮我们处理。上面所说的Http序列化/反序列化就是指的这第二个步骤，它是controller层框架的核心功能之一，有了这个功能，就能大大减少代码量，让controller的逻辑更简洁清晰，就像上面示意的代码那样，方法中只有一行代码。 spirngmvc进行第二步操作，也就是Http序列化和反序列化的核心是HttpMessageConverter。用过老版本springmvc的可能有些印象，那时候需要在xml配置文件中注入MappingJackson2HttpMessageConverter这个类型的bean，告诉springmvc我们需要进行Json格式的转换，它就是HttpMessageConverter的一种实现。 几种实现 json:gson,fastjson,jackson Protobuf java序列化 HttpMessageConverter优先级另外有很重要的一点需要说明一下，springmvc可以同时配置多个Converter，根据一定的规则（主要是Content-Type、Accept、controller方法的consumes/produces、Converter.mediaType以及Converter的排列顺序这四个属性）来选择到底是使用哪一个，这使得springmvc能够一个接口支持多种报文格式。 默认的converters12345678910ByteArrayHttpMessageConverter – converts byte arraysStringHttpMessageConverter – converts StringsResourceHttpMessageConverter – converts org.springframework.core.io.Resource for any type of octet streamSourceHttpMessageConverter – converts javax.xml.transform.SourceFormHttpMessageConverter – converts form data to/from a MultiValueMap&lt;String, String&gt;.Jaxb2RootElementHttpMessageConverter – converts Java objects to/from XML (added only if JAXB2 is present on the classpath)MappingJackson2HttpMessageConverter – converts JSON (added only if Jackson 2 is present on the classpath)MappingJacksonHttpMessageConverter – converts JSON (added only if Jackson is present on the classpath)AtomFeedHttpMessageConverter – converts Atom feeds (added only if Rome is present on the classpath)RssChannelHttpMessageConverter – converts RSS feeds (added only if Rome is present on the classpath) 源码中的调用栈1234567891011com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter.write(FastJsonHttpMessageConverter.java:185) at org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor.writeWithMessageConverters(AbstractMessageConverterMethodProcessor.java:231) at org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor.handleReturnValue(HttpEntityMethodProcessor.java:203) at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:81) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:113) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at 常见的contentType 1.text/html 2.text/plain 3.text/css 4.text/javascript 5.application/x-www-form-urlencoded 6.multipart/form-data 7.application/json 8.application/xml]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置FastJsonHttpMessageConverter(实战篇)]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_common%2Fstudy-fastjson-formatter%2F</url>
    <content type="text"><![CDATA[背景老的方式:controller的参数与返回值123456public JsonResult queryDrillDetail(@RequestBody String body) &#123;List&lt;Map&lt;String, Object&gt;&gt; detailMapList = new ArrayList&lt;&gt;();.......return new JsonResult(JsonResult.SUCCESSFUL, new PagedList&lt;&gt;(query.getPage() + 1, pageable.getPageSize(), query.getTotalCount(), detailMapList));&#125; 老的方式:问题 入参不明确 返回值类型不明确 Map的key只有在运行时,才会知道,且不知道类型 期望的方式:使用vo改造步骤:1.在使用converters的最后一个优先级,添加FastJsonHttpMessageConverter 1234567891011121314@Componentpublic class MyWebAppConfigurer extends WebMvcConfigurerAdapter &#123; // 添加converter的第三种方式 // 同一个WebMvcConfigurerAdapter中的configureMessageConverters方法先于extendMessageConverters方法执行 // 可以理解为是三种方式中最后执行的一种，不过这里可以通过add指定顺序来调整优先级，也可以使用remove/clear来删除converter，功能强大 // 使用converters.add(xxx)会放在最低优先级（List的尾部） // 使用converters.add(0,xxx)会放在最高优先级（List的头部） @Override public void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; converters.add(new FastJsonHttpMessageConverter()); &#125;&#125; 2.model遵循老的接口原则,转为下划线分割的 1234567891011@JSONType(naming = PropertyNamingStrategy.SnakeCase)public class PurchaseDetailDrillVo &#123; private Long pmsPurchaseOrderId; private Long pmsPurchaseOrderDetailId; private String pmsPurchaseOrderNo; private Integer productType; private String deliverAddress; private Long provinceId; ....&#125; 3.使用@RequestBody注解,类型改为vo 测试,接受参数和返回参数都是vo,而接口的字段映射依然为下划线, 以下为项目本身的问题4.pom文件中排除jackson的依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;com.ejlerp&lt;/groupId&gt; &lt;artifactId&gt;ejlerp-common&lt;/artifactId&gt; &lt;version&gt;3.2.0-SNAPSHOT&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 5.fastjason默认支持所有的contentType,及*, 与springmvc校验相冲突,so需要声明fastjason能支持的contentType,在初始化FastJsonHttpMessageConverter,注入参数1234567891011@Overridepublic void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); ArrayList&lt;MediaType&gt; supportedMediaTypes = Lists.newArrayList(); supportedMediaTypes.add(MediaType.APPLICATION_FORM_URLENCODED); supportedMediaTypes.add(MediaType.APPLICATION_JSON); supportedMediaTypes.add(MediaType.TEXT_HTML); supportedMediaTypes.add(MediaType.TEXT_PLAIN); fastJsonHttpMessageConverter.setSupportedMediaTypes(supportedMediaTypes); converters.add(fastJsonHttpMessageConverter);&#125; fastjson官网https://github.com/alibaba/fastjson/issues/1555https://github.com/alibaba/fastjson/wiki/PropertyNamingStrategy_cn]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>fastjson</tag>
        <tag>http</tag>
        <tag>springMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study_equals_and_hashCode]]></title>
    <url>%2F2018%2F01%2F22%2Fjava_common%2Fstudy-equals-and-hashCode%2F</url>
    <content type="text"><![CDATA[https://www.ibm.com/developerworks/cn/java/j-jtp05273/index.html 为什么 Override equals()和hashCode()? 如果 Integer 不 Override equals() 和 hashCode() 情况又将如何?如果我们从未在 HashMap 或其它基于散列的集合中使用 Integer 作为关键字的话，什么也不会发生。但是，如果我们在 HashMap中 使用这类 Integer 对象作为关键字，我们将不能够可靠地检索相关的值，除非我们在 get() 调用中使用与 put() 调用中极其类似的 Integer 实例。这要求确保在我们的整个程序中，只能使用对应于特定整数值的 Integer 对象的一个实例。不用说，这种方法极不方便而且错误频频。 Object 的interface contract要求如果根据 equals() 两个对象是相等的，那么它们必须有相同的 hashCode() 值。当其识别能力整个包含在 equals() 中时，为什么我们的根对象类需要 hashCode() ？ 如果重写了equals方法，则一定要重写hashCode方法。 hashCode() 方法纯粹用于提高效率。Java平台设计人员预计到了典型Java应用程序中基于散列的集合类（Collection Class)的重要性–如 Hashtable 、 HashMap 和 HashSet ，并且使用 equals() 与许多对象进行比较在计算方面非常昂贵。使所有Java对象都能够支持 hashCode() 并结合使用基于散列的集合，可以实现有效的存储和检索。 hashCode方法 如果重写了equals方法，则一定要重写hashCode方法。 重写hashCode方法的原则如下： 在程序执行期间，只要equals方法的比较操作用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法必须始终如一地返回同一个整数 如果两个对象通过equals方法比较得到的结果是相等的，那么对这两个对象进行hashCode得到的值应该相同 两个不同的对象，hashCode的结果可能是相同的，这就是哈希表中的冲突。为了保证哈希表的效率，哈希算法应尽可能的避免冲突 关于相应的哈希算法，一个简单的算法如下: 永远不要让哈希算法返回一个常值，这时哈希表将退化成链表，查找时间复杂度也从 O(1)O(1) 退化到 O(N)O(N) 如果参数是boolean型，计算(f ? 1 : 0) 如果参数是byte, char, short或者int型，计算(int) f 如果参数是long型，计算(int) (f ^ (f &gt;&gt;&gt; 32)) 如果参数是float型，计算Float.floatToIntBits(f) 如果参数是double型，计算Double.doubleToLongBits(f)得到long类型的值，再根据公式计算出相应的hash值 如果参数是Object型，那么应计算其有用的成员变量的hash值，并按照下面的公式计算最终的hash值 如果参数是个数组，那么把数组中的每个值都当做单独的值，分别按照上面的方法单独计算hash值，最后按照下面的公式计算最终的hash值 组合公式：result = 31 * result + c String类的hashCode方法如下（JDK 1.8）：1234567891011public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; 举个自定义类的hashCode例子：123456789101112131415161718192021222324252627282930class Duck &#123; private int id; private String name; private double weight; private float height; private String note; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Duck duck = (Duck) o; if (id != duck.id) return false; if (Double.compare(duck.weight, weight) != 0) return false; if (Float.compare(duck.height, height) != 0) return false; if (name != null ? !name.equals(duck.name) : duck.name != null) return false; return !(note != null ? !note.equals(duck.note) : duck.note != null); &#125; @Override public int hashCode() &#123; int result; long temp; result = id; result = 31 * result + (name != null ? name.hashCode() : 0); temp = Double.doubleToLongBits(weight); result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); result = 31 * result + (height != +0.0f ? Float.floatToIntBits(height) : 0); result = 31 * result + (note != null ? note.hashCode() : 0); return result; &#125;&#125; BTW 回顾一下 hashmap内部的实现e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[review_spring]]></title>
    <url>%2F2018%2F01%2F19%2Fjava_spring%2Freview-spring%2F</url>
    <content type="text"><![CDATA[Spring的优点 轻量级：相较于EJB容器，Spring采用的IoC容器非常的轻量级，基础版本的Spring框架大约只有2MB。Spring可以让开发者们仅仅使用POJO(Plain Old Java Object，相对于EJB)就能够开发出企业级的应用。这样做的好处是，你不需要使用臃肿庞大的 EJB容器(应用服务器)，你只需要轻量的servlet容器(如Tomcat)。尤其在一些开发当中，很稀缺内存和CPU资源时，采用Spring比EJB无论是开发还是部署应用都更节约资源。 控制反转(IOC)：Spring使用控制反转技术实现了松耦合。依赖被注入到对象，而不是创建或寻找依赖对象。 面向切面编程(AOP)： Spring支持面向切面编程，同时把应用的业务逻辑与系统的服务分离开来。 MVC框架：Spring MVC是一个非常好的MVC框架，可以替换其他web框架诸如Struts。 集成性：Spring非常容易和其他的流行框架一起集成开发，这些框架包括：ORM框架，logging框架，JEE, Quartz，以及Struts等表现层框架。 事务管理：Spring强大的事务管理功能，能够处理本地事务(一个数据库)或是全局事务(多个数据，采用JTA)。 模块分离：Spring框架是由模块构成的。虽然已经有太多的包和类了，但它们都按照模块分好类了，你只需要考虑你会用到的模块，而不用理其他的模块。 异常处理：由于Java的JDBC，Hibernate等API中有很多方法抛出的是checked exception，而很多开发者并不能很好的处理异常。Spring提供了统一的API将这些checked exception的异常转换成Spring的unchecked exception。 单元测试：Spring写出来的代码非常容易做单元测试，可以采用依赖注射(Dependency Injection)将测试的数据注射到程序中。 IOC就是典型的工厂模式，通过sessionfactory去注入实例。 AOP就是典型的代理模式的体现。 IOC概念IOC解耦引进了中间位置的“第三方”，也就是IOC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了 通过引入IOC容器，利用依赖关系注入的方式，实现对象之间的解耦。 IOC为我们带来了什么好处我们还是从USB的例子说起，使用USB外部设备比使用内置硬盘，到底带来什么好处？ 第一、USB设备作为电脑主机的外部设备，在插入主机之前，与电脑主机没有任何的关系，只有被我们连接在一起之后，两者才发生联系，具有相关性。所以，无论两者中的任何一方出现什么的问题，都不会影响另一方的运行。这种特性体现在软件工程中，就是可维护性比较好，非常便于进行单元测试，便于调试程序和诊断故障。代码中的每一个Class都可以单独测试，彼此之间互不影响，只要保证自身的功能无误即可，这就是组件之间低耦合或者无耦合带来的好处。 第二、USB设备和电脑主机的之间无关性，还带来了另外一个好处，生产USB设备的厂商和生产电脑主机的厂商完全可以是互不相干的人，各干各事，他们之间唯一需要遵守的就是USB接口标准。这种特性体现在软件开发过程中，好处可是太大了。每个开发团队的成员都只需要关心实现自身的业务逻辑，完全不用去关心其它的人工作进展，因为你的任务跟别人没有任何关系，你的任务可以单独测试，你的任务也不用依赖于别人的组件，再也不用扯不清责任了。所以，在一个大中型项目中，团队成员分工明确、责任明晰，很容易将一个大的任务划分为细小的任务，开发效率和产品质量必将得到大幅度的提高。 第三、同一个USB外部设备可以插接到任何支持USB的设备，可以插接到电脑主机，也可以插接到DV机，USB外部设备可以被反复利用。在软件工程中，这种特性就是可复用性好，我们可以把具有普遍性的常用组件独立出来，反复利用到项目中的其它部分，或者是其它项目，当然这也是面向对象的基本特征。显然，IOC不仅更好地贯彻了这个原则，提高了模块的可复用性。符合接口标准的实现，都可以插接到支持此标准的模块中。 第四、同USB外部设备一样，模块具有热插拔特性。IOC生成对象的方式转为外置方式，也就是把对象生成放在配置文件里进行定义，这样，当我们更换一个实现子类将会变得很简单，只要修改配置文件就可以了，完全具有热插拨的特性。 IOC容器的一些产品spring EJB Spring的IOC(将一个类实例化成对象的技术)IOC技术第一个解释叫做控制反转(IOC)，它还有个解释就是依赖注入(DI)，这两个名字很难从字面理解，但是当你理解它的原理后就会发现它们的描述是何等准确。IOC技术的本质就是构建对象的技术换句话说就是将一个类实例化成对象的技术。 耦合具有两面性。一方面，紧密耦合的代码难以测试，难以复用，难以理解，并且表现出“打地鼠”式的bug特性（修复一个bug，导致出现一个新的或者甚至更多的bug）。另一方面，一定程度的耦合又是必须的，完全没有耦合的代码什么也做不了。为了完成有实际意义的工作，不同的类必须以适当的方式进行交互。总而言之，耦合是必须的，但应当小心谨慎的管理它。通过控制反转或者依赖注入，对象的依赖关系将由负责协调系统中各个对象的第三方组件在创建对象时设定。对象无需自行创建或管理它们的依赖关系，依赖关系将被自动注入到需要它们的对象中去。 我们通过实际生活中的一个例子来解释一下IOC： 例如我们有个roo对象作用是完成打猎的操作，那么打猎这个对象内部包含两个辅助对象：人和枪，只有人和枪赋予了打猎这个对象，那么打猎对象才能完成打猎的操作，但是构建一个人和枪的对象并不是看起来那么简单，这里以枪为例，要创造一把枪我们需要金属，需要机床，需要子弹，而机床和子弹又是两个新对象，这些对象一个个相互嵌套相互关联，大伙试想下如果我们在java代码里构建一个枪的对象那是何其的复杂，假如我们要构造的不是简单的枪对象而是更加复杂的航空母舰，那么构造这个对象的成本之高是让人难以想象的，怎么来消除这种对象相互嵌套相互依赖的关系了？ Spring提供了一种方式，这种方式就是Spring提供一个容器，我们在xml文件里定义各个对象的依赖关系，由容器完成对象的构建，当我们Java代码里需要使用某个实例的时候就可以从容器里获取，那么对象的构建操作就被Spring容器接管，所以它被称为控制反转。 控制反转的意思就是本来属于java程序里构建对象的功能交由容器接管，依赖注入就是当程序要使用某个对象时候，容器会把它注入到程序里。在Java开发里我们想使用某个类提供的功能，有两种方式：一种就是构造一个新的类，新的类继承该类，另一种方式则是将某个类定义在新类里，那么两个类之间就建立一种关联关系，Spring的IOC容器就是实现了这种关联关系。 通过上面这段内容，相信大家应该会对IOC有个比较清晰的了解了。关于Spring中IOC部分是如何实现以及使用，就不进行讨论了，本文的目的也是能从整体上把握一下。但可以稍微提一点，Spring的IOC功能其实就是依赖于Java的反射机制。直白点说，当你在xml文件中配置好了bean（bean需要提供全类名）之后，Spring通过自己的类对xml文件进行解析，然后利用反射机制将对象创建出来，然后放到自己的数据结构中，比如Map。然后键就是bean中的id属性的值，值就是创建的对象。 Spring的AOP在设计模式里有一种代理模式，代理模式将继承模式和关联模式结合在一起使用，代理模式就是继承模式和关联模式的综合体，不过这个综合体的作用倒不是解决对象注入的问题，而是为具体操作对象找到一个保姆或者是秘书，这就和小说里的二号首长一样，这个二号首长对外代表了具体的实例对象，实例对象的入口和出口都是通过这个二号首长，具体的实例对象是一号首长，一号首长是要干大事的，所以一些事务性，重复性的工作例如泡茶，安排车子，这样的工作是不用劳烦一号首长的大驾，而是二号首长帮忙解决的，这就是AOP的思想。AOP解决程序开发里事务性，和核心业务无关的问题，但这些问题对于业务场景的实现是很有必要的，在实际开发里AOP也是节省代码的一种方式。 AOP将应用系统分为两部分，核心业务逻辑（Core business concerns）及横向的通用逻辑，也就是所谓的方面Crosscutting enterprise concerns，例如，所有大中型应用都要涉及到的持久化管理（Persistent）、事务管理（Transaction Management）、安全管理（Security）、日志管理（Logging）和调试管理（Debugging）等。 实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“方面”的代码。 过程1. 初始化大致单步跟了下Spring IOC的初始化过程，整个脉络很庞大，初始化的过程主要就是读取XML资源，并解析，最终注册到Bean Factory中： 2. 注入依赖当完成初始化IOC容器后，如果bean没有设置lazy-init(延迟加载)属性，那么bean的实例就会在初始化IOC完成之后，及时地进行初始化。初始化时会先建立实例，然后根据配置利用反射对实例进行进一步操作，具体流程如下所示： 创建bean的实例 注入bean的属性 AOP术语 Join Point: Spring AOP中，join point就是一个方法。（通俗来讲就是起作用的那个方法）。 Pointcut: 用来指定join point（通俗来讲就是描述的一组符合某个条件的join point）。通常使用pointcut表达式来限定joint point，Spring默认使用AspectJ pointcut expression language。 Advice: 在join point上特定的时刻执行的操作，Advice有几种不同类型，下文将会讨论（通俗地来讲就是起作用的内容和时间点）。 Introduction：给对象增加方法或者属性。 Target object: Advice起作用的那个对象。 AOP proxy: 为实现AOP所生成的代理。在Spring中有两种方式生成代理:JDK代理和CGLIB代理。 Aspect: 组合了Pointcut与Advice，在Spring中有时候也称为Advisor。某些资料说Advisor是一种特殊的Aspect，其区别是Advisor只能包含一对pointcut和advice，但是aspect可以包含多对。AOP中的aspect可以类比于OOP中的class。 Weaving：将Advice织入join point的这个过程。 静态代理静态代理是编译阶段生成AOP代理类，也就是说生成的字节码就织入了增强后的AOP对象；动态代理则不会修改字节码，而是在内存中临时生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。实现静态代理常用的方法是通过AspectJ，AspectJ 是一个基于 Java 语言的 AOP 框架，提供了强大的 AOP 功能，主要包含两个部分，第一个部分定义了如何表达、定义 AOP 编程中的语法规范；另一个部分是工具部分，包括编译器、调试工具等。Aspectj实现了独有的编译器，在编译时生成代理类文件 Spring的AOP代理对象的生成spring支持AspectJ风格的AOP还是动态的，标注中用到的JoinPoint等类都来自aspectj包 Spring提供了两种方式来生成代理对象: JDKProxy和Cglib，具体使用哪种方式生成由AopProxyFactory根据AdvisedSupport对象的配置来决定。默认的策略是如果目标类是接口，则使用JDK动态代理技术，否则使用Cglib来生成代理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;@Component@Aspectpublic class SimpleAspect &#123; @Pointcut(&quot;execution(* cn.outofmemory.spring_aop_aspect.*Service*.*(..))&quot;) public void pointCut() &#123; &#125; @After(&quot;pointCut()&quot;) public void after(JoinPoint joinPoint) &#123; System.out.println(&quot;after aspect executed&quot;); &#125; @Before(&quot;pointCut()&quot;) public void before(JoinPoint joinPoint) &#123; //如果需要这里可以取出参数进行处理 //Object[] args = joinPoint.getArgs(); System.out.println(&quot;before aspect executing&quot;); &#125; @AfterReturning(pointcut = &quot;pointCut()&quot;, returning = &quot;returnVal&quot;) public void afterReturning(JoinPoint joinPoint, Object returnVal) &#123; System.out.println(&quot;afterReturning executed, return result is &quot; + returnVal); &#125; @Around(&quot;pointCut()&quot;) public void around(ProceedingJoinPoint pjp) throws Throwable &#123; System.out.println(&quot;around start..&quot;); try &#123; pjp.proceed(); &#125; catch (Throwable ex) &#123; System.out.println(&quot;error in around&quot;); throw ex; &#125; System.out.println(&quot;around end&quot;); &#125; @AfterThrowing(pointcut = &quot;pointCut()&quot;, throwing = &quot;error&quot;) public void afterThrowing(JoinPoint jp, Throwable error) &#123; System.out.println(&quot;error:&quot; + error); &#125;&#125; jdkProxyJDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。 核心是InvocationHandler接口和Proxy类。 java.lang.reflect.Proxy，这是Java动态代理机制生成的所有动态代理类的父类，它提供静态方法来为一组接口动态地生成代理类及其对象。 java.lang.reflect.InvocationHandler，这是调用处理器接口，它自定义了一个invoke方法，用于实现代理逻辑、转发请求给对原始类对象。 继承了Proxy类，实现了代理的接口，由于java不能多继承，这里已经继承了Proxy类了，不能再继承其他的类，所以JDK的动态代理不支持对实现类的代理，只支持接口的代理 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; // prefix for all proxy class names private static final String proxyClassNamePrefix = &quot;$Proxy&quot;; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + &quot; is not visible from class loader&quot;); &#125; /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + &quot; is not an interface&quot;); &#125; /* * Verify that this interface is not a duplicate. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( &quot;repeated interface: &quot; + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf(&apos;.&apos;); String pkg = ((n == -1) ? &quot;&quot; : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( &quot;non-public interfaces from different packages&quot;); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + &quot;.&quot;; &#125; /* * Choose a name for the proxy class to generate. */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125; &#125; 1234567apply:639, Proxy$ProxyClassFactory &#123;java.lang.reflect&#125;apply:557, Proxy$ProxyClassFactory &#123;java.lang.reflect&#125;get:230, WeakCache$Factory &#123;java.lang.reflect&#125;get:127, WeakCache &#123;java.lang.reflect&#125;getProxyClass0:419, Proxy &#123;java.lang.reflect&#125;newProxyInstance:719, Proxy &#123;java.lang.reflect&#125;main:11, ProxyTest &#123;com.example.demo.proxy.jdk&#125; 获取的对象是$Proxy对象,里面持有了真正的原始对象 cglib核心是MethodInterceptor接口和Enhancer类对于final方法，无法进行代理(不报错,正常执行原方法) 123456789101112131415161718192021222324252627282930public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); public Object getProxy(Class clazz)&#123; //设置需要创建子类的类 enhancer.setSuperclass(clazz); enhancer.setCallback(this); //通过字节码技术动态创建子类实例 return enhancer.create(); &#125; //实现MethodInterceptor接口方法 public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println(&quot;前置代理&quot;); //通过代理类调用父类中的方法 Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;后置代理&quot;); return result; &#125;&#125;public class DoCGLib &#123; public static void main(String[] args) &#123; CglibProxy proxy = new CglibProxy(); //通过生成子类的方式创建代理类 HelloWorldImpl proxyImp = (HelloWorldImpl)proxy.getProxy(HelloWorldImpl.class); proxyImp.sayHello(&quot;wing&quot;);&#125;&#125; spring生命周期 1.Spring对Bean进行实例化（相当于程序中的new Xx()） 2.Spring将值和Bean的引用注入进Bean对应的属性中 3.如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的） 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等） 5.如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把y应用上下文作为参数传入.(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory ) 6.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization（预初始化）方法（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能） 7.如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。 8.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization（后初始化）方法（作用与6的一样，只不过6是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 ) 9.经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 10.如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。 Bean的完整生命周期经历了各种方法调用，这些方法可以划分为以下几类： 1、Bean自身的方法 ： 这个包括了Bean本身调用的方法和通过配置文件中的init-method和destroy-method指定的方法 2、Bean级生命周期接口方法 ： 这个包括了BeanNameAware、BeanFactoryAware、InitializingBean和DiposableBean这些接口的方法 3、容器级生命周期接口方法 ： 这个包括了InstantiationAwareBeanPostProcessor 和 BeanPostProcessor 这两个接口实现，一般称它们的实现类为“后处理器”。 4、工厂后处理器接口方法 ： 这个包括了AspectJWeavingEnabler, ConfigurationClassPostProcessor, CustomAutowireConfigurer等等非常有用的工厂后处理器 接口的方法。工厂后处理器也是容器级的。在应用上下文装配配置文件之后立即调用。 1.类级别生命周期回调 1.1 init-method xml配置 1.2 InitializingBean接口 1.3 PostConstruct注解2.容器级别扩展 2.1BeanPostProcessor接口bean实例初始化后处理器及后处理器链实例初始化后处理器多用于对实例的一些代理操作。Spring中一些使用到AOP的特性也是通过后处理器的方式实现的。实例初始化后处理器链 是多个后处理器，就会有执行顺序的问题，可以通过实现Ordered接口，指定后处理的执行顺序，Ordered接口声明了getOrder方法，方法返回值越小，后处理的优先级越高，越早执行。在通过实现BeanPostProcessor接口自定义实例初始化后处理器的时候，建议也实现Ordered接口，指定优先级。 2.2 BeanFactoryPostProcessor接口2.2.1 bean factory后处理器BeanFactoryPostProcessors接口在bean实例化前处理bean的配置元数据，BeanPostProcessor接口在bean实例化后处理bean的实例 https://www.cnblogs.com/zrtqsk/p/3735273.html springbean是否线程安全我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。 无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。 spring 的优点？1.降低了组件之间的耦合性 ，实现了软件各层之间的解耦 2.可以使用容易提供的众多服务，如事务管理，消息服务等 3.容器提供单例模式支持 4.容器提供了AOP技术，利用它很容易实现如权限拦截，运行期监控等功能 5.容器提供了众多的辅助类，能加快应用的开发 6.spring对于主流的应用框架提供了集成支持，如hibernate，JPA，Struts等 7.spring属于低侵入式设计，代码的污染极低 8.独立于各种应用服务器 9.spring的DI机制降低了业务对象替换的复杂性 10.Spring的高度开放性，并不强制应用完全依赖于Spring，开发者可以自由选择spring的部分或全部]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[desin_pattern]]></title>
    <url>%2F2018%2F01%2F19%2Fdesign_pattern%2Fdesin-pattern%2F</url>
    <content type="text"><![CDATA[模板方法（Template Method ）定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。Template Method模式一般是需要继承的。这里想要探讨另一种对Template Method的理解。spring中的JdbcTemplate，在用这个类时并不想去继承这个类，因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。这可能是Template Method不需要继承的另一种实现方式吧。 策略（Strategy ）观察者（Observer ）定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。spring中Observer模式常用的地方是listener的实现。如ApplicationListener。 包装器（Decorator ）在我们的项目中遇到这样一个问题：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。我们以往在spring和hibernate框架中总是配置一个数据源，因而sessionFactory的dataSource属性总是指向这个数据源并且恒定不变，所有DAO在使用sessionFactory的时候都是通过这个数据源访问数据库。但是现在，由于项目的需要，我们的DAO在访问sessionFactory的时候都不得不在多个数据源中不断切换，问题就出现了：如何让sessionFactory在执行数据持久化的时候，根据客户的需求能够动态切换不同的数据源？我们能不能在spring的框架下通过少量修改得到解决？是否有什么设计模式可以利用呢？首先想到在spring的applicationContext中配置所有的dataSource。这些dataSource可能是各种不同类型的，比如不同的数据库：Oracle、SQL Server、MySQL等，也可能是不同的数据源：比如apache 提供的org.apache.commons.dbcp.BasicDataSource、spring提供的org.springframework.jndi.JndiObjectFactoryBean等。然后sessionFactory根据客户的每次请求，将dataSource属性设置成不同的数据源，以到达切换数据源的目的。spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。基本上都是动态地给一个对象添加一些额外的职责。 代理（Proxy ）为其他对象提供一种代理以控制对这个对象的访问。 从结构上来看和Decorator模式类似，但Proxy是控制，更像是一种对功能的限制，而Decorator是增加职责。spring的Proxy模式在aop中有体现，比如JdkDynamicAopProxy和Cglib2AopProxy。 单例模式（Singleton ）保证一个类仅有一个实例，并提供一个访问它的全局访问点。spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是是任意的java对象。核心提示点：Spring下默认的bean均为singleton，可以通过singleton=“true|false” 或者 scope=“？”来指定 适配器（Adapter ）在Spring的Aop中，使用的Advice（通知）来增强被代理类的功能。Spring实现这一AOP功能的原理就使用代理模式（1、JDK动态代理。2、CGLib字节码生成技术代理。）对类进行方法级别的切面增强，即，生成被代理类的代理类， 并在代理类的方法前，设置拦截器，通过执行拦截器重的内容增强了代理方法的功能，实现的面向切面编程。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reivew_spring_mvc]]></title>
    <url>%2F2018%2F01%2F18%2Fjava_spring%2Freivew-spring-mvc%2F</url>
    <content type="text"><![CDATA[springmvc是什么 Spring Web MVC是一种基于Java的实现了Web MVC设计模式的请求驱动类型的轻量级Web框架 将web层进行职责解耦 工作者模式的实现???帮我们做什么 让我们能非常简单的设计出干净的Web层和薄薄的Web层； 进行更简洁的Web层的开发； 天生与Spring框架集成（如IoC容器、AOP等）； 提供强大的约定大于配置的契约式编程支持； 能简单的进行Web层的单元测试； 支持灵活的URL到页面控制器的映射； 非常容易与其他视图技术集成，如Velocity、FreeMarker等等，因为模型数据不放在特定的API里，而是放在一个Model里（Map数据结构实现，因此很容易被其他框架使用）； 非常灵活的数据验证、格式化和数据绑定机制，能使用任何对象进行数据绑定，不必实现特定框架的API； 提供一套强大的JSP标签库，简化JSP开发； 支持灵活的本地化、主题等解析； 更加简单的异常处理； 对静态资源的支持； 支持Restful风格。 架构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//前端控制器分派方法 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; int interceptorIndex = -1; try &#123; ModelAndView mv; boolean errorView = false; try &#123; //检查是否是请求是否是multipart（如文件上传），如果是将通过MultipartResolver解析 processedRequest = checkMultipart(request); //步骤2、请求到处理器（页面控制器）的映射，通过HandlerMapping进行映射 mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; //步骤3、处理器适配，即将我们的处理器包装成相应的适配器（从而支持多种类型的处理器） HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 304 Not Modified缓存支持 //此处省略具体代码 // 执行处理器相关的拦截器的预处理（HandlerInterceptor.preHandle） //此处省略具体代码 // 步骤4、由适配器执行处理器（调用处理器相应功能处理方法） mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // Do we need view name translation? if (mv != null &amp;&amp; !mv.hasView()) &#123; mv.setViewName(getDefaultViewName(request)); &#125; // 执行处理器相关的拦截器的后处理（HandlerInterceptor.postHandle） //此处省略具体代码 &#125; catch (ModelAndViewDefiningException ex) &#123; logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, ex); mv = ex.getModelAndView(); &#125; catch (Exception ex) &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(processedRequest, response, handler, ex); errorView = (mv != null); &#125; //步骤5 步骤6、解析视图并进行视图的渲染 //步骤5 由ViewResolver解析View（viewResolver.resolveViewName(viewName, locale)） //步骤6 视图在渲染时会把Model传入（view.render(mv.getModelInternal(), request, response);） if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, processedRequest, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Null ModelAndView returned to DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;: assuming HandlerAdapter completed request handling&quot;); &#125; &#125; // 执行处理器相关的拦截器的完成后处理（HandlerInterceptor.afterCompletion） //此处省略具体代码 catch (Exception ex) &#123; // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; catch (Error err) &#123; ServletException ex = new NestedServletException(&quot;Handler processing failed&quot;, err); // Trigger after-completion for thrown exception. triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, ex); throw ex; &#125; finally &#123; // Clean up any resources used by a multipart request. if (processedRequest != request) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; 核心架构的具体流程步骤如下： 1、 首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制； 2、 DispatcherServlet——&gt;HandlerMapping， HandlerMapping将会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略； 3、 DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器； 4、 HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）； 5、 ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术； 6、 View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术； 7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 此处我们只是讲了核心流程，没有考虑拦截器、本地解析、文件上传解析等，后边再细述。 hello world DispatcherServlet：Spring提供的前端控制器，所有的请求都有经过它来统一分发。在DispatcherServlet将请求分发给Spring Controller之前，需要借助于Spring提供的HandlerMapping定位到具体的Controller。 HandlerMapping：能够完成客户请求到Controller映射。 Controller：需要为并发用户处理上述请求，因此实现Controller接口时，必须保证线程安全并且可重用。Controller将处理用户请求，这和Struts Action扮演的角色是一致的。一旦Controller处理完用户请求，则返回ModelAndView对象给DispatcherServlet前端控制器，ModelAndView中包含了模型（Model）和视图（View）。从宏观角度考虑，DispatcherServlet是整个Web应用的控制器；从微观考虑，Controller是单个Http请求处理过程中的控制器，而ModelAndView是Http请求过程中返回的模型（Model）和视图（View）。 ViewResolver：Spring提供的视图解析器（ViewResolver）在Web应用中查找View对象，从而将相应结果渲染给客户。 DispatcherServlet与HttpMessageConverter的关系//TODO http://sishuok.com/forum/blogPost/list/5160.html]]></content>
      <categories>
        <category>springmvc</category>
      </categories>
      <tags>
        <tag>springmvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[btrace-study]]></title>
    <url>%2F2018%2F01%2F18%2Fjava_tools%2Fbtrace-study%2F</url>
    <content type="text"><![CDATA[btrace概念: Probe Point: “location” or “event” at which a set of tracing statements are executed. Probe point is “place” or “event” of interest where we want to execute some tracing statements.（探测点，就是我们想要执行一些追踪语句的地方或事件） Trace Actions or Actions: Trace statements that are executed whenever a probe “fires”.（当探测触发时执行追踪语句） Action Methods: BTrace trace statements that are executed when a probe fires are defined inside a static method a class. Such methods are called “action” methods.（当在类的静态方法中定义了探测触发时执行的BTrace跟踪语句。这种方法被称为“操作”方法。） 学习的博客:http://mgoann.iteye.com/blog/1409685http://calvin1978.blogcn.com/articles/btrace1.htmlhttp://codepub.cn/2017/09/22/btrace-uses-tutorials/ byteman局部变量http://codepub.cn/2017/09/22/byteman-uses-tutorials/ github地址:https://github.com/btraceio/btrace 可运行包 下载地址https://github.com/btraceio/btrace/releases/tag/v1.3.10]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo需求]]></title>
    <url>%2F2018%2F01%2F17%2Fjava_dubbo%2Fstudy-dubbo%2F</url>
    <content type="text"><![CDATA[需求流程图服务授权服务降级软负载均衡服务路由服务编排服务质量协定服务容量服务注册与发现服务质量协定 其他需求 服务注册中心 替代 f5负载均衡服务器(内部使用) 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。 此时需要一个服务注册中心，动态的注册和发现服务，使服务的位置透明。并通过在消费方获取服务提供方地址列表，实现软负载均衡和 Failover，降低对 F5 硬件负载均衡器的依赖，也能减少部分成本。 应用依赖 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。 这时，需要自动画出应用间的依赖关系图，以帮助架构师理清理关系。 调用(调用量,响应时间)监控 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？ 为了解决这些问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阀值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 架构]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful-API概念学习]]></title>
    <url>%2F2018%2F01%2F15%2Fhttp%2Fadvantage-api%2F</url>
    <content type="text"><![CDATA[RESTful API 透明性，暴露资源存在。 充分利用 HTTP 协议本身语义。 无状态，这点非常重要。在调用一个接口（访问、操作资源）的时候，可以不用考虑上下文，不用考虑当前状态，极大的降低了复杂度 HTTP 本身提供了丰富的内容协商手段，无论是缓存，还是资源修改的乐观并发控制，都可以以业务无关的中间件来实现 理解RESTful架构 Representational State Transfer REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 最常见的一种设计错误，就是URI包含动词。因为”资源”表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。 因为不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。版本号可以在HTTP请求头信息的Accept字段中进行区分http://www.ruanyifeng.com/blog/2011/09/restful.html RESTful API 设计指南 协议 域名 版本（Versioning） 路径（Endpoint）在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 HTTP动词 过滤信息（Filtering） 状态码（Status Codes） 错误处理 返回结果 Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 其他 （1）API的身份认证应该使用OAuth 2.0框架。 （2）服务器返回的数据格式，应该尽量使用JSON，避免使用XML。 http://www.ruanyifeng.com/blog/2014/05/restful_api.html]]></content>
      <categories>
        <category>HTTP协议</category>
      </categories>
      <tags>
        <tag>HTTP协议</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-线程复习]]></title>
    <url>%2F2018%2F01%2F13%2Fjava_thread%2Freview-java-thread%2F</url>
    <content type="text"><![CDATA[线程创建线程有两种方式：一、继承 Thread 类，扩展线程。二、实现 Runnable 接口。 Callable接口Future接口FutureTask实现了 Future 接口FutureTask 的好处是 FutureTask 是为了弥补 Thread 的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果。FutureTask 是一种可以取消的异步的计算任务，它的计算是通过 Callable 实现的，它等价于可以携带结果的 Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。 多线程多线程的概念很好理解就是多条线程同时存在，但要用好多线程确不容易，涉及到多线程间通信，多线程共用一个资源等诸多问题。 synchronized解决多个线程之间访问资源的同步性 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 锁提供了两种主要特性：互斥（mutual exclusion） 和可见性（visibility）。互斥即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。可见性要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题。 volatile解决变量在多个线程之间的可见性 出于简易性或可伸缩性的考虑，您可能倾向于使用 volatile 变量而不是锁。当使用 volatile 变量而非锁时，某些习惯用法（idiom）更加易于编码和阅读。此外，volatile 变量不会像锁那样造成线程阻塞，因此也很少造成可伸缩性问题。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。 正确使用 volatile 变量的条件您只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件： 对变量的写操作不依赖于当前值。该变量没有包含在具有其他变量的不变式中。实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使 x 的值在操作期间保持不变，而 volatile 变量无法实现这点。（然而，如果将值调整为只从单个线程写入，那么可以忽略第一个条件。） 大多数编程情形都会与这两个条件的其中之一冲突，使得 volatile 变量不能像 synchronized 那样普遍适用于实现线程安全。清单 1 显示了一个非线程安全的数值范围类。它包含了一个不变式 —— 下界总是小于或等于上界。 小结与锁相比，Volatile 变量是一种非常简单但同时又非常脆弱的同步机制，它在某些情况下将提供优于锁的性能和伸缩性。如果严格遵循 volatile 的使用条件 —— 即变量真正独立于其他变量和自己以前的值 —— 在某些情况下可以使用 volatile 代替 synchronized 来简化代码。然而，使用 volatile 的代码往往比使用锁的代码更加容易出错。本文介绍的模式涵盖了可以使用 volatile 代替 synchronized 的最常见的一些用例。遵循这些模式（注意使用时不要超过各自的限制）可以帮助您安全地实现大多数用例，使用 volatile 变量获得更佳性能。 wait()、notify()、notifyAll()wait():我的部分已经做完了,等别人让我做的时候再做,释放锁notify():等我做完了,释放锁后,让其他一个人做wait() 与 Thread.sleep(long time) 的区别:sleep傻等,sleep不释放锁 1234567891011121314作者：孙立伟链接：https://www.zhihu.com/question/23328075/answer/24228413来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。首先，要记住这个差别，“sleep是Thread类的方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。线程的状态参考 Thread.State的定义。新创建的但是没有执行（还没有调用start())的线程处于“就绪”，或者说Thread.State.NEW状态。Thread.State.BLOCKED（阻塞）表示线程正在获取锁时，因为锁不能获取到而被迫暂停执行下面的指令，一直等到这个锁被别的线程释放。BLOCKED状态下线程，OS调度机制需要决定下一个能够获取锁的线程是哪个，这种情况下，就是产生锁的争用，无论如何这都是很耗时的操作。 ThreadLocal 变量线程隔离InheritableTreadLocal让子线程获取父线程中取得值 join() 方法等待线程对象销毁等待子进程执行完,我再执行Thread.yield() 方法 ReentrantLocklock()unlock()condition等待/通知 awiate() 相当于Object类中的wait()方法 await(long time,TImeUnit unit) 相当于Object类中的wait()方法 signal() 相当于Object类中的notify()方法 sigalAll() 相当于Object类中的notifyAll()方法 通知部分线程Lock lock=new Reentrantock();Condition conditionA=lock.newCondition();Condition conditionB=lock.newCondition(); 公平锁,非公平锁 获取锁的顺序是按照线程加锁的顺序来分配的,及先来先得的FIFO先进先出顺序 getHoldCount(),getQueueLength(),getWaiteQueueLength() getHoldCount()查询当前线程保持此锁定的个数,调用lock()方法的次数 getQueueLength()返回正在等待次锁定的线程估计数 getWaiteQueueLength(Condition condition)返回等待与此锁定翔安的给定条件Condition的线程估计数 线程状态切换 监视器代表synchronized lock代表锁 AtomicInteger类ReentrantReadWriteLock参考https://www.ibm.com/developerworks/cn/java/j-jtp06197.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk1.9-maven-fix]]></title>
    <url>%2F2018%2F01%2F08%2Fjava_tools%2Fjdk1-9-maven-fix%2F</url>
    <content type="text"><![CDATA[背景在安装了多个jdk版本后,发现maven命令不好使了 现象 maven-compiler-plugin:3.1:compile (default-compile) @ report 出现异常12345678910111213141516171819202122[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ report ---[INFO] Changes detected - recompiling the module![INFO] Compiling 60 source files to /Users/victor/code/egenieProjects/report/target/classesWARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by lombok.javac.apt.Processor to field com.sun.tools.javac.processing.JavacProcessingEnvironment.processorClassLoaderWARNING: Please consider reporting this to the maintainers of lombok.javac.apt.ProcessorWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.198 s[INFO] Finished at: 2018-01-08T14:04:55+08:00[INFO] Final Memory: 35M/115M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project report: Fatal error compiling: java.lang.NoSuchFieldError: pid -&gt; [Help 1][ERROR][ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR][ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException 解决 1.9 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 9.0.1, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/HomeDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 执行命令 1echo -n &quot;JAVA_HOME=`/usr/libexec/java_home -v 1.8`&quot; &gt; ~/.mavenrc 1.8 1234567victordeMacBook-Pro:report victor$ mvn -vApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/Cellar/maven/3.5.2/libexecJava version: 1.8.0_151, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.13.2&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot; 思考虽然此种方法解决了这个问题,但具体是什么原因导致的此问题,还需进一步研究 参考http://geeekr.com/fix-maven-java-version-mac-osx/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>JDK1.9</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-sql-update-lock]]></title>
    <url>%2F2018%2F01%2F06%2Fegenie_bugfix%2Ferror-sql-update-lock%2F</url>
    <content type="text"><![CDATA[com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Lock wait timeout exceeded; try restarting transaction 事务没有提交导致 锁等待 https://www.jianshu.com/p/0b4aaa93e7f6]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenv安装(管理多个jdk版本)]]></title>
    <url>%2F2018%2F01%2F06%2Fjava_tools%2Finstall-jenv%2F</url>
    <content type="text"><![CDATA[1.安装jenv1brew install jenv 2.oracle官网下载各版本jdk 3.安装本地123jenv add /Library/Java/JavaVirtualMachines/jdk-9.0.1.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home 4.列表jdk1jenv versions system (set by /Users/victor/.jenv/version)1.71.7.0.801.81.8.0.1519.09.0.1oracle64-1.7.0.80oracle64-1.8.0.151oracle64-9.0.1 5.选择jdk12jenv global 1.7java -version java version “1.7.0_80”Java(TM) SE Runtime Environment (build 1.7.0_80-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.80-b11, mixed mode)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BI-olap技术选型]]></title>
    <url>%2F2018%2F01%2F05%2Fdata_warehouse%2FBI-olap-tool%2F</url>
    <content type="text"><![CDATA[备选列表: 阿里云-分析性数据库 GreePlum Presto Kylin 阿里云-分析性数据库 GreePlum Greenplum采用Postgresl作为底层引擎，良好的兼容了Postgresql的功能 Greenplum的艺术，一切皆并行（Parallel Everything） Greenplum建立在Share-nothing无共享架构上，让每一颗CPU和每一块磁盘IO都运转起来，无共享架构将这种并行处理发挥到极致。相比一些其它传统数据仓库的Sharedisk架构，后者最大瓶颈就是在IO吞吐上，在大规模数据处理时，IO无法及时feed数据给到CPU，CPU资源处于wait 空转状态，无法充分利用系统资源，导致SQL效率低下 得益于Postgresql的良好扩展性（这里是extension，不是scalability），Greenplum 可以采用各种开发语言来扩展用户自定义函数（UDF） Greenplum MPP 与 Hadoop相同点 分布式存储数据在多个节点服务器上 采用分布式并行计算框架 支持横向扩展来提高整体的计算能力和存储容量 都支持X86开放集群架构 差异点 MPP按照关系数据库行列表方式存储数据（有模式），Hadoop按照文件切片方式分布式存储（无模式） 两者采用的数据分布机制不同，MPP采用Hash分布，计算节点和存储紧密耦合，数据分布粒度在记录级的更小粒度（一般在1k以下）；Hadoop FS按照文件切块后随机分配，节点和数据无耦合，数据分布粒度在文件块级（缺省64MB）。 MPP采用SQL并行查询计划，Hadoop采用Mapreduce框架 Presto Facebook贡献的开源MPP OLAP引擎。 这是一个红酒的名字，因为开发组所有的人都喜欢喝这个牌子的红酒，所以把它命名为这个名字。作为MPP引擎，它的处理方式是把所有的数据Scan出来，通过Hash的方法把数据变成更小的块，让不同的节点并发，处理完结果后快速地返回给用户。我们看到它的逻辑架构也是这样，发起一个SQL，然后找这些数据在哪些HDFS节点上，然后分配后做具体的处理，最后再把数据返回。 Kylin Kylin是由eBay开源的一个引擎，Kylin把数据读出来做计算，结算的结果会被存在HBase里，通过HBase做Ad-hoc的功能。HBase的好处是有索引的，所以做Ad-hoc的性能非常好。]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>olap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java集合并发修改]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_common%2Fstudy-ConcurrentModificationException%2F</url>
    <content type="text"><![CDATA[并发修改当一个或多个线程正在遍历一个集合Collection，此时另一个线程修改了这个集合的内容（添加，删除或者修改）.这就是并发修改 快速失败（fail—fast） “快速失败”，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出ConcurrentModificationException 异常，从而产生fail-fast机制。 何时触发快速失败 无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。所以我们这里可以初步判断由于expectedModCount得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。 安全失败（fail—safe） 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 p.s.迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的 快速失败和安全失败的比较 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModification Exception Yes No Clone object No Yes Memory Overhead No Yes Examples HashMap,Vector,ArrayList,HashSet CopyOnWriteArrayList,ConcurrentHashMap 产生fail-fast的是在java.util包中的collection实现类；产生fail-safe的是在java.util.concurrent包中的collection实现类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发修改</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-skip-list]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-skip-list%2F</url>
    <content type="text"><![CDATA[跳跃表 一种基于有序链表的扩展 利用类似索引的思想,找到关键点 删除 自上而下，查找第一次出现节点的索引，并逐层找到每一层对应的节点。O（logN） 删除每一层查找到的节点，如果该层只剩下1个节点，删除整个一层（原链表除外）。O（logN） 区别 跳跃表 维持平衡的成本较低,完全靠随机 二叉树需要靠rebalance来重新调整结构 应用Redis当中的Sorted-set]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>跳跃表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-red–black-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-red%E2%80%93black-tree%2F</url>
    <content type="text"><![CDATA[二叉搜索树由于红黑树本质上就是一棵二叉查找树，所以在了解红黑树之前，咱们先来看下二叉查找树。 二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 因为，一棵由n个结点，随机构造的二叉查找树的高度为lgn，所以顺理成章，一般操作的执行时间为O（lgn）.（至于n个结点的二叉树高度为lgn的证明，可参考算法导论 第12章 二叉查找树 第12.4节）。 但二叉树若退化成了一棵具有n个结点的线性链后，则此些操作最坏情况运行时间为O（n）。后面我们会看到一种基于二叉查找树-红黑树，它通过一些性质使得树相对平衡，使得最终查找、插入、删除的时间复杂度最坏情况下依然为O（lgn）。 红黑树特性前面我们已经说过，红黑树，本质上来说就是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。 但它是如何保证一棵n个结点的红黑树的高度始终保持在h = logn的呢？这就引出了红黑树的5条性质： 1）每个结点要么是红的，要么是黑的。 2）根结点是黑的。 3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 4）如果一个结点是红的，那么它的俩个儿子都是黑的。 5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度，从而也就解释了上面我们所说的“红黑树的查找、插入、删除的时间复杂度最坏为O(log n)”这一结论的原因。 如下图所示，即是一颗红黑树(下图引自wikipedia：http://t.cn/hgvH1l)： 应用 treemap treeset 1.8中的hashset https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.01.md https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-b-tree]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_data_structure%2Fstudy-b-tree%2F</url>
    <content type="text"><![CDATA[b-树 数据库索引使用b-树 二叉树查找的时间复杂度O(logN) 问题:磁盘IO 最坏的情况下,磁盘IO等于索引树的高度 把原来”瘦高”的树结构变得”矮胖”就是b-树的特征之一 B树是一种多路平衡查找树 B树与红黑树最大的不同在于，B树的结点可以有许多子女，从几个到几千个。 定义 树中每个结点最多含有m个孩子（m&gt;=2）； 除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子（其中ceil(x)是一个取上限的函数）； 根结点至少有2个孩子（除非B树只包含一个结点：根结点）； 所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询失败的结点，指向这些结点的指针都为null)；（注：叶子节点只是没有孩子和指向孩子的指针，这些节点也存在，也有元素。类似红黑树中，每一个NULL指针即当做叶子结点，只是没画出来而已）。 每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，……，Kn，Pn)。其中：a) Ki (i=1…n)为关键字，且关键字按顺序升序排序K(i-1)&lt; Ki。b) Pi为指向子树根的结点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。c) 关键字的个数n必须满足： [ceil(m / 2)-1]&lt;= n &lt;= m-1。比如有j个孩子的非叶结点恰好有j-1个关键码。 应用 文件系统 数据库索引 b+树 1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。 b+树种,只有叶子节点带有卫星信息,其余中间节点仅仅是索引,没有任何数据关联 在数据库的聚集索引（Clustered Index）中，叶子节点直接包含卫星数据。在非聚集索引（NonClustered Index）中，叶子节点带有指向卫星数据的指针。 B+树的优势：1.单一节点存储更多的元素，使得查询的IO次数更少。2.所有查询都要查找到叶子节点，查询性能稳定。3.所有叶子节点形成有序链表，便于范围查询。 引用 mysql的b树索引的物理文件 B*树 B-tree是B+-tree的变体，在B+树的基础上(所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针)，B树中非根和非叶子结点再增加指向兄弟的指针；B树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）。 B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针。 B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。 所以，B*树分配新结点的概率比B+树要低，空间使用率更高； 总结通过以上介绍，大致将B树，B+树，B*树总结如下： B树：有序数组+平衡多叉树； B+树：有序数组链表+平衡多叉树； B*树：一棵丰满的B+树。 顺便说一句，无论是B树，还是B+树、b树，由于根或者树的上面几层被反复查询，所以这几块可以存在内存中，换言之，B树、B+树、B树的根结点和部分顶层数据在内存中，大部分下层数据在磁盘上。 mysql中InnoDB索引和MyISAM索引的区别： myISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。 InnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。使用辅助索引需要查找 两次索引。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组，其中各个元素均为数据表的一列。 主索引的区别，InnoDB的数据文件本身就是索引文件。而MyISAM的索引和数据是分开的。 辅助索引的区别：InnoDB的辅助索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。 聚簇索引 非聚簇索引 聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 https://github.com/julycoding/The-Art-Of-Programming-By-July/blob/master/ebook/zh/03.02.md]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>b-tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK- MashMap 学习]]></title>
    <url>%2F2018%2F01%2F05%2Fjava_common%2Fstudy-hashmap%2F</url>
    <content type="text"><![CDATA[hashmap数据结构12345678910//链表static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125;//数组transient Node&lt;K,V&gt;[] table; HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干。 HashMap 使用后台数组（backing array）作为桶，并使用链表（linked list）存储键／值对。 通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Factor则resize为原来的2倍)。 获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。 如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。HashMap存储着Entry(hash, key, value, next)对象。 当key==null时，存在table[0]即第一个桶中，hash值为0。HashMap对key==null的键值对会做单独处理 Capacity的默认值为16： static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; 负载因子的默认值为0.75： static final float DEFAULT_LOAD_FACTOR = 0.75f; 简单的说，Capacity就是bucket的大小，Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话不要把Capacity设置过大，也不要把load factor设置过小。当bucket中的entries的数目大于capacity*load factor时就需要调整bucket的大小为当前的2倍。 可以设置初始容量Capacity，但是在HashMap处理过程中，是会把Capacity扩充成2的倍数 HashMap中有一个成员变量modCount，这个用来实现“fast-fail”机制（也就是快速失败）。所谓快速失败就是在并发集合中，其进行迭代操作时，若有其他线程对其结构性的修改，这是迭代器会立马感知到，并且立刻抛出ConcurrentModificationException异常，而不是等待迭代完成之后才告诉你已经出错。 get方法 取key的hashCode值 高位运算 取模运算jdk1.7的hash方法12345678910final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; jdk1.8的hash方法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 混合原始哈希码的高位和低位，以此来加大低位的随机性 而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来 图片出处:https://www.zhihu.com/question/20733617 indexFor方法(根据上一步hash结果,计算数组的下表)1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; getNode/getEntry–在链表中确定元素12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; hashmap的初始长度 16,长度必须是2的幂 之所以16是为了服务于哈希函数 index = HashCode（Key） &amp; （Length - 1） 与运算，101110001110101110 1001 &amp; 1111 = 1001，十进制是9，所以 index=9。 Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位 效果上等同于取模,而且大大提高了性能 put方法 先插找 如果已存在,则替换 如果不存在,插入 检查是否需要rehash rehash用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 默认当Entry数量达到桶数量的75%时，哈希冲突已比较严重，就会成倍扩容桶数组，并重新分配所有原来的Entry。 hashmap在扩容时候的步骤之一 衡量HashMap是否进行Resize的条件如下： HashMap.Size &gt;= Capacity * LoadFactor 具体两个步骤 1.扩容:创建一个新的Entry空数组，长度是原数组的2倍。 2.ReHash:遍历原Entry数组，把所有的Entry重新Hash到新数组 1.7源码123456789101112131415161718192021222324252627282930 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置 在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 其他博客中resize的错误表述:1对于原bullet中的链表中的数据在扩容之后肯定还在一个链表中，因为hash值是一样的 此描述是错误的,在一个链表中,不一定代表hash是一样的,只是代表hash&amp;(length-1)计算后的结果是一样的 并发问题 ReHash在并发的情况下可能会形成链表环。 让下一次循环出现死循环 ConcurrentHashMap 避免hashmap的方法有:hashtable,Collections.sysnchronizedMap 但是上面的都有性能问题,导致阻塞 Sement 可以说，ConcurrentHashMap是一个二级哈希表。在一个总的哈希表下面，有若干个子哈希表。这样的二级结构，和数据库的水平拆分有些相似。 不同Segment的写入是可以并发执行的。 同一Segment的一写一读 同一Segment的并发写入 12345678910111213141516171819202122Get方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.再次通过hash值，定位到Segment当中数组的具体位置。Put方法：1.为输入的Key做Hash运算，得到hash值。2.通过hash值，定位到对应的Segment对象3.获取可重入锁4.再次通过hash值，定位到Segment当中数组的具体位置。5.插入或覆盖HashEntry对象。6.释放锁。 如果在统计Segment元素数量的过程中，已统计过的Segment瞬间插入新的元素，这时候该怎么办呢？ 123456789101112131415ConcurrentHashMap的Size方法是一个嵌套循环，大体逻辑如下：1.遍历所有的Segment。2.把Segment的元素数量累加起来。3.把Segment的修改次数累加起来。4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。7.释放锁，统计结束。 为了尽量不锁住所有Segment，首先乐观地假设Size过程中不会有修改。当尝试一定次数，才无奈转为悲观锁，锁住所有Segment保证强一致性。 jdk 1.8hashmap HashMap采用的是数组+链表+红黑树的形式。 什么时候链表转化为红黑树？当数组大小已经超过64并且链表中的元素个数超过默认设定（8个）时，将链表转化为红黑树 jdk 1.8ConcurrentHashMap与hashTable的区别 继承的父类不同:Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类， 线程安全性不同:Hashtable 中的方法是Synchronize的 是否提供contains方法:HashMap把Hashtable的contains方法去掉了 key和value是否允许null值:Hashtable中，key和value都不允许出现null值。HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。 两个遍历方式的内部实现上不同:Hashtable还使用了Enumeration的方式 。 hash值不同:哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。 内部实现使用的数组初始化和扩容方式不同:Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 数据结构要知道hashmap是什么，首先要搞清楚它的数据结构，在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，hashmap也不例外。Hashmap实际上是一个数组和链表的结合体（在数据结构中，一般称之为“链表散列“） 哈希冲突概念 hashcode通过hash算法得到有限的地址区间 哈希冲突：由于哈希算法被计算的数据是无限的，而计算后的结果范围有限，因此总会存在不同的数据经过计算后得到的值相同，这就是哈希冲突。 解决哈希冲突的方法 开放定址法 开放定址法需要的表长度要大于等于所需要存放的元素。 线行探查法 它从发生冲突的单元起，依次判断下一个单元是否为空，当达到最后一个单元时，再从表首依次判断。直到碰到空闲的单元或者探查完全部单元为止。 平方探查法 双散列函数探查法 链地址法（拉链法） 注：在java中，链接地址法也是HashMap解决哈希冲突的方法之一，jdk1.7完全采用单链表来存储同义词，jdk1.8则采用了一种混合模式，对于链表长度大于8的，会转换为红黑树存储。 再哈希法 就是同时构造多个不同的哈希函数,发生冲突时，再用H2 = RH2(key) 进行计算，直到冲突不再产生，这种方法不易产生聚集，但是增加了计算时间。 建立公共溢出区 将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。 1.8源码hash算法1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 混合高位和地位,以此来加大地位的随机性 数组的位置: (n - 1) &amp; hash 确定数组后,链表中确定相同的方法: e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))) always check first node 在一个数组中,不代表hash是一样的,so必须判断 数组的长度:因为16是2的整数次幂的原因,n-1 二进制中都是x个1,这样,更能减少key之间的碰撞 位运算符(知识补充)左移( &lt;&lt; )、右移( &gt;&gt; ) 、无符号右移( &gt;&gt;&gt; )位与、位或、位异或、位非 123456789101112131415161718192021222324255&lt;&lt;20000 0000 0000 0000 0000 0000 0000 0101 然后左移2位后，低位补0：0000 0000 0000 0000 0000 0000 0001 0100 换算成10进制为205&gt;&gt;2还是先将5转为2进制表示形式：0000 0000 0000 0000 0000 0000 0000 0101 然后右移2位，高位补0：0000 0000 0000 0000 0000 0000 0000 0001-5&gt;&gt;&gt;3-5换算成二进制： 1111 1111 1111 1111 1111 1111 1111 1011-5无符号右移3位后的结果 536870911 换算成二进制： 0001 1111 1111 1111 1111 1111 1111 1111 // (用0进行补位)------------位与：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为05 &amp; 35转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 00111转换为二进制 ：0000 0000 0000 0000 0000 0000 0000 0001位异或：第一个操作数的的第n位于第二个操作数的第n位 相反，那么结果的第n为也为1，否则为05 ^ 35转换为二进制：0000 0000 0000 0000 0000 0000 0000 01013转换为二进制：0000 0000 0000 0000 0000 0000 0000 00116转换为二进制：0000 0000 0000 0000 0000 0000 0000 0110 参考http://blog.csdn.net/u013256816/article/details/50912762https://tech.meituan.com/java-hashmap.htmlhttps://bestswifter.com/hashtable/ 更新日志 2018.01.22:终于理解这段的代码:e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>数据结构</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-线性回归]]></title>
    <url>%2F2018%2F01%2F03%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study-linear-regression%2F</url>
    <content type="text"><![CDATA[概念 线性回归假设输出变量是若干输入变量的线性组合,并根据这一关系求解线性组合中的最优系数. 误差 在线性回归中,误差误差是以军方误差来定义的 求解 当线性回归的模型为二维平面上的直线时,军方误差就是预测输出和真实输出之间的欧几里得距离 求解方法是:最小二乘法 防止过拟合 存在多个最优解,意味着存在拟合,要解决过拟合问题,常见的做法是正则化,即添加额外的惩罚项,可分为两种:灵回过和LASSO回归 岭回归又被称作”参数衰减” LASSO回归,全程是”最小绝对缩减和选择算子” 与岭回归相比,LASSO回归的特点在于稀疏性的引入,时间花复杂问题的常用方法,在数据压缩,信号处理等其他领域中已有广泛的应用]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课-机器学习概率]]></title>
    <url>%2F2018%2F01%2F02%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study-outline%2F</url>
    <content type="text"><![CDATA[概念 经验学习:从大量现象中提取反复出现的规律和模式 计算机给予数据构建概率统计模型并与应用模型对数据进行预测与分析的学科 根据输入输出类型的不行,预测问题分为三类 分类问题:输出离散变量 回归问题:连续变量 标注问题:序列 实际中就会存在误差,机器学习也是一样(误差性能) 误差并定义为学习器的实际预测与样本真实输出之间的差异 误差分为训练误差和测试误差 典型的过拟合现象:训练误差较低,但是训练误差较低 欠拟合:学习能力太弱 整体来看,测试误差与模型复杂度之间呈现得是抛物线的关系 交叉验证法,重复利用有限的样本,不同模型中平均测试误差最小的模型就是最有模型 调参:性能和效率之间的这种 根据训练数据是否有标签信息,可以将机器学习的任务分为三类 监督学习 无监督学习 半监督学习 监督学习分为: 生成方法:更快的收敛速度和更广的应用范围 判别方法:更高的准确性和更简单的使用方式 生成/判别方法 https://www.zhihu.com/question/20446337 有监督机器学习方法可以分为生成方法和判别方法 常见的生成方法有混合高斯模型、朴素贝叶斯法和隐形马尔科夫模型等 常见的判别方法有SVM、LR等 生成模型的求解思路是：联合分布——-&gt;求解类别先验概率和类别条件概率 判别模型求解的思路是：条件分布——&gt;模型参数后验概率最大——-&gt;（似然函数\cdot 参数先验）最大——-&gt;最大似然 生成模型:要知道原始数据的概率密度（或者估计参数得到），然后习惯用bayes理论去做预测 判别模型是不需要知道原始数据概率密度，比较粗线条 wiki例子 假设有四个samples： 生成式模型的世界是这个样子： 而判定式模型的世界是这个样子：]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>概率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-saleorder]]></title>
    <url>%2F2017%2F12%2F28%2Fegenie_bugfix%2Ferror-saleorder%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## An error report file with more information is saved as:# /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#Process finished with exit code 134 (interrupted by signal 6: SIGABRT) /Users/victor/code/egenieProjects/ejlerp-saleorder/hs_err_pid65032.log中的文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x000000010146e882, pid=65032, tid=0x0000000000005303## JRE version: Java(TM) SE Runtime Environment (8.0_151-b12) (build 1.8.0_151-b12)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode bsd-amd64 compressed oops)# Problematic frame:# V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4## Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again## If you would like to submit a bug report, please visit:# http://bugreport.java.com/bugreport/crash.jsp#--------------- T H R E A D ---------------Current thread (0x00007fae5502f800): VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251]siginfo: si_signo: 11 (SIGSEGV), si_code: 1 (SEGV_MAPERR), si_addr: 0x00007f2e56b22522Registers:RAX=0x000000010c14e578, RBX=0x000000010c5c9148, RCX=0x0000000000330006, RDX=0x000000000000060aRSP=0x000070000d787430, RBP=0x000070000d787430, RSI=0x0000000000000000, RDI=0x00007f2e56b22520R8 =0x0000000000000007, R9 =0x00007fae56abe9c0, R10=0x000007fae56abee1, R11=0x0000000000000008R12=0x00000000000007d0, R13=0x000000010c5c9148, R14=0x000000000000034d, R15=0x0000000000000001RIP=0x000000010146e882, EFLAGS=0x0000000000010246, ERR=0x0000000000000004 TRAPNO=0x000000000000000eTop of Stack: (sp=0x000070000d787430)0x000070000d787430: 000070000d787450 000000010111c8970x000070000d787440: 000000010c5c9148 000000010c5c91480x000070000d787450: 000070000d787470 000000010112057c0x000070000d787460: 00007fae54611360 000000010c5c91480x000070000d787470: 000070000d787490 00000001011205f90x000070000d787480: 000000010c5c9148 00007fae546113600x000070000d787490: 000070000d7874c0 00000001010c46560x000070000d7874a0: 0000000000000003 0000000101518ec80x000070000d7874b0: 00007fae54611360 00000000000000030x000070000d7874c0: 000070000d787500 00000001010c8e640x000070000d7874d0: 000000010137f91e 00007fae546113600x000070000d7874e0: 000000010182d590 00000000000000000x000070000d7874f0: 000000010182d501 00007fae54502d100x000070000d787500: 000070000d787520 00000001010c8ec60x000070000d787510: 0000000000000000 00000000000000000x000070000d787520: 000070000d787550 00000001010c8f500x000070000d787530: 000070000d787550 00000001010c831b0x000070000d787540: 000000010182d501 000000010182d5010x000070000d787550: 000070000d787590 00000001010c8ff20x000070000d787560: 0000000000000000 000000010182d5900x000070000d787570: 0000000000000000 00007fae553f3ce00x000070000d787580: 000000010182d590 000070000d7876e00x000070000d787590: 000070000d7875b0 0000000101474c300x000070000d7875a0: 000070000d787690 000000010182d5900x000070000d7875b0: 000070000d787760 00000001013ff48b0x000070000d7875c0: 000000010182d810 000000000000001c0x000070000d7875d0: 0000000000000000 00000000000003a50x000070000d7875e0: 0000000000000172 00000000000000110x000070000d7875f0: 000000010151e9b3 00000000000000800x000070000d787600: 000070000d787640 00007fff6764d5620x000070000d787610: 000070000d787728 00000000000000000x000070000d787620: 00000000000003a5 0000000000000172 Instructions: (pc=0x000000010146e882)0x000000010146e862: 4c 89 e6 e8 c8 d0 f5 ff 49 ff c7 0f b7 03 41 390x000000010146e872: c7 7c e2 48 8d 35 25 da 0a 00 eb a5 55 48 89 e50x000000010146e882: 66 83 7f 02 00 79 02 5d c3 48 83 c7 02 5d e9 f70x000000010146e892: 74 b9 ff 90 55 48 89 e5 66 83 7f 02 00 79 02 5d Register to memory mapping:RAX=0x000000010c14e578 is pointing into metadataRBX=0x000000010c5c9148 is pointing into metadataRCX=0x0000000000330006 is an unknown valueRDX=0x000000000000060a is an unknown valueRSP=0x000070000d787430 is an unknown valueRBP=0x000070000d787430 is an unknown valueRSI=0x0000000000000000 is an unknown valueRDI=0x00007f2e56b22520 is an unknown valueR8 =0x0000000000000007 is an unknown valueR9 =0x00007fae56abe9c0 is an unknown valueR10=0x000007fae56abee1 is an unknown valueR11=0x0000000000000008 is an unknown valueR12=0x00000000000007d0 is an unknown valueR13=0x000000010c5c9148 is pointing into metadataR14=0x000000000000034d is an unknown valueR15=0x0000000000000001 is an unknown valueStack: [0x000070000d688000,0x000070000d788000], sp=0x000070000d787430, free space=1021kNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)V [libjvm.dylib+0x534882] Symbol::decrement_refcount()+0x4V [libjvm.dylib+0x1e2897] ConstantPool::unreference_symbols()+0x29V [libjvm.dylib+0x1e657c] ConstantPool::release_C_heap_structures()+0x12V [libjvm.dylib+0x1e65f9] ConstantPool::deallocate_contents(ClassLoaderData*)+0x51V [libjvm.dylib+0x18a656] void MetadataFactory::free_metadata&lt;ConstantPool*&gt;(ClassLoaderData*, ConstantPool*)+0x44V [libjvm.dylib+0x18ee64] ClassLoaderData::free_deallocate_list()+0x96V [libjvm.dylib+0x18eec6] ClassLoaderDataGraph::free_deallocate_lists()+0x1aV [libjvm.dylib+0x18ef50] ClassLoaderDataGraph::clean_metaspaces()+0x5cV [libjvm.dylib+0x18eff2] ClassLoaderDataGraph::do_unloading(BoolObjectClosure*, bool)+0x90V [libjvm.dylib+0x53ac30] SystemDictionary::do_unloading(BoolObjectClosure*, bool)+0x12V [libjvm.dylib+0x4c548b] PSParallelCompact::marking_phase(ParCompactionManager*, bool, ParallelOldTracer*)+0x52fV [libjvm.dylib+0x4c6977] PSParallelCompact::invoke_no_policy(bool)+0x41bV [libjvm.dylib+0x4c6f8b] PSParallelCompact::invoke(bool)+0x57V [libjvm.dylib+0x19eef6] CollectedHeap::collect_as_vm_thread(GCCause::Cause)+0x5eV [libjvm.dylib+0x5b2cb4] VM_CollectForMetadataAllocation::doit()+0xb0V [libjvm.dylib+0x5b9b29] VM_Operation::evaluate()+0x4fV [libjvm.dylib+0x5b8195] VMThread::evaluate_operation(VM_Operation*)+0xdfV [libjvm.dylib+0x5b85e2] VMThread::loop()+0x328V [libjvm.dylib+0x5b7f01] VMThread::run()+0x79V [libjvm.dylib+0x48bbb2] java_start(Thread*)+0xf6C [libsystem_pthread.dylib+0x36c1] _pthread_body+0x154C [libsystem_pthread.dylib+0x356d] _pthread_body+0x0C [libsystem_pthread.dylib+0x2c5d] thread_start+0xdVM_Operation (0x0000700016e3fbd8): CollectForMetadataAllocation, mode: safepoint, requested by thread 0x00007fae55a24000--------------- P R O C E S S ---------------Java Threads: ( =&gt; current thread ) 0x00007fae5638a000 JavaThread &quot;JMX server connection timeout 320&quot; daemon [_thread_blocked, id=128775, stack(0x0000700016838000,0x0000700016938000)] 0x00007fae55a24000 JavaThread &quot;RMI TCP Connection(10)-192.168.0.123&quot; daemon [_thread_blocked, id=88323, stack(0x0000700016d47000,0x0000700016e47000)] 0x00007fae55353000 JavaThread &quot;JMX server connection timeout 317&quot; daemon [_thread_blocked, id=129027, stack(0x0000700016c44000,0x0000700016d44000)] 0x00007fae55808800 JavaThread &quot;RMI TCP Connection(9)-192.168.0.123&quot; daemon [_thread_blocked, id=129283, stack(0x0000700016b41000,0x0000700016c41000)] 0x00007fae55352800 JavaThread &quot;RMI TCP Connection(8)-127.0.0.1&quot; daemon [_thread_in_native, id=129795, stack(0x0000700016a3e000,0x0000700016b3e000)] 0x00007fae5638f000 JavaThread &quot;RMI TCP Connection(7)-127.0.0.1&quot; daemon [_thread_in_native, id=130051, stack(0x000070001693b000,0x0000700016a3b000)] 0x00007fae54c28800 JavaThread &quot;DestroyJavaVM&quot; [_thread_blocked, id=4611, stack(0x000070000d073000,0x000070000d173000)] 0x00007fae5534f000 JavaThread &quot;Thread-149&quot; [_thread_blocked, id=87315, stack(0x0000700016735000,0x0000700016835000)] 0x00007fae54c23000 JavaThread &quot;RMI TCP Connection(6)-192.168.0.123&quot; daemon [_thread_in_native, id=65027, stack(0x0000700016632000,0x0000700016732000)] 0x00007fae5532b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-41&quot; daemon [_thread_blocked, id=65539, stack(0x000070001652f000,0x000070001662f000)] 0x00007fae56310800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-40&quot; daemon [_thread_blocked, id=66051, stack(0x000070001642c000,0x000070001652c000)] 0x00007fae5532a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-39&quot; daemon [_thread_blocked, id=64259, stack(0x0000700016329000,0x0000700016429000)] 0x00007fae55cc4000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-38&quot; daemon [_thread_blocked, id=63747, stack(0x0000700016226000,0x0000700016326000)] 0x00007fae55335800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-37&quot; daemon [_thread_blocked, id=66567, stack(0x0000700016123000,0x0000700016223000)] 0x00007fae54c22000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-36&quot; daemon [_thread_blocked, id=63235, stack(0x0000700016020000,0x0000700016120000)] 0x00007fae54c21800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-35&quot; daemon [_thread_blocked, id=66819, stack(0x0000700015f1d000,0x000070001601d000)] 0x00007fae56502800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-34&quot; daemon [_thread_blocked, id=67075, stack(0x0000700015e1a000,0x0000700015f1a000)] 0x00007fae55cc3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-33&quot; daemon [_thread_blocked, id=62467, stack(0x0000700015d17000,0x0000700015e17000)] 0x00007fae562fc000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-32&quot; daemon [_thread_blocked, id=67587, stack(0x0000700015c14000,0x0000700015d14000)] 0x00007fae55bd9000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-31&quot; daemon [_thread_blocked, id=67843, stack(0x0000700015b11000,0x0000700015c11000)] 0x00007fae55335000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-30&quot; daemon [_thread_blocked, id=68359, stack(0x0000700015a0e000,0x0000700015b0e000)] 0x00007fae562fa000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-29&quot; daemon [_thread_blocked, id=61443, stack(0x000070001590b000,0x0000700015a0b000)] 0x00007fae54f20800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-28&quot; daemon [_thread_blocked, id=68611, stack(0x0000700015808000,0x0000700015908000)] 0x00007fae55334000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-27&quot; daemon [_thread_blocked, id=60679, stack(0x0000700015705000,0x0000700015805000)] 0x00007fae54f1f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-26&quot; daemon [_thread_blocked, id=60467, stack(0x0000700015602000,0x0000700015702000)] 0x00007fae5631e000 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-4&quot; daemon [_thread_blocked, id=60163, stack(0x00007000154ff000,0x00007000155ff000)] 0x00007fae55cc1800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-3&quot; daemon [_thread_blocked, id=69635, stack(0x00007000153fc000,0x00007000154fc000)] 0x00007fae54d20000 JavaThread &quot;job-event-8&quot; daemon [_thread_blocked, id=70163, stack(0x00007000152f9000,0x00007000153f9000)] 0x00007fae5631f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-25&quot; daemon [_thread_blocked, id=59683, stack(0x00007000151f6000,0x00007000152f6000)] 0x00007fae55383800 JavaThread &quot;job-event-7&quot; daemon [_thread_blocked, id=59399, stack(0x00007000150f3000,0x00007000151f3000)] 0x00007fae56316800 JavaThread &quot;job-event-6&quot; daemon [_thread_blocked, id=58883, stack(0x0000700014ff0000,0x00007000150f0000)] 0x00007fae54d06800 JavaThread &quot;job-event-5&quot; daemon [_thread_blocked, id=58379, stack(0x0000700014eed000,0x0000700014fed000)] 0x00007fae56316000 JavaThread &quot;DubboResponseTimeoutScanTimer&quot; daemon [_thread_blocked, id=70915, stack(0x0000700014dea000,0x0000700014eea000)] 0x00007fae56409800 JavaThread &quot;job-event-3&quot; daemon [_thread_blocked, id=71171, stack(0x0000700014ce7000,0x0000700014de7000)] 0x00007fae5594e800 JavaThread &quot;job-event-4&quot; daemon [_thread_blocked, id=57859, stack(0x0000700014be4000,0x0000700014ce4000)] 0x00007fae5594d800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-2&quot; daemon [_thread_blocked, id=71683, stack(0x0000700014ae1000,0x0000700014be1000)] 0x00007fae56406800 JavaThread &quot;inner-job-com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob-1&quot; daemon [_thread_blocked, id=71939, stack(0x00007000149de000,0x0000700014ade000)] 0x00007fae54cfa800 JavaThread &quot;job-event-2&quot; daemon [_thread_blocked, id=72195, stack(0x00007000148db000,0x00007000149db000)] 0x00007fae56405000 JavaThread &quot;job-event-1&quot; daemon [_thread_blocked, id=72723, stack(0x00007000147d8000,0x00007000148d8000)] 0x00007fae54d48800 JavaThread &quot;RMI TCP Connection(5)-192.168.0.123&quot; daemon [_thread_in_native, id=73223, stack(0x00007000146d5000,0x00007000147d5000)] 0x00007fae55341000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=73739, stack(0x00007000145d2000,0x00007000146d2000)] 0x00007fae55362800 JavaThread &quot;Curator-TreeCache-6&quot; daemon [_thread_blocked, id=56839, stack(0x00007000144cf000,0x00007000145cf000)] 0x00007fae55361800 JavaThread &quot;Timer-6&quot; daemon [_thread_blocked, id=56323, stack(0x00007000143cc000,0x00007000144cc000)] 0x00007fae5644d800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=56067, stack(0x00007000142c9000,0x00007000143c9000)] 0x00007fae5644d000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForEvalRemindJob_Worker-1&quot; [_thread_blocked, id=55555, stack(0x00007000141c6000,0x00007000142c6000)] 0x00007fae55361000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=55311, stack(0x00007000140c3000,0x00007000141c3000)] 0x00007fae552de000 JavaThread &quot;Curator-TreeCache-5&quot; daemon [_thread_blocked, id=55047, stack(0x0000700013fc0000,0x00007000140c0000)] 0x00007fae54ca0800 JavaThread &quot;Timer-5&quot; daemon [_thread_blocked, id=54531, stack(0x0000700013ebd000,0x0000700013fbd000)] 0x00007fae54ca0000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_QuartzSchedulerThread&quot; [_thread_blocked, id=75011, stack(0x0000700013dba000,0x0000700013eba000)] 0x00007fae552dd000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.AfterSaleMessageJob_Worker-1&quot; [_thread_blocked, id=54019, stack(0x0000700013cb7000,0x0000700013db7000)] 0x00007fae5534b800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=75779, stack(0x0000700013bb4000,0x0000700013cb4000)] 0x00007fae55a1c000 JavaThread &quot;Curator-TreeCache-4&quot; daemon [_thread_blocked, id=76295, stack(0x0000700013ab1000,0x0000700013bb1000)] 0x00007fae5534b000 JavaThread &quot;Timer-4&quot; daemon [_thread_blocked, id=76547, stack(0x00007000139ae000,0x0000700013aae000)] 0x00007fae55a3b000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=53507, stack(0x00007000138ab000,0x00007000139ab000)] 0x00007fae54c96000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.WaitingForReceivePaymentJob_Worker-1&quot; [_thread_blocked, id=52999, stack(0x00007000137a8000,0x00007000138a8000)] 0x00007fae5644a000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=52743, stack(0x00007000136a5000,0x00007000137a5000)] 0x00007fae56449000 JavaThread &quot;Curator-TreeCache-3&quot; daemon [_thread_blocked, id=77323, stack(0x00007000135a2000,0x00007000136a2000)] 0x00007fae54c95800 JavaThread &quot;Timer-3&quot; daemon [_thread_blocked, id=52227, stack(0x000070001349f000,0x000070001359f000)] 0x00007fae54c94800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_QuartzSchedulerThread&quot; [_thread_blocked, id=51971, stack(0x000070001339c000,0x000070001349c000)] 0x00007fae54c94000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.ShipmentRemindJob_Worker-1&quot; [_thread_blocked, id=51459, stack(0x0000700013299000,0x0000700013399000)] 0x00007fae564e6800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=78351, stack(0x0000700013196000,0x0000700013296000)] 0x00007fae54c92800 JavaThread &quot;Curator-TreeCache-2&quot; daemon [_thread_blocked, id=51207, stack(0x0000700013093000,0x0000700013193000)] 0x00007fae562ef800 JavaThread &quot;Timer-2&quot; daemon [_thread_blocked, id=79107, stack(0x0000700012f90000,0x0000700013090000)] 0x00007fae562ef000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_QuartzSchedulerThread&quot; [_thread_blocked, id=79363, stack(0x0000700012e8d000,0x0000700012f8d000)] 0x00007fae54c91800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.sms.PushPaymentJob_Worker-1&quot; [_thread_blocked, id=79895, stack(0x0000700012d8a000,0x0000700012e8a000)] 0x00007fae5533d000 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80131, stack(0x0000700012c87000,0x0000700012d87000)] 0x00007fae552a6800 JavaThread &quot;Curator-TreeCache-1&quot; daemon [_thread_blocked, id=50187, stack(0x0000700012b84000,0x0000700012c84000)] 0x00007fae55a3d800 JavaThread &quot;Timer-1&quot; daemon [_thread_blocked, id=49667, stack(0x0000700012a81000,0x0000700012b81000)] 0x00007fae55a3c800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_QuartzSchedulerThread&quot; [_thread_blocked, id=49411, stack(0x000070001297e000,0x0000700012a7e000)] 0x00007fae55be1000 JavaThread &quot;com.ejlerp.saleorder.jobs.job.OutOfStockToNormalFromStockInventoryJob_Worker-1&quot; [_thread_blocked, id=49155, stack(0x000070001287b000,0x000070001297b000)] 0x00007fae55be0800 JavaThread &quot;ReconcileService&quot; [_thread_blocked, id=80915, stack(0x0000700012778000,0x0000700012878000)] 0x00007fae56400000 JavaThread &quot;Curator-TreeCache-0&quot; daemon [_thread_blocked, id=81411, stack(0x0000700012675000,0x0000700012775000)] 0x00007fae563ff800 JavaThread &quot;Timer-0&quot; daemon [_thread_blocked, id=48643, stack(0x0000700012572000,0x0000700012672000)] 0x00007fae56112800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_QuartzSchedulerThread&quot; [_thread_blocked, id=48387, stack(0x000070001246f000,0x000070001256f000)] 0x00007fae562bf800 JavaThread &quot;com.ejlerp.saleorder.jobs.job.AutoCheckOrderJob_Worker-1&quot; [_thread_blocked, id=82439, stack(0x000070001236c000,0x000070001246c000)] 0x00007fae54ae4800 JavaThread &quot;DubboClientHandler-192.168.0.157:20881-thread-1&quot; daemon [_thread_blocked, id=82703, stack(0x0000700012269000,0x0000700012369000)] 0x00007fae5533e800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-24&quot; daemon [_thread_blocked, id=82947, stack(0x0000700012166000,0x0000700012266000)] 0x00007fae54a64800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-23&quot; daemon [_thread_blocked, id=47363, stack(0x0000700012063000,0x0000700012163000)] 0x00007fae560f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-22&quot; daemon [_thread_blocked, id=83459, stack(0x0000700011f60000,0x0000700012060000)] 0x00007fae54b1b800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-21&quot; daemon [_thread_blocked, id=83971, stack(0x0000700011e5d000,0x0000700011f5d000)] 0x00007fae54b1a800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-20&quot; daemon [_thread_blocked, id=84227, stack(0x0000700011d5a000,0x0000700011e5a000)] 0x00007fae563f3000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-19&quot; daemon [_thread_blocked, id=46595, stack(0x0000700011c57000,0x0000700011d57000)] 0x00007fae54b1a000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-18&quot; daemon [_thread_blocked, id=46083, stack(0x0000700011b54000,0x0000700011c54000)] 0x00007fae54b7f000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-17&quot; daemon [_thread_blocked, id=45831, stack(0x000070001194e000,0x0000700011a4e000)] 0x00007fae563f2000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-16&quot; daemon [_thread_blocked, id=84739, stack(0x0000700011a51000,0x0000700011b51000)] 0x00007fae54b7e000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-15&quot; daemon [_thread_blocked, id=45571, stack(0x000070001184b000,0x000070001194b000)] 0x00007fae54a3f800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-14&quot; daemon [_thread_blocked, id=85507, stack(0x0000700011748000,0x0000700011848000)] 0x00007fae562a7000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-13&quot; daemon [_thread_blocked, id=45059, stack(0x0000700011645000,0x0000700011745000)] 0x00007fae54a54800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-12&quot; daemon [_thread_blocked, id=86275, stack(0x0000700011542000,0x0000700011642000)] 0x00007fae54a54000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-11&quot; daemon [_thread_blocked, id=44547, stack(0x000070001143f000,0x000070001153f000)] 0x00007fae54b76000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-10&quot; daemon [_thread_blocked, id=44035, stack(0x000070001133c000,0x000070001143c000)] 0x00007fae551ee800 JavaThread &quot;Druid-ConnectionPool-Destroy-2073021938&quot; daemon [_thread_blocked, id=86787, stack(0x0000700011239000,0x0000700011339000)] 0x00007fae55202800 JavaThread &quot;Druid-ConnectionPool-Create-2073021938&quot; daemon [_thread_blocked, id=87051, stack(0x0000700011136000,0x0000700011236000)] 0x00007fae564b8000 JavaThread &quot;Abandoned connection cleanup thread&quot; daemon [_thread_blocked, id=32003, stack(0x0000700011033000,0x0000700011133000)] 0x00007fae54976000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-9&quot; daemon [_thread_blocked, id=31763, stack(0x0000700010f30000,0x0000700011030000)] 0x00007fae552c4000 JavaThread &quot;DubboClientHandler-192.168.0.134:20880-thread-1&quot; daemon [_thread_blocked, id=31495, stack(0x0000700010e2d000,0x0000700010f2d000)] 0x00007fae54b36800 JavaThread &quot;DubboClientHandler-192.168.0.157:20887-thread-1&quot; daemon [_thread_blocked, id=31003, stack(0x0000700010d2a000,0x0000700010e2a000)] 0x00007fae5622d000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-8&quot; daemon [_thread_blocked, id=30723, stack(0x0000700010c27000,0x0000700010d27000)] 0x00007fae54b91000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-7&quot; daemon [_thread_blocked, id=33031, stack(0x0000700010b24000,0x0000700010c24000)] 0x00007fae54b8b000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-6&quot; daemon [_thread_blocked, id=33283, stack(0x0000700010a21000,0x0000700010b21000)] 0x00007fae56231800 JavaThread &quot;DubboClientHandler-192.168.0.157:20883-thread-1&quot; daemon [_thread_blocked, id=29955, stack(0x000070001091e000,0x0000700010a1e000)] 0x00007fae559ae000 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-2&quot; daemon [_thread_blocked, id=29443, stack(0x000070001081b000,0x000070001091b000)] 0x00007fae552a3800 JavaThread &quot;DubboClientHandler-192.168.0.126:20882-thread-1&quot; daemon [_thread_blocked, id=34067, stack(0x0000700010718000,0x0000700010818000)] 0x00007fae56228000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-5&quot; daemon [_thread_blocked, id=28939, stack(0x0000700010615000,0x0000700010715000)] 0x00007fae56200000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-4&quot; daemon [_thread_blocked, id=34307, stack(0x0000700010512000,0x0000700010612000)] 0x00007fae54bbf800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-3&quot; daemon [_thread_blocked, id=28431, stack(0x000070001040f000,0x000070001050f000)] 0x00007fae56421800 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-2&quot; daemon [_thread_blocked, id=28163, stack(0x000070001030c000,0x000070001040c000)] 0x00007fae54b66000 JavaThread &quot;DubboServerHandler-192.168.0.123:20881-thread-1&quot; daemon [_thread_blocked, id=35339, stack(0x0000700010209000,0x0000700010309000)] 0x00007fae54bf4800 JavaThread &quot;dubbo-remoting-server-heartbeat-thread-1&quot; daemon [_thread_blocked, id=27651, stack(0x0000700010106000,0x0000700010206000)] 0x00007fae54bf3800 JavaThread &quot;New I/O server boss #12&quot; daemon [_thread_in_native, id=27139, stack(0x0000700010003000,0x0000700010103000)] 0x00007fae54b63000 JavaThread &quot;New I/O worker #11&quot; daemon [_thread_in_native, id=35843, stack(0x000070000ff00000,0x0000700010000000)] 0x00007fae54bf3000 JavaThread &quot;New I/O worker #10&quot; daemon [_thread_in_native, id=36099, stack(0x000070000fdfd000,0x000070000fefd000)] 0x00007fae54bf2000 JavaThread &quot;New I/O worker #9&quot; daemon [_thread_in_native, id=26371, stack(0x000070000fcfa000,0x000070000fdfa000)] 0x00007fae56421000 JavaThread &quot;New I/O worker #8&quot; daemon [_thread_in_native, id=36611, stack(0x000070000fbf7000,0x000070000fcf7000)] 0x00007fae54bf1800 JavaThread &quot;New I/O worker #7&quot; daemon [_thread_in_native, id=37139, stack(0x000070000faf4000,0x000070000fbf4000)] 0x00007fae54c5f800 JavaThread &quot;DubboClientReconnectTimer-thread-2&quot; daemon [_thread_blocked, id=26131, stack(0x000070000f9f1000,0x000070000faf1000)] 0x00007fae563e4800 JavaThread &quot;dubbo-remoting-client-heartbeat-thread-1&quot; daemon [_thread_blocked, id=37891, stack(0x000070000f8ee000,0x000070000f9ee000)] 0x00007fae563e4000 JavaThread &quot;DubboClientHandler-192.168.0.157:20880-thread-1&quot; daemon [_thread_blocked, id=25859, stack(0x000070000f7eb000,0x000070000f8eb000)] 0x00007fae54c3c800 JavaThread &quot;Hashed wheel timer #1&quot; [_thread_blocked, id=25603, stack(0x000070000f6e8000,0x000070000f7e8000)] 0x00007fae56016800 JavaThread &quot;DubboClientReconnectTimer-thread-1&quot; daemon [_thread_blocked, id=25091, stack(0x000070000f5e5000,0x000070000f6e5000)] 0x00007fae54a33800 JavaThread &quot;New I/O boss #6&quot; daemon [_thread_in_native, id=38659, stack(0x000070000f4e2000,0x000070000f5e2000)] 0x00007fae54c3e000 JavaThread &quot;New I/O worker #5&quot; daemon [_thread_blocked, id=24579, stack(0x000070000f3df000,0x000070000f4df000)] 0x00007fae561d4800 JavaThread &quot;New I/O worker #4&quot; daemon [_thread_in_native, id=39427, stack(0x000070000f2dc000,0x000070000f3dc000)] 0x00007fae561c7800 JavaThread &quot;New I/O worker #3&quot; daemon [_thread_in_native, id=39683, stack(0x000070000f1d9000,0x000070000f2d9000)] 0x00007fae561c6800 JavaThread &quot;New I/O worker #2&quot; daemon [_thread_in_native, id=24067, stack(0x000070000f0d6000,0x000070000f1d6000)] 0x00007fae561cb800 JavaThread &quot;New I/O worker #1&quot; daemon [_thread_blocked, id=23811, stack(0x000070000efd3000,0x000070000f0d3000)] 0x00007fae55c61000 JavaThread &quot;DubboSaveRegistryCache-thread-1&quot; daemon [_thread_blocked, id=40459, stack(0x000070000eed0000,0x000070000efd0000)] 0x00007fae561c6000 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=40963, stack(0x000070000edcd000,0x000070000eecd000)] 0x00007fae56502000 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_in_native, id=41475, stack(0x000070000ecca000,0x000070000edca000)] 0x00007fae56501000 JavaThread &quot;ZkClient-EventThread-50-192.168.0.156:2181&quot; daemon [_thread_blocked, id=23307, stack(0x000070000ebc7000,0x000070000ecc7000)] 0x00007fae564fc000 JavaThread &quot;DubboRegistryFailedRetryTimer-thread-1&quot; daemon [_thread_blocked, id=5703, stack(0x000070000eac4000,0x000070000ebc4000)] 0x00007fae55283800 JavaThread &quot;Curator-Framework-0&quot; daemon [_thread_blocked, id=42243, stack(0x000070000e9c1000,0x000070000eac1000)] 0x00007fae55282800 JavaThread &quot;main-EventThread&quot; daemon [_thread_blocked, id=42499, stack(0x000070000e8be000,0x000070000e9be000)] 0x00007fae564f2800 JavaThread &quot;main-SendThread(192.168.0.156:2181)&quot; daemon [_thread_blocked, id=22787, stack(0x000070000e7bb000,0x000070000e8bb000)] 0x00007fae5526d800 JavaThread &quot;Curator-ConnectionStateManager-0&quot; daemon [_thread_blocked, id=43047, stack(0x000070000e6b8000,0x000070000e7b8000)] 0x00007fae55aad000 JavaThread &quot;RMI TCP Connection(3)-192.168.0.123&quot; daemon [_thread_in_native, id=43267, stack(0x000070000e5b5000,0x000070000e6b5000)] 0x00007fae551e2000 JavaThread &quot;RMI Scheduler(0)&quot; daemon [_thread_blocked, id=21763, stack(0x000070000e4b2000,0x000070000e5b2000)] 0x00007fae5497b000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=15875, stack(0x000070000e2ac000,0x000070000e3ac000)] 0x00007fae55a09000 JavaThread &quot;RMI TCP Connection(1)-127.0.0.1&quot; daemon [_thread_in_native, id=15363, stack(0x000070000e1a9000,0x000070000e2a9000)] 0x00007fae55a16000 JavaThread &quot;RMI TCP Accept-52007&quot; daemon [_thread_in_native, id=16899, stack(0x000070000e0a6000,0x000070000e1a6000)] 0x00007fae5617f000 JavaThread &quot;RMI TCP Accept-0&quot; daemon [_thread_in_native, id=17155, stack(0x000070000dfa3000,0x000070000e0a3000)] 0x00007fae54956800 JavaThread &quot;Service Thread&quot; daemon [_thread_blocked, id=17411, stack(0x000070000dea0000,0x000070000dfa0000)] 0x00007fae560f0000 JavaThread &quot;C1 CompilerThread2&quot; daemon [_thread_blocked, id=14083, stack(0x000070000dd9d000,0x000070000de9d000)] 0x00007fae5593f000 JavaThread &quot;C2 CompilerThread1&quot; daemon [_thread_blocked, id=13571, stack(0x000070000dc9a000,0x000070000dd9a000)] 0x00007fae560ef800 JavaThread &quot;C2 CompilerThread0&quot; daemon [_thread_blocked, id=17923, stack(0x000070000db97000,0x000070000dc97000)] 0x00007fae55034000 JavaThread &quot;Monitor Ctrl-Break&quot; daemon [_thread_in_native, id=18435, stack(0x000070000da94000,0x000070000db94000)] 0x00007fae5600f000 JavaThread &quot;Signal Dispatcher&quot; daemon [_thread_blocked, id=12811, stack(0x000070000d991000,0x000070000da91000)] 0x00007fae5482b000 JavaThread &quot;Finalizer&quot; daemon [_thread_blocked, id=11779, stack(0x000070000d88e000,0x000070000d98e000)] 0x00007fae55032800 JavaThread &quot;Reference Handler&quot; daemon [_thread_blocked, id=20995, stack(0x000070000d78b000,0x000070000d88b000)]Other Threads:=&gt;0x00007fae5502f800 VMThread [stack: 0x000070000d688000,0x000070000d788000] [id=21251] 0x00007fae5497b800 WatcherThread [stack: 0x000070000e3af000,0x000070000e4af000] [id=16131]VM state:at safepoint (normal execution)VM Mutex/Monitor currently owned by a thread: ([mutex/lock_event])[0x00007fae54601800] Threads_lock - owner thread: 0x00007fae5502f800[0x00007fae54601d00] Heap_lock - owner thread: 0x00007fae55a24000Heap: PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KCard table byte_map: [0x0000000102bc0000,0x0000000102fc1000] byte_map_base: 0x00000000ff1c0000Marking Bits: (ParMarkBitMap*) 0x000000010182d5d0 Begin Bits: [0x000000010326c000, 0x000000010526c000) End Bits: [0x000000010526c000, 0x000000010726c000)Polling page: 0x0000000101f24000CodeCache: size=245760Kb used=13228Kb max_used=13248Kb free=232531Kb bounds [0x000000010d78b000, 0x000000010e48b000, 0x000000011c78b000] total_blobs=6800 nmethods=6274 adapters=438 compilation: enabledCompilation events (10 events):Event: 72.788 Thread 0x00007fae560f0000 nmethod 6375 0x000000010dd32b10 code [0x000000010dd32c80, 0x000000010dd32da8]Event: 72.790 Thread 0x00007fae560f0000 6376 1 com.sun.jmx.mbeanserver.MBeanSupport::invoke (19 bytes)Event: 72.790 Thread 0x00007fae560f0000 nmethod 6376 0x000000010dd50590 code [0x000000010dd50700, 0x000000010dd50898]Event: 72.792 Thread 0x00007fae560f0000 6377 1 javax.management.remote.rmi.RMIConnectionImpl::nullIsEmpty (12 bytes)Event: 72.793 Thread 0x00007fae560f0000 nmethod 6377 0x000000010dd502d0 code [0x000000010dd50420, 0x000000010dd50530]Event: 72.793 Thread 0x00007fae560f0000 6378 1 com.sun.jmx.mbeanserver.PerInterface::invoke (269 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6378 0x000000010dd3e510 code [0x000000010dd3e820, 0x000000010dd3f4a8]Event: 72.797 Thread 0x00007fae560f0000 6379 1 javax.management.remote.rmi.RMIConnectionImpl$6::run (17 bytes)Event: 72.797 Thread 0x00007fae560f0000 nmethod 6379 0x000000010dd3e190 code [0x000000010dd3e300, 0x000000010dd3e448]Event: 72.797 Thread 0x00007fae560f0000 6380 ! 1 javax.management.remote.rmi.RMIConnectionImpl::unwrap (301 bytes)GC Heap History (10 events):Event: 54.010 GC heap afterHeap after GC invocations=24 (full 3): PSYoungGen total 611840K, used 34359K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40321K, capacity 41992K, committed 42112K, reserved 1085440K class space used 4923K, capacity 5182K, committed 5248K, reserved 1048576K&#125;Event: 55.308 GC heap before&#123;Heap before GC invocations=25 (full 3): PSYoungGen total 611840K, used 568887K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 534528K, 100% used [0x0000000795580000,0x00000007b5f80000,0x00000007b5f80000) from space 77312K, 44% used [0x00000007b5f80000,0x00000007b810df98,0x00000007bab00000) to space 75264K, 0% used [0x00000007bb680000,0x00000007bb680000,0x00000007c0000000) ParOldGen total 191488K, used 137232K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486040d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576KEvent: 55.332 GC heap afterHeap after GC invocations=25 (full 3): PSYoungGen total 617472K, used 47568K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 40816K, capacity 42512K, committed 42624K, reserved 1087488K class space used 5004K, capacity 5248K, committed 5248K, reserved 1048576K&#125;Event: 56.843 GC heap before&#123;Heap before GC invocations=26 (full 3): PSYoungGen total 617472K, used 589776K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 75264K, 63% used [0x00000007bb680000,0x00000007be4f4270,0x00000007c0000000) to space 78336K, 0% used [0x00000007b6700000,0x00000007b6700000,0x00000007bb380000) ParOldGen total 191488K, used 137240K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486060d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576KEvent: 56.881 GC heap afterHeap after GC invocations=26 (full 3): PSYoungGen total 586752K, used 44259K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 42398K, capacity 44102K, committed 44416K, reserved 1087488K class space used 5172K, capacity 5449K, committed 5504K, reserved 1048576K&#125;Event: 71.208 GC heap before&#123;Heap before GC invocations=27 (full 3): PSYoungGen total 586752K, used 586467K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 542208K, 100% used [0x0000000795580000,0x00000007b6700000,0x00000007b6700000) from space 44544K, 99% used [0x00000007b6700000,0x00000007b9238de0,0x00000007b9280000) to space 78848K, 0% used [0x00000007bb300000,0x00000007bb300000,0x00000007c0000000) ParOldGen total 191488K, used 137248K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x00000007486080d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576KEvent: 71.246 GC heap afterHeap after GC invocations=27 (full 3): PSYoungGen total 623616K, used 33938K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43443K, capacity 45208K, committed 45312K, reserved 1089536K class space used 5264K, capacity 5565K, committed 5632K, reserved 1048576K&#125;Event: 72.798 GC heap before&#123;Heap before GC invocations=28 (full 3): PSYoungGen total 623616K, used 66204K [0x0000000795580000, 0x00000007c0000000, 0x00000007c0000000) eden space 544768K, 5% used [0x0000000795580000,0x0000000797502a20,0x00000007b6980000) from space 78848K, 43% used [0x00000007bb300000,0x00000007bd424850,0x00000007c0000000) to space 75264K, 0% used [0x00000007b6980000,0x00000007b6980000,0x00000007bb300000) ParOldGen total 191488K, used 137256K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860a0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KEvent: 72.833 GC heap afterHeap after GC invocations=28 (full 3): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576K&#125;Event: 72.833 GC heap before&#123;Heap before GC invocations=29 (full 4): PSYoungGen total 564736K, used 19670K [0x0000000795580000, 0x00000007bf780000, 0x00000007c0000000) eden space 544768K, 0% used [0x0000000795580000,0x0000000795580000,0x00000007b6980000) from space 19968K, 98% used [0x00000007b6980000,0x00000007b7cb5a10,0x00000007b7d00000) to space 72704K, 0% used [0x00000007bb080000,0x00000007bb080000,0x00000007bf780000) ParOldGen total 191488K, used 137264K [0x0000000740000000, 0x000000074bb00000, 0x0000000795580000) object space 191488K, 71% used [0x0000000740000000,0x000000074860c0d0,0x000000074bb00000) Metaspace used 43836K, capacity 45586K, committed 45656K, reserved 1089536K class space used 5324K, capacity 5612K, committed 5632K, reserved 1048576KDeoptimization events (0 events):No eventsInternal exceptions (10 events):Event: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeBeanInfo&gt; (0x0000000795895208) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictionaEvent: 71.281 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/jmx/export/metadata/ManagedAttributeCustomizer&gt; (0x00000007958b3560) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictioEvent: 71.290 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795901e88) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanBeanInfo&gt; (0x00000007959c81d8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systEvent: 71.307 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/LoggersEndpointMBeanCustomizer&gt; (0x00000007959ea158) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/syEvent: 71.309 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ClassNotFoundException&apos;: org/springframework/boot/actuate/endpoint/jmx/JmxEndpointCustomizer&gt; (0x0000000795a1a220) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/classfile/systemDictiEvent: 71.327 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b18538) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2dd00) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b2ead8) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Event: 71.329 Thread 0x00007fae55808800 Exception &lt;a &apos;java/lang/ArrayIndexOutOfBoundsException&apos;&gt; (0x0000000795b34770) thrown at [/Users/java_re/workspace/8-2-build-macosx-x86_64/jdk8u151/9699/hotspot/src/share/vm/runtime/sharedRuntime.cpp, line 605]Events (10 events):Event: 72.768 Thread 0x00007fae560f0000 flushing nmethod 0x000000010df51bd0Event: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparatorEvent: 72.789 loading class org/springframework/boot/actuate/health/OrderedHealthAggregator$StatusComparator doneEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContextEvent: 72.791 loading class com/fasterxml/jackson/core/json/JsonWriteContext doneEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContextEvent: 72.792 loading class com/fasterxml/jackson/core/JsonStreamContext doneEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$SegmentEvent: 72.797 loading class com/fasterxml/jackson/databind/util/TokenBuffer$Segment doneEvent: 72.798 Executing VM operation: CollectForMetadataAllocationDynamic libraries:0x000000001832f000 /System/Library/Frameworks/Cocoa.framework/Versions/A/Cocoa0x000000001832f000 /System/Library/Frameworks/Security.framework/Versions/A/Security0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices0x000000001832f000 /usr/lib/libz.1.dylib0x000000001832f000 /usr/lib/libSystem.B.dylib0x000000001832f000 /usr/lib/libobjc.A.dylib0x000000001832f000 /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation0x000000001832f000 /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation0x000000001832f000 /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit0x000000001832f000 /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData0x000000001832f000 /System/Library/PrivateFrameworks/RemoteViewServices.framework/Versions/A/RemoteViewServices0x000000001832f000 /System/Library/PrivateFrameworks/UIFoundation.framework/Versions/A/UIFoundation0x000000001832f000 /System/Library/PrivateFrameworks/DFRFoundation.framework/Versions/A/DFRFoundation0x000000001832f000 /System/Library/Frameworks/Metal.framework/Versions/A/Metal0x000000001832f000 /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv0x000000001832f000 /usr/lib/libenergytrace.dylib0x000000001832f000 /System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight0x000000001832f000 /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics0x000000001832f000 /usr/lib/libScreenReader.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate0x000000001832f000 /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface0x000000001832f000 /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox0x000000001832f000 /System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit0x000000001832f000 /System/Library/PrivateFrameworks/DataDetectorsCore.framework/Versions/A/DataDetectorsCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox0x000000001832f000 /usr/lib/libicucore.A.dylib0x000000001832f000 /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition0x000000001832f000 /usr/lib/libauto.dylib0x000000001832f000 /usr/lib/libxml2.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI0x000000001832f000 /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio0x000000001832f000 /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration0x000000001832f000 /usr/lib/liblangid.dylib0x000000001832f000 /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport0x000000001832f000 /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit0x000000001832f000 /usr/lib/libDiagnosticMessagesClient.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices0x000000001832f000 /System/Library/PrivateFrameworks/PerformanceAnalysis.framework/Versions/A/PerformanceAnalysis0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL0x000000001832f000 /System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync0x000000001832f000 /System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage0x000000001832f000 /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO0x000000001832f000 /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup0x000000001832f000 /usr/lib/libarchive.2.dylib0x000000001832f000 /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork0x000000001832f000 /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration0x000000001832f000 /usr/lib/libCRFSuite.dylib0x000000001832f000 /usr/lib/libc++.1.dylib0x000000001832f000 /usr/lib/libc++abi.dylib0x000000001832f000 /usr/lib/system/libcache.dylib0x000000001832f000 /usr/lib/system/libcommonCrypto.dylib0x000000001832f000 /usr/lib/system/libcompiler_rt.dylib0x000000001832f000 /usr/lib/system/libcopyfile.dylib0x000000001832f000 /usr/lib/system/libcorecrypto.dylib0x000000001832f000 /usr/lib/system/libdispatch.dylib0x000000001832f000 /usr/lib/system/libdyld.dylib0x000000001832f000 /usr/lib/system/libkeymgr.dylib0x000000001832f000 /usr/lib/system/liblaunch.dylib0x000000001832f000 /usr/lib/system/libmacho.dylib0x000000001832f000 /usr/lib/system/libquarantine.dylib0x000000001832f000 /usr/lib/system/libremovefile.dylib0x000000001832f000 /usr/lib/system/libsystem_asl.dylib0x000000001832f000 /usr/lib/system/libsystem_blocks.dylib0x000000001832f000 /usr/lib/system/libsystem_c.dylib0x000000001832f000 /usr/lib/system/libsystem_configuration.dylib0x000000001832f000 /usr/lib/system/libsystem_coreservices.dylib0x000000001832f000 /usr/lib/system/libsystem_darwin.dylib0x000000001832f000 /usr/lib/system/libsystem_dnssd.dylib0x000000001832f000 /usr/lib/system/libsystem_info.dylib0x000000001832f000 /usr/lib/system/libsystem_m.dylib0x000000001832f000 /usr/lib/system/libsystem_malloc.dylib0x000000001832f000 /usr/lib/system/libsystem_network.dylib0x000000001832f000 /usr/lib/system/libsystem_networkextension.dylib0x000000001832f000 /usr/lib/system/libsystem_notify.dylib0x000000001832f000 /usr/lib/system/libsystem_sandbox.dylib0x000000001832f000 /usr/lib/system/libsystem_secinit.dylib0x000000001832f000 /usr/lib/system/libsystem_kernel.dylib0x000000001832f000 /usr/lib/system/libsystem_platform.dylib0x000000001832f000 /usr/lib/system/libsystem_pthread.dylib0x000000001832f000 /usr/lib/system/libsystem_symptoms.dylib0x000000001832f000 /usr/lib/system/libsystem_trace.dylib0x000000001832f000 /usr/lib/system/libunwind.dylib0x000000001832f000 /usr/lib/system/libxpc.dylib0x000000001832f000 /usr/lib/closure/libclosured.dylib0x000000001832f000 /usr/lib/libbsm.0.dylib0x000000001832f000 /usr/lib/system/libkxld.dylib0x000000001832f000 /usr/lib/libOpenScriptingUtil.dylib0x000000001832f000 /usr/lib/libcoretls.dylib0x000000001832f000 /usr/lib/libcoretls_cfhelpers.dylib0x000000001832f000 /usr/lib/libpam.2.dylib0x000000001832f000 /usr/lib/libsqlite3.dylib0x000000001832f000 /usr/lib/libxar.1.dylib0x000000001832f000 /usr/lib/libbz2.1.0.dylib0x000000001832f000 /usr/lib/liblzma.5.dylib0x000000001832f000 /usr/lib/libnetwork.dylib0x000000001832f000 /usr/lib/libapple_nghttp2.dylib0x000000001832f000 /usr/lib/libpcap.A.dylib0x000000001832f000 /usr/lib/libboringssl.dylib0x000000001832f000 /usr/lib/libusrtcp.dylib0x000000001832f000 /usr/lib/libapple_crypto.dylib0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices0x000000001832f000 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList0x000000001832f000 /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS0x000000001832f000 /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth0x000000001832f000 /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport0x000000001832f000 /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC0x000000001832f000 /usr/lib/libmecabra.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis0x000000001832f000 /System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib0x000000001832f000 /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib0x000000001832f000 /System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator0x000000001832f000 /System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment0x000000001832f000 /System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib0x000000001832f000 /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo0x000000001832f000 /System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders0x000000001832f000 /usr/lib/libFosl_dynamic.dylib0x000000001832f000 /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore0x000000001832f000 /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL0x000000001832f000 /usr/lib/libcompression.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib0x000000001832f000 /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib0x000000001832f000 /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG0x000000001832f000 /System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix0x000000001832f000 /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib0x000000001832f000 /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib0x000000001832f000 /usr/lib/libcups.2.dylib0x000000001832f000 /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos0x000000001832f000 /System/Library/Frameworks/GSS.framework/Versions/A/GSS0x000000001832f000 /usr/lib/libresolv.9.dylib0x000000001832f000 /usr/lib/libiconv.2.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal0x000000001832f000 /usr/lib/libheimdal-asn1.dylib0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory0x000000001832f000 /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth0x000000001832f000 /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory0x000000001832f000 /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation0x000000001832f000 /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS0x000000001832f000 /usr/lib/libutil.dylib0x000000001832f000 /System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce0x000000001832f000 /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData0x000000001832f000 /usr/lib/libmarisa.dylib0x000000001832f000 /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon0x000000001832f000 /usr/lib/libChineseTokenizer.dylib0x000000001832f000 /usr/lib/libcmph.dylib0x000000001832f000 /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling0x000000001832f000 /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji0x000000001832f000 /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement0x000000001832f000 /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement0x000000001832f000 /usr/lib/libxslt.1.dylib0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink0x000000001832f000 /System/Library/PrivateFrameworks/TextureIO.framework/Versions/A/TextureIO0x000000001832f000 /usr/lib/libate.dylib0x000000001832f000 /System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport0x000000001832f000 /System/Library/PrivateFrameworks/Sharing.framework/Versions/A/Sharing0x000000001832f000 /System/Library/PrivateFrameworks/IconServices.framework/Versions/A/IconServices0x000000001832f000 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/Versions/A/ProtocolBuffer0x000000001832f000 /System/Library/PrivateFrameworks/Apple80211.framework/Versions/A/Apple802110x000000001832f000 /System/Library/Frameworks/CoreWLAN.framework/Versions/A/CoreWLAN0x000000001832f000 /System/Library/PrivateFrameworks/CoreUtils.framework/Versions/A/CoreUtils0x000000001832f000 /System/Library/Frameworks/IOBluetooth.framework/Versions/A/IOBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/CoreWiFi.framework/Versions/A/CoreWiFi0x000000001832f000 /System/Library/Frameworks/CoreBluetooth.framework/Versions/A/CoreBluetooth0x000000001832f000 /System/Library/PrivateFrameworks/SignpostNotification.framework/Versions/A/SignpostNotification0x000000001832f000 /System/Library/PrivateFrameworks/DebugSymbols.framework/Versions/A/DebugSymbols0x000000001832f000 /System/Library/PrivateFrameworks/CoreSymbolication.framework/Versions/A/CoreSymbolication0x000000001832f000 /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication0x000000001832f000 /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression0x000000001832f000 /System/Library/PrivateFrameworks/SpeechRecognitionCore.framework/Versions/A/SpeechRecognitionCore0x000000001832f000 /System/Library/CoreServices/Encodings/libSimplifiedChineseConverter.dylib0x0000000100f3a000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib0x000000001832f000 /usr/lib/libstdc++.6.0.9.dylib0x0000000101ee1000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libverify.dylib0x0000000101eef000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libjava.dylib0x0000000101f25000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libinstrument.dylib0x0000000101fc3000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libzip.dylib0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaRuntimeSupport.framework/Versions/A/JavaRuntimeSupport0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/Frameworks/JavaNativeFoundation.framework/Versions/A/JavaNativeFoundation0x000000001832f000 /System/Library/Frameworks/JavaVM.framework/Versions/A/JavaVM0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon0x000000001832f000 /System/Library/PrivateFrameworks/JavaLaunching.framework/Versions/A/JavaLaunching0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print0x000000001832f000 /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI0x000000010ae78000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnet.dylib0x000000010aed7000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libmanagement.dylib0x000000010aee5000 /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/libnio.dylibVM Arguments:jvm_args: -XX:TieredStopAtLevel=1 -Xverify:none -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=52007 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=52008:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8 java_command: com.ejlerp.saleorder.SaleOrderProviderApplicationjava_class_path (initial): /Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomeLauncher Type: SUN_STANDARDEnvironment Variables:JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/HomePATH=/Users/victor/jar/byteman-download-3.0.10/bin:/Users/victor/jar/btrace-bin-1.3.10/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbinSHELL=/bin/bashSignal Handlers:SIGSEGV: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_ONSTACK|SA_RESTART|SA_SIGINFOSIGBUS: [libjvm.dylib+0x5b27a5], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGFPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGPIPE: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGXFSZ: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGILL: [libjvm.dylib+0x4891c4], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGUSR1: SIG_DFL, sa_mask[0]=00000000000000000000000000000000, sa_flags=noneSIGUSR2: [libjvm.dylib+0x488ce2], sa_mask[0]=00100000000000000000000000000000, sa_flags=SA_RESTART|SA_SIGINFOSIGHUP: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGINT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGTERM: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFOSIGQUIT: [libjvm.dylib+0x4872b9], sa_mask[0]=11111111011111110111111111111111, sa_flags=SA_RESTART|SA_SIGINFO--------------- S Y S T E M ---------------OS:Bsduname:Darwin 17.3.0 Darwin Kernel Version 17.3.0: Thu Nov 9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64rlimit: STACK 8192k, CORE 0k, NPROC 709, NOFILE 10240, AS infinityload average:5.50 4.41 3.51CPU:total 4 (initial active 4) (2 cores per cpu, 2 threads per core) family 6 model 61 stepping 4, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, avx, avx2, aes, clmul, erms, 3dnowpref, lzcnt, ht, tsc, tscinvbit, bmi1, bmi2, adxMemory: 4k page, physical 8388608k(184936k free)/proc/meminfo:vm_info: Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for bsd-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:37:08 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)time: Thu Dec 28 15:17:01 2017elapsed time: 72 seconds (0d 0h 1m 12s)]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error-web-zookeeper]]></title>
    <url>%2F2017%2F12%2F28%2Fegenie_bugfix%2Ferror-web-zookeeper%2F</url>
    <content type="text"><![CDATA[123452017-12-26 19:42:40.907 WARN [localhost-startStop-1-SendThread(10.26.235.193:2181)][ClientCnxn.java:1162] - Session 0x15e05c1c95a0370 for server 10.26.235.193/10.26.235.193:2181, unexpected error, closing socket connection and attempting reconnectjava.lang.NoClassDefFoundError: org/apache/zookeeper/proto/SetWatches at org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:926) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363) ~[zookeeper-3.4.8.jar:3.4.8--1] at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141) [zookeeper-3.4.8.jar:3.4.8--1] 问题 问题1:一直包上面的错误 问题2:26号把25号的日志给覆盖了,同时15号的错误日志也写到了9号的文件中]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2F%E7%88%B1%E5%A5%BD%2Fstudy-snowboard%2F</url>
    <content type="text"><![CDATA[goski视频教学走刃练习 前刃,后刃(不间断的跳,掌握重心重心和支撑的感觉) 向刃上加压力 直线加速,然后骤停 用刃向上跳。(前后刃) 换刃转身练习 双手抓裤子 防止搓雪太多 回山动作 如果能上去 代表 中心 不止是在前脚 两种转弯技巧 刻滑和扫雪 央视视频教学连续小回转 如羚羊一般自如 换刃平稳性检测双手背上放学块,不掉下来,说明稳定性高 滑雪助手视频教学换刃 重心前脚。身体站起。 直滑降 重心中心。下蹲。 走刃 换刃的开始 是靠膝盖的下降 YouTuBe Snowboard Addiction 前后刃刹车,一定要蹲下去,不能直腿,否则会chachacha 板头平衡/板尾平衡/后刃横向两侧平衡/后刃横向两侧平衡 Eurocarve 可以贴在地上 练习反脚 重心靠前,巧记后脚板子3下 连续转4个360度(慢慢的做) 其他视频 搓雪转弯:后刃减速,因为能看到前面,前刃比较自然 换刃: 用后面的板子的刃,向两边搓雪减速, 更快的转弯,(利用膝盖),陡坡管用 后刃,后手往前伸 前刃,后手往后伸,可以保持身体直立 走刃: 前刃时,弯曲膝盖;身体要直,不能太前倾,否则卡不住雪;重心在中间 后刃时,坐的越深;身体越要向前倾斜,否则卡不住雪;重心在中间 滑雪笔记历史视频 https://v.qq.com/x/page/y0374rcpz1y.html https://v.qq.com/x/page/p0374j04u5p.html https://v.qq.com/x/page/e0374vazd55.html 2017年11月30日-怀北-2017年冬天第一次滑单板 正脚：身体跟随刃一起动,可以保持不搓雪，压刃，重心中心;总体感觉较好,有时候后任会chachacha,应该是立刃不足,或者身体太直 反脚: 总体不是很流畅, https://v.qq.com/x/page/p0527pxet7b.html]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[双板滑雪笔记]]></title>
    <url>%2F2017%2F12%2F26%2F%E7%88%B1%E5%A5%BD%2Fstudy-ski%2F</url>
    <content type="text"><![CDATA[犁式直降动作成v字 犁式转弯练习方案 平举双手,转弯时,双手放到山下腿,其中山下退要承受重量,让身体靠近山下腿 重心的转移很重要 山上腿,打开(解锁)膝盖,很自然的并板子 动作要流畅,s形,而不是z形 平行式 之前是入弯后们转为平行 打开膝盖,提早并腿 转换重心时,同时换刃 转弯一个弯,再下一个(控制好速度,再转下一个) 转弯时拧板,会出现型 两个阶段: 准备入弯 控制速度 避免过早结束转弯 立刃,类似于单板的推坡(垂直方向) 练习:立刃,放平,来回切换 练习”直线,立刃,转弯,停]]></content>
      <categories>
        <category>滑雪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mac安装kubernetes]]></title>
    <url>%2F2017%2F12%2F21%2Fdocker%2Fstudy-ubernetes-install%2F</url>
    <content type="text"><![CDATA[https://github.com/jolestar/kubernetes-complete-course 容器的特性 让不标准的物品标准化（杂物，水，应用） 给上层工具提供标准化的操作方式，屏蔽细节 包装，运输 add/remove/iterator（复用算法） 应用管理和调度 Docker (Moby) 如何实现应用标准化 问题 现状 Docker 的方案 安装包 war/jar，rpm/deb, src, bin Image/Image Layer 运行环境 jvm，php, ruby, python Image/Image Layer 进程启动方式 web container, cmd, script Image ENTRYPOINT/CMD 进程资源隔离限制 Namespace/CGroup 进程文件路径冲突 Chroot 端口冲突 修改配置 Network（IP per Container） 日志输出 文件 stderr/stdout 安装包的仓库 nexus, rpm rep，ftp Docker Registry Kubernetes 为何而生 - 云发展到一个新阶段IaaS 云解决了哪些问题按需购买接管硬件资源的运维提供可编程接口来管理资源提供 SDN，SDS 模拟硬件网络以及存储 特点对应用无侵入面向资源 用户从关注资源的运维转向关注应用的开发运维成本 Kubernetes 为何而生 - 容器的成熟奠定了基础容器（Docker/Moby） 解决了哪些问题应用安装包的标准化（Image）应用进程的标准化（Container） 特点单进程标准化 容器编排系统应运而生我们需要一种 面向应用（Application Oriented） 的系统来降低服务端应用的开发部署和运维成本 We wanted people to be able to program for the data center just like they program for their laptop –Ben Hindman 我们再引申一下，从开发延伸到部署运维 We wanted people to be able to manager app for the data center just like they manager app on their laptop 官网地址http://kubernetes.kansea.com/docs/whatisk8s/ mac本地安装kubernetes(minikube)http://kubernetes.kansea.com/docs/getting-started-guides/minikube/ virtualBox安装 minikube安装 kubectl安装 需要ss的的代理,否则google的镜像无法下载123456789minikube deleteminikube start --docker-env HTTP_PROXY=http://192.168.99.1:1087 --docker-env HTTPS_PROXY=http://192.168.99.1:1087 --docker-env NO_PROXY=192.168.99.0/24kubectl get pods --all-namespaces等待readykubectl get nodes 12345678910111213141516171819202122232425victordeMacBook-Pro:~ victor$ kubectl run nginx --image=nginx --port=80deployment &quot;nginx&quot; createdvictordeMacBook-Pro:~ victor$ kubectl expose deployment nginx --port=80 --type=NodePort --name=nginx-httpservice &quot;nginx-http&quot; exposedvictordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 0/1 ContainerCreating 0 17svictordeMacBook-Pro:~ victor$ kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20mnginx-http NodePort 10.99.7.195 &lt;none&gt; 80:32562/TCP 12svictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlWaiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...Waiting, endpoint for service is not ready yet...^CvictordeMacBook-Pro:~ victor$ kubectl get nodesNAME STATUS ROLES AGE VERSIONminikube Ready &lt;none&gt; 22m v1.8.0victordeMacBook-Pro:~ victor$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-85dfb4bc54-72fbk 1/1 Running 0 2mvictordeMacBook-Pro:~ victor$ minikube service nginx-http --urlhttp://192.168.99.100:32562 tips: 本地的ss需要设置http代理,其中监听的地址从127.0.0.1改为0.0.0.0,这样虚拟机就可以访问到了,在这步卡了很久 docker安装https://yeasy.gitbooks.io/docker_practice/content/kubernetes/quickstart.html 这些服务大概分为三类：主节点服务、工作节点服务和其它服务。 主节点服务apiserver 是整个系统的对外接口，提供 RESTful 方式供客户端和其它组件调用； scheduler 负责对资源进行调度，分配某个 pod 到某个节点上； controller-manager 负责管理控制器，包括 endpoint-controller（刷新服务和 pod 的关联信息）和 replication-controller（维护某个 pod 的复制为配置的数值）。 工作节点服务kubelet 是工作节点执行操作的 agent，负责具体的容器生命周期管理，根据从数据库中获取的信息来管理容器，并上报 pod 运行状态等； proxy 为 pod 上的服务提供访问的代理。 其它服务Etcd 是所有状态的存储数据库； gcr.io/google_containers/pause:0.8.0 是 Kubernetes 启动后自动 pull 下来的测试镜像。 https://yeasy.gitbooks.io/docker_practice/content/kubernetes/concepts.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[study-service-mesh(服务网格)]]></title>
    <url>%2F2017%2F12%2F20%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fstudy-service-mesh%2F</url>
    <content type="text"><![CDATA[service-mesh概念首先服务网格是一个基础设施层，功能在于处理服务间通信，职责是负责实现请求的可靠传递。在实践中，服务网格通常实现为轻量级网络代理，通常与应用程序部署在一起，但是对应用程序透明。 设计图 概念学习https://zhuanlan.zhihu.com/p/28794062https://zhuanlan.zhihu.com/p/30292372 Kubernetes和Spring Cloud哪个部署微服务更好？https://www.kubernetes.org.cn/1057.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>service-mesh</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opitimize_git_clone]]></title>
    <url>%2F2017%2F12%2F20%2Ftools%2Fopitimize-git-clone%2F</url>
    <content type="text"><![CDATA[找到自己代理的端口 命令:git config –global http.https://github.com.proxy https://127.0.0.1:1087git config –global https.https://github.com.proxy https://127.0.0.1:1087 作者：汪小九链接：https://www.zhihu.com/question/27159393/answer/141047266来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 查看git设置git config –list #BTW此种加速对http和https协议有效 对ssh协议无效,如:git clone git@github.com:xxxxxx/xxxxxx.git]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-人工智能基础课1]]></title>
    <url>%2F2017%2F12%2F19%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-base-study1%2F</url>
    <content type="text"><![CDATA[最优化方法百度https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95 知乎抽象概念1234567 在一定的约束条件下，求一个函数的最大（小）值。 要理解的其实只有两个概念，函数和约束条件。甚至函数这个概念已经包含了对约束条件的考虑。所谓函数，简单理解的话，可以当做一个机器，你给它一个输入，它就给你一个输出，它是一个对应。你通过调节输入，达到最好的输出。它是现实状况的数学语言表达。例如我们要最小化总费用，我们知道单价，我们可以决定数量，于是我们得到的数学表达：总费用=单价乘以数量。我们通过调整数量来最小的总费用。至于约束条件，它有很多种，例如等式的约束，不等式的约束，微分方程的约束，概率的约束，等等等等。他们也是对我们现实状况中的约束的数学表达。不同的约束配上不同的目标函数就会得到一个不同的问题。例如目标函数和约束都是线性的，这个最优化问题就叫线性规划，如果约束是个常微分方程，就叫最优控制。等等等等。作者：滴水链接：https://www.zhihu.com/question/26341871/answer/41242951来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 蛮形象的解释https://www.zhihu.com/question/263418711234567之所以要使用计算机，是因为数据量太大，远远超过人脑的处理能力。比如我们需要从一堆人脸图片里给每个人标上正确的名字，一幅32像素见方的人脸图像有1024颗像素点，你能想象出一百万张这样的照片和1万个人名字之间的关系是什么样吗。再比如给你1万个患者的DNA序列，每个患者的序列由百万级的碱基对构成，你能找到这些天文数字量级的序列和是否患某种疾病之间的联系吗？答案是不能！所以研究者退而求其次，建立很多学习模型，这些模型输入是一个样本的数据（头像图片、一个人的DNA序列），输出是样本的标签（人名、是否患病）。模型里有大量可以调整的参数，这些参数通过训练，能够学习到数据和标签之间人类无法直接理解的、复杂的关系。科学家期望当模型训练完成后，再拿来一个样本，喂给这个训练好的机器，它能够吐出一个标签，这个标签恰好就是样本对应的那个正确的标签。目前人们已经研究出一大堆学习模型：神经网络、支持向量机、AdaBoost、随机森林、隐马尔科夫链、卷积神经网络等等。它们的结构差异很大，但是共同点都是拥有一大堆参数，就等着你喂给它数据供它学习。这些模型的学习也需要一个目标函数：让模型的分类错误率尽量小。为了达到目的，模型的训练往往首先给参数赋上随机初值，然后用各种下降法来寻找能让分类错误率更小的参数设置，梯度下降、牛顿法、共轭梯度法和Levenberg—Marquard法都是常见的方法。 随着研究的深入，问题也越来越多，比如下降法往往只能保证找到目标函数的局部最小值，找不到全局最小值，怎么办呢？答案是不一味下降、也适当爬爬山，说不定能跳出小水沟（局部极小值）找到真正的深井（全局极小值），这种算法叫模拟退火。也可以增大搜索范围，让一群蚂蚁（蚁群算法）或者鸟儿（粒子群算法）一齐搜索，或者让参数巧妙地随机改变（遗传算法）。 那么多模型，到底该选哪个？研究者又发现了一个定理“天下没有免费的午餐”定理，意思是没有一个模型能一直比其他模型好，对于不同类型的数据，必须要通过实验才能发现哪种学习模型更适合。机器学习领域也就成了学界灌水严重的领域之一——换模型、调参数就能发文章哎。 下面说到了调参数，问题又来了，到底是参数多了好还是少了好？参数少了模型太笨学不到数据内的复杂关系，参数多了模型太精明又可能会把数据中的随机噪声当作某种关系进行认真学习（过拟合）。最后大家一致认为，确定模型的复杂度时，要保证模型能力足够强，能够学会数据之间的关系，能力又不能太强，以至于耍小聪明乱学习。这种选择模型的思想被称为奥卡姆剃刀：选择有能力的模型中最简单的那个。此外，训练模型的目标并不是为了使训练样本能够被尽量正确分类，更需要对未知新样本有好的分类效果，这样模型才有实用价值，这种能力被称为泛化能力。除了奥卡姆剃刀原理外，训练时引入随机性的模型比确定的模型（比如BP神经网络）具有更好的泛化能力。 模型的更新也是问题。如果引入了新数据，全部模型都需要重新训练是一笔很大的开销，在线学习模型采用来一个样本学一点的模式，能够不断自我更新；半监督学习利用少量带标签的样本训练一个原始模型，然后利用大量无标签数据再学习。 举例1比如想从广州去杭州，怎样最快又最经济（目标函数）？你有很多种方法，可以坐火车，飞机，汽车(很多种解，而且可以对这些解进行组合)，但总是有个组合最让你满意（最优解），最符合你的期望。怎么去求解这个最优解，由此产生的一系列方法。 博客http://www.cnblogs.com/maybe2030/p/4751804.html]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极客时间-学习笔记-AI技术内参1-经典搜索核心算法]]></title>
    <url>%2F2017%2F12%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fjikeshijian-ai-study1%2F</url>
    <content type="text"><![CDATA[TF-IDF及其变种 信息检索,文本挖掘,自然语言处理领域 把查询关键字(Query)和文档(Document)都转为向量 ‘向量空间模型’Vector Spcece Model就是希望吧查询关键字和文档都表达成变量,然后利用向量之间的运算来进行进一步表达向量之间的关系 相似性:余弦相似性,或者是点积 V个词汇,V维度,查询关键字和每个文档的向量都有V个维度 TF和IDF的乘机 TF单词频率Term Frequency,计算一个查询关键字中某一个单子在目标文档中出现的次数 如查询’car insurance’,那么计算car出现了多少次,insurance出现了多少次 表示相关度 IDF,逆文档频率Inerse Document Frequency,需要去惩罚哪些出现在太多文档中的单词 多少文档包含了这个单词,越大越不重要 其他学习资料http://www.ruanyifeng.com/blog/2013/03/tf-idf.html123让我们从一个实例开始讲起。假定现在有一篇长文《中国的蜜蜂养殖》，我们准备用计算机提取它的关键词。所以，排在最前面的几个词，就是这篇文章的关键词。除了自动提取关键词，TF-IDF算法还可以用于许多别的地方。比如，信息检索时，对于每个文档，都可以分别计算一组搜索词（&quot;中国&quot;、&quot;蜜蜂&quot;、&quot;养殖&quot;）的TF-IDF，将它们相加，就可以得到整个文档的TF-IDF。这个值最高的文档就是与搜索词最相关的文档。TF-IDF算法的优点是简单快速，结果比较符合实际情况。缺点是，单纯以&quot;词频&quot;衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。而且，这种算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的。（一种解决方法是，对全文的第一段和每一段的第一句话，给予较大的权重。） BM25及其变种 BM是’最佳匹配’Best Match的简称 用来计算某一目标文档(Document)相对于一个查询关键字(Query)的”相关性”(Relevance)的流程, 非监督学习排序算法中的一个典型代表 定义: 单词和目标文档的相关性 词频 TF-IDF里面的TF部分,but词频需要”标准化”,某一个单词对最后的分数的贡献不会随着词频的增加而无限增加 两个超参数:当前文档的长度,整个数据集所有文档的平均长度 单词和查询关键词的相关性 同样需要标准化过程 单词的权重部分 某种变形的来对单词加权,例如某种变形的IDF来对单词甲醛 罗伯逊-斯巴克-琼斯权重,需要一个监督信息 在很多情况下,利用IDF来直接对单词权重的版本更加普遍,如果再有监督信息的情况下,RSJ值也不失为一个很好的选择 这个三个部分的乘积组成某一个单词的分数,然后,整个文档相对于某个查询关键字的分数,就是所有查询关键字里所有单词分数的总和 bm25是对某一概率相关模型的逼近 bm25算法变种:bm25f, 域的概念(文档包括标题,摘要和正文) 把BM25和其他文档信息(非文字)结合起来 BM25和PageRank的线性结果来确定网页的相关性 语言模型及其变种 详解:用概率模型(Probabilistic Model)来描述查询关键字和目标文档之间的关系 最简单的:查询关键字似然检索模型 一个语言模型就是一个针对词汇表的概率分布 词汇表1w个单词,1w个单词上的离散概率分布 查询关键字是从一个语言模型中”抽样”得到一个样本 对一个查询关键字打分=这组词出现的联合概率,因为联合概率可能会很小,因此很多时候都通过一个对数变化,来把概率的乘积变成概率对数加和 语言模型的参数:”类别分布”(Categorical Distiribution),也就是多项式分布,去除排列组合信息 参数股计算法:最大似然估计 每个单词出现的可能性,正好等于这个单词在目标文档中出现的次数,除以所有单词在文档中出现的次数. 每个文档都对应一个类别分布,有多少文档,就有多少个类别分布 如果没有在训练数据中出现过,最优解就是0 平滑(Smoohting)http://52opencourse.com/111/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88language-modeling%EF%BC%89]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[api网关学习]]></title>
    <url>%2F2017%2F12%2F18%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2Fstudy-api-gateway%2F</url>
    <content type="text"><![CDATA[什么是api网关123王延炯：API Gateway（API GW / API 网关），顾名思义，是出现在系统边界上的一个面向API的、串行集中式的强管控服务，这里的边界是企业IT系统的边界。在微服务概念的流行之前，API GW的实体就已经诞生了，这时的主要应用场景是OpenAPI，也就是开放平台，面向的是企业外部合作伙伴，对于这个应用场景，相信接触的人会比较多。当在微服务概念流行起来之后，API网关似乎成了在上层应用层集成的标配组件。 为什么需要api网关 负载均衡 减少客户端与服务端的直接调用 容错 服务发现与注册 统一认证 选型spring cloud zuulhttps://github.com/Netflix/zuul nginx konghttps://github.com/Kong/kong 阿里云apigatewayhttps://www.aliyun.com/product/apigateway API 生命周期管理 支持包括 API 发布、API 测试、API 下线等生命周期管理功能。 支持 API 日常管理、API 版本管理、API 快速回滚等维护功能。 全面的安全防护 支持多种认证方式，支持 HMAC (SHA-1，SHA-256) 算法签名。 支持 HTTPS 协议，支持 SSL 加密。 防攻击、防注入、请求防重放、请求防篡改。 灵活的权限控制 用户以 APP 作为请求 API 的身份，网关支持针对 APP 的权限控制。 只有已经获得授权的 APP 才能请求相应的 API。 API 提供者可以主动授权某个 APP 调用某个 API 的权限。 API 若上架到 API 市场，则购买者可以将已购买的 API 授权给自己的 APP。 精准的流量控制 流量控制可以用于管控 API的被访问频率、APP的请求频率、用户的请求频率。 流量控制的时间单位可以是分钟、小时、天。 同时支持流控例外，允许设置特殊的 APP 或者用户。 请求校验 支持参数类型、参数值（范围、枚举、正则、Json Schema）校验，无效校验直接会被 API 网关拒绝，减少无效请求对后端造成的资源浪费，大大降低后端服务的处理成本。 数据转换 通过配置映射规则，实现前、后端数据翻译。 支持前端请求的数据转换。 支持返回结果的数据转换。 监控报警 提供可视化的API实时监控，包括：调用量、流量大小、响应时间、错误率，在陆续增加维度。 支持历史情况查询，以便统筹分析。 可配置预警方式（短信、Email），订阅预警信息，以便实时掌握API运行情况。 自动工具 自动生成 API 文档，可供在线查看。 API 网关提供多种语言 SDK 的示例。降低 API 的运维成本。 提供可视化的界面调试工具，快速测试，快速上线。 API 市场 可将 API 上架到 API 市场，供更多开发者采购和使用。 参考资料http://www.infoq.com/cn/news/2016/07/API-background-architecture-floohttp://www.infoq.com/cn/articles/construct-micro-service-using-api-gateway]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[禁止使用@Reference的注解]]></title>
    <url>%2F2017%2F12%2F14%2Fegenie_bugfix%2Foptimize-dubbuo-reference%2F</url>
    <content type="text"><![CDATA[dubbo服务引用默认情况下可以通过@Reference和xml注解来引入例如1234567891011@Reference(version = "0.1", timeout = 8000) private TenantService tenantService; @Reference(version = "0.1", timeout = 8000) private ProductService productService; @Reference(version = "0.1", timeout = 8000) private DictService dictService; @Reference(version = "0.1", timeout = 8000) private CategoryService categoryService; 或者123456&lt;dubbo:reference id="remoteBaseCustomPropsService" interface="com.ejlerp.baseinfo.api.BaseCustomPropsService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuStepPriceService" interface="com.ejlerp.baseinfo.api.SkuStepPriceService" version="0.1" timeout="60000"/&gt;&lt;dubbo:reference id="remoteSkuUnitService" interface="com.ejlerp.baseinfo.api.SkuUnitService" version="0.1" timeout="60000"/&gt; 出现的问题生产环境上调用微服务超时,结果发现即使通过123service: @Reference(version = "0.1", timeout = 8000) private ProductService productService; 的方式设置了超时时间,但生产环境的错误,还是设置的1000ms的超时时间, 问题原因在其他的service中同样是引用了这个注解123其他service: @Reference(version = "0.1") private ProductService productService; Reference注解 包含了初始化和注入dubbo的bean,两种功能其实是声明了一个bean,但是到底是用哪个timeout,是有spring初始化bean的顺序所决定的,很可能出现设置了timeout但是仍然没有效果的情况 解决办法 在2017-12-12后的,所有微服务,禁止使用Reference注解,通过autowirdj进行钟乳 统一使用xml的方式,进行声明dubbo的bean 优点 统一Reference方式对其他微服务的引用,放置不一致的配置出现 xml的方式,方便设置方法级别的参数 1234&lt;dubbo:reference id="remoteArrivalStockOutReportService" interface="com.ejlerp.pms.api.StockOutReportService" version="0.1" timeout="60000"&gt; &lt;dubbo:method name="refreshAction" timeout="9000000" retry="0"/&gt;&lt;/dubbo:reference&gt; 修改步骤如下 去除掉DubboConf.java中大部分代码 添加spring-dubbo,xml 删除旧的@Reference,同时添加@Autowird 替换默认的@Reference无超时时间的,基本为dao中id 和 sn generater 将web中最全的dubbo.conf复制到为服务中 本项目为pms,删除掉所有pms相关的xml注入 逐行全文搜索,删掉没用的service 再次遍历dubb.conf的所有service,修改成项目中原来的超时时间,并去掉个性化设置的@Reference 编译,解决编译问题,补充一些@Autowird的包 尝试启动,补充一些egenie-web中没有声明,但是微服务中用到的service 例如:com.ejlerp.messages.api.QueueService,com.ejlerp.cache.api.SortedSetCacher,com.ejlerp.cache.api.IDGenerator,com.ejlerp.cache.api.IDGenerator等 启动成功 具体改动,见git: http://git.ejlerp.com/egenie/ejlerp-pms/commit/4d431233af740e0f1c85c8733afcaadfb0638a18 BTW http://dubbo.io/books/dubbo-user-book/demos/fault-tolerent-strategy.html 在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。 Failover Cluster 失败自动切换，当出现失败，重试其它服务器 1。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错 2。通常用于通知所有提供者更新缓存或日志等本地资源信息。 开发人员可以根据自己的实际业务,设置失败时的处理方式]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>reference</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm崩溃]]></title>
    <url>%2F2017%2F12%2F14%2Fjava_jvm%2Foperation-jvm%2F</url>
    <content type="text"><![CDATA[日常日志及错误1232017-12-13 18:26:00.001 [pool-27-thread-1] INFO com.ejlerp.pms.provider.mqCrond.MqPmsTradeOrderCrond.sendMsgToInter - == 处理采购推送交易库定时任务 start ==2017-12-13 18:26:05.711 [pool-27-thread-1] ERROR org.springframework.scheduling.support.TaskUtils$LoggingErrorHandler.handleError - Unexpected error occurred in scheduled task.java.lang.OutOfMemoryError: Java heap space 同时jvm由于重启过,gc日志也刷新了 每个jvm不仅用自己个性化的参数调优,还应该有共同参数,例如:打印gc日志,dump内存等参数TODO 待总结]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上redis崩溃记录]]></title>
    <url>%2F2017%2F12%2F14%2Fredis%2Foperation-redis%2F</url>
    <content type="text"><![CDATA[错误日志grep com.alibaba.dubbo.rpc.filter.ExceptionFilter.error123456789101112131415161718199:02org.springframework.data.redis.RedisConnectionFailureException: Unexpected end of stream.; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Unexpected end of stream.好多条org.springframework.dao.InvalidDataAccessApiUsageException: LOADING Redis is loading the dataset in memory; nested exception is redis.clients.jedis.exceptions.JedisDataException: LOADING Redis is loading the dataset in memory 好多条org.springframework.data.redis.RedisConnectionFailureException: java.net.SocketTimeoutException: Read timed out; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketTimeoutException: Read timed outorg.springframework.data.redis.RedisConnectionFailureException: java.net.SocketException: Connection reset; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: java.net.SocketException: Connection resetorg.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool很多9:21开始org.springframework.dao.InvalidDataAccessApiUsageException: ERR READONLY You can&apos;t write against a read only instance; nested exception is redis.clients.jedis.exceptions.JedisDataException: ERR READONLY You can&apos;t write against a read only instance很多 期间代码回滚到了上一版本,过了一段时间系统正常最后发现是 业务层面循环调用了redis操作,一次请求会有1k次的redis,导致redis崩掉,而且我们使用的阿里云的主从版云redis 几次循环调用,inFlow的变化 具体得失hset方法的调用 反思 对于监控系统,应该有各个节点的平时统计数据,包括,调用次数+相应时长 通过环比和同比数据的对比,可以快速的发现问题,解决问题,而不是当系统垮掉时,才有所反应 BTWnest exception学习http://www.iteye.com/problems/87876 即调用顺序是 action—&gt;service—&gt;dao—-&gt;hibernate—&gt;jdbc 抛出异常顺序是 jdbc—-&gt;hibernate—-&gt;dao–抛出–&gt;service–继续抛出–&gt;action 异常其实是栈调用的快照 1、最下层的异常是出错的原因，上边的异常是对下边的封装，目的是一致性 和 更可读；（即下边异常是引起上边异常的原因，每一个Exception都有一个cause，如hibernate异常的cause就是jdbc的异常） 2、对于每一段异常，方法调用顺序是从下往上 3、想知道是由于前面创建的错误导致后边的异常，还是后边的异常导致前面的创建错误，后边导致前面，，，前面对后面的进行了封装，，目的是提供一致的异常（并且把原始错误显示出来 就是 nested exception 后边部分） NestedRuntimeException 例子我们最熟悉的就是 DataAccessException12345678910111213package org.springframework.dao;import org.springframework.core.NestedRuntimeException;public abstract class DataAccessException extends NestedRuntimeException &#123; public DataAccessException(String msg) &#123; super(msg); &#125; public DataAccessException(String msg, Throwable cause) &#123; super(msg, cause); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>breakdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix总结-12.13]]></title>
    <url>%2F2017%2F12%2F14%2Fegenie_bugfix%2Fbugfix-2-1213%2F</url>
    <content type="text"><![CDATA[bugfix1-redis相关 快速定位问题 12345678910111213141516171819202017-12-13 18:33:39.688 DEBUG [http-bio-6000-exec-17][JdbcTemplate.java:875] - SQL update affected 1 rows2017-12-13 18:33:40.590 ERROR [http-bio-6000-exec-17][UniExceptionHandler.java:57] - 捕捉到技术异常: URI: /shop/insert 最大内存: 1012m 已分配内存: 1012m 已分配内存中的剩余空间: 532m 最大可用内存: 532mjava.lang.RuntimeException: org.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerExceptionorg.springframework.data.redis.RedisSystemException: Unknown redis exception; nested exception is java.lang.NullPointerException at org.springframework.data.redis.FallbackExceptionTranslationStrategy.getFallback(FallbackExceptionTranslationStrategy.java:48) at org.springframework.data.redis.FallbackExceptionTranslationStrategy.translate(FallbackExceptionTranslationStrategy.java:38) at org.springframework.data.redis.connection.jedis.JedisConnection.convertJedisAccessException(JedisConnection.java:242) at org.springframework.data.redis.connection.jedis.JedisConnection.set(JedisConnection.java:1236) at org.springframework.data.redis.connection.DefaultStringRedisConnection.set(DefaultStringRedisConnection.java:744) at org.springframework.data.redis.core.DefaultValueOperations$10.inRedis(DefaultValueOperations.java:172) at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:57) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:207) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:91) at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169) at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34) at com.alibaba.dubbo.common.bytecode.Wrapper7.invokeMethod(Wrapper7.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) 首先这个是一个没有见过的异常 解决途径: 搜索自己公司包开头的代码,找到调用地方 下载源码,底层依赖可能有真的有 在本次bugfix中,由于是微服务调用,真正看出问题是在,controller层才看出的问题12345678910@ApiOperation(value = &quot;新增&quot;)@RequestMapping(value = &quot;/insert&quot;, method = RequestMethod.POST)public JsonResult insert(@RequestBody String body) &#123; Long id = IdGenerator.generate(getEntityName(), fetchTenantId()).getIdValue(); CommonVo vo = CommonVo.of(getEntityName(), WebHelper.parseJsonBody(body, false, false)); vo.put(&quot;shop_id&quot;, id); getService().insert(fetchTenantId(), fetchUserId(), vo); kvCacher.set(&quot;logistic_node_&quot; + id.toString(), vo.get(&quot;logistic_node&quot;)); return new JsonResult(JsonResult.SUCCESSFUL, null);&#125; vo可能别没有获取到 反思:at com.ejlerp.cache.redis.KVCacherImpl.set(KVCacherImpl.java:34),这个一句其实只有两个参数,一个是传入的key,一个是value,一定是其中一个入参发生了问题,才会导致底层出现问题的 当然,也不排除是redis服务可能出现了问题,但是当时已经重启了reids,错误依旧存在 最后,bug定位到了是前端一个select标签,由于数据库中的dict没有初始化,导致这个select标签的初始值没有初始化完成,当然表单提交时,便不会提交这个字段, 小结 controller层的vo依然不要使用map,否则排查起来很费劲 bugfix2 分组问题 这个bugfix,其实是这样的,条件写反导致的 1234 Map&lt;Long, VSaleOrder&gt; orderMap = omsAgentService.findByIds(callerInfo, arriveMap.keySet());- Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::isNull).filter(v -&gt; &#123;+ Set&lt;Long&gt; legalIds = orderMap.values().stream().filter(Objects::nonNull).filter(v -&gt; &#123; Integer courierPrintMarkState = v.getCourierPrintMarkState(); 问题是,历史数据的修复,其实应该在线上发现问题时,作为一套完整的方案,进行提交的,而不是部署到生产环境后,又发现历史数据有问题,在半夜升级后改数据,风险真是很大 对于一些合并操作,虽然业务上提出了操作,其实从逻辑上讲,应该出现拆分的反响逻辑预支对应 问题3 jvm参数设置]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bugfix对接baidu语音合成]]></title>
    <url>%2F2017%2F12%2F13%2Fegenie_bugfix%2Fbugfix-voice-generate%2F</url>
    <content type="text"><![CDATA[背景项目中使用了baidu的语音合成,原本的设计是,批量获取设置到redis中,用户每次使用时从redis中获取 空指针异常12345678910112017-12-13 16:34:30.076 ERROR [http-bio-6000-exec-45][DownloadVoiceFromBaiduYY.java:36] - DownloadVoiceFromBaiduYY error &#123;&#125;java.lang.NullPointerException at com.baidu.aip.speech.AipSpeech.synthesis(AipSpeech.java:133) ~[java-sdk-3.2.0.jar:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoice(DownloadVoiceFromBaiduYY.java:33) [classes/:?] at com.ejlerp.web.wms.voice.baidu.DownloadVoiceFromBaiduYY.downloadVoiceB64(DownloadVoiceFromBaiduYY.java:45) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getB64(VoiceController.java:233) [classes/:?] at com.ejlerp.web.wms.voice.VoiceController.getVoiceData(VoiceController.java:149) [classes/:?] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_92] 下载源码后debug返现返回的response Content-Type是大写,与sdk中get的string不一致,于是查找github的源文件 发现了,这个bug已经fix了,https://github.com/Baidu-AIP/java-sdk/commit/c338bc71690f84351def0d64b311986c586763d2 其他遇到的问题 判断字符串写反 1234- if (StringUtils.isEmpty(value)) &#123;+ if (!StringUtils.isEmpty(value)) &#123; redisMap.put(key, value); &#125; APPkey修改错了配置文件 反思 在与外部api进行接口对接时,一定要判断各种异常情况的发生,不能只考虑正常情况 1234567try &#123; TtsResponse res = client.synthesis(voice, &quot;zh&quot;, 1, options); JSONObject result = res.getResult(); if (result != null) &#123; LOGGER.warn(&quot;downloadVoice:&#123;&#125;&quot;, result); &#125; download = res.getData(); 删除掉无用的代码,放置误导自己和别人 本地充分测试后,再提交测试部署,否则害人害己,耽误时间 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 不能依靠测试发现程序问题,即使是别人的代码,也要认真研读,滤清思路,不能头疼医头,脚痛医脚 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署 待提高 应该充分利用各种调试工具或手段,如Btrace,(临时抱佛脚,来不及,自己有待提高) 测试用例编写 要有自己的脚手架工程,方便自己后门程序的快速编写,和部署]]></content>
      <categories>
        <category>bugfix</category>
      </categories>
      <tags>
        <tag>bugfix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化2:定位io高的原因mysql]]></title>
    <url>%2F2017%2F12%2F13%2Fegenie_bugfix%2Foptime-156%2F</url>
    <content type="text"><![CDATA[#重新定位问题-%wa指CPU等待磁盘写入完成的时间 首先看下%wa的解释：Percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. #iostat #pidstat 2 10 -d发现mysql的读写量非常高]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>io高</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[156服务器优化1:清理zookeeper过多的历史文件]]></title>
    <url>%2F2017%2F12%2F12%2Fegenie_bugfix%2Foptimize-zookeeper%2F</url>
    <content type="text"><![CDATA[背景156机器是本地开发环境上的机器跑了如下服务:mysqlzookeeperdubbokeeper 现象从ssh登陆服务器就比较卡top命令后,负载一直很高 排查iotop命令看到zookeeper的io比较高http://pic.victor123.cn/17-12-12/59575921.jpg 操作步骤 https://www.cnblogs.com/jxwch/p/6526271.html 打开这两个参数 autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个； autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。 清空历史数据 效果 相关知识http://www.linuxidc.com/Linux/2016-03/129509.htmdataDir用于存储Log（事务日志）与Snapshot（快照）数据 http://blog.51cto.com/nileader/932156 1在后续的观察中发现,156的io高并不全是zookeeper的问题,so本次只是清除了历史文件,对于156的io高问题目前定位是mysql问题,待续]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>io高</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习pandas api时发现了一个奇怪的现象]]></title>
    <url>%2F2017%2F12%2F10%2Fegenie_bugfix%2Ferror-pandas-date-range%2F</url>
    <content type="text"><![CDATA[学习pandas api时发现了一个奇怪的现象 通过代码 dates = pd.date_range(‘20130101’, periods=6) 定义了函数, 下一行无法打印出来, 可是下面仍然能够使用这个datas的变脸,很是神奇,百思不得其解 结论 怀疑是应该是jupyter notebook的问题, 直接打印出pd.date_range(‘20130101’, periods=6)的结果都是正确的]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>机器学习</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas中read_csv方法的学习]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fpython-pandas-read-csv%2F</url>
    <content type="text"><![CDATA[#read_csv内容过大的处理方式:123451.train = pd.read_csv(&quot;/Users/victor/code/kaggle/Expedia/input/train.csv&quot;,nrows=3000)2.chunksize=100 总apihttp://pandas.pydata.org/pandas-docs/version/0.15]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kaggle-expedia-hotel-recommendations学习笔记]]></title>
    <url>%2F2017%2F12%2F05%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fkaggle%2Fkaggle-expedia-hotel-recommendations%2F</url>
    <content type="text"><![CDATA[题目地址https://www.kaggle.com/c/expedia-hotel-recommendations#description 学习地址https://www.dataquest.io/blog/kaggle-tutorial/ 目标 初步了解机器学习流程 通过实际代码,了解python代码的语法 学习心得 数据探索 1234567import pandas as pddestinations = pd.read_csv("destinations.csv")test = pd.read_csv("test.csv")train = pd.read_csv("train.csv")#train文件有4个g大,读了半天都不出来 数据量 数据分布 目标变量 目标变量是什么 探索目标变量 探索用户id 采样统计 添加时间和日期 挑选1000名用户 区分测试集和验证集 移除无关数据(click 事件) 一个简单的算法 生成预测 1234567891011predictions = [most_common_clusters for i in range(t2.shape[0])]# 不是很理解 [] 和 shape[0]的含义# shape()方法返回 行数 和 维度数 .其中:0:行数 1:维度数# pyhton中的遍历:for iterating_var in sequence: statements(s)# 但是 for前面的most_common_clusters 是什么意思?# 通过测试了解到是复制一个变量n遍的意思aa=[&quot;abc&quot; for i in range(10)]print(aa)输出了10个 abc 评估效果 123456789import ml_metrics as metricstarget = [[l] for l in t2[&quot;hotel_cluster&quot;]]metrics.mapk(target, predictions, k=5)# 不是很理解 [l]代表什么# 把t2[&quot;hotel_cluster&quot;]列表中的变量l,外面 前一层 列表 []xx=[1,2,3,4]target = [[l] for l in xx]print(target)[[1], [2], [3], [4]] 查找相关因素 更近一步 生成特征 从destinations生成特征 123456789from sklearn.decomposition import PCApca = PCA(n_components=3)dest_small = pca.fit_transform(destinations[[&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)]])dest_small = pd.DataFrame(dest_small)dest_small[&quot;srch_destination_id&quot;] = destinations[&quot;srch_destination_id&quot;]# 解释 取d1-d149字段print([&quot;d&#123;0&#125;&quot;.format(i + 1) for i in range(149)])[&apos;d1&apos;, &apos;d2&apos;, &apos;d3&apos;, &apos;d4&apos;, &apos;d5&apos;, &apos;d6&apos;, &apos;d7&apos;, &apos;d8&apos;, &apos;d9&apos;, &apos;d10&apos;, &apos;d11&apos;, &apos;d12&apos;, &apos;d13&apos;, &apos;d14&apos;, &apos;d15&apos;, &apos;d16&apos;, &apos;d17&apos;, &apos;d18&apos;, &apos;d19&apos;, &apos;d20&apos;, &apos;d21&apos;, &apos;d22&apos;, &apos;d23&apos;, &apos;d24&apos;, &apos;d25&apos;, &apos;d26&apos;, &apos;d27&apos;, &apos;d28&apos;, &apos;d29&apos;, &apos;d30&apos;, &apos;d31&apos;, &apos;d32&apos;, &apos;d33&apos;, &apos;d34&apos;, &apos;d35&apos;, &apos;d36&apos;, &apos;d37&apos;, &apos;d38&apos;, &apos;d39&apos;, &apos;d40&apos;, &apos;d41&apos;, &apos;d42&apos;, &apos;d43&apos;, &apos;d44&apos;, &apos;d45&apos;, &apos;d46&apos;, &apos;d47&apos;, &apos;d48&apos;, &apos;d49&apos;, &apos;d50&apos;, &apos;d51&apos;, &apos;d52&apos;, &apos;d53&apos;, &apos;d54&apos;, &apos;d55&apos;, &apos;d56&apos;, &apos;d57&apos;, &apos;d58&apos;, &apos;d59&apos;, &apos;d60&apos;, &apos;d61&apos;, &apos;d62&apos;, &apos;d63&apos;, &apos;d64&apos;, &apos;d65&apos;, &apos;d66&apos;, &apos;d67&apos;, &apos;d68&apos;, &apos;d69&apos;, &apos;d70&apos;, &apos;d71&apos;, &apos;d72&apos;, &apos;d73&apos;, &apos;d74&apos;, &apos;d75&apos;, &apos;d76&apos;, &apos;d77&apos;, &apos;d78&apos;, &apos;d79&apos;, &apos;d80&apos;, &apos;d81&apos;, &apos;d82&apos;, &apos;d83&apos;, &apos;d84&apos;, &apos;d85&apos;, &apos;d86&apos;, &apos;d87&apos;, &apos;d88&apos;, &apos;d89&apos;, &apos;d90&apos;, &apos;d91&apos;, &apos;d92&apos;, &apos;d93&apos;, &apos;d94&apos;, &apos;d95&apos;, &apos;d96&apos;, &apos;d97&apos;, &apos;d98&apos;, &apos;d99&apos;, &apos;d100&apos;, &apos;d101&apos;, &apos;d102&apos;, &apos;d103&apos;, &apos;d104&apos;, &apos;d105&apos;, &apos;d106&apos;, &apos;d107&apos;, &apos;d108&apos;, &apos;d109&apos;, &apos;d110&apos;, &apos;d111&apos;, &apos;d112&apos;, &apos;d113&apos;, &apos;d114&apos;, &apos;d115&apos;, &apos;d116&apos;, &apos;d117&apos;, &apos;d118&apos;, &apos;d119&apos;, &apos;d120&apos;, &apos;d121&apos;, &apos;d122&apos;, &apos;d123&apos;, &apos;d124&apos;, &apos;d125&apos;, &apos;d126&apos;, &apos;d127&apos;, &apos;d128&apos;, &apos;d129&apos;, &apos;d130&apos;, &apos;d131&apos;, &apos;d132&apos;, &apos;d133&apos;, &apos;d134&apos;, &apos;d135&apos;, &apos;d136&apos;, &apos;d137&apos;, &apos;d138&apos;, &apos;d139&apos;, &apos;d140&apos;, &apos;d141&apos;, &apos;d142&apos;, &apos;d143&apos;, &apos;d144&apos;, &apos;d145&apos;, &apos;d146&apos;, &apos;d147&apos;, &apos;d148&apos;, &apos;d149&apos;] 生成其他特征 12345678910111213141516171819202122232425262728def calc_fast_features(df): df[&quot;date_time&quot;] = pd.to_datetime(df[&quot;date_time&quot;]) df[&quot;srch_ci&quot;] = pd.to_datetime(df[&quot;srch_ci&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) # 参数errors=&quot;coerce&quot; 遇到错误可以赋值为空。 df[&quot;srch_co&quot;] = pd.to_datetime(df[&quot;srch_co&quot;], format=&apos;%Y-%m-%d&apos;, errors=&quot;coerce&quot;) props = &#123;&#125; for prop in [&quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;minute&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;]: props[prop] = getattr(df[&quot;date_time&quot;].dt, prop) carryover = [p for p in df.columns if p not in [&quot;date_time&quot;, &quot;srch_ci&quot;, &quot;srch_co&quot;]] for prop in carryover: props[prop] = df[prop] date_props = [&quot;month&quot;, &quot;day&quot;, &quot;dayofweek&quot;, &quot;quarter&quot;] for prop in date_props: props[&quot;ci_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_ci&quot;].dt, prop) props[&quot;co_&#123;0&#125;&quot;.format(prop)] = getattr(df[&quot;srch_co&quot;].dt, prop) props[&quot;stay_span&quot;] = (df[&quot;srch_co&quot;] - df[&quot;srch_ci&quot;]).astype(&apos;timedelta64[h]&apos;) ret = pd.DataFrame(props) ret = ret.join(dest_small, on=&quot;srch_destination_id&quot;, how=&apos;left&apos;, rsuffix=&quot;dest&quot;) ret = ret.drop(&quot;srch_destination_iddest&quot;, axis=1) return retdf = calc_fast_features(t1)df.fillna(-1, inplace=True) 123456789101112131415161718192021新的列:[ &apos;channel&apos;, &apos;ci_day&apos;, &apos;ci_dayofweek&apos;, &apos;ci_month&apos;, &apos;ci_quarter&apos;, &apos;cnt&apos;, &apos;co_day&apos;, &apos;co_dayofweek&apos;, &apos;co_month&apos;, &apos;co_quarter&apos;, &apos;day&apos;, &apos;dayofweek&apos;, &apos;hotel_cluster&apos;, &apos;hotel_continent&apos;, &apos;hotel_country&apos;, &apos;hotel_market&apos;, &apos;hour&apos;, &apos;is_booking&apos;, &apos;is_mobile&apos;, &apos;is_package&apos;, &apos;minute&apos;, &apos;month&apos;, &apos;orig_destination_distance&apos;, &apos;posa_continent&apos;, &apos;quarter&apos;, &apos;site_name&apos;, &apos;srch_adults_cnt&apos;, &apos;srch_children_cnt&apos;, &apos;srch_destination_id&apos;, &apos;srch_destination_type_id&apos;, &apos;srch_rm_cnt&apos;, &apos;stay_span&apos;, &apos;user_id&apos;, &apos;user_location_city&apos;, &apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;year&apos;, 0, 1, 2] + 机器学习 * 随机森林 1234567predictors = [c for c in df.columns if c not in [&quot;hotel_cluster&quot;]]from sklearn import cross_validationfrom sklearn.ensemble import RandomForestClassifierclf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1)scores = cross_validation.cross_val_score(clf, df[predictors], df[&apos;hotel_cluster&apos;], cv=3)scores * 二分分类 123456789101112131415161718192021222324252627282930313233from sklearn.ensemble import RandomForestClassifierfrom sklearn.cross_validation import KFoldfrom itertools import chainall_probs = []unique_clusters = df[&quot;hotel_cluster&quot;].unique()for cluster in unique_clusters: df[&quot;target&quot;] = 1 df[&quot;target&quot;][df[&quot;hotel_cluster&quot;] != cluster] = 0 predictors = [col for col in df if col not in [&apos;hotel_cluster&apos;, &quot;target&quot;]] probs = [] cv = KFold(len(df[&quot;target&quot;]), n_folds=2) # 交叉验证(CrossValidation) # 方法思想是为了在不动用测试集之前，就评估一下模型是否过于复杂而引起过度拟合 clf = RandomForestClassifier(n_estimators=10, min_weight_fraction_leaf=0.1) for i, (tr, te) in enumerate(cv): # 不是很理解 上面一句 clf.fit(df[predictors].iloc[tr], df[&quot;target&quot;].iloc[tr]) preds = clf.predict_proba(df[predictors].iloc[te]) probs.append([p[1] for p in preds]) full_probs = chain.from_iterable(probs) all_probs.append(list(full_probs))prediction_frame = pd.DataFrame(all_probs).Tprediction_frame.columns = unique_clustersdef find_top_5(row): return list(row.nlargest(5).index)preds = []for index, row in prediction_frame.iterrows(): preds.append(find_top_5(row))metrics.mapk([[l] for l in t2.iloc[&quot;hotel_cluster&quot;]], preds, k=5) 在目的地下的最受欢迎的酒店选择 123456789101112131415161718192021222324252627def make_key(items): return &quot;_&quot;.join([str(i) for i in items])match_cols = [&quot;srch_destination_id&quot;]cluster_cols = match_cols + [&apos;hotel_cluster&apos;]groups = t1.groupby(cluster_cols)top_clusters = &#123;&#125;for name, group in groups: clicks = len(group.is_booking[group.is_booking == False]) bookings = len(group.is_booking[group.is_booking == True]) score = bookings + .15 * clicks clus_name = make_key(name[:len(match_cols)]) if clus_name not in top_clusters: top_clusters[clus_name] = &#123;&#125; top_clusters[clus_name][name[-1]] = scoreimport operatorcluster_dict = &#123;&#125;for n in top_clusters: tc = top_clusters[n] top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]] cluster_dict[n] = top 给予目的地,进行预测 1234567preds = []for index, row in t2.iterrows(): key = make_key([row[m] for m in match_cols]) if key in cluster_dict: preds.append(cluster_dict[key]) else: preds.append([]) 评估错误 1metrics.mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], preds, k=5) 更好的结果 根据用户 12345678910111213141516match_cols = [&apos;user_location_country&apos;, &apos;user_location_region&apos;, &apos;user_location_city&apos;, &apos;hotel_market&apos;, &apos;orig_destination_distance&apos;]groups = t1.groupby(match_cols) def generate_exact_matches(row, match_cols): index = tuple([row[t] for t in match_cols]) try: group = groups.get_group(index) except Exception: return [] clus = list(set(group.hotel_cluster)) return clusexact_matches = []for i in range(t2.shape[0]): exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols)) 合并预测 1234567891011121314def f5(seq, idfun=None): if idfun is None: def idfun(x): return x seen = &#123;&#125; result = [] for item in seq: marker = idfun(item) if marker in seen: continue seen[marker] = 1 result.append(item) return result full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]mapk([[l] for l in t2[&quot;hotel_cluster&quot;]], full_preds, k=5) 生成提交文件 12345write_p = [&quot; &quot;.join([str(l) for l in p]) for p in full_preds]write_frame = [&quot;&#123;0&#125;,&#123;1&#125;&quot;.format(t2[&quot;id&quot;][i], write_p[i]) for i in range(len(full_preds))]write_frame = [&quot;id,hotel_clusters&quot;] + write_framewith open(&quot;predictions.csv&quot;, &quot;w+&quot;) as f: f.write(&quot;\n&quot;.join(write_frame)) 总结 下一步]]></content>
      <categories>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>kaggle</tag>
        <tag>随机森林</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac_Chrome浏览器下载csv.gz后缀时遇到的问题]]></title>
    <url>%2F2017%2F12%2F04%2Fegenie_bugfix%2Ferror-download-gz%2F</url>
    <content type="text"><![CDATA[问题描述: 下载一个应该为csv.gz后缀名的问题,不知道为什么没有了后缀名,一开始以为是字符集问题 下载的是kaggle的data数据https://www.kaggle.com/c/expedia-hotel-recommendations/data 报错错误 问了小伙伴,解压后的文件应该有几个g,不应该几百兆,因此推断是后缀名问题 解决http://pic.victor123.cn/17-12-4/7396408.jpg 知识小结123456789101112131415.tar 解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）———————————————.gz解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName.tar.gz 和 .tgz解压：tar zxvf FileName.tar.gz压缩：tar zcvf FileName.tar.gz DirName———————————————]]></content>
      <categories>
        <category>问题解决</category>
      </categories>
      <tags>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化idea插件安装]]></title>
    <url>%2F2017%2F12%2F01%2Ftools%2Fidea-plugins-install%2F</url>
    <content type="text"><![CDATA[常常遇到从idea程序中搜索插件，下载超时的情况,解决方式如下1.直接在官网下载并进行安装,然后Install from diskhttps://plugins.jetbrains.com/search?correctionAllowed=true&amp;pr=idea&amp;orderBy=&amp;search= 2.使用ss作代理，直接下载]]></content>
      <categories>
        <category>idea</category>
      </categories>
      <tags>
        <tag>代理</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next主题保存]]></title>
    <url>%2F2017%2F11%2F30%2Fegenie_bugfix%2Ferror-next-submodule%2F</url>
    <content type="text"><![CDATA[通过git的submodule功能对博客内容和主题分别进行版本控制方案https://stackoverflow.com/questions/12898278/issue-with-adding-common-code-as-git-submodule-already-exists-in-the-index 12345678git ls-files --stagegit rm --cached themes/nextgit submodule add git@github.com:victorsheng/hexo-theme-next.git themes/nextgit add .gitmodules .gitmodulesn内容如下：[submodule “themes/next”] path = themes/next url = git@github.com:victorsheng/hexo-theme-next.git]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>git</tag>
        <tag>submodule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac安装seaborn遇到的问题]]></title>
    <url>%2F2017%2F11%2F30%2Fegenie_business%2Ferror-pip-install-seaborn%2F</url>
    <content type="text"><![CDATA[异常信息12345678910111213141516171819202122232425262728293031323334353637pip install numpyMacBook-Pro:~ victor$ pip install seabornCollecting seaborn Downloading seaborn-0.8.1.tar.gz (178kB) 100% |████████████████████████████████| 184kB 666kB/sCollecting pandas (from seaborn) Using cached pandas-0.21.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Collecting numpy&gt;=1.9.0 (from pandas-&gt;seaborn) Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlRequirement already satisfied: pytz&gt;=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas-&gt;seaborn)Installing collected packages: numpy, pandas, seaborn Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-gOIIvZ-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos; 发现卸载这个numpy都不行1234567891011121314151617181920212223242526sudo -H pip uninstall numpyDEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.Uninstalling numpy-1.8.0rc1: /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-infoProceed (y/n)? yException:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/uninstall.py&quot;, line 76, in run requirement_set.uninstall(auto_confirm=options.yes) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 346, in uninstall req.uninstall(auto_confirm=auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/tmp/pip-Ez2DTF-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info 解决方案https://blog.wizchen.com/2016/06/17/Mac%E4%B8%8B%E6%9B%B4%E6%96%B0python%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93numpy/ 说是System Integrity Protection的问题，解决的办法是关闭SIP: 重启电脑，电脑启动的时候安住 command + R 等画面上出现 apple logo 的，你会看到 OS X 工具程式的窗口，选择终端，等待终端打开，直接输入csrutil disable，回车后重启即可 重启完毕后，再次在终端输入 最后成功1234567891011121314151617181920212223242526272829303132333435363738pip install -U numpyCollecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/var/folders/sk/hl26sn7n1pg9jrzgzqydvfq00000gn/T/pip-rfPgIG-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos;shengsiyudeMacBook-Pro:~ victor$ sudo -H pip install -U numpyPassword:Collecting numpy Using cached numpy-1.13.3-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whlInstalling collected packages: numpy Found existing installation: numpy 1.8.0rc1 DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling numpy-1.8.0rc1: Successfully uninstalled numpy-1.8.0rc1Successfully installed numpy-1.13.3]]></content>
      <categories>
        <category>异常</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mac</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术搜索技巧]]></title>
    <url>%2F2017%2F11%2F28%2Fcommon_tools%2Fcode-blog-website%2F</url>
    <content type="text"><![CDATA[结合搜索引擎语法 site:功能,可以高效的搜索出常见的技术类问题的解决方案常见的网址如下: 国内 博客园 cnblogs.com CSDN csdn.net 开源中国 oschina.net 简书 jianshu.com SegmentFault segmentfault.com 掘金 juejin.im 国外 stackoverflow Github GithubPage 知识分享 知乎 quora 而对于相对专业的技能 api文档 和官方文档]]></content>
      <categories>
        <category>搜索技巧</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据展现技术选型]]></title>
    <url>%2F2017%2F11%2F28%2Fdata_warehouse%2FBI-show-tool%2F</url>
    <content type="text"><![CDATA[数据展现技术选型 阿里云Quick Bi(试用过30天)Quick BI 是一个基于云计算的灵活的轻量级的自助 BI 工具服务平台。 Quick BI 支持众多种类的数据源，既可以连接 MaxCompute（ODPS）、RDS、Analytic DB、HybridDB（Greenplum）等云数据源，也支持连接 ECS 上您自有的 MySQL 数据库，还支持上传本地文件到 Quick BI 内置的探索空间进行分析。 Tableauhttps://www.tableau.com/ From GitHubSuperset Superset 是 Airbnb （知名在线房屋短租公司）开源的数据探查与可视化平台（曾用名Panoramix、Caravel），该工具在可视化、易用性和交互性上非常有特色，用户可以轻松对数据进行可视化分析。 https://github.com/apache/incubator-superset Saiku https://github.com/OSBI/saiku 另外一些是没有实际调研过的一些工具 QlikviewFineBIBDP商业数据平台永洪]]></content>
      <categories>
        <category>BI</category>
      </categories>
      <tags>
        <tag>BI</tag>
        <tag>数据展示</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习分型]]></title>
    <url>%2F2017%2F11%2F27%2Fdocker%2Fshare-docker%2F</url>
    <content type="text"><![CDATA[简介 Docker 是个划时代的开源项目，它彻底释放了计算虚拟化的威力，极大提高了应用的运行效率，降低了云计算资源供应的成本！使用 Docker，可以让应用的部署、测试和分发都变得前所未有的高效和轻松！ 无论是应用开发者、运维人员、还是其他信息技术从业人员，都有必要认识和掌握 Docker，节约有限的时间。 docker的由来 Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎，由 Go 语言编写的，源代码托管在 github 而且居然只有 1W 行就完成了这些功能。 Docker自2013年以来非常火热，无论是从 github 上的代码活跃度，还是Redhat在RHEL6.5中集成对Docker的支持, 就连 Google 的 Compute Engine 也支持 docker 在其之上运行。 Docker设想是交付运行环境如同海运，OS如同一个货轮，每一个在OS基础上的软件都如同一个集装箱，用户可以通过标准化手段自由组装运行环境，同时集装箱的内容可以由用户自定义，也可以由专业人员制造。这样，交付一个软件，就是一系列标准化组件的集合的交付，如同乐高积木，用户只需要选择合适的积木组合，并且在最顶端署上自己的名字(最后个标准化组件是用户的app)。这也就是基于docker的PaaS产品的原型。 为什么要使用 Docker？ 更高效的利用系统资源 更快速的启动时间 一致的运行环境 持续交付和部署 更轻松的迁移 更轻松的维护和扩展 基本概念 镜像（Image） Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container） 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 仓库（Repository） 一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。 基本命令 docker run busybox echo “hello world” docker ps 官方仓库https://store.docker.com/ mac版本图形化客户端:kitematicKitematic 完全自动化了 Docker 安装和设置过程，并提供了一个直观的图形用户接口（GUI）来在 Mac 上运行 Docker。Kitematic 集成了 Docker Machine 来在 Mac 上分发一个虚拟机并安装 Docker 引擎。 一旦安装成功，Kitematic GUI 便会启动，紧接着你可以立刻运行控制台中的镜像。你仅仅只需要在 Kitematic 搜索框键入镜像名就可以搜索任何在 Docker Hub 上存在的镜像。通过 GUI 你可以非常容易的创建、运行和管理你的容器，不需要使用命令行或者是在 Docker CLI 和 GUI之间来回切换。 Kitematic 也让Docker的一些高级特性使用更加方便，比如管理端口和配置 volumes。你可以方便的修改环境变量、查看日志，单机终端就可以进入容器，这些特性GUI都支持。dockerfileDockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。例如:https://hub.docker.com/r/haocen/docker-hexo-with-hexo-admin/ 进阶数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性: 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 网络管理Docker启动时，会自动在主机上创建一个docker0虚拟网桥，实际上是Linux的一个bridge,可以理解为一个软件交换机，它会而挂载到它的网口之间进行转发 当创建一个Docker容器的时候，同理会创建一对veth pair接口(当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包)，这对接口一端在容器内，即eth0;另一端在本地并被挂载到docker0网桥，名称以veth开头。 容器安全 内核命名空间 控制组控制组是 Linux 容器机制的另外一个关键组件，负责实现资源的审计和限制。它提供了很多有用的特性；以及确保各个容器可以公平地分享主机的内存、CPU、磁盘 IO 等资源；当然，更重要的是，控制组确保了当容器内的资源使用产生压力时不会连累主机系统。 内核能力机制12345678910大部分情况下，容器并不需要“真正的” root 权限，容器只需要少数的能力即可。为了加强安全，容器可以禁用一些没必要的权限。 完全禁止任何 mount 操作； 禁止直接访问本地主机的套接字； 禁止访问一些文件系统的操作，比如创建新的设备、修改文件属性等； 禁止模块加载。这样，就算攻击者在容器中取得了 root 权限，也不能获得本地主机的较高权限，能进行的破坏也有限。默认情况下，Docker采用白名单机制，禁用必需功能之外的其它权限。 当然，用户也可以根据自身需求来为 Docker 容器启用额外的权限。 容器编排编排是一个新的词汇，指的是容器的集群化和调度。另一类含义指的是容器管理，负责管理容器化应用和组件任务。 &lt;img src=&quot;http://pic.victor123.cn/17-11-29/58239834.jpg&quot;&gt; Docker Swarm、Kubernetes、Marathon和Nomad 快速安装docker12345678910useradd appusrpasswd appusrgroupadd dockerusermod -aG docker appusryum install epel-release –yyum install docker-io –ysystemctl start dockersystemctl enable docker 使用案例本地的nginx12345678910111213141516171819202122232425262728293031323334353637383940docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -v $PWD/logs:/etc/nginx/logs -d nginxnginx配置文件:server &#123; listen 80 default_server; location /api/iac &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.222:9060; &#125; location /api/bi &#123; add_header &apos;Access-Control-Allow-Origin&apos; &quot;*&quot;; add_header &apos;Access-Control-Allow-Credentials&apos; true; proxy_pass http://192.168.0.106:9991; &#125; location = / &#123; proxy_connect_timeout 1800; proxy_read_timeout 1800; proxy_send_timeout 1800; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location / &#123; proxy_pass http://192.168.0.106:8099; &#125; location /page &#123; proxy_pass http://192.168.0.106:8888; &#125; location /static &#123; proxy_pass http://192.168.0.106:8888; &#125; location /main &#123; proxy_pass http://192.168.0.106:8888/page/index.html; &#125; location /login&#123; proxy_pass http://192.168.0.106:8888/page/login/index.html; &#125;&#125; 用docker安装mysql数据库准备工作123456789101112yum install gitmkdir /dockerchown -R appusr /dockersudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://cz3my8je.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 启动12345678910要复制conf到制定目录下docker run -p 3306:3306 --name mymysql -v /docker/mysql/conf/my.cnf:/etc/mysql/my.cnf -v /docker/mysql/logs:/logs -v /docker/mysql/data:/mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6docker ps -adocker run -it --link mymysql:mysql --rm mysql sh -c &apos;exec mysql -h 172.18.0.1 -P 3306 -u root -p123456&apos;CREATE USER &apos;pig&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;GRANT ALL ON *.* TO &apos;pig&apos;@&apos;%&apos;; 附录10张图带你深入理解Docker容器和镜像http://dockone.io/article/783 菜鸟网 http://www.runoob.com/docker/docker-hello-world.html Docker 安装 Nginx Docker 安装 PHP Docker 安装 MySQL Docker 安装 Tomcat Docker 安装 Python Docker 安装 Redis Docker 安装 MongoDB Docker 安装 Apache 学习资料 https://joshhu.gitbooks.io/docker_theory_install/content/ https://docs.docker.com/ https://yeasy.gitbooks.io/docker_practice/content/introduction/why.html]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>技术分享</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能采购实现逻辑梳理]]></title>
    <url>%2F2017%2F11%2F27%2Fegenie_business%2Fcode-samrtPurchase%2F</url>
    <content type="text"><![CDATA[智能采购实现逻辑梳理销量部分计算(一天执行一次) 刷新1天,7天,30天,自定义天销量方法 排除掉不采购仓库的销量 排除掉备货仓的销量 分批进行持久化 触发一次采购部分计算 采购部分计算(定时半个小时执行一次) 获取界面上手动覆盖的参数 如果有批量修改勾选的ids则至处理这部分智能采购记录,否则查询全部智能采购记录 如果修改了上限和下限库存,则县持久化 填充库存 本仓库库存+本仓库的备货仓的库粗查询 计算存货天数 取采购周期,供货商 1234567* 根据excel公式,计算备货的字段* 日均销量=7天销量/7* 最低库存=日均销量*备货天数* 上限库存=日均销量*(备货天数+采购周期)* 存货预警库存=在途库存-最低库存 P.S.小于0的需要采购* 建议采购数量=上限采购数量-在途库存*/ 查询参数 强制覆盖采购周期和存货天数 计算上限和下限库存 Double minStock = avgSaleVolume * inventoryDays; Double maxStock = avgSaleVolume * (inventoryDays + procurementCycle); 强制覆盖上限和下限库存 如果开启智能计算跳过此步骤 查询SaleStockSetting表中记录的上限和线下库存,别设置isManual=true 计算预警库存和建议采购量 Integer saleStock = v.getSaleStock(); Integer onWayStock = v.getOnWayStock(); int stock = saleStock + onWayStock; double warningStock = stock - minStock; 如果预警库存&lt;0,double originAdviceNum = maxStock - stock,并向上取整 如果预警库存&gt;=0,不进行建议 强制覆盖最总结果 对verifyNum进行赋值 强制覆盖verifyNum 持久化更新]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数学习]]></title>
    <url>%2F2017%2F11%2F24%2Fmath%2Fmath-linear-algebra%2F</url>
    <content type="text"><![CDATA[推荐一(博客)http://www.hahack.com/wiki/math-linear-algebra.html 矩阵 基本运算 加 减 乘 求逆 矩阵的转职 应用举例 求解方程组 求向量组合 向量 基本运算 加 减 乘 标量乘向量 向量点积 向量外积 矩阵向量积 向量的转置 线性无关 张成空间 线性相关和线性无关 判断是否线性相关 张量 线性代数进阶 阶梯形矩阵 阶梯形矩阵 行简化阶梯形矩阵 行最简形矩阵 将矩阵化简成行最简阶梯形 线性子空间 零空间 列空间 行空间 左零空间 子空间的正交补 最小二乘逼近 实例1：求解方程 实例2：线性回归 特征向量 求解特征值 求解特征向量 推荐二 http://space.bilibili.com/88461692#!/ 线性代数的本质 http://space.bilibili.com/88461692#!/channel/detail?cid=9450 一天就看了好几集,让我对数学又重新产生了兴趣, 对此,本篇的目的旨在记录这两天所学到的内容: 线性代数的本质01向量究竟是什么 向量是函数 向量是一条记录(多个观察值) 向量是物理运动 02线性组合、张成的空间03矩阵与线性变换 矩阵向量乘法是一种线性变化,第一列是i帽移动的,第二列是j帽移动的位置 其中,2X2矩阵就是二维线性变换 04矩阵乘法与线性变换复合 矩阵的乘法就是两个线性变化的相继结果 从右往左读 先是e,g向量,线性变化,chengwei ae+bg,ce+dg,如图 矩阵的乘法没有交换律,有结合律 04三维空间中的线性05行列式(线性变化的行列式) 行列式= 二位线性变化所对应的面积缩放比例,三维实体积 行列式结果=1,代表面积没有变化 行列式结果=6,代表面积乘以6 行列式结果=0,代表在降维了 行列式结果为负数,代表空间反面了 结算公式:ad-bc det(矩阵)=行列式 06逆矩阵、列空间与零空 求解线性方程组 行列式不为0时:线性变化*逆向线性变化=什么都不做(1) 行列式为0时:无法求逆 秩:变化后的空间维数 3*3矩阵的最大秩:为3,否则就意味着被压缩了 矩阵的列空间:所有可能的输出向量构成的集合(列张成的空间=列空间) 整个线被压缩:降1维(零空间) 整个平面被压缩:降2维(零空间) 06补充说明:非方阵07点积与对偶性 向量的点成:一个向量*另一个向量在该向量上的投影 矩阵和向量之间的联系 转换*向量 矩阵向量乘积 类似 向量的点积 08第一部分:叉积的标准介绍08第二部分:以线性变化的眼光看叉积09基变换10特征向量与特征值11抽象向量空间]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺货销售订单生成采购单逻辑梳理]]></title>
    <url>%2F2017%2F11%2F21%2Fegenie_business%2Fcode-saleGeneratePurchaseOrder%2F</url>
    <content type="text"><![CDATA[缺货销售订单生成采购单逻辑梳理入口: 采购单界面,一键生成采购单 订单处理界面 勾选制定订单,生成采购单 按照查询条件,生成采购单 实现逻辑: 查询基档案warehouse 是否需要采购,以及换货仓 查询之前的组号映射关系 未关闭的采购单 到货状态的唯一码 更新之前组的到货数量 查询总的缺货销售订单数 分页生成采购单,默认5000单一组 分页查询缺货销售订单 根据系统参数 过滤掉申请退款的明细 复制订单和订单明细,到新的数据结构(VSaleOrder,VSaleOrderDetail)–&gt;(PmsDailyPurchase,PmsDailyPurchaseDetail) 过滤采购完成 过滤无需采购 绝对唯一码规则.一条明细生成多个唯一码 根据三级明细分配采购单号 将未分拣墙上的设置到制定A组中 单件不进分组 相同订单的,使用上次的组号,同一订单组号继续使用 大单量分组 普通分组,并且分组下的订单数没有超过计划的订单数量 使用已有的分组(按A-Z的优先顺序) 创建新的分组 合并最后一个分组信息 回写新增的组至totalGroupMap(内存级别) 批量填充唯一码 生成36进制的唯一码 唯一码规则:租户内唯一 唯一码规则:9位唯一码 sku的唯一码,以1开头 (前绑定)根据采购单数,绑定订单和唯一码 (后绑定)先尝试使用为分拣墙上的sku,此部分无需采购,更新updateNum为-1 持久化PmsPurchaseOrder 汇总三级明细,生成二级明细 次品仓业务(原采购单有相同sku的,用次品仓的货物换;没有的,增加采购数量) 根据skuIds,查询换货仓的库存 原采购数量&lt;换货仓库存,新采购数量=换货仓数量 原采购数量&gt;=换货仓数量,新采购数量=原采购数量 自动生成次品仓盘点单 填充供货信息VendorSupply 根据skuIds查询默认供应商 设置采购周期和到货时间 设置最小采购数量 设置采购供应商 设置采购价格 优先价格体系 设置采购人(PDA推送的依据) 查询不到的取sku得采购信息,取sku得采购信息 设置采购周期和到货时间 设置最小采购数量 设置采购价格 反写采购单明细的信息到拿货明细 二级明细业务处理: update 和 insert的 持久化二级明细 回写二级明细id到二点五级明细和三级明细 移除掉不需要采购的采购单明细,和拿货订单明细,二级和三级需要同时移除 规则一:供应商无需采购(之所以再次移除,是因为此处采购供应商) 规则二:几天后到货的(目前已废弃) 如果所有明细都移除了,则无需持久化采购单主表 持久化(update 和 insert)订单主表 持久化PmsDailyPurchase,PmsDailyPurchaseDetail 返回生成采购单报告]]></content>
      <categories>
        <category>业务梳理</category>
      </categories>
      <tags>
        <tag>采购</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的武器库]]></title>
    <url>%2F2017%2F11%2F21%2F%E6%88%91%E7%9A%84%E6%AD%A6%E5%99%A8%E5%BA%93%2F</url>
    <content type="text"><![CDATA[搜索引擎我掌握的语言 java sql python 技术框架持续使用的githubmac常用软件 Sublime DateGrip IntliJ IDEA WebStorm SourceTree Jprofiler MAT Beyound Compare PlantUML ShadowSocks_NG Postman 命令常用软件 brew docker 文本处理器 vim Pandoc markdown]]></content>
      <categories>
        <category>技术栈</category>
      </categories>
      <tags>
        <tag>我的</tag>
      </tags>
  </entry>
</search>
